experName ....  24.4.2-0050-sciemd-size_100-test2
Processing index 1794...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exists an interdisciplinary multidimensional gradation on published studies of neocortex, with one primary dimension of mathematical physics represented by two extremes. At one extreme, there is much scientifically unsupported talk of chaos and quantum physics being responsible for many important macroscopic neocortical processes (involving many thousands to millions of neurons) (Wilczek, 1994). At another extreme, many non-mathematically trained neuroscientists uncritically lump all neocortical mathematical theory into one file, and consider only statistical averages of citations for opinions on the quality of that research (Nunez, 1995). In this context, it is important to appreciate that Wright and Liley (W&L) report on their scientifically sound studies on macroscopic neocortical function, based on simulation and a blend of sound theory and reproducible experiments. However, their pioneering work, given the absence of much knowledge of neocortex at this time, is open to criticism, especially with respect to their present inferences and conclusions. Their conclusion that EEG data exhibit linear near-equilibrium dynamics may very well be true, but only in the sense of focusing only on one local minima, possibly with individual-specific and physiological-state dependent 
Title: Title: NONLINEAR NONEQUILIBRIUM NONQUANTUM NONCHAOTIC STATISTICAL MECHANICS OF NEOCORTICAL INTERACTIONS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems  
Abstract: The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exis
Paper 3  Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of
Abstract: The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exis
Label: Neural Networks
Paper 4  Title: Replicability of Neural Computing Experiments  
Abstract: If an experiment requires statistical analysis to establish a result, then one should do a better experiment. Ernest Rutherford, 1930 Most proponents of cold fusion reporting excess heat from their electrolysis experiments were claiming that one of the main characteristics of cold fusion was its irreproducibility | J.R. Huizenga, Cold Fusion, 1993, p. 78 Abstract Amid the ever increasing
Label: Neural Networks
Paper 5  Title: MULTIPLE SCALES OF BRAIN-MIND INTERACTIONS  
Abstract: Posner and Raichle's Images of Mind is an excellent educational book and very well written. Some aws as a scientific publication are: (a) the accuracy of the linear subtraction method used in PET is subject to scrutiny by further research at finer spatial-temporal resolutions; (b) lack of accuracy of the experimental paradigm used for EEG complementary studies. Images (Posner & Raichle, 
Paper 6  Title: Statistical mechanics of neocortical interactions: Training and testing canonical momenta indicators of EEG  
Abstract: A series of papers has developed a statistical mechanics of neocortical interactions (SMNI), deriving aggregate behavior of experimentally observed columns of neurons from statistical electrical-chemical properties of synaptic interactions. While not useful to yield insights at the single neuron level, SMNI has demonstrated its capability in describing large-scale properties of short-ter
Label: Neural Networks
Paper 7  Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  
Abstract: Neural computation, also called connectionism, parallel distributed processing, neural network modeling or brain-style computation, has grown rapidly in the last decade. Despite this explosion, and ultimately because of impressive applications, there has been a dire need for a concise introduction from a theoretical perspective, analyzing the strengths and weaknesses of connectionist app
Paper 8  Title: Studies of Neurological Transmission Analysis using Hierarchical Bayesian Mixture Models  
Abstract: Hierarchically structured mixture models are studied in the context of data analysis and inference on neural synaptic transmission characteristics in mammalian, and other, central nervous systems. Mixture structures arise due to uncertainties about the stochastic mechanisms governing the responses to electro-chemical stimulation of individual neuro-transmitter release sites at nerve junc
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 455...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A learning agent employing reinforcement learning is hindered because it only receives the critic's sparse and weakly informative training information. We present an approach in which an automated training agent may also provide occasional instruction to the learner in the form of actions for the learner to perform. The learner has access to both the critic's feedback and the trainer's instruction. In the experiments, we vary the level of the trainer's interaction with the learner, from allowing the trainer to instruct the learner at almost every time step, to not allowing the trainer to respond at all. We also vary a parameter that controls how the learner incorporates the trainer's actions. The results show significant reductions in the average number of training trials necessary to learn to perform the task.
Title: Title: Learning from an Automated Training Agent  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Introspection Approach to Querying a Trainer  
Abstract: Technical Report 96-13 January 22, 1996 Abstract This paper introduces the Introspection Approach, a method by which a learning agent employing reinforcement learning can decide when to ask a training agent for instruction. When using our approach, we find that the same number of trainer's responses produced significantly faster learners than by having the learner ask for aid randomly. G
Paper 3  Title: Modeling the Student with Reinforcement Learning  
Abstract: We describe a methodology for enabling an intelligent teaching system to make high level strategy decisions on the basis of low level student modeling information. This framework is less costly to construct, and superior to hand coding teaching strategies as it is more responsive to the learner's needs. In order to accomplish this, reinforcement learning is used to learn to associate sup
Paper 4  Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  
Abstract: The application of decision making and learning algorithms to multi-agent systems presents many interestingresearch challenges and opportunities. Among these is the ability for agents to learn how to act by observing or imitating other agents. We describe an algorithm, the IQ-algorithm, that integrates imitation with Q-learning. Roughly, a Q-learner uses the observations it has made of a
Paper 5  Title: Machine Learning,  Creating Advice-Taking Reinforcement Learners  
Abstract: Learning from reinforcements is a promising approach for creating intelligent agents. However, reinforcement learning usually requires a large number of training episodes. We present and evaluate a design that addresses this shortcoming by allowing a connectionist Q-learner to accept advice given, at any time and in a natural manner, by an external observer. In our approach, the advice-g
Paper 6  Title: Improving Generalization with Active Learning  
Abstract: Active learning differs from passive "learning from examples" in that the learning algorithm assumes at least some control over what part of the input domain it receives information about. In some situations, active learning is provably more powerful that learning from examples alone, giving better generalization for a fixed number of training examples. In this paper, we consider the pro
Paper 7  Title: Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email  
Abstract: This paper describes a novel method by which a dialogue agent can learn to choose an optimal dialogue strategy. While it is widely agreed that dialogue strategies should be formulated in terms of communicative intentions, there has been little work on automatically optimizing an agent's choices when there are multiple ways to realize a communicative intention. Our method is based on a co
Label: Reinforcement Learning
Paper 8  Title: Learning to Predict User Operations for Adaptive Scheduling  
Abstract: Mixed-initiative systems present the challenge of finding an effective level of interaction between humans and computers. Machine learning presents a promising approach to this problem in the form of systems that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive assistant for crisis sched
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 1759...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these features a reduced ring representation (RRR) of the local environment is derived. As the robot navigates, it learns the RRR signatures of all the new environment types it encounters. For purpose of identification, a ring matching criteria is proposed where the robot tries to match the RRR from the sensory input to one of the RRRs in its library. The second issue addressed is that of learning hill climbing control laws in the local environments. Unlike conventional neuro-controllers, a reinforcement learning framework, where the robot first learns a model of the environment and then learns the control law in terms of a neural network is proposed here. The reinforcement function is generated from the sensory inputs of the robot before and after a control action is taken. Three key results shown in this work are that (1) The robot is able to build its library of RRR signatures perfectly even with significant sensor noise for eight different local environ-mets, (2) It was able to identify its local environment with an accuracy of more than 96%, once the library is build, and (3) the robot was able to learn adequate hill climbing control laws which take it to the distinctive state of the local environment for five different environment types.
Title: Title: Belief Maintenance in Bayesian Networks  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Simultaneous Learning of Control Laws and Local Environment Representations for Intelligent Navigation Robots  
Abstract: Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these fe
Paper 3  Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,
Abstract: We have recently introduced a neural network mobile robot controller (NETMORC) that autonomously learns the forward and inverse odometry of a differential drive robot through an unsupervised learning-by-doing cycle. After an initial learning phase, the controller can move the robot to an arbitrary stationary or moving target while compensating for noise and other forms of disturbance, su
Paper 4  Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  
Abstract: This paper demonstrates the exploitation of certain vision processing techniques to index into a case base of surfaces. The surfaces are the result of reinforcement learning and represent the optimum choice of actions to achieve some goal from anywhere in the state space. This paper shows how strong features that occur in the interaction of the system with its environment can be detected
Paper 5  Title: Exploration and Model Building in Mobile Robot Domains  
Abstract: I present first results on COLUMBUS, an autonomous mobile robot. COLUMBUS operates in initially unknown, structured environments. Its task is to explore and model the environment efficiently while avoiding collisions with obstacles. COLUMBUS uses an instance-based learning technique for modeling its environment. Real-world experiences are generalized via two artificial neural networks th
Label: Reinforcement Learning
Paper 6  Title: A Modular Q-Learning Architecture for Manipulator Task Decomposition `Data storage in the cerebellar model ar
Abstract: Compositional Q-Learning (CQ-L) (Singh 1992) is a modular approach to learning to perform composite tasks made up of several elemental tasks by reinforcement learning. Skills acquired while performing elemental tasks are also applied to solve composite tasks. Individual skills compete for the right to act and only winning skills are included in the decomposition of the composite task. We
Paper 7  Title: A Simulation of Adaptive Agents in a Hostile Environment  
Abstract: In this paper we use the genetic programming technique to evolve programs to control an autonomous agent capable of learning how to survive in a hostile environment. In order to facilitate this goal, agents are run through random environment configurations. Randomly generated programs, which control the interaction of the agent with its environment, are recombined to form better programs
Paper 8  Title: Dynamic Automatic Model Selection  
Abstract: COINS Technical Report 92-30 February 1992 Abstract The problem of how to learn from examples has been studied throughout the history of machine learning, and many successful learning algorithms have been developed. A problem that has received less attention is how to select which algorithm to use for a given learning task. The ability of a chosen algorithm to induce a good generalizatio
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  False

Prediction: 0
Processing index 512...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Recently, we have proven that the dynamics of any deterministic finite-state automata (DFA) with n states and m input symbols can be implemented in a sparse second-order recurrent neural network (SORNN) with n + 1 state neurons and O(mn) second-order weights and sigmoidal discriminant functions [5]. We investigate how that constructive algorithm can be extended to fault-tolerant neural DFA implementations where faults in an analog implementation of neurons or weights do not affect the desired network performance. We show that tolerance to weight perturbation can be achieved easily; tolerance to weight and/or neuron stuck-at-zero faults, however, requires duplication of the network resources. This result has an impact on the construction of neural DFAs with a dense internal representation of DFA states.
Title: Title: Fault-Tolerant Implementation of Finite-State Automata in Recurrent Neural Networks  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Constructing Deterministic Finite-State Automata in Recurrent Neural Networks  
Abstract: Recurrent neural networks that are trained to behave like deterministic finite-state automata (DFAs) can show deteriorating performance when tested on long strings. This deteriorating performance can be attributed to the instability of the internal representation of the learned DFA states. The use of a sigmoidal discriminant function together with the recurrent structure contribute to th
Label: Neural Networks
Paper 3  Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  
Abstract: This work describes an approach for inferring Deterministic Context-free (DCF) Grammars in a Connectionist paradigm using a Recurrent Neural Network Pushdown Automaton (NNPDA). The NNPDA consists of a recurrent neural network connected to an external stack memory through a common error function. We show that the NNPDA is able to learn the dynamics of an underlying pushdown automaton from
Paper 4  Title: Constructive Learning of Recurrent Neural Networks: Limitations of Recurrent Casade Correlation and a Simple Solution  
Abstract: It is often difficult to predict the optimal neural network size for a particular application. Constructive or destructive methods that add or subtract neurons, layers, connections, etc. might offer a solution to this problem. We prove that one method, Recurrent Cascade Correlation, due to its topology, has fundamental limitations in representation and thus in its learning capabilities. 
Label: Neural Networks
Paper 5  Title: Even with Arbitrary Transfer Functions, RCC Cannot Compute Certain FSA  
Abstract: Category: algorithms and architectures | recurrent networks. No part of this paper has been submitted elsewhere. Preference: poster. Abstract Existing proofs demonstrating the computational limitations of the Recurrent Cascade Correlation (RCC) Network (Fahlman, 1991) explicitly limit their results to units having sigmoidal or hard-threshold transfer functions (Giles et al., 1995; and Kr
Paper 6  Title: An Analytical Framework for Local Feedforward Networks  
Abstract: Interference in neural networks occurs when learning in one area of the input space causes unlearning in another area. Networks that are less susceptible to interference are referred to as spatially local networks. To understand these properties, a theoretical framework, consisting of a measure of interference and a measure of network localization, is developed. These measures incorporat
Paper 7  Title: Local Feedforward Networks  
Abstract: Although feedforward neural networks are well suited to function approximation, in some applications networks experience problems when learning a desired function. One problem is interference which occurs when learning in one area of the input space causes unlearning in another area. Networks that are less susceptible to interference are referred to as spatially local networks. To unders
Paper 8  Title: Pruning Recurrent Neural Networks for Improved Generalization Performance  
Abstract: Determining the architecture of a neural network is an important issue for any learning task. For recurrent neural networks no general methods exist that permit the estimation of the number of layers of hidden neurons, the size of layers or the number of weights. We present a simple pruning heuristic which significantly improves the generalization performance of trained recurrent network
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1191...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The term "bias" is widely used|and with different meanings|in the fields of machine learning and statistics. This paper clarifies the uses of this term and shows how to measure and visualize the statistical bias and variance of learning algorithms. Statistical bias and variance can be applied to diagnose problems with machine learning bias, and the paper shows four examples of this. Finally, the paper discusses methods of reducing bias and variance. Methods based on voting can reduce variance, and the paper compares Breiman's bagging method and our own tree randomization method for voting decision trees. Both methods uniformly improve performance on data sets from the Irvine repository. Tree randomization yields perfect performance on the Letter Recognition task. A weighted nearest neighbor algorithm based on the infinite bootstrap is also introduced. In general, decision tree algorithms have moderate-to-high variance, so an important implication of this work is that variance|rather than appropriate or inappropriate machine learning bias|is an important cause of poor performance for decision tree algorithms. 
Title: Title: Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants  
Abstract: Methods for voting classification algorithms, such as Bagging and AdaBoost, have been shown to be very successful in improving the accuracy of certain classifiers for artificial and real-world datasets. We review these algorithms and describe a large empirical study comparing several variants in conjunction with a decision tree inducer (three variants) and a Naive-Bayes inducer. The purp
Label: Theory
Paper 3  Title: BOOSTING AND NAIVE BAYESIAN LEARNING  
Abstract: Although so-called naive Bayesian classification makes the unrealistic assumption that the values of the attributes of an example are independent given the class of the example, this learning method is remarkably successful in practice, and no uniformly better learning method is known. Boosting is a general method of combining multiple classifiers due to Yoav Freund and Rob Schapire. Thi
Paper 4  Title: Experiments with a New Boosting Algorithm  
Abstract: In an earlier paper, we introduced a new boosting algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that consistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a pseudo-loss which is a method for forcing a learning algorithm of multi-label 
Paper 5  Title: Error-Correcting Output Coding Corrects Bias and Variance  
Abstract: Previous research has shown that a technique called error-correcting output coding (ECOC) can dramatically improve the classification accuracy of supervised learning algorithms that learn to classify data points into one of k 2 classes. This paper presents an investigation of why the ECOC technique works, particularly when employed with decision-tree learning algorithms. It shows that th
Paper 6  Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  
Abstract: In the past, nearest neighbor algorithms for learning from examples have worked best in domains in which all features had numeric values. In such domains, the examples can be treated as points and distance metrics can use standard definitions. In symbolic domains, a more sophisticated treatment of the feature space is required. We introduce a nearest neighbor algorithm for learning in do
Paper 7  Title: Simultaneous Evolution of Programs and their Control Structures Simultaneous Evolution of Programs and their Control
Abstract: Previous research has shown that a technique called error-correcting output coding (ECOC) can dramatically improve the classification accuracy of supervised learning algorithms that learn to classify data points into one of k 2 classes. This paper presents an investigation of why the ECOC technique works, particularly when employed with decision-tree learning algorithms. It shows that th
Paper 8  Title: Bias and the Quantification of Stability Bias and the Quantification of Stability Bias and the
Abstract: Research on bias in machine learning algorithms has generally been concerned with the impact of bias on predictive accuracy. We believe that there are other factors that should also play a role in the evaluation of bias. One such factor is the stability of the algorithm; in other words, the repeatability of the results. If we obtain two sets of data from the same phenomenon, with the sam
Label: Theory
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 474...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We introduce a parallel approach, "DT-Select," for selecting features used by inductive learning algorithms to predict protein secondary structure. DT-Select is able to rapidly choose small, nonredundant feature sets from pools containing hundreds of thousands of potentially useful features. It does this by building a decision tree, using features from the pool, that classifies a set of training examples. The features included in the tree provide a compact description of the training data and are thus suitable for use as inputs to other inductive learning algorithms. Empirical experiments in the protein secondary-structure task, in which sets of complex features chosen by DT-Select are used to augment a standard artificial neural network representation, yield surprisingly little performance gain, even though features are selected from very large feature pools. We discuss some possible reasons for this result. 1 
Title: Title: Protein Structure Prediction: Selecting Salient Features from Large Candidate Pools  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Evolution, Learning, and Instinct: 100 Years of the Baldwin Effect Using Learning to Facilitate the
Abstract: This paper describes a hybrid methodology that integrates genetic algorithms and decision tree learning in order to evolve useful subsets of discriminatory features for recognizing complex visual concepts. A genetic algorithm (GA) is used to search the space of all possible subsets of a large set of candidate discrimination features. Candidate feature subsets are evaluated by using C4.5,
Label: Genetic Algorithms
Paper 3  Title: Maximum A Posteriori Classification of DNA Structure from Sequence Information  
Abstract: We introduce an algorithm, lllama, which combines simple pattern recognizers into a general method for estimating the entropy of a sequence. Each pattern recognizer exploits a partial match between subsequences to build a model of the sequence. Since the primary features of interest in biological sequence domains are subsequences with small variations in exact composition, lllama is part
Label: Neural Networks
Paper 4  Title: Feature Generation for Sequence Categorization  
Abstract: The problem of sequence categorization is to generalize from a corpus of labeled sequences procedures for accurately labeling future unlabeled sequences. The choice of representation of sequences can have a major impact on this task, and in the absence of background knowledge a good representation is often not known and straightforward representations are often far from optimal. We propo
Paper 5  Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  
Abstract: With the goal of reducing computational costs without sacrificing accuracy, we describe two algorithms to find sets of prototypes for nearest neighbor classification. Here, the term prototypes refers to the reference instances used in a nearest neighbor computation the instances with respect to which similarity is assessed in order to assign a class to a new data item. Both algorithms re
Paper 6  Title: Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology  
Abstract: In the wrapper approach to feature subset selection, a search for an optimal set of features is made using the induction algorithm as a black box. The estimated future performance of the algorithm is the heuristic guiding the search. Statistical methods for feature subset selection including forward selection, backward elimination, and their stepwise variants can be viewed as simple hill
Paper 7  Title: Stochastic Propositionalization of Non-Determinate Background Knowledge  
Abstract: It is a well-known fact that propositional learning algorithms require "good" features to perform well in practice. So a major step in data engineering for inductive learning is the construction of good features by domain experts. These features often represent properties of structured objects, where a property typically is the occurrence of a certain substructure having certain properti
Paper 8  Title: Compression-Based Feature Subset Selection  Keywords: Minimum Description Length Principle, Cross Validation, Noise  
Abstract: Irrelevant and redundant features may reduce both predictive accuracy and comprehensibility of induced concepts. Most common Machine Learning approaches for selecting a good subset of relevant features rely on cross-validation. As an alternative, we present the application of a particular Minimum Description Length (MDL) measure to the task of feature subset selection. Using the MDL prin
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  False

Prediction: 0
Processing index 1065...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: IlliGAL Report No. 97003 May 1997 
Title: Title: A Survey of Parallel Genetic Algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Genetic Algorithms, Tournament Selection, and the Effects of Noise  
Abstract: IlliGAL Report No. 95006 July 1995 
Paper 3  Title: The Bayesian Approach to Tree-Structured Regression  
Abstract: TECHNICAL REPORT NO. 967 August 1996 
Paper 4  Title: Finding Analogues for Innovative Design  
Abstract: Knowledge Systems Laboratory March 1995 Report No. KSL 95-32 
Paper 5  Title: Environments with Classifier Systems (Experiments on Adding Memory to XCS)  
Abstract: Pier Luca Lanzi Technical Report N. 97.45 October 17 th , 1997 
Paper 6  Title: The Role of Transfer in Learning (extended abstract)  
Abstract: Technical Report No. 670 December, 1997 
Label: Reinforcement Learning
Paper 7  Title: Model of the Environment to Avoid Local Learning  
Abstract: Pier Luca Lanzi Technical Report N. 97.46 December 20 th , 1997 
Paper 8  Title: A Comparison of Selection Schemes used in Genetic Algorithms  
Abstract: TIK-Report Nr. 11, December 1995 Version 2 (2. Edition) 
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2561...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Given a problem, a case-based reasoning (CBR) system will search its case memory and use the stored cases to find the solution, possibly modifying retrieved cases to adapt to the required input specifications. In discrete domains CBR reasoning can be based on a rigorous Bayesian probability propagation algorithm. Such a Bayesian CBR system can be implemented as a probabilistic feedforward neural network with one of the layers representing the cases. In this paper we introduce a Minimum Description Length (MDL) based learning algorithm to obtain the proper network structure with the associated conditional probabilities. This algorithm together with the resulting neural network implementation provide a massively parallel architecture for solving the efficiency bottleneck in case-based reasoning. 
Title: Title: MDL Learning of Probabilistic Neural Networks for Discrete Problem Domains  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Bayesian Case-Based Reasoning with Neural Networks  
Abstract: Given a problem, a case-based reasoning (CBR) system will search its case memory and use the stored cases to find the solution, possibly modifying retrieved cases to adapt to the required input specifications. In this paper we introduce a neural network architecture for efficient case-based reasoning. We show how a rigorous Bayesian probability propagation algorithm can be implemented as
Label: Probabilistic Methods
Paper 3  Title: Adaptive Tuning of Numerical Weather Prediction Models: Simultaneous Estimation of Weighting, Smoothing and Physical Parameters 1  
Abstract: In recent years, case-based reasoning has been demonstrated to be highly useful for problem solving in complex domains. Also, mixed paradigm approaches emerged for combining CBR and induction techniques aiming at verifying the knowledge and/or building an efficient case memory. However, in complex domains induction over the whole problem space is often not possible or too time consuming.
Paper 4  Title: Massively Parallel Case-Based Reasoning with Probabilistic Similarity Metrics  
Abstract: We propose a probabilistic case-space metric for the case matching and case adaptation tasks. Central to our approach is a probability propagation algorithm adopted from Bayesian reasoning systems, which allows our case-based reasoning system to perform theoretically sound probabilistic reasoning. The same probability propagation mechanism actually offers a uniform solution to both the c
Label: Probabilistic Methods
Paper 5  Title: FONN: Combining First Order Logic with Connectionist Learning  
Abstract: This paper presents a neural network architecture that can manage structured data and refine knowledge bases expressed in a first order logic language. The presented framework is well suited to classification problems in which concept de scriptions depend upon numerical features of the data. In fact, the main goal of the neural architecture is that of refining the numerical part of the k
Paper 6  Title: ADAPtER: an Integrated Diagnostic System Combining Case-Based and Abductive Reasoning  
Abstract: The aim of this paper is to describe the ADAPtER system, a diagnostic architecture combining case-based reasoning with abductive reasoning and exploiting the adaptation of the solution of old episodes, in order to focus the reasoning process. Domain knowledge is represented via a logical model and basic mechanisms, based on abductive reasoning with consistency constraints, have been defi
Label: Case Based
Paper 7  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 8  Title: Lazy Induction Triggered by CBR  
Abstract: In recent years, case-based reasoning has been demonstrated to be highly useful for problem solving in complex domains. Also, mixed paradigm approaches emerged for combining CBR and induction techniques aiming at verifying the knowledge and/or building an efficient case memory. However, in complex domains induction over the whole problem space is often not possible or too time consuming.
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 2676...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Performance of human subjects in a wide variety of early visual processing tasks improves with practice. HyperBF networks (Poggio and Girosi, 1990) constitute a mathematically well-founded framework for understanding such improvement in performance, or perceptual learning, in the class of tasks known as visual hyperacuity. The present article concentrates on two issues raised by the recent psychophysical and computational findings reported in (Poggio et al., 1992b; Fahle and Edelman, 1992). First, we develop a biologically plausible extension of the HyperBF model that takes into account basic features of the functional architecture of early vision. Second, we explore various learning modes that can coexist within the HyperBF framework and focus on two unsupervised learning rules which may be involved in hyperacuity learning. Finally, we report results of psychophysical experiments that are consistent with the hypothesis that activity-dependent presynaptic amplification may be involved in perceptual learning in hyperacuity. 
Title: Title: Models of perceptual learning in vernier hyperacuity  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Cortical Mechanisms of Visual Recognition and Learning: A Hierarchical Kalman Filter Model  
Abstract: We describe a biologically plausible model of dynamic recognition and learning in the visual cortex based on the statistical theory of Kalman filtering from optimal control theory. The model utilizes a hierarchical network whose successive levels implement Kalman filters operating over successively larger spatial and temporal scales. Each hierarchical level in the network predicts the cu
Paper 3  Title: A Model of Invariant Object Recognition in the Visual System  
Abstract: Neurons in the ventral stream of the primate visual system exhibit responses to the images of objects which are invariant with respect to natural transformations such as translation, size, and view. Anatomical and neurophysiological evidence suggests that this is achieved through a series of hierarchical processing areas. In an attempt to elucidate the manner in which such representation
Paper 4  Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  
Abstract: The sensorimotor integration system can be viewed as an observer attempting to estimate its own state and the state of the environment by integrating multiple sources of information. We describe a computational framework capturing this notion, and some specific models of integration and adaptation that result from it. Psychophysical results from two sensorimotor systems, subserving the i
Paper 5  Title: A Neural Network Model of Memory Consolidation  
Abstract: Some forms of memory rely temporarily on a system of brain structures located in the medial temporal lobe that includes the hippocampus. The recall of recent events is one task that relies crucially on the proper functioning of this system. As the event becomes less recent, the medial temporal lobe becomes less critical to the recall of the event, and the recollection appears to rely mor
Paper 6  Title: Multiassociative Memory  
Abstract: This paper discusses the problem of how to implement many-to-many, or multi-associative, mappings within connectionist models. Traditional symbolic approaches wield explicit representation of all alternatives via stored links, or implicitly through enumerative algorithms. Classical pattern association models ignore the issue of generating multiple outputs for a single input pattern, and 
Paper 7  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract: A novel architecture and set of learning rules for cortical self-organization is proposed. The model is based on the idea that multiple information channels can modulate one another's plasticity. Features learned from bottom-up information sources can thus be influenced by those learned from contextual pathways, and vice versa. A maximum likelihood cost function allows this scheme to be 
Label: Neural Networks
Paper 8  Title: VISIT: An Efficient Computational Model of Human Visual Attention  
Abstract: One of the challenges for models of cognitive phenomena is the development of efficient and exible interfaces between low level sensory information and high level processes. For visual processing, researchers have long argued that an attentional mechanism is required to perform many of the tasks required by high level vision. This thesis presents VISIT, a connectionist model of covert vi
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 2612...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper overviews a proposed architecture for adaptive parallel logic referred to as ASOCS (Adaptive Self-Organizing Concurrent System). The ASOCS approach is based on an adaptive network composed of many simple computing elements which operate in a parallel asynchronous fashion. Problem specification is given to the system by presenting if-then rules in the form of boolean conjunctions. Rules are added incrementally and the system adapts to the changing rule-base. Adaptation and data processing form two separate phases of operation. During processing the system acts as a parallel hardware circuit. The adaptation process is distributed amongst the computing elements and efficiently exploits parallelism. Adaptation is done in a self-organizing fashion and takes place in time linear with the depth of the network. This paper summarizes the overall ASOCS concept and overviews three specific architectures. 
Title: Title: Models of Parallel Adaptive Logic  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Self-Adjusting Dynamic Logic Module  
Abstract: This paper presents an ASOCS (Adaptive Self-Organizing Concurrent System) model for massively parallel processing of incrementally defined rule systems in such areas as adaptive logic, robotics, logical inference, and dynamic control. An ASOCS is an adaptive network composed of many simple computing elements operating asynchronously and in parallel. This paper focuses on Adaptive Algorit
Paper 3  Title: A Self-Organizing Binary Decision Tree For Incrementally Defined Rule Based  
Abstract: This paper presents an ASOCS (adaptive self-organizing concurrent system) model for massively parallel processing of incrementally defined rule systems in such areas as adaptive logic, robotics, logical inference, and dynamic control. An ASOCS is an adaptive network composed of many simple computing elements operating asynchronously and in parallel. This paper focuses on adaptive algorit
Paper 4  Title: Digital Neural Networks  
Abstract: Demands for applications requiring massive parallelism in symbolic environments have given rebirth to research in models labeled as neura l networks. These models are made up of many simple nodes which are highly interconnected such that computation takes place as data flows amongst the nodes of the network. To present, most models have proposed nodes based on simple analog functions, wh
Paper 5  Title: ASOCS: A Multilayered Connectionist Network with Guaranteed Learning of Arbitrary Mappings  
Abstract: This paper reviews features of a new class of multilayer connectionist architectures known as ASOCS (Adaptive Self-Organizing Concurrent Systems). ASOCS is similar to most decision-making neural network models in that it attempts to learn an adaptive set of arbitrary vector mappings. However, it differs dramatically in its mechanisms. ASOCS is based on networks of adaptive digital elemen
Label: Neural Networks
Paper 6  Title: Priority ASOCS  ASOCS models have two significant advantages over other learning models:  
Abstract: This paper presents an ASOCS (Adaptive Self-Organizing Concurrent System) model for massively parallel processing of incrementally defined rule systems in such areas as adaptive logic, robotics, logical inference, and dynamic control. An ASOCS is an adaptive network composed of many simple computing elements operating asynchronously and in parallel. An ASOCS can operate in either a data 
Paper 7  Title: A VLSI Implementation of a Parallel, Self-Organizing Learning Model  
Abstract: This paper presents a VLSI implementation of the Priority Adaptive Self-Organizing Concurrent System (PASOCS) learning model that is built using a multi-chip module (MCM) substrate. Many current hardware implementations of neural network learning models are direct implementations of classical neural network structures|a large number of simple computing nodes connected by a dense number o
Label: Neural Networks
Paper 8  Title: Massively Parallel Matching of Knowledge Structures  
Abstract: As knowledge bases used for AI systems increase in size, access to relevant information is the dominant factor in the cost of inference. This is especially true for analogical (or case-based) reasoning, in which the ability of the system to perform inference is dependent on efficient and flexible access to a large base of exemplars (cases) judged likely to be relevant to solving a proble
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 34...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper demonstrates the exploitation of certain vision processing techniques to index into a case base of surfaces. The surfaces are the result of reinforcement learning and represent the optimum choice of actions to achieve some goal from anywhere in the state space. This paper shows how strong features that occur in the interaction of the system with its environment can be detected early in the learning process. Such features allow the system to identify when an identical, or very similar, task has been solved previously and to retrieve the relevant surface. This results in an orders of magnitude increase in learning rate. 
Title: Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Expectation-Based Selective Attention for Visual Monitoring and Control of a Robot Vehicle  
Abstract: Reliable vision-based control of an autonomous vehicle requires the ability to focus attention on the important features in an input scene. Previous work with an autonomous lane following system, ALVINN [Pomerleau, 1993], has yielded good results in uncluttered conditions. This paper presents an artificial neural network based learning approach for handling difficult scenes which will co
Label: Neural Networks
Paper 3  Title: Finding Structure in Reinforcement Learning  
Abstract: Reinforcement learning addresses the problem of learning to select actions in order to maximize one's performance in unknown environments. To scale reinforcement learning to complex real-world tasks, such as typically studied in AI, one must ultimately be able to discover the structure in the world, in order to abstract away the myriad of details and to operate in more tractable problem 
Paper 4  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract: We present a new approach to reinforcement learning in which the policies considered by the learning process are constrained by hierarchies of partially specified machines. This allows for the use of prior knowledge to reduce the search space and provides a framework in which knowledge can be transferred across problems and in which component solutions can be recombined to solve larger a
Paper 5  Title: Experiments on the Transfer of Knowledge between Neural Networks Reprinted from: Computational Learning Theory and
Abstract: This chapter describes three studies which address the question of how neural network learning can be improved via the incorporation of information extracted from other networks. This general problem, which we call network transfer, encompasses many types of relationships between source and target networks. Our focus is on the utilization of weights from source networks which solve a sub
Paper 6  Title: Modeling the Student with Reinforcement Learning  
Abstract: We describe a methodology for enabling an intelligent teaching system to make high level strategy decisions on the basis of low level student modeling information. This framework is less costly to construct, and superior to hand coding teaching strategies as it is more responsive to the learner's needs. In order to accomplish this, reinforcement learning is used to learn to associate sup
Paper 7  Title: Using Mixtures of Factor Analyzers for Segmentation and Pose Estimation  Category: Visual Processing Preference: Oral  
Abstract: To read a hand-written digit string, it is helpful to segment the image into separate digits. Bottom-up segmentation heuristics often fail when neighboring digits overlap substantially. We describe a system that has a stochastic generative model of each digit class and we show that this is the only knowledge required for segmentation. The system uses Gibbs sampling to construct a percept
Label: Neural Networks
Paper 8  Title: Learning One More Thing  
Abstract: Most research on machine learning has focused on scenarios in which a learner faces a single, isolated learning task. The lifelong learning framework assumes that the learner encounters a multitude of related learning tasks over its lifetime, providing the opportunity for the transfer of knowledge among these. This paper studies lifelong learning in the context of binary classification. 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 1082...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: program w.r.t. positive and negative examples can be viewed as the problem of pruning an SLD-tree such that all refutations of negative examples and no refutations of positive examples are excluded. It is shown that the actual pruning can be performed by applying unfolding and clause removal. The algorithm spectre is presented, which is based on this idea. The input to the algorithm is, besides a logic program and positive and negative examples, a computation rule, which determines the shape of the SLD-tree that is to be pruned. It is shown that the generality of the resulting specialization is dependent on the computation rule, and experimental results are presented from using three different computation rules. The experiments indicate that the computation rule should be formulated so that the number of applications of unfolding is kept as low as possible. The algorithm, which uses a divide-and-conquer method, is also compared with a covering algorithm. The experiments show that a higher predictive accuracy can be achieved if the focus is on discriminating positive from negative examples rather than on achieving a high coverage of positive examples only. 
Title: Title: Specialization of Logic Programs by Pruning SLD-Trees  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Specialization of Recursive Predicates  
Abstract: When specializing a recursive predicate in order to exclude a set of negative examples without excluding a set of positive examples, it may not be possible to specialize or remove any of the clauses in a refutation of a negative example without excluding any positive exam ples. A previously proposed solution to this problem is to apply program transformation in order to obtain non-recurs
Paper 3  Title: Theory-Guided Induction of Logic Programs by Inference of Regular Languages recursive clauses. merlin on the
Abstract: resent allowed sequences of resolution steps for the initial theory. There are, however, many characterizations of allowed sequences of resolution steps that cannot be expressed by a set of resolvents. One approach to this problem is presented, the system mer-lin, which is based on an earlier technique for learning finite-state automata that represent allowed sequences of resolution step
Paper 4  Title: Predicate Invention and Learning from Positive Examples Only  
Abstract: Previous bias shift approaches to predicate invention are not applicable to learning from positive examples only, if a complete hypothesis can be found in the given language, as negative examples are required to determine whether new predicates should be invented or not. One approach to this problem is presented, MERLIN 2.0, which is a successor of a system in which predicate invention i
Label: Rule Learning
Paper 5  Title: Bottom-up induction of logic programs with more than one recursive clause  
Abstract: In this paper we present a bottom-up algorithm called MRI to induce logic programs from their examples. This method can induce programs with a base clause and more than one recursive clause from a very small number of examples. MRI is based on the analysis of saturations of examples. It first generates a path structure, which is an expression of a stream of values processed by predicates
Label: Rule Learning
Paper 6  Title: Learning Decision Trees from Decision Rules:  
Abstract: A method and initial results from a comparative study ABSTRACT A standard approach to determining decision trees is to learn them from examples. A disadvantage of this approach is that once a decision tree is learned, it is difficult to modify it to suit different decision making situations. Such problems arise, for example, when an attribute assigned to some node cannot be measured, or 
Label: Rule Learning
Paper 7  Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some
Abstract: covering has been formalized and used extensively. In this work, the divide-and-conquer technique is formalized as well and compared to the covering technique in a logic programming framework. Covering works by repeatedly specializing an overly general hypothesis, on each iteration focusing on finding a clause with a high coverage of positive examples. Divide-and-conquer works by special
Label: Genetic Algorithms
Paper 8  Title: THE DISCOVERY OF ALGORITHMIC PROBABILITY  
Abstract: covering has been formalized and used extensively. In this work, the divide-and-conquer technique is formalized as well and compared to the covering technique in a logic programming framework. Covering works by repeatedly specializing an overly general hypothesis, on each iteration focusing on finding a clause with a high coverage of positive examples. Divide-and-conquer works by special
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 2082...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract:  
Title: Title: %A L. Ingber %T Adaptive simulated annealing (ASA): Lessons learned %J Control and Cybernetics Annealing
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Genetic Algorithms, Tournament Selection, and the Effects of Noise  
Abstract: IlliGAL Report No. 95006 July 1995 
Paper 3  Title: CABeN: A Collection of Algorithms for Belief Networks  Correspond with:  
Abstract: Portions of this report have been published in the Proceedings of the Fifteenth Annual Symposium on Computer Applications in Medical Care (November, 1991). 
Paper 4  Title: A Survey of Parallel Genetic Algorithms  
Abstract: IlliGAL Report No. 97003 May 1997 
Paper 5  Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  
Abstract: TECHNICAL REPORT NO. 947 June 5, 1995 
Paper 6  Title: Cognitive Computation (Extended Abstract)  
Abstract: Cognitive computation is discussed as a discipline that links together neurobiology, cognitive psychology and artificial intelligence. 
Paper 7  Title: MML mixture modelling of multi-state, Poisson, von Mises circular and Gaussian distributions  
Abstract: 11] M.H. Overmars. A random approach to motion planning. Technical Report RUU-CS-92-32, Department of Computer Science, Utrecht University, October 1992. 
Paper 8  Title: References Linear Controller Design, Limits of Performance, "The parallel projection operators of a nonlinear feedback
Abstract: 13] Yang, Y., H.J. Sussmann, and E.D. Sontag, "Stabilization of linear systems with bounded controls," in Proc. Nonlinear Control Systems Design Symp., Bordeaux, June 1992 (M. Fliess, Ed.), IFAC Publications, pp. 15-20. Journal version to appear in IEEE Trans. Autom. Control . 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 466...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Following terminology used in adaptive control, we distinguish between indirect learning methods, which learn explicit models of the dynamic structure of the system to be controlled, and direct learning methods, which do not. We compare an existing indirect method, which uses a conventional dynamic programming algorithm, with a closely related direct reinforcement learning method by applying both methods to an infinite horizon Markov decision problem with unknown state-transition probabilities. The simulations show that although the direct method requires much less space and dramatically less computation per control action, its learning ability in this task is superior to, or compares favorably with, that of the more complex indirect method. Although these results do not address how the methods' performances compare as problems become more difficult, they suggest that given a fixed amount of computational power available per control action, it may be better to use a direct reinforcement learning method augmented with indirect techniques than to devote all available resources to a computation-ally costly indirect method. Comprehensive answers to the questions raised by this study depend on many factors making up the eco nomic context of the computation.
Title: Title: On the Computational Economics of Reinforcement Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Reinforcement Learning Algorithms for Average-Payoff Markovian Decision Processes  
Abstract: Reinforcement learning (RL) has become a central paradigm for solving learning-control problems in robotics and artificial intelligence. RL researchers have focussed almost exclusively on problems where the controller has to maximize the discounted sum of payoffs. However, as emphasized by Schwartz (1993), in many problems, e.g., those for which the optimal behavior is a limit cycle, it 
Label: Reinforcement Learning
Paper 3  Title: A Teaching Strategy for Memory-Based Control  
Abstract: Combining different machine learning algorithms in the same system can produce benefits above and beyond what either method could achieve alone. This paper demonstrates that genetic algorithms can be used in conjunction with lazy learning to solve examples of a difficult class of delayed reinforcement learning problems better than either method alone. This class, the class of differentia
Paper 4  Title: Toward Learning Systems That Integrate Different Strategies and Representations TR93-22  
Abstract: Temporal difference (TD) methods constitute a class of methods for learning predictions in multi-step prediction problems, parameterized by a recency factor . Currently the most important application of these methods is to temporal credit assignment in reinforcement learning. Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learnin
Paper 5  Title: A Statistical Approach to Solving the EBL Utility Problem  
Abstract: Many "learning from experience" systems use information extracted from problem solving experiences to modify a performance element PE, forming a new element PE 0 that can solve these and similar problems more efficiently. However, as transformations that improve performance on one set of problems can degrade performance on other sets, the new PE 0 is not always better than the original P
Paper 6  Title: Machine Learning,  Reinforcement Learning with Replacing Eligibility Traces  
Abstract: The eligibility trace is one of the basic mechanisms used in reinforcement learning to handle delayed reward. In this paper we introduce a new kind of eligibility trace, the replacing trace, analyze it theoretically, and show that it results in faster, more reliable learning than the conventional trace. Both kinds of trace assign credit to prior events according to how recently they occu
Label: Reinforcement Learning
Paper 7  Title: Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems  
Abstract: Increasing attention has been paid to reinforcement learning algorithms in recent years, partly due to successes in the theoretical analysis of their behavior in Markov environments. If the Markov assumption is removed, however, neither generally the algorithms nor the analyses continue to be usable. We propose and analyze a new learning algorithm to solve a certain class of non-Markov d
Paper 8  Title: NEUROCONTROL BY REINFORCEMENT LEARNING  
Abstract: Reinforcement learning (RL) is a model-free tuning and adaptation method for control of dynamic systems. Contrary to supervised learning, based usually on gradient descent techniques, RL does not require any model or sensitivity function of the process. Hence, RL can be applied to systems that are poorly understood, uncertain, nonlinear or for other reasons untractable with conventional 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 2598...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Research into the utility of non-coding segments, or introns, in genetic-based encodings has shown that they expedite the evolution of solutions in domains by protecting building blocks against destructive crossover. We consider a genetic programming system where non-coding segments can be removed, and the resultant chromosomes returned into the population. This parsimonious repair leads to premature convergence, since as we remove the naturally occurring non-coding segments, we strip away their protective backup feature. We then duplicate the coding segments in the repaired chromosomes, and place the modified chromosomes into the population. The duplication method significantly improves the learning rate in the domain we have considered. We also show that this method can be applied to other domains.
Title: Title: Duplication of Coding Segments in Genetic Programming  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Recognizing Handwritten Digit Strings Using Modular Spatio-temporal Connectionist Networks  
Abstract: Research into the utility of non-coding segments, or introns, in genetic-based encodings has shown that they expedite the evolution of solutions in domains by protecting building blocks against destructive crossover. We consider a genetic programming system where non-coding segments can be removed, and the resultant chromosomes returned into the population. This parsimonious repair leads
Paper 3  Title: A comparison of the fixed and floating building block representation in the genetic algorithm  
Abstract: This article compares the traditional, fixed problem representation style of a genetic algorithm (GA) with a new floating representation in which the building blocks of a problem are not fixed at specific locations on the individuals of the population. In addition, the effects of non-coding segments on both of these representations is studied. Non-coding segments are a computational mode
Paper 4  Title: Hybridized Crossover-Based Search Techniques for Program Discovery  
Abstract: In this paper we address the problem of program discovery as defined by Genetic Programming [10]. We have two major results: First, by combining a hierarchical crossover operator with two traditional single point search algorithms: Simulated Annealing and Stochastic Iterated Hill Climbing, we have solved some problems with fewer fitness evaluations and a greater probability of a success 
Label: Genetic Algorithms
Paper 5  Title: Empirical studies of the genetic algorithm with non-coding segments  
Abstract: The genetic algorithm (GA) is a problem solving method that is modelled after the process of natural selection. We are interested in studying a specific aspect of the GA: the effect of non-coding segments on GA performance. Non-coding segments are segments of bits in an individual that provide no contribution, positive or negative, to the fitness of that individual. Previous research on 
Label: Genetic Algorithms
Paper 6  Title: Testing the Robustness of the Genetic Algorithm on the Floating Building Block Representation.  
Abstract: Recent studies on a floating building block representation for the genetic algorithm (GA) suggest that there are many advantages to using the floating representation. This paper investigates the behavior of the GA on floating representation problems in response to three different types of pressures: (1) a reduction in the amount of genetic material available to the GA during the problem 
Label: Genetic Algorithms
Paper 7  Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  
Abstract: Genetic algorithms have been used to solve hard optimization problems ranging from the Travelling Salesman problem to the Quadratic Assignment problem. We show that the Simple Genetic Algorithm can be used to solve an optimization problem derived from the 3-Conjunctive Normal Form problem. By separating the populations into small sub-populations, parallel genetic algorithms exploits the 
Paper 8  Title: Culling Teaching -1 Culling and Teaching in Neuro-evolution  
Abstract: The evolving population of neural nets contains information not only in terms of genes, but also in the collection of behaviors of the population members. Such information can be thought of as a kind of culture of the population. Two ways of exploiting that culture are explored in this paper: (1) Culling overlarge litters: Generate a large number of offspring with different crossovers, q
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1217...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A control law is constructed for a linear time varying system by solving a two player zero sum differential game on a moving horizon, the game being that which is used to construct an H 1 controller on a finite horizon. Conditions are given under which this controller results in a stable system and satisfies an infinite horizon H 1 norm bound. A risk sensitive formulation is used to provide a state estimator in the observation feedback case.
Title: Title: A game theoretic approach to moving horizon control  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Robust performance and adaptation using receding horizon H 1 control of time varying systems.  
Abstract: In this paper we construct suboptimal H 1 controllers which satisfy a new robust performance condition, using the receding horizon technique. A method is described for the synthesis of H 1 controllers online, making use of the exact plant model only on a finite interval extending into the future. Inequalities based on the two Riccati differential equation solution to the finite horizon H
Paper 3  Title: Adaptive Wavelet Control of Nonlinear Systems  
Abstract: This paper considers the design and analysis of adaptive wavelet control algorithms for uncertain nonlinear dynamical systems. The Lyapunov synthesis approach is used to develop a state-feedback adaptive control scheme based on nonlinearly parametrized wavelet network models. Semi-global stability results are obtained under the key assumption that the system uncertainty satisfies a "matc
Paper 4  Title: CONTROL-LYAPUNOV FUNCTIONS FOR TIME-VARYING SET STABILIZATION  
Abstract: This paper shows that, for time varying systems, global asymptotic controllability to a given closed subset of the state space is equivalent to the existence of a continuous control-Lyapunov function with respect to the set. 
Paper 5  Title: On Finite Gain Stabilizability of Linear Systems Subject to Input Saturation  
Abstract: This paper deals with (global) finite-gain input/output stabilization of linear systems with saturated controls. For neutrally stable systems, it is shown that the linear feedback law suggested by the passivity approach indeed provides stability, with respect to every L p -norm. Explicit bounds on closed-loop gains are obtained, and they are related to the norms for the respective system
Paper 6  Title: Avoiding Saturation By Trajectory Reparameterization  
Abstract: The problem of trajectory tracking in the presence of input constraints is considered. The desired trajectory is reparameterized on a slower time scale in order to avoid input saturation. Necessary conditions that the reparameterizing function must satisfy are derived. The deviation from the nominal trajectory is minimized by formulating the problem as an optimal control problem. 
Paper 7  Title: Identification in H 1 with Nonuniformly Spaced Frequency Response Measurements  
Abstract: In this paper, the problem of "system identification in H 1 " is investigated in the case when the given frequency response data is not necessarily on a uniformly spaced grid of frequencies. A large class of robustly convergent identification algorithms are derived. A particular algorithm is further examined and explicit worst case error bounds (in the H 1 norm) are derived for both disc
Paper 8  Title: Incremental methods for computing bounds in partially observable Markov decision processes  
Abstract: Partially observable Markov decision processes (POMDPs) allow one to model complex dynamic decision or control problems that include both action outcome uncertainty and imperfect observabil-ity. The control problem is formulated as a dynamic optimization problem with a value function combining costs or rewards from multiple steps. In this paper we propose, analyse and test various increm
Label: Reinforcement Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 2470...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We describe recent extensions to our framework for the automatic generation of music-making programs. We have previously used genetic programming techniques to produce music-making programs that satisfy user-provided critical criteria. In this paper we describe new work on the use of connectionist techniques to automatically induce musical structure from a corpus. We show how the resulting neural networks can be used as critics that drive our genetic programming system. We argue that this framework can potentially support the induction and recapitulation of deep structural features of music. We present some initial results produced using neural and hybrid symbolic/neural critics, and we discuss directions for future work.
Title: Title: Induction and Recapitulation of Deep Musical Structure  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: ILA: Combining Inductive Learning with Prior Knowledge and Reasoning  
Abstract: We describe recent extensions to our framework for the automatic generation of music-making programs. We have previously used genetic programming techniques to produce music-making programs that satisfy user-provided critical criteria. In this paper we describe new work on the use of connectionist techniques to automatically induce musical structure from a corpus. We show how the resulti
Label: Case Based
Paper 3  Title: Cultural Transmission of Information in Genetic Programming  
Abstract: This paper shows how the performance of a genetic programming system can be improved through the addition of mechanisms for non-genetic transmission of information between individuals (culture). Teller has previously shown how genetic programming systems can be enhanced through the addition of memory mechanisms for individual programs [Teller 1994]; in this paper we show how Teller's mem
Paper 4  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract: We present a new approach to reinforcement learning in which the policies considered by the learning process are constrained by hierarchies of partially specified machines. This allows for the use of prior knowledge to reduce the search space and provides a framework in which knowledge can be transferred across problems and in which component solutions can be recombined to solve larger a
Paper 5  Title: Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email  
Abstract: This paper describes a novel method by which a dialogue agent can learn to choose an optimal dialogue strategy. While it is widely agreed that dialogue strategies should be formulated in terms of communicative intentions, there has been little work on automatically optimizing an agent's choices when there are multiple ways to realize a communicative intention. Our method is based on a co
Label: Reinforcement Learning
Paper 6  Title: Knowledge Acquisition with a Knowledge-Intensive Machine Learning System  
Abstract: In this paper, we investigate the integration of knowledge acquisition and machine learning techniques. We argue that existing machine learning techniques can be made more useful as knowledge acquisition tools by allowing the expert to have greater control over and interaction with the learning process. We describe a number of extensions to FOCL (a multistrategy Horn-clause learning prog
Label: Rule Learning
Paper 7  Title: Robot Shaping: Developing Situated Agents through Learning  
Abstract: Learning plays a vital role in the development of situated agents. In this paper, we explore the use of reinforcement learning to "shape" a robot to perform a predefined target behavior. We connect both simulated and real robots to A LECSYS, a parallel implementation of a learning classifier system with an extended genetic algorithm. After classifying different kinds of Animat-like behav
Paper 8  Title: Evolution of Mapmaking: Learning, planning, and memory using Genetic Programming  
Abstract: An essential component of an intelligent agent is the ability to observe, encode, and use information about its environment. Traditional approaches to Genetic Programming have focused on evolving functional or reactive programs with only a minimal use of state. This paper presents an approach for investigating the evolution of learning, planning, and memory using Genetic Programming. The
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 600...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The place fields of hippocampal cells in old animals sometimes change when an animal is removed from and then returned to an environment [ Barnes et al., 1997 ] . The ensemble correlation between two sequential visits to the same environment shows a strong bimodality for old animals (near 0, indicative of remapping, and greater than 0.7, indicative of a similar representation between experiences), but a strong unimodality for young animals (greater than 0.7, indicative of a similar representation between experiences). One explanation for this is the multi-map hypothesis in which multiple maps are encoded in the hippocampus: old animals may sometimes be returning to the wrong map. A theory proposed by Samsonovich and McNaughton (1997) suggests that the Barnes et al. experiment implies that the maps are pre-wired in the CA3 region of hippocampus. Here, we offer an alternative explanation in which orthogonalization properties in the dentate gyrus (DG) region of hippocampus interact with errors in self-localization (reset of the path integrator on re-entry into the environment) to produce the bimodality. 
Title: Title: Separating hippocampal maps  Spatial Functions of the Hippocampal Formation and the  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Model of Visually Guided Plasticity of the Auditory Spatial Map in the Barn Owl  
Abstract: In the barn owl, the self-organization of the auditory map of space in the external nucleus of the inferior colliculus (ICx) is strongly influenced by vision, but the nature of this interaction is unknown. In this paper a biologically plausible and mini-malistic model of ICx self-organization is proposed where the ICx receives a learn signal based on the owl's visual attention. When the 
Label: Neural Networks
Paper 3  Title: Learning Harmonic Progression Using Markov Models EECS545 Project  
Abstract: It is argued that the memorization of events and situations (episodic memory) requires the rapid formation of neural circuits responsive to binding errors and binding matches. While the formation of circuits responsive to binding matches can be modeled by associative learning mechanisms, the rapid formation of circuits responsive to binding errors is difficult to explain given their seem
Paper 4  Title: Learning Viewpoint Invariant Representations of Faces in an Attractor Network  
Abstract: In natural visual experience, different views of an object tend to appear in close temporal proximity as an animal manipulates the object or navigates around it. We investigated the ability of an attractor network to acquire view invariant visual representations by associating first neighbors in a pattern sequence. The pattern sequence contains successive views of faces of ten individual
Paper 5  Title: Task and Spatial Frequency Effects on Face Specialization  
Abstract: There is strong evidence that face processing is localized in the brain. The double dissociation between prosopagnosia, a face recognition deficit occurring after brain damage, and visual object agnosia, difficulty recognizing other kinds of complex objects, indicates that face and non-face object recognition may be served by partially independent mechanisms in the brain. Is neural speci
Paper 6  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract: A novel architecture and set of learning rules for cortical self-organization is proposed. The model is based on the idea that multiple information channels can modulate one another's plasticity. Features learned from bottom-up information sources can thus be influenced by those learned from contextual pathways, and vice versa. A maximum likelihood cost function allows this scheme to be 
Label: Neural Networks
Paper 7  Title: Rapid learning of binding-match and binding-error detector circuits via long-term potentiation  
Abstract: It is argued that the memorization of events and situations (episodic memory) requires the rapid formation of neural circuits responsive to binding errors and binding matches. While the formation of circuits responsive to binding matches can be modeled by associative learning mechanisms, the rapid formation of circuits responsive to binding errors is difficult to explain given their seem
Paper 8  Title: A Neural Network Model of Visual Tilt Aftereffects  
Abstract: RF-LISSOM, a self-organizing model of laterally connected orientation maps in the primary visual cortex, was used to study the psychological phenomenon known as the tilt aftereffect. The same self-organizing processes that are responsible for the long-term development of the map and its lateral connections are shown to result in tilt aftereffects over short time scales in the adult. The 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 2647...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Dynamic programming provides a methodology to develop planners and controllers for nonlinear systems. However, general dynamic programming is computationally intractable. We have developed procedures that allow more complex planning and control problems to be solved. We use second order local trajectory optimization to generate locally optimal plans and local models of the value function and its derivatives. We maintain global consistency of the local models of the value function, guaranteeing that our locally optimal plans are actually globally optimal, up to the resolution of our search procedures.
Title: Title: Using Local Trajectory Optimizers To Speed Up Global Optimization In Dynamic Programming  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Approximating Value Trees in Structured Dynamic Programming  
Abstract: We propose and examine a method of approximate dynamic programming for Markov decision processes based on structured problem representations. We assume an MDP is represented using a dynamic Bayesian network, and construct value functions using decision trees as our function representation. The size of the representation is kept within acceptable limits by pruning these value trees so tha
Paper 3  Title: Generalized Queries on Probabilistic Context-Free Grammars  on Pattern Analysis and Machine Intelligence  
Abstract: In this paper, we describe methods for efficiently computing better solutions to control problems in continuous state spaces. We provide algorithms that exploit online search to boost the power of very approximate value functions discovered by traditional reinforcement learning techniques. We examine local searches, where the agent performs a finite-depth lookahead search, and global sea
Paper 4  Title: Incremental methods for computing bounds in partially observable Markov decision processes  
Abstract: Partially observable Markov decision processes (POMDPs) allow one to model complex dynamic decision or control problems that include both action outcome uncertainty and imperfect observabil-ity. The control problem is formulated as a dynamic optimization problem with a value function combining costs or rewards from multiple steps. In this paper we propose, analyse and test various increm
Label: Reinforcement Learning
Paper 5  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract: We present a new approach to reinforcement learning in which the policies considered by the learning process are constrained by hierarchies of partially specified machines. This allows for the use of prior knowledge to reduce the search space and provides a framework in which knowledge can be transferred across problems and in which component solutions can be recombined to solve larger a
Paper 6  Title: Applying Online Search Techniques to Continuous-State Reinforcement Learning key to the success of the local
Abstract: In this paper, we describe methods for efficiently computing better solutions to control problems in continuous state spaces. We provide algorithms that exploit online search to boost the power of very approximate value functions discovered by traditional reinforcement learning techniques. We examine local searches, where the agent performs a finite-depth lookahead search, and global sea
Paper 7  Title: Spurious Solutions to the Bellman Equation  
Abstract: Reinforcement learning algorithms often work by finding functions that satisfy the Bellman equation. This yields an optimal solution for prediction with Markov chains and for controlling a Markov decision process (MDP) with a finite number of states and actions. This approach is also frequently applied to Markov chains and MDPs with infinite states. We show that, in this case, the Bellma
Paper 8  Title: Intelligent Gradient-Based Search of Incompletely Defined Design Spaces  
Abstract: Gradient-based numerical optimization of complex engineering designs offers the promise of rapidly producing better designs. However, such methods generally assume that the objective function and constraint functions are continuous, smooth, and defined everywhere. Unfortunately, realistic simulators tend to violate these assumptions. We present a rule-based technique for intelligently co
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 335...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper outlines some problems that may occur with Reduced Error Pruning in relational learning algorithms, most notably efficiency. Thereafter a new method, Incremental Reduced Error Pruning, is proposed that attempts to address all of these problems. Experiments show that in many noisy domains this method is much more efficient than alternative algorithms, along with a slight gain in accuracy. However, the experiments show as well that the use of the algorithm cannot be recommended for domains which require a very specific concept description.
Title: Title: Incremental Reduced Error Pruning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Incremental Reduced Error Pruning  
Abstract: This paper outlines some problems that may occur with Reduced Error Pruning in Inductive Logic Programming, most notably efficiency. Thereafter a new method, Incremental Reduced Error Pruning, is proposed that attempts to address all of these problems. Experiments show that in many noisy domains this method is much more efficient than alternative algorithms, along with a slight gain in a
Paper 3  Title: More Efficient Windowing  
Abstract: Windowing has been proposed as a procedure for efficient memory use in the ID3 decision tree learning algorithm. However, previous work has shown that windowing may often lead to a decrease in performance. In this work, we try to argue that separate-and-conquer rule learning algorithms are more appropriate for windowing than divide-and-conquer algorithms, because they learn rules indepen
Paper 4  Title: Top-Down Pruning in Relational Learning  
Abstract: Pruning is an effective method for dealing with noise in Machine Learning. Recently pruning algorithms, in particular Reduced Error Pruning, have also attracted interest in the field of Inductive Logic Programming. However, it has been shown that these methods can be very inefficient, because most of the time is wasted for generating clauses that explain noisy examples and subsequently p
Paper 5  Title: Instance Pruning Techniques  
Abstract: The nearest neighbor algorithm and its derivatives are often quite successful at learning a concept from a training set and providing good generalization on subsequent input vectors. However, these techniques often retain the entire training set in memory, resulting in large memory requirements and slow execution speed, as well as a sensitivity to noise. This paper provides a discussion 
Paper 6  Title: Fossil: A Robust Relational Learner  
Abstract: The research reported in this paper describes Fossil, an ILP system that uses a search heuristic based on statistical correlation. This algorithm implements a new method for learning useful concepts in the presence of noise. In contrast to Foil's stopping criterion, which allows theories to grow in complexity as the size of the training sets increases, we propose a new stopping criterion
Paper 7  Title: The Utility of Feature Weighting in Nearest-Neighbor Algorithms  
Abstract: Nearest-neighbor algorithms are known to depend heavily on their distance metric. In this paper, we investigate the use of a weighted Euclidean metric in which the weight for each feature comes from a small set of options. We describe Diet, an algorithm that directs search through a space of discrete weights using cross-validation error as its evaluation function. Although a large set of
Paper 8  Title: Rule Induction with CN2: Some Recent Improvements  
Abstract: The CN2 algorithm induces an ordered list of classification rules from examples using entropy as its search heuristic. In this short paper, we describe two improvements to this algorithm. Firstly, we present the use of the Laplacian error estimate as an alternative evaluation function and secondly, we show how unordered as well as ordered rules can be generated. We experimentally demonst
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 815...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The application of adaptive optimization strategies to scheduling in manufacturing systems has recently become a research topic of broad interest. Population based approaches to scheduling predominantly treat static data models, whereas real-world scheduling tends to be a dynamic problem. This paper briefly outlines the application of a genetic algorithm to the dynamic job shop problem arising in production scheduling. First we sketch a genetic algorithm which can handle release times of jobs. In a second step a preceding simulation method is used to improve the performance of the algorithm. Finally the job shop is regarded as a nondeterministic optimization problem arising from the occurrence of job releases. Temporal Decomposition leads to a scheduling control that interweaves both simulation in time and genetic search.
Title: Title: Genetic Algorithm based Scheduling in a Dynamic Manufacturing Environment  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Value Function Based Production Scheduling  
Abstract: Production scheduling, the problem of sequentially configuring a factory to meet forecasted demands, is a critical problem throughout the manufacturing industry. The requirement of maintaining product inventories in the face of unpredictable demand and stochastic factory output makes standard scheduling models, such as job-shop, inadequate. Currently applied algorithms, such as simulated
Paper 3  Title: An evolutionary tabu search algorithm and the NHL scheduling problem  
Abstract: We present in this paper a new evolutionary procedure for solving general optimization problems that combines efficiently the mechanisms of genetic algorithms and tabu search. In order to explore the solution space properly interaction phases are interspersed with periods of optimization in the algorithm. An adaptation of this search principle to the National Hockey League (NHL) problem 
Paper 4  Title: On Genetic Programming of Fuzzy Rule-Based Systems for Intelligent Control  
Abstract: Fuzzy logic and evolutionary computation have proven to be convenient tools for handling real-world uncertainty and designing control systems, respectively. An approach is presented that combines attributes of these paradigms for the purpose of developing intelligent control systems. The potential of the genetic programming paradigm (GP) for learning rules for use in fuzzy logic controll
Paper 5  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract: In the field of Operation Research and Artificial Intelligence, several stochastic search algorithms have been designed based on the theory of global random search (Zhigljavsky 1991). Basically, those techniques iteratively sample the search space with respect to a probability distribution which is updated according to the result of previous samples and some predefined strategy. Genetic 
Paper 6  Title: Solving Combinatorial Optimization Tasks by Reinforcement Learning: A General Methodology Applied to Resource-Constrained Scheduling  
Abstract: This paper introduces a methodology for solving combinatorial optimization problems through the application of reinforcement learning methods. The approach can be applied in cases where several similar instances of a combinatorial optimization problem must be solved. The key idea is to analyze a set of "training" problem instances and learn a search control policy for solving new problem
Paper 7  Title: A Genetic Algorithm for Continuous Design Space Search  
Abstract: Genetic algorithms (GAs) have been extensively used as a means for performing global optimization in a simple yet reliable manner. However, in some realistic engineering design optimization domains the simple, classical implementation of a GA based on binary encoding and bit mutation and crossover is often inefficient and unable to reach the global optimum. In this paper we describe a GA
Label: Genetic Algorithms
Paper 8  Title: AN APPROACH TO A PROBLEM IN NETWORK DESIGN USING GENETIC ALGORITHMS  
Abstract: Air Traffic Control is involved in the real-time planning of aircraft trajectories. This is a heavily constrained optimization problem. We concentrate on free-route planning, in which aircraft are not required to fly over way points. The choice of a proper representation for this real-world problem is non-trivial. We propose a two level representation: one level on which the evolutionary
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1841...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Reinforcement learning (RL) algorithms provide a sound theoretical basis for building learning control architectures for embedded agents. Unfortunately all of the theory and much of the practice (see Barto et al., 1983, for an exception) of RL is limited to Marko-vian decision processes (MDPs). Many real-world decision tasks, however, are inherently non-Markovian, i.e., the state of the environment is only incompletely known to the learning agent. In this paper we consider only partially observable MDPs (POMDPs), a useful class of non-Markovian decision processes. Most previous approaches to such problems have combined computationally expensive state-estimation techniques with learning control. This paper investigates learning in POMDPs without resorting to any form of state estimation. We present results about what TD(0) and Q-learning will do when applied to POMDPs. It is shown that the conventional discounted RL framework is inadequate to deal with POMDPs. Finally we develop a new framework for learning without state-estimation in POMDPs by including stochastic policies in the search space, and by defining the value or utility of a dis tribution over states.
Title: Title: Learning Without State-Estimation in Partially Observable Markovian Decision Processes  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems  
Abstract: Increasing attention has been paid to reinforcement learning algorithms in recent years, partly due to successes in the theoretical analysis of their behavior in Markov environments. If the Markov assumption is removed, however, neither generally the algorithms nor the analyses continue to be usable. We propose and analyze a new learning algorithm to solve a certain class of non-Markov d
Paper 3  Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  
Abstract: The problem of maximizing the expected total discounted reward in a completely observable Markovian environment, i.e., a Markov decision process (mdp), models a particular class of sequential decision problems. Algorithms have been developed for making optimal decisions in mdps given either an mdp specification or the opportunity to interact with the mdp over time. Recently, other sequen
Label: Reinforcement Learning
Paper 4  Title: Approximating Optimal Policies for Partially Observable Stochastic Domains  
Abstract: The problem of making optimal decisions in uncertain conditions is central to Artificial Intelligence. If the state of the world is known at all times, the world can be modeled as a Markov Decision Process (MDP). MDPs have been studied extensively and many methods are known for determining optimal courses of action, or policies. The more realistic case where state information is only par
Paper 5  Title: Parallel Search for Neural Network  Under the guidance of  
Abstract: The problem of making optimal decisions in uncertain conditions is central to Artificial Intelligence. If the state of the world is known at all times, the world can be modeled as a Markov Decision Process (MDP). MDPs have been studied extensively and many methods are known for determining optimal courses of action, or policies. The more realistic case where state information is only par
Paper 6  Title: Connectionist Modeling of the Fast Mapping Phenomenon  
Abstract: The problem of making optimal decisions in uncertain conditions is central to Artificial Intelligence. If the state of the world is known at all times, the world can be modeled as a Markov Decision Process (MDP). MDPs have been studied extensively and many methods are known for determining optimal courses of action, or policies. The more realistic case where state information is only par
Paper 7  Title: TD Models: Modeling the World at a Mixture of Time Scales  
Abstract: Temporal-difference (TD) learning can be used not just to predict rewards, as is commonly done in reinforcement learning, but also to predict states, i.e., to learn a model of the world's dynamics. We present theory and algorithms for intermixing TD models of the world at different levels of temporal abstraction within a single structure. Such multi-scale TD models can be used in model-b
Paper 8  Title: Between MDPs and Semi-MDPs: Learning, Planning, and Representing Knowledge at Multiple Temporal Scales  
Abstract: Learning, planning, and representing knowledge at multiple levels of temporal abstraction are key challenges for AI. In this paper we develop an approach to these problems based on the mathematical framework of reinforcement learning and Markov decision processes (MDPs). We extend the usual notion of action to include options|whole courses of behavior that may be temporally extended, sto
Label: Reinforcement Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 658...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Simple modification of standard hill climbing optimization algorithm by taking into account learning features is discussed. Basic concept of this approach is the socalled probability vector, its single entries determine probabilities of appearance of '1' entries in n-bit vectors. This vector is used for the random generation of n-bit vectors that form a neighborhood (specified by the given probability vector). Within the neighborhood a few best solutions (with smallest functional values of a minimized function) are recorded. The feature of learning is introduced here so that the probability vector is updated by a formal analogue of Hebbian learning rule, well-known in the theory of artificial neural networks. The process is repeated until the probability vector entries are close either to zero or to one. The resulting probability vector unambiguously determines an n-bit vector which may be interpreted as an optimal solution of the given optimization task. Resemblance with genetic algorithms is discussed. Effectiveness of the proposed method is illustrated by an example of looking for global minima of a highly multimodal function. 
Title: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Towards Automatic Discovery of Building Blocks in Genetic Programming  
Abstract: This paper presents an algorithm for the discovery of building blocks in genetic programming (GP) called adaptive representation through learning (ARL). The central idea of ARL is the adaptation of the problem representation, by extending the set of terminals and functions with a set of evolvable subroutines. The set of subroutines extracts common knowledge emerging during the evolutiona
Paper 3  Title: Genetic Programming and Redundancy  
Abstract: The Genetic Programming optimization method (GP) elaborated by John Koza [ Koza, 1992 ] is a variant of Genetic Algorithms. The search space of the problem domain consists of computer programs represented as parse trees, and the crossover operator is realized by an exchange of subtrees. Empirical analyses show that large parts of those trees are never used or evaluated which means that t
Paper 4  Title: 21 Using n 2 classifier in constructive induction  
Abstract: In this paper, we propose a multi-classification approach for constructive induction. The idea of an improvement of classification accuracy is based on iterative modification of input data space. This process is independently repeated for each pair of n classes. Finally, it gives (n 2 n)/2 input data subspaces of attributes dedicated for optimal discrimination of appropriate pairs of cla
Label: Theory
Paper 5  Title: Optimal Mutation Rates in Genetic Search  
Abstract: The optimization of a single bit string by means of iterated mutation and selection of the best (a (1+1)-Genetic Algorithm) is discussed with respect to three simple fitness functions: The counting ones problem, a standard binary encoded integer, and a Gray coded integer optimization problem. A mutation rate schedule that is optimal with respect to the success probability of mutation is 
Paper 6  Title: Control of Parallel Population Dynamics by Social-Like Behavior of GA-Individuals  
Abstract: A frequently observed difficulty in the application of genetic algorithms to the domain of optimization arises from premature convergence. In order to preserve genotype diversity we develop a new model of auto-adaptive behavior for individuals. In this model a population member is an active individual that assumes social-like behavior patterns. Different individuals living in the same po
Paper 7  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Paper 8  Title: A Generalized Permutation Approach to Job Shop Scheduling with Genetic Algorithms  
Abstract: In order to sequence the tasks of a job shop problem (JSP) on a number of machines related to the technological machine order of jobs, a new representation technique mathematically known as "permutation with repetition" is presented. The main advantage of this single chromosome representation is in analogy to the permutation scheme of the traveling salesman problem (TSP) that it cannot p
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1733...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We provide a generic Monte Carlo method to find the alternative of maximum expected utility in a decision analysis. We define an artificial distribution on the product space of alternatives and states, and show that the optimal alternative is the mode of the implied marginal distribution on the alternatives. After drawing a sample from the artificial distribution, we may use exploratory data analysis tools to approximately identify the optimal alternative. We illustrate our method for some important types of influence diagrams. (Decision Analysis, Influence Diagrams, Markov chain Monte Carlo, Simulation) 
Title: Title: Decision Analysis by Augmented Probability Simulation  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Chaos, Fractals, and Genetic Algorithms  
Abstract: This paper presents exact solutions and convergent approximations for inferences in Bayesian networks associated with finitely generated convex sets of distributions. Robust Bayesian inference is the calculation of bounds on posterior values given perturbations in a probabilistic model. The paper presents exact inference algorithms and analyzes the circumstances where exact inference bec
Label: Genetic Algorithms
Paper 3  Title: Maximum Working Likelihood Inference with Markov Chain Monte Carlo  
Abstract: Maximum working likelihood (MWL) inference in the presence of missing data can be quite challenging because of the intractability of the associated marginal likelihood. This problem can be further exacerbated when the number of parameters involved is large. We propose using Markov chain Monte Carlo (MCMC) to first obtain both the MWL estimator and the working Fisher information matrix an
Label: Probabilistic Methods
Paper 4  Title: Estimating Bayes Factors via Posterior Simulation with the Laplace-Metropolis Estimator  
Abstract: The key quantity needed for Bayesian hypothesis testing and model selection is the marginal likelihood for a model, also known as the integrated likelihood, or the marginal probability of the data. In this paper we describe a way to use posterior simulation output to estimate marginal likelihoods. We describe the basic Laplace-Metropolis estimator for models without random effects. For m
Label: Probabilistic Methods
Paper 5  Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  
Abstract: New methodology for fully Bayesian mixture analysis is developed, making use of reversible jump Markov chain Monte Carlo methods, that are capable of jumping between the parameter subspaces corresponding to different numbers of components in the mixture. A sample from the full joint distribution of all unknown variables is thereby generated, and this can be used as a basis for a thorough
Paper 6  Title: Robustness Analysis of Bayesian Networks with Finitely Generated Convex Sets of Distributions  
Abstract: This paper presents exact solutions and convergent approximations for inferences in Bayesian networks associated with finitely generated convex sets of distributions. Robust Bayesian inference is the calculation of bounds on posterior values given perturbations in a probabilistic model. The paper presents exact inference algorithms and analyzes the circumstances where exact inference bec
Label: Probabilistic Methods
Paper 7  Title: Markov Chain Monte Carlo Model Determination for Hierarchical and Graphical Log-linear Models  
Abstract: The Bayesian approach to comparing models involves calculating the posterior probability of each plausible model. For high-dimensional contingency tables, the set of plausible models is very large. We focus attention on reversible jump Markov chain Monte Carlo (Green, 1995) and develop strategies for calculating posterior probabilities of hierarchical, graphical or decomposable log-linea
Label: Probabilistic Methods
Paper 8  Title: Adaptive Markov Chain Monte Carlo through Regeneration  Summary  
Abstract: Markov chain Monte Carlo (MCMC) is used for evaluating expectations of functions of interest under a target distribution . This is done by calculating averages over the sample path of a Markov chain having as its stationary distribution. For computational efficiency, the Markov chain should be rapidly mixing. This can sometimes be achieved only by careful design of the transition kernel 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 2597...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Instance-based learning techniques typically handle continuous and linear input values well, but often do not handle nominal input attributes appropriately. The Value Difference Metric (VDM) was designed to find reasonable distance values between nominal attribute values, but it largely ignores continuous attributes, requiring discretization to map continuous values into nominal values. This paper proposes three new heterogeneous distance functions, called the Heterogeneous Value Difference Metric (HVDM), the Interpolated Value Difference Metric (IVDM), and the Windowed Value Difference Metric (WVDM). These new distance functions are designed to handle applications with nominal attributes, continuous attributes, or both. In experiments on 48 applications the new distance metrics achieve higher classification accuracy on average than three previous distance functions on those datasets that have both nominal and continuous attributes.
Title: Title: Improved Heterogeneous Distance Functions  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Optimal Weighting Criterion of Case Indexing for Both Numeric and Symbolic Attributes  
Abstract: Indexing of cases is an important topic for Memory-Based Reasoning(MBR). One key problem is how to assign weights to attributes of cases. Although several weighting methods have been proposed, some methods cannot handle numeric attributes directly, so it is necessary to discretize numeric values by classification. Furthermore, existing methods have no theoretical background, so little ca
Label: Case Based
Paper 3  Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  
Abstract: In the past, nearest neighbor algorithms for learning from examples have worked best in domains in which all features had numeric values. In such domains, the examples can be treated as points and distance metrics can use standard definitions. In symbolic domains, a more sophisticated treatment of the feature space is required. We introduce a nearest neighbor algorithm for learning in do
Paper 4  Title: AN EFFICIENT METRIC FOR HETEROGENEOUS INDUCTIVE LEARNING APPLICATIONS IN THE ATTRIBUTE-VALUE LANGUAGE 1  
Abstract: Many inductive learning problems can be expressed in the classical attribute-value language. In order to learn and to generalize, learning systems often rely on some measure of similarity between their current knowledge base and new information. The attribute-value language defines a heterogeneous multidimensional input space, where some attributes are nominal and others linear. Defining
Label: Case Based
Paper 5  Title: Continuous-valued Xof-N Attributes Versus Nominal Xof-N Attributes for Constructive Induction: A Case Study  
Abstract: An Xof-N is a set containing one or more attribute-value pairs. For a given instance, its value corresponds to the number of its attribute-value pairs that are true. In this paper, we explore the characteristics and performance of continuous-valued Xof-N attributes versus nominal Xof-N attributes for constructive induction. Nominal Xof-Ns are more representationally powerful than continu
Paper 6  Title: A Review and Empirical Evaluation of Feature Weighting Methods for a Class of Lazy Learning Algorithms  
Abstract: Many lazy learning algorithms are derivatives of the k-nearest neighbor (k-NN) classifier, which uses a distance function to generate predictions from stored instances. Several studies have shown that k-NN's performance is highly sensitive to the definition of its distance function. Many k-NN variants have been proposed to reduce this sensitivity by parameterizing the distance function w
Paper 7  Title: Supervised and Unsupervised Discretization of Continuous Features  
Abstract: Many supervised machine learning algorithms require a discrete feature space. In this paper, we review previous work on continuous feature discretization, identify defining characteristics of the methods, and conduct an empirical evaluation of several methods. We compare binning, an unsupervised discretization method, to entropy-based and purity-based methods, which are supervised algori
Label: Theory
Paper 8  Title: Constructing Nominal Xof-N Attributes  
Abstract: Most constructive induction researchers focus only on new boolean attributes. This paper reports a new constructive induction algorithm, called XofN, that constructs new nominal attributes in the form of Xof-N representations. An Xof-N is a set containing one or more attribute-value pairs. For a given instance, its value corresponds to the number of its attribute-value pairs that are tru
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 11...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper presents an evolutionary approach to finding learning rules to several supervised tasks. In this approach potential solutions are represented as variable length mathematical LISP S-expressions. Thus, it is similar to Genetic Programming (GP) but it employs a fixed set of non-problem-specific functions to solve a variety of problems. In this paper three Monk's and parity problems are tested. The results indicate the usefulness of the encoding schema in discovering learning rules for supervised learning problems with the emphasis on hard learning problems. The problems and future research directions are discussed within the context of GP practices. 
Title: Title: Simple Genetic Programming for Supervised Learning Problems  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Evolving Compact Solutions in Genetic Programming: A Case Study  
Abstract: Genetic programming (GP) is a variant of genetic algorithms where the data structures handled are trees. This makes GP especially useful for evolving functional relationships or computer programs, as both can be represented as trees. Symbolic regression is the determination of a function dependence y = g(x) that approximates a set of data points (x i ; y i ). In this paper the feasibilit
Label: Genetic Algorithms
Paper 3  Title: "What is the best thing to do right now?": getting beyond greedy exploration  
Abstract: Genetic programming is a methodology for program development, consisting of a special form of genetic algorithm capable of handling parse trees representing programs, that has been successfully applied to a variety of problems. In this paper a new approach to the construction of neural networks based on genetic programming is presented. A linear chromosome is combined to a graph represen
Paper 4  Title: Knowledge-Based Genetic Learning  
Abstract: Genetic algorithms have been proven to be a powerful tool within the area of machine learning. However, there are some classes of problems where they seem to be scarcely applicable, e.g. when the solution to a given problem consists of several parts that influence each other. In that case the classic genetic operators cross-over and mutation do not work very well thus preventing a good p
Paper 5  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Paper 6  Title: Towards Automatic Discovery of Building Blocks in Genetic Programming  
Abstract: This paper presents an algorithm for the discovery of building blocks in genetic programming (GP) called adaptive representation through learning (ARL). The central idea of ARL is the adaptation of the problem representation, by extending the set of terminals and functions with a set of evolvable subroutines. The set of subroutines extracts common knowledge emerging during the evolutiona
Paper 7  Title: Using generative models for handwritten digit recognition  
Abstract: Genetic Programming is a method of program discovery consisting of a special kind of genetic algorithm capable of operating on nonlinear chromosomes (parse trees) representing programs and an interpreter which can run the programs being optimised. This paper describes PDGP (Parallel Distributed Genetic Programming), a new form of genetic programming which is suitable for the development 
Label: Neural Networks
Paper 8  Title: Evolution of the Topology and the Weights of Neural Networks using Genetic Programming with a
Abstract: Genetic programming is a methodology for program development, consisting of a special form of genetic algorithm capable of handling parse trees representing programs, that has been successfully applied to a variety of problems. In this paper a new approach to the construction of neural networks based on genetic programming is presented. A linear chromosome is combined to a graph represen
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 728...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Traditionally, genetic algorithms have relied upon 1 and 2-point crossover operators. Many recent empirical studies, however, have shown the benefits of higher numbers of crossover points. Some of the most intriguing recent work has focused on uniform crossover, which involves on the average L/2 crossover points for strings of length L. Theoretical results suggest that, from the view of hyperplane sampling disruption, uniform crossover has few redeeming features. However, a growing body of experimental evidence suggests otherwise. In this paper, we attempt to reconcile these opposing views of uniform crossover and present a framework for understanding its virtues.
Title: Title: On the Virtues of Parameterized Uniform Crossover  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Adapting Crossover in a Genetic Algorithm  
Abstract: Traditionally, genetic algorithms have relied upon 1 and 2-point crossover operators. Many recent empirical studies, however, have shown the benefits of higher numbers of crossover points. Some of the most intriguing recent work has focused on uniform crossover, which involves on the average L/2 crossover points for strings of length L. Despite theoretical analysis, however, it appears d
Label: Genetic Algorithms
Paper 3  Title: A Comparison of Crossover and Mutation in Genetic Programming  
Abstract: This paper presents a large and systematic body of data on the relative effectiveness of mutation, crossover, and combinations of mutation and crossover in genetic programming (GP). The literature of traditional genetic algorithms contains related studies, but mutation and crossover in GP differ from their traditional counterparts in significant ways. In this paper we present the results
Label: Genetic Algorithms
Paper 4  Title: An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms  
Abstract: In this paper we present some theoretical and empirical results on the interacting roles of population size and crossover in genetic algorithms. We summarize recent theoretical results on the disruptive effect of two forms of multi-point crossover: n-point crossover and uniform crossover. We then show empirically that disruption analysis alone is not sufficient for selecting appropriate 
Paper 5  Title: Crossover or Mutation?  
Abstract: Genetic algorithms rely on two genetic operators crossover and mutation. Although there exists a large body of conventional wisdom concerning the roles of crossover and mutation, these roles have not been captured in a theoretical fashion. For example, it has never been theoretically shown that mutation is in some sense "less powerful" than crossover or vice versa. This paper provides so
Paper 6  Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Abstract: Holland's analysis of the sources of power of genetic algorithms has served as guidance for the applications of genetic algorithms for more than 15 years. The technique of applying a recombination operator (crossover) to a population of individuals is a key to that power. Neverless, there have been a number of contradictory results concerning crossover operators with respect to overall p
Label: Genetic Algorithms
Paper 7  Title: Issues in Using Function Approximation for Reinforcement Learning  
Abstract: Reinforcement learning techniques address the problem of learning to select actions in unknown, dynamic environments. It is widely acknowledged that to be of use in complex domains, reinforcement learning techniques must be combined with generalizing function approximation methods such as artificial neural networks. Little, however, is understood about the theoretical properties of such 
Paper 8  Title: Performance Enhanced Genetic Programming  
Abstract: Genetic Programming is increasing in popularity as the basis for a wide range of learning algorithms. However, the technique has to date only been successfully applied to modest tasks because of the performance overheads of evolving a large number of data structures, many of which do not correspond to a valid program. We address this problem directly and demonstrate how the evolutionary 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2027...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Combinating reactivity with planning has been proposed as a means of compensating for potentially slow response times of planners while still making progress toward long term goals. The demands of rapid response and the complexity of many environments make it difficult to decompose, tune and coordinate reactive behaviors while ensuring consistency. Neural networks can address the tuning problem, but are less useful for decomposition and coordination. We hypothesize that interacting reactions can be decomposed into separate behaviors resident in separate networks and that the interaction can be coordinated through the tuning mechanism and a higher level controller. To explore these issues, we have implemented a neural network architecture as the reactive component of a two layer control system for a simulated race car. By varying the architecture, we test whether decomposing reactivity into separate behaviors leads to superior overall performance, coordination and learning convergence. 
Title: Title: Coordinating Reactive Behaviors  keywords: reactive systems, planning and learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: REINFORCEMENT LEARNING FOR COORDINATED REACTIVE CONTROL  
Abstract: The demands of rapid response and the complexity of many environments make it difficult to decompose, tune and coordinate reactive behaviors while ensuring consistency. Reinforcement learning networks can address the tuning problem, but do not address the problem of decomposition and coordination. We hypothesize that interacting reactions can often be decomposed into separate control tas
Paper 3  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract: We present a new approach to reinforcement learning in which the policies considered by the learning process are constrained by hierarchies of partially specified machines. This allows for the use of prior knowledge to reduce the search space and provides a framework in which knowledge can be transferred across problems and in which component solutions can be recombined to solve larger a
Paper 4  Title: Learning to coordinate without sharing information  
Abstract: Researchers in the field of Distributed Artificial Intelligence (DAI) have been developing efficient mechanisms to coordinate the activities of multiple autonomous agents. The need for coordination arises because agents have to share resources and expertise required to achieve their goals. Previous work in the area includes using sophisticated information exchange protocols, investigatin
Paper 5  Title: A Model for Projection and Action  
Abstract: In designing autonomous agents that deal competently with issues involving time and space, there is a tradeoff to be made between guaranteed response-time reactions on the one hand, and flexibility and expressiveness on the other. We propose a model of action with probabilistic reasoning and decision analytic evaluation for use in a layered control architecture. Our model is well suited 
Paper 6  Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  
Abstract: Mixed-initiative systems present the challenge of finding an effective level of interaction between humans and computers. Machine learning presents a promising approach to this problem in the form of systems that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive assistant for crisis sched
Paper 7  Title: Emergent Hierarchical Control Structures: Learning Reactive/Hierarchical Relationships in Reinforcement Environments  
Abstract: The use of externally imposed hierarchical structures to reduce the complexity of learning control is common. However, it is acknowledged that learning the hierarchical structure itself is an important step towards more general (learning of many things as required) and less bounded (learning of a single thing as specified) learning. Presented in this paper is a reinforcement learning alg
Paper 8  Title: Learning Hierarchical Control Structures for Multiple Tasks and Changing Environments  
Abstract: While the need for hierarchies within control systems is apparent, it is also clear to many researchers that such hierarchies should be learned. Learning both the structure and the component behaviors is a difficult task. The benefit of learning the hierarchical structures of behaviors is that the decomposition of the control structure into smaller transportable chunks allows previously 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 46...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: In IEEE Transactions on Neural Networks, 7(1):97-106, 1996 Also available as GMD report #794 
Title: Title: The Pandemonium System of Reflective Agents  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning from Examples, Agent Teams and the Concept of Reflection  
Abstract: In International Journal of Pattern Recognition and AI, 10(3):251-272, 1996 Also available as GMD report #766 
Label: Neural Networks
Paper 3  Title: The Role of Development in Genetic Algorithms  
Abstract: A Genetic Algorithm Tutorial Darrell Whitley Technical Report CS-93-103 (Revised) November 10, 1993 
Paper 4  Title: What should be minimized in a decision tree: A re-examination  
Abstract: Computer Science Department University of Massachusetts at Amherst CMPSCI Technical Report 95-20 September 6, 1995 
Paper 5  Title: Extended Selection Mechanisms in Genetic Algorithms  
Abstract: A Genetic Algorithm Tutorial Darrell Whitley Technical Report CS-93-103 (Revised) November 10, 1993 
Paper 6  Title: Experiments with the Cascade-Correlation Algorithm  
Abstract: Technical Report # 91-16 July 1991; Revised August 1991 
Paper 7  Title: Neural Learning of Chaotic Dynamics: The Error Propagation Algorithm trains a neural network to identify
Abstract: Technical Report UMIACS-TR-97-77 and CS-TR-3843 Abstract 
Paper 8  Title: The Design and Evaluation of a Rule Induction Algorithm  
Abstract: technical report BYU-CS-93-11 June 1993 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 833...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper presents the results of an experimental investigation on solving graph coloring problems with Evolutionary Algorithms (EA). After testing different algorithm variants we conclude that the best option is an asexual EA using order-based representation and an adaptation mechanism that periodically changes the fitness function during the evolution. This adaptive EA is general, using no domain specific knowledge, except, of course, from the decoder (fitness function). We compare this adaptive EA to a powerful traditional graph coloring technique DSatur and the Grouping GA on a wide range of problem instances with different size, topology and edge density. The results show that the adaptive EA is superior to the Grouping GA and outperforms DSatur on the hardest problem instances. Furthermore, it scales up better with the problem size than the other two algorithms and indicates a linear computational complexity. 
Title: Title: Graph Coloring with Adaptive Evolutionary Algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Feature Selection Methods: Genetic Algorithms vs. Greedy-like Search  
Abstract: This paper presents a comparison between two feature selection methods, the Importance Score (IS) which is based on a greedy-like search and a genetic algorithm-based (GA) method, in order to better understand their strengths and limitations and their area of application. The results of our experiments show a very strong relation between the nature of the data and the behavior of both sy
Paper 3  Title: An Evolutionary Approach to Combinatorial Optimization Problems  
Abstract: The paper reports on the application of genetic algorithms, probabilistic search algorithms based on the model of organic evolution, to NP-complete combinatorial optimization problems. In particular, the subset sum, maximum cut, and minimum tardy task problems are considered. Except for the fitness function, no problem-specific changes of the genetic algorithm are required in order to ac
Paper 4  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Paper 5  Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Abstract: Genetic algorithms have been used for neural networks in two main ways: to optimize the network architecture and to train the weights of a fixed architecture. While most previous work focuses on only one of these two options, this paper investigates an alternative evolutionary approach called Breeder Genetic Programming (BGP) in which the architecture and the weights are optimized simult
Paper 6  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Label: Genetic Algorithms
Paper 7  Title: Genetic algorithms with multi-parent recombination  
Abstract: In this paper we investigate genetic algorithms where more than two parents are involved in the recombination operation. In particular, we introduce gene scanning as a reproduction mechanism that generalizes classical crossovers, such as n-point crossover or uniform crossover, and is applicable to an arbitrary number (two or more) of parents. We performed extensive tests for optimizing n
Paper 8  Title: Incremental Co-evolution of Organisms: A New Approach for Optimization and Discovery of Strategies  
Abstract: In the field of optimization and machine learning techniques, some very efficient and promising tools like Genetic Algorithms (GAs) and Hill-Climbing have been designed. In this same field, the Evolving Non-Determinism (END) model presented in this paper proposes an inventive way to explore the space of states that, using the simulated "incremental" co-evolution of some organisms, remedi
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1021...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Here we show a similar construction for multiple-output systems, with some modifications. Let = (A; B; C) s be a discrete-time sign-linear system with state space IR n and p outputs. Perform a change of ; where A 1 (n 1 fi n 1 ) is invertible and A 2 (n 2 fi n 2 ) is nilpotent. If (A; B) is a reachable pair and (A; C) is an observable pair, then is minimal in the sense that any other sign-linear system with the same input/output behavior has dimension at least n. But, if n 1 &lt; n, then det A = 0 and is not observable and hence not canonical. Let us find another system ~ (necessarily not sign-linear) which has the same input/output behavior as , but is canonical. Let i be the relative degree of the ith row of the Markov sequence A, and = minf i : i = 1; : : : ; pg. Let the initial state be x. There is a difference between the case when the smallest relative degree is greater or equal to n 2 and the case when &lt; n 2 . Roughly speaking, when n 2 the outputs of the sign-linear system give us information about sign (Cx), sign (CAx), : : : , sign (CA 1 x), which are the first outputs of the sys tem. After that, we can use the inputs and outputs to learn only about x 1 (the first n 1 components of x). When &lt; n 2 , we may be able to use some controls to learn more about x 2 (the last n 2 components of x) before time n 2 when the nilpotency of A 2 has finally Lemma 2.4 Two states x and z are indistinguishable for if and only if (x) = (z). Proof. In the case n 2 , we have only the equations x 1 = z 1 and the equality of the 's. The first ` output terms for are exactly the terms of . So these equalities are satisfied if and only if the first ` output terms coincide for x and z, for any input. Equality of everything but the first n 1 components is equivalent to the first n 2 output terms coinciding for x and z, since the jth row of the qth output, for initial state x, for example, is either sign (c j A q x) if j &gt; q, or sign (c j A q x + + A j j u q j +1 + ) if j q in which case we may use the control u q j +1 to identify c j A q x (using Remark 3.3 in [1]). 
Title: Title: Lemma 2.3 The system is reachable and observable and realizes the same input/output behavior as
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Inserting the best known bounds for weighted bipar tite matching [11], with 1=2 p polynomial-time
Abstract: we apply the reduction to their two core children, the total sum of their matching weights becomes O(n), and if for each comparison of a spine node and a critical node we apply the reduction to the core child of the spine node, the total sum of their matching weights becomes O(n). With regards to the O( 2 ) comparisons of two critical nodes, their sum cannot exceed O( 2 n) in total weigh
Label: Theory
Paper 3  Title: 82 Lag-space estimation in time-series modelling keep track of cases where the estimation of P
Abstract: When m = 0 (no delays), we set A 0 (ffi) = f(j; k) ; j 6= kg, such that P m (*jffi) depends only on *. The estimated probabilities above become quite noisy when the number of elements in set A m and B m are small. For this reason, we estimate the standard deviation of P m (*jffi). Notice that this estimate is the empirical average of a binomial variable (either a given couple satisfied t
Paper 4  Title: ABSTRACTION CONSIDERED HARMFUL: LAZY LEARNING OF LANGUAGE PROCESSING  
Abstract: When m = 0 (no delays), we set A 0 (ffi) = f(j; k) ; j 6= kg, such that P m (*jffi) depends only on *. The estimated probabilities above become quite noisy when the number of elements in set A m and B m are small. For this reason, we estimate the standard deviation of P m (*jffi). Notice that this estimate is the empirical average of a binomial variable (either a given couple satisfied t
Paper 5  Title: j  
Abstract: So applying Corollary 4.3 to the second equation in (47), we conclude that From (38), we then get jg(y n + ~ k( y (51), we obtain jy n + ~ k( From (39) we see that the right-hand side of (54) is bounded by . Since the system _ y = A 1 y k( y )b 2 jyj ev N : (55) Now, suppose lim sup t!1 jy(t)j = &gt; 0. Then jyj ev 2. Since j k(y)j Ljyj, we have and using (56) and (57), we obtain j~yj ev
Paper 6  Title: A Computer Scientist's View of Life, the Universe, and Everything  
Abstract: Is the universe computable? If so, it may be much cheaper in terms of information requirements to compute all computable universes instead of just ours. I apply basic concepts of Kolmogorov complexity theory to the set of possible universes, and chat about perceived and true randomness, life, generalization, and learning in a given universe. Assumptions. A long time ago, the Great Progra
Label: Reinforcement Learning
Paper 7  Title: NP-Completeness of Searches for Smallest Possible Feature Sets a subset of the set of all
Abstract: In many learning problems, the learning system is presented with values for features that are actually irrelevant to the concept it is trying to learn. The FOCUS algorithm, due to Almuallim and Dietterich, performs an explicit search for the smallest possible input feature set S that permits a consistent mapping from the features in S to the output feature. The FOCUS algorithm can also b
Paper 8  Title: Vapnik-Chervonenkis entropy of the spherical perceptron  
Abstract: Perceptron learning of randomly labeled patterns is analyzed using a Gibbs distribution on the set of realizable labelings of the patterns. The entropy of this distribution is an extension of the Vapnik-Chervonenkis (VC) entropy, reducing to it exactly in the limit of infinite temperature. The close relationship between the VC and Gardner entropies can be seen within the replica formalis
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Theory
Prediction:  Theory
Is prediction correct?  False

Prediction: 0
Processing index 955...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model is closely related to the Harmonium model defined by Smolensky [RM86][Ch.6]. In the first part of the paper we analyze properties of this distribution representation scheme. We show that arbitrary distributions of binary vectors can be approximated by the combination model. We show how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits. We compare the combination model with the mixture model and with principle component analysis. In the second part of the paper we present two algorithms for learning the combination model from examples. The first algorithm is based on gradient ascent. Here we give a closed form for this gradient that is significantly easier to compute than the corresponding gradient for the general Boltzmann machine. The second learning algorithm is a greedy method that creates the hidden units and computes their weights one at a time. This method is a variant of projection pursuit density estimation. In the third part of the paper we give experimental results for these learning methods on synthetic data and on natural data of handwritten digit images. 
Title: Title: Separating Formal Bounds from Practical Performance in Learning Systems  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Unsupervised learning of distributions on binary vectors using two layer networks  
Abstract: We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model is closely related to the Harmonium model defined by Smolensky [RM86][Ch.6]. In the first part of the paper we analyze properties of this distribution representation scheme. We sho
Paper 3  Title: On the Learnability and Usage of Acyclic Probabilistic Finite Automata  
Abstract: We propose and analyze a distribution learning algorithm for a subclass of Acyclic Probabilistic Finite Automata (APFA). This subclass is characterized by a certain distinguishability property of the automata's states. Though hardness results are known for learning distributions generated by general APFAs, we prove that our algorithm can efficiently learn distributions generated by the s
Paper 4  Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,
Abstract: Although probabilistic inference in a general Bayesian belief network is an NP-hard problem, inference computation time can be reduced in most practical cases by exploiting domain knowledge and by making appropriate approximations in the knowledge representation. In this paper we introduce the property of similarity of states and a new method for approximate knowledge representation whic
Label: Theory
Paper 5  Title: Distribution Category:  Users Guide to the PGAPack Parallel Genetic Algorithm Library  
Abstract: The problem of modeling complicated data sequences, such as DNA or speech, often arises in practice. Most of the algorithms select a hypothesis from within a model class assuming that the observed sequence is the direct output of the underlying generation process. In this paper we consider the case when the output passes through a memoryless noisy channel before observation. In particula
Paper 6  Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  
Abstract: The work discussed in this paper is motivated by the need of building decision support systems for real-world problem domains. Our goal is to use these systems as a tool for supporting Bayes optimal decision making, where the action maximizing the expected utility, with respect to predicted probabilities of the possible outcomes, should be selected. For this reason, the models used need 
Paper 7  Title: Constructing Bayesian finite mixture models by the EM algorithm  
Abstract: Email: Firstname.Lastname@cs.Helsinki.FI Report C-1996-9, University of Helsinki, Department of Computer Science. Abstract In this paper we explore the use of finite mixture models for building decision support systems capable of sound probabilistic inference. Finite mixture models have many appealing properties: they are computationally efficient in the prediction (reasoning) phase, the
Paper 8  Title: Training Algorithms for Hidden Markov Models Using Entropy Based Distance Functions  
Abstract: We present new algorithms for parameter estimation of HMMs. By adapting a framework used for supervised learning, we construct iterative algorithms that maximize the likelihood of the observations while also attempting to stay close to the current estimated parameters. We use a bound on the relative entropy between the two HMMs as a distance measure between them. The result is new iterat
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 1528...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper presents a method for using qualitative models to guide inductive learning. Our objectives are to induce rules which are not only accurate but also explainable with respect to the qualitative model, and to reduce learning time by exploiting domain knowledge in the learning process. Such ex-plainability is essential both for practical application of inductive technology, and for integrating the results of learning back into an existing knowledge-base. We apply this method to two process control problems, a water tank network and an ore grinding process used in the mining industry. Surprisingly, in addition to achieving explainability the classificational accuracy of the induced rules is also increased. We show how the value of the qualitative models can be quantified in terms of their equivalence to additional training examples, and finally discuss possible extensions.
Title: Title: Using Qualitative Models to Guide Inductive Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Rule Generation and Compaction in the wwtp  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 3  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 4  Title: Constructing Intermediate Concepts by Decomposition of Real Functions  
Abstract: In learning from examples it is often useful to expand an attribute-vector representation by intermediate concepts. The usual advantage of such structuring of the learning problem is that it makes the learning easier and improves the comprehensibility of induced descriptions. In this paper, we develop a technique for discovering useful intermediate concepts when both the class and the at
Paper 5  Title: Lookahead and Discretization in ILP  
Abstract: We present and evaluate two methods for improving the performance of ILP systems. One of them is discretization of numerical attributes, based on Fayyad and Irani's text [9], but adapted and extended in such a way that it can cope with some aspects of discretization that only occur in relational learning problems (when indeterminate literals occur). The second technique is lookahead. It 
Paper 6  Title: Theory Revision in Fault Hierarchies  
Abstract: The fault hierarchy representation is widely used in expert systems for the diagnosis of complex mechanical devices. On the assumption that an appropriate bias for a knowledge representation language is also an appropriate bias for learning in this domain, we have developed a theory revision method that operates directly on a fault hierarchy. This task presents several challenges: A typi
Label: Theory
Paper 7  Title: FONN: Combining First Order Logic with Connectionist Learning  
Abstract: This paper presents a neural network architecture that can manage structured data and refine knowledge bases expressed in a first order logic language. The presented framework is well suited to classification problems in which concept de scriptions depend upon numerical features of the data. In fact, the main goal of the neural architecture is that of refining the numerical part of the k
Paper 8  Title: Cost-sensitive feature reduction applied to a hybrid genetic algorithm  
Abstract: This study is concerned with whether it is possible to detect what information contained in the training data and background knowledge is relevant for solving the learning problem, and whether irrelevant information can be eliminated in preprocessing before starting the learning process. A case study of data preprocessing for a hybrid genetic algorithm shows that the elimination of irrel
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 1434...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper demonstrates the capabilities of Foidl, an inductive logic programming (ILP) system whose distinguishing characteristics are the ability to produce first-order decision lists, the use of an output completeness assumption as a substitute for negative examples, and the use of intensional background knowledge. The development of Foidl was originally motivated by the problem of learning to generate the past tense of English verbs; however, this paper demonstrates its superior performance on two different sets of benchmark ILP problems. Tests on the finite element mesh design problem show that Foidl's decision lists enable it to produce generally more accurate results than a range of methods previously applied to this problem. Tests with a selection of list-processing problems from Bratko's introductory Prolog text demonstrate that the combination of implicit negatives and intensionality allow Foidl to learn correct programs from far fewer examples than Foil.
Title: Title: Advantages of Decision Lists and Implicit Negatives in Inductive Logic Programming  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: on Inductive Logic Programming (ILP-95) Inducing Logic Programs without Explicit Negative Examples  
Abstract: This paper presents a method for learning logic programs without explicit negative examples by exploiting an assumption of output completeness. A mode declaration is supplied for the target predicate and each training input is assumed to be accompanied by all of its legal outputs. Any other outputs generated by an incomplete program implicitly represent negative examples; however, large 
Label: Rule Learning
Paper 3  Title: Combining Top-down and Bottom-up Techniques in Inductive Logic Programming  
Abstract: This paper describes a new method for inducing logic programs from examples which attempts to integrate the best aspects of existing ILP methods into a single coherent framework. In particular, it combines a bottom-up method similar to Golem with a top-down method similar to Foil. It also includes a method for predicate invention similar to Champ and an elegant solution to the "noisy ora
Label: Rule Learning
Paper 4  Title: Knowledge Acquisition with a Knowledge-Intensive Machine Learning System  
Abstract: In this paper, we investigate the integration of knowledge acquisition and machine learning techniques. We argue that existing machine learning techniques can be made more useful as knowledge acquisition tools by allowing the expert to have greater control over and interaction with the learning process. We describe a number of extensions to FOCL (a multistrategy Horn-clause learning prog
Label: Rule Learning
Paper 5  Title: Natural Language Grammatical Inference with Recurrent Neural Networks  
Abstract: This paper examines the inductive inference of a complex grammar with neural networks specifically, the task considered is that of training a network to classify natural language sentences as grammatical or ungrammatical, thereby exhibiting the same kind of discriminatory power provided by the Principles and Parameters linguistic framework, or Government-and-Binding theory. Neural networ
Paper 6  Title: ILP with Noise and Fixed Example Size: A Bayesian Approach  
Abstract: Current inductive logic programming systems are limited in their handling of noise, as they employ a greedy covering approach to constructing the hypothesis one clause at a time. This approach also causes difficulty in learning recursive predicates. Additionally, many current systems have an implicit expectation that the cardinality of the positive and negative examples reflect the "prop
Paper 7  Title: Inductive Constraint Logic and the Mutagenesis Problem  
Abstract: A novel approach to learning first order logic formulae from positive and negative examples is incorporated in a system named ICL (Inductive Constraint Logic). In ICL, examples are viewed as interpretations which are true or false for the target theory, whereas in present inductive logic programming systems, examples are true and false ground facts (or clauses). Furthermore, ICL uses a c
Paper 8  Title: DISTRIBUTED GENETIC ALGORITHMS FOR PARTITIONING UNIFORM GRIDS  
Abstract: The fault hierarchy representation is widely used in expert systems for the diagnosis of complex mechanical devices. On the assumption that an appropriate bias for a knowledge representation language is also an appropriate bias for learning in this domain, we have developed a theory revision method that operates directly on a fault hierarchy. This task presents several challenges: A typi
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 2641...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We use a simulated evolution search (genetic programming) for the automatic synthesis of small iterative machine-language programs. For an integer register machine with an addition instruction as its sole arithmetic operator, we show that genetic programming can produce exact and general multiplication routines by synthesizing the necessary iterative control structures from primitive machine-language instructions. Our program representation is a virtual register machine that admits arbitrary control flow. Our evolution strategy furthermore does not artificially restrict the synthesis of any control structure; we only place an upper bound on program evaluation time. A program's fitness is the distance between the output produced by a test case and the desired output (multiplication). The test cases exhaustively cover multiplication over a finite subset of the natural numbers (N 10 ); yet the derived solutions constitute general multiplication for the positive integers. For this problem, simulated evolution with a two-point crossover operator examines significantly fewer individuals in finding a solution than random search. Introduction of a small rate of mutation fur ther increases the number of solutions.
Title: Title: Toward Simulated Evolution of Machine-Language Iteration  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning to Play Games From Experience: An Application of Artificial Neural Networks and Temporal Difference Learning  
Abstract: We use a simulated evolution search (genetic programming) for the automatic synthesis of small iterative machine-language programs. For an integer register machine with an addition instruction as its sole arithmetic operator, we show that genetic programming can produce exact and general multiplication routines by synthesizing the necessary iterative control structures from primitive mac
Label: Neural Networks
Paper 3  Title: Learning Recursive Sequences via Evolution of Machine-Language Programs  
Abstract: We use directed search techniques in the space of computer programs to learn recursive sequences of positive integers. Specifically, the integer sequences of squares, x 2 ; cubes, x 3 ; factorial, x!; and Fibonacci numbers are studied. Given a small finite prefix of a sequence, we show that three directed searches|machine-language genetic programming with crossover, exhaustive iterative 
Paper 4  Title: Evolving Turing-Complete Programs for a Register Machine with Self-modifying Code  
Abstract: The majority of commercial computers today are register machines of von Neumann type. We have developed a method to evolve Turing-complete programs for a register machine. The described implementation enables the use of most program constructs, such as arithmetic operators, large indexed memory, automatic decomposition into subfunctions and subroutines (ADFs), conditional constructs i.e.
Label: Genetic Algorithms
Paper 5  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Paper 6  Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  
Abstract: Genetic programming is distinguished from other evolutionary algorithms in that it uses tree representations of variable size instead of linear strings of fixed length. The flexible representation scheme is very important because it allows the underlying structure of the data to be discovered automatically. One primary difficulty, however, is that the solutions may grow too big without a
Paper 7  Title: Balancing Accuracy and Parsimony in Genetic Programming 1  
Abstract: Genetic programming is distinguished from other evolutionary algorithms in that it uses tree representations of variable size instead of linear strings of fixed length. The flexible representation scheme is very important because it allows the underlying structure of the data to be discovered automatically. One primary difficulty, however, is that the solutions may grow too big without a
Paper 8  Title: Inverting Implication with Small Training Sets  
Abstract: We present an algorithm for inducing recursive clauses using inverse implication (rather than inverse resolution) as the underlying generalization method. Our approach applies to a class of logic programs similar to the class of primitive recursive functions. Induction is performed using a small number of positive examples that need not be along the same resolution path. Our algorithm, i
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2648...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: An hypothesis of functional transfer of task knowledge is presented that requires the development of a measure of task relatedness and a method of sequential learning. The task rehearsal method (TRM) is introduced to address the issues of sequential learning, namely retention and transfer of knowledge. TRM is a knowledge based inductive learning system that uses functional domain knowledge as a source of inductive bias. The representations of successfully learned tasks are stored within domain knowledge. Virtual examples generated by domain knowledge are rehearsed in parallel with the each new task using either the standard multiple task learning (MTL) or the MTL neural network methods. The results of experiments conducted on a synthetic domain of seven tasks demonstrate the method's ability to retain and transfer task knowledge. TRM is shown to be effective in developing hypothesis for tasks that suffer from impoverished training sets. Difficulties encountered during sequential learning over the diverse domain reinforce the need for a more robust measure of task relatedness. 
Title: Title: The Task Rehearsal Method of Sequential Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The Functional Transfer of Knowledge for Coronary Artery Disease Diagnosis  
Abstract: A distinction between two forms of task knowledge transfer, representational and functional, is reviewed followed by a discussion of MTL, a modified version of the multiple task learning (MTL) neural network method of functional transfer. The MTL method employs a separate learning rate, k , for each task output node k. k varies as a function of a measure of relatedness, R k , between the
Paper 3  Title: Theory Revision in Fault Hierarchies  
Abstract: The fault hierarchy representation is widely used in expert systems for the diagnosis of complex mechanical devices. On the assumption that an appropriate bias for a knowledge representation language is also an appropriate bias for learning in this domain, we have developed a theory revision method that operates directly on a fault hierarchy. This task presents several challenges: A typi
Label: Theory
Paper 4  Title: Experiments on the Transfer of Knowledge between Neural Networks Reprinted from: Computational Learning Theory and
Abstract: This chapter describes three studies which address the question of how neural network learning can be improved via the incorporation of information extracted from other networks. This general problem, which we call network transfer, encompasses many types of relationships between source and target networks. Our focus is on the utilization of weights from source networks which solve a sub
Paper 5  Title: Modeling the Student with Reinforcement Learning  
Abstract: We describe a methodology for enabling an intelligent teaching system to make high level strategy decisions on the basis of low level student modeling information. This framework is less costly to construct, and superior to hand coding teaching strategies as it is more responsive to the learner's needs. In order to accomplish this, reinforcement learning is used to learn to associate sup
Paper 6  Title: DISTRIBUTED GENETIC ALGORITHMS FOR PARTITIONING UNIFORM GRIDS  
Abstract: The fault hierarchy representation is widely used in expert systems for the diagnosis of complex mechanical devices. On the assumption that an appropriate bias for a knowledge representation language is also an appropriate bias for learning in this domain, we have developed a theory revision method that operates directly on a fault hierarchy. This task presents several challenges: A typi
Paper 7  Title: Data Exploration with Reflective Adaptive Models  
Abstract: Case-Based Planning (CBP) provides a way of scaling up domain-independent planning to solve large problems in complex domains. It replaces the detailed and lengthy search for a solution with the retrieval and adaptation of previous planning experiences. In general, CBP has been demonstrated to improve performance over generative (from-scratch) planning. However, the performance improveme
Paper 8  Title: Knowledge Acquisition with a Knowledge-Intensive Machine Learning System  
Abstract: In this paper, we investigate the integration of knowledge acquisition and machine learning techniques. We argue that existing machine learning techniques can be made more useful as knowledge acquisition tools by allowing the expert to have greater control over and interaction with the learning process. We describe a number of extensions to FOCL (a multistrategy Horn-clause learning prog
Label: Rule Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  False

Prediction: 0
Processing index 2431...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Handling multi-class problems and real numbers is important in practical applications of machine learning to KDD problems. While attribute-value learners address these problems as a rule, very few ILP systems do so. The few ILP systems that handle real numbers mostly do so by trying out all real values that are applicable, thus running into efficiency or overfitting problems. This paper discusses some recent extensions of ICL that address these problems. ICL, which stands for Inductive Constraint Logic, is an ILP system that learns first order logic formulae from positive and negative examples. The main charateristic of ICL is its view on examples. These are seen as interpretations which are true or false for the clausal target theory (in CNF). We first argue that ICL can be used for learning a theory in a disjunctive normal form (DNF). With this in mind, a possible solution for handling more than two classes is given (based on some ideas from CN2). Finally, we show how to tackle problems with continuous values by adapting discretization techniques from attribute value learners. 
Title: Title: Multi-class problems and discretization in ICL Extended abstract  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Inductive Constraint Logic and the Mutagenesis Problem  
Abstract: A novel approach to learning first order logic formulae from positive and negative examples is incorporated in a system named ICL (Inductive Constraint Logic). In ICL, examples are viewed as interpretations which are true or false for the target theory, whereas in present inductive logic programming systems, examples are true and false ground facts (or clauses). Furthermore, ICL uses a c
Paper 3  Title: Structural Regression Trees  
Abstract: In many real-world domains the task of machine learning algorithms is to learn a theory predicting numerical values. In particular several standard test domains used in Inductive Logic Programming (ILP) are concerned with predicting numerical values from examples and relational and mostly non-determinate background knowledge. However, so far no ILP algorithm except one can predict number
Label: Rule Learning
Paper 4  Title: Inductive Constraint Logic  
Abstract: A novel approach to learning first order logic formulae from positive and negative examples is presented. Whereas present inductive logic programming systems employ examples as true and false ground facts (or clauses), we view examples as interpretations which are true or false for the target theory. This viewpoint allows to reconcile the inductive logic programming paradigm with classic
Paper 5  Title: ILP with Noise and Fixed Example Size: A Bayesian Approach  
Abstract: Current inductive logic programming systems are limited in their handling of noise, as they employ a greedy covering approach to constructing the hypothesis one clause at a time. This approach also causes difficulty in learning recursive predicates. Additionally, many current systems have an implicit expectation that the cardinality of the positive and negative examples reflect the "prop
Paper 6  Title: Symposium Title: Tutorial Discourse What Makes Human Explanations Effective?  
Abstract: Many state-of-the-art ILP systems require large numbers of negative examples to avoid overgeneralization. This is a considerable disadvantage for many ILP applications, namely indu ctive program synthesis where relativelly small and sparse example sets are a more realistic scenario. Integrity constraints are first order clauses that can play the role of negative examples in an inductive 
Paper 7  Title: Integrity Constraints in ILP using a Monte Carlo approach  
Abstract: Many state-of-the-art ILP systems require large numbers of negative examples to avoid overgeneralization. This is a considerable disadvantage for many ILP applications, namely indu ctive program synthesis where relativelly small and sparse example sets are a more realistic scenario. Integrity constraints are first order clauses that can play the role of negative examples in an inductive 
Paper 8  Title: The Difficulties of Learning Logic Programs with Cut  
Abstract: As real logic programmers normally use cut (!), an effective learning procedure for logic programs should be able to deal with it. Because the cut predicate has only a procedural meaning, clauses containing cut cannot be learned using an extensional evaluation method, as is done in most learning systems. On the other hand, searching a space of possible programs (instead of a space of ind
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 452...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Technical Report 317 Department of Statistics University of Washington. 1 Derek Stanford is Graduate Research Assistant and Adrian E. Raftery is Professor of Statistics and Sociology, both at the Department of Statistics, University of Washington, Box 354322, Seattle, WA 98195-4322, USA. E-mail: stanford@stat.washington.edu and raftery@stat.washington.edu. Web: http://www.stat.washington.edu/raftery. This research was supported by ONR grants N00014-96-1-0192 and N00014-96-1-0330. The authors are grateful to Simon Byers, Gilles Celeux and Christian Posse for helpful discussions. 
Title: Title: Principal Curve Clustering With Noise  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Detecting Features in Spatial Point Processes with Clutter via Model-Based Clustering  
Abstract: Technical Report No. 295 Department of Statistics, University of Washington October, 1995 1 Abhijit Dasgupta is a graduate student at the Department of Biostatistics, University of Washington, Box 357232, Seattle, WA 98195-7232, and his e-mail address is dasgupta@biostat.washington.edu. Adrian E. Raftery is Professor of Statistics and Sociology, Department of Statistics, University of Wa
Paper 3  Title: Model Selection and Accounting for Model Uncertainty in Linear Regression Models  
Abstract: 1 Adrian E. Raftery is Professor of Statistics and Sociology, David Madigan is Assistant Professor of Statistics, and Jennifer Hoeting is a Ph.D. Candidate, all at the Department of Statistics, GN-22, University of Washington, Seattle, WA 98195. The research of Raftery and Hoeting was supported by ONR Contract N-00014-91-J-1074. Madigan's research was partially supported by NSF grant no.
Label: Probabilistic Methods
Paper 4  Title: Covariate Selection in Hierarchical Models of Hospital Admission Counts: A Bayes Factor Approach 1  
Abstract: TECHNICAL REPORT No. 268 Department of Statistics, GN-22 University of Washington Seattle, Washington 98195 USA 1 Susan L. Rosenkranz is Pew Health Policy Postdoctoral Fellow at the Institute for Health Policy Studies, Box 0936, University of California at San Francisco, San Francisco, CA 94143, and Adrian E. Raftery is Professor of Statistics and Sociology, Department of Statistics, GN-
Paper 5  Title: A Note on the Dirichlet Process Prior in Bayesian Nonparametric Inference with Partial Exchangeability 1  
Abstract: Technical Report no. 297 Department of Statistics University of Washington 1 Sonia Petrone is Assistant Professor, Universita di Pavia, Dipartimento di Economia Politica e Metodi Quantitativi, I-27100 Pavia, Italy and Adrian E. Raftery is Professor of Statistics and Sociology, Department of Statistics, University of Washington, Box 354322, Seattle, WA 98195-4322. This research was suppor
Label: Probabilistic Methods
Paper 6  Title: Change Point and Change Curve Modeling in Stochastic Processes and Spatial Statistics  
Abstract: 1 This article will appear in Volume 1, no. 4 (1994) of Journal of Applied Statistical Science. Adrian E. Raftery is Professor of Statistics and Sociology, Department of Statistics, GN-22, University of Washington, Seattle, WA 98195. This research was supported by ONR contract no. N-00014-91-J-1074, by NIH Grant no. 5R01HD26330-02, by the Ministere de la Recherche et de l'Espace, Paris, 
Paper 7  Title: Estimating Dependency Structure as a Hidden Variable  
Abstract: This paper introduces a probability model, the mixture of trees that can account for sparse, dynamically changing dependence relationships. We present a family of efficient algorithms that use EM and the Minimum Spanning Tree algorithm to find the ML and MAP mixture of trees for a variety of priors, including the Dirichlet and the MDL priors. This report describes research done at the De
Paper 8  Title: FLEXIBLE PARAMETRIC MEASUREMENT ERROR MODELS  
Abstract: Inferences in measurement error models can be sensitive to modeling assumptions. Specifically, if the model is incorrect then the estimates can be inconsistent. To reduce sensitivity to modeling assumptions and yet still retain the efficiency of parametric inference we propose to use flexible parametric models which can accommodate departures from standard parametric models. We use mixtu
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 1516...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Handling NP complete problems with GAs is a great challenge. In particular the presence of constraints makes finding solutions hard for a GA. In this paper we present a problem independent constraint handling mechanism, Stepwise Adaptation of Weights (SAW), and apply it for solving the 3-SAT problem. Our experiments prove that the SAW mechanism substantially increases GA performance. Furthermore, we compare our SAW-ing GA with the best heuristic technique we could trace, WGSAT, and conclude that the GA is superior to the heuristic method. 
Title: Title: Solving 3-SAT by GAs Adapting Constraint Weights  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Graph Coloring with Adaptive Evolutionary Algorithms  
Abstract: This paper presents the results of an experimental investigation on solving graph coloring problems with Evolutionary Algorithms (EA). After testing different algorithm variants we conclude that the best option is an asexual EA using order-based representation and an adaptation mechanism that periodically changes the fitness function during the evolution. This adaptive EA is general, usi
Paper 3  Title: An Evolutionary Approach to Time Constrained Routing Problems  
Abstract: Routing problems are an important class of planning problems. Usually there are many different constraints and optimization criteria involved, and it is difficult to find general methods for solving routing problems. We propose an evolutionary solver for such planning problems. An instance of this solver has been tested on a specific routing problem with time constraints. The performance
Label: Genetic Algorithms
Paper 4  Title: A GENETIC ALGORITHM FOR FRAGMENT ALLOCATION IN A DISTRIBUTED DATABASE SYSTEM  
Abstract: In this paper we explore the distributed database allocation problem, which is intractable. We also discuss genetic algorithms and how they have been used successfully to solve combinatorial problems. Our experimental results show the GA to be far superior to the greedy heuristic in obtaining optimal and near optimal fragment placements for the allocation problem with various data sets.
Label: Genetic Algorithms
Paper 5  Title: High-Performance Job-Shop Scheduling With A Time-Delay TD() Network  
Abstract: Job-shop scheduling is an important task for manufacturing industries. We are interested in the particular task of scheduling payload processing for NASA's space shuttle program. This paper summarizes our previous work on formulating this task for solution by the reinforcement learning algorithm T D(). A shortcoming of this previous work was its reliance on hand-engineered input features
Label: Reinforcement Learning
Paper 6  Title: Bibliography "SMART: Support Management Automated Reasoning Technology for COMPAQ Customer Service," "Instance-Based Learning Algorithms," Machine
Abstract: Satisfiability (SAT) refers to the task of finding a truth assignment that makes an arbitrary boolean expression true. This paper compares a simulated annealing algorithm (SASAT) with GSAT (Selman et al., 1992), a greedy algorithm for solving satisfiability problems. GSAT can solve problem instances that are extremely difficult for traditional satisfiability algorithms. Results suggest t
Label: Theory
Paper 7  Title: How good are genetic algorithms at finding large cliques: an experimental study  
Abstract: This paper investigates the power of genetic algorithms at solving the MAX-CLIQUE problem. We measure the performance of a standard genetic algorithm on an elementary set of problem instances consisting of embedded cliques in random graphs. We indicate the need for improvement, and introduce a new genetic algorithm, the multi-phase annealed GA, which exhibits superior performance on the 
Paper 8  Title: A Genetic Local Search Approach to the Quadratic Assignment Problem  
Abstract: Augmenting genetic algorithms with local search heuristics is a promising approach to the solution of combinatorial optimization problems. In this paper, a genetic local search approach to the quadratic assignment problem (QAP) is presented. New genetic operators for realizing the approach are described, and its performance is tested on various QAP instances containing between 30 and 256
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2298...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper analyzes the convergence properties of the canonical genetic algorithm (CGA) with mutation, crossover and proportional reproduction applied to static optimization problems. It is proved by means of homogeneous finite Markov chain analysis that a CGA will never converge to the global optimum regardless of the initialization, crossover operator and objective function. But variants of CGAs that always maintain the best solution in the population, either before or after selection, are shown to converge to the global optimum due to the irreducibility property of the underlying original nonconvergent CGA. These results are discussed with respect to the schema theorem.
Title: Title: Convergence Analysis of Canonical Genetic Algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Graph Coloring with Adaptive Evolutionary Algorithms  
Abstract: This paper presents the results of an experimental investigation on solving graph coloring problems with Evolutionary Algorithms (EA). After testing different algorithm variants we conclude that the best option is an asexual EA using order-based representation and an adaptation mechanism that periodically changes the fitness function during the evolution. This adaptive EA is general, usi
Paper 3  Title: An Analysis of the MAX Problem in Genetic Programming hold only in some cases, in
Abstract: We present a detailed analysis of the evolution of genetic programming (GP) populations using the problem of finding a program which returns the maximum possible value for a given terminal and function set and a depth limit on the program tree (known as the MAX problem). We confirm the basic message of [ Gathercole and Ross, 1996 ] that crossover together with program size restrictions c
Label: Genetic Algorithms
Paper 4  Title: The Power of Self-Directed Learning  
Abstract: A lower-bound result on the power of Abstract This paper presents a lower-bound result on the computational power of a genetic algorithm in the context of combinatorial optimization. We describe a new genetic algorithm, the merged genetic algorithm, and prove that for the class of monotonic functions, the algorithm finds the optimal solution, and does so with an exponential convergence r
Paper 5  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Label: Genetic Algorithms
Paper 6  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Paper 7  Title: Vector Quantizer Design Using Genetic Algorithms  
Abstract: A Genetic Algorithmic (GA) approach to vector quantizer design that combines the conventional Generalized Lloyd Algorithm (GLA) [6] is presented. We refer to this hybrid as the Genetic Generalized Lloyd Algorithm (GGLA). It works briefly as follows: A finite number of codebooks, called chromosomes, are selected. Each codebook undergoes iterative cycles of reproduction. We perform experim
Paper 8  Title: Reformulation: Nonsmooth, Piecewise Smooth, Semismooth and Smoothing Methods, A Globally Convergent Inexact Newton Method for
Abstract: We propose an algorithm for solving systems of monotone equations which combines Newton, proximal point, and projection methodologies. An important property of the algorithm is that the whole sequence of iterates is always globally convergent to a solution of the system without any additional regularity assumptions. Moreover, under standard assumptions the local su-perlinear rate of conv
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2459...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Intermediate and higher vision processes require selection of a subset of the available sensory information before further processing. Usually, this selection is implemented in the form of a spatially circumscribed region of the visual field, the so-called "focus of attention" which scans the visual scene dependent on the input and on the attentional state of the subject. We here present a model for the control of the focus of attention in primates, based on a saliency map. This mechanism is not only expected to model the functionality of biological vision but also to be essential for the understanding of complex scenes in machine vision.
Title: Title: Control of Selective Visual Attention: Modeling the "Where" Pathway  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  
Abstract: The sensorimotor integration system can be viewed as an observer attempting to estimate its own state and the state of the environment by integrating multiple sources of information. We describe a computational framework capturing this notion, and some specific models of integration and adaptation that result from it. Psychophysical results from two sensorimotor systems, subserving the i
Paper 3  Title: Expectation-Based Selective Attention for Visual Monitoring and Control of a Robot Vehicle  
Abstract: Reliable vision-based control of an autonomous vehicle requires the ability to focus attention on the important features in an input scene. Previous work with an autonomous lane following system, ALVINN [Pomerleau, 1993], has yielded good results in uncluttered conditions. This paper presents an artificial neural network based learning approach for handling difficult scenes which will co
Label: Neural Networks
Paper 4  Title: Optimising Local Hebbian Learning: use the ffi-rule  
Abstract: Many of the lower-level areas in the mammalian visual system are organized retinotopically, that is, as maps which preserve to a certain degree the topography of the retina. A unit that is a part of such a retinotopic map normally responds selectively to stimulation in a well-delimited part of the visual field, referred to as its receptive field (RF). Receptive fields are probably the mo
Label: Neural Networks
Paper 5  Title: Hidden Markov Modeling of simultaneously recorded cells in the Associative cortex of behaving monkeys  
Abstract: A widely held idea regarding information processing in the brain is the cell-assembly hypothesis suggested by Hebb in 1949. According to this hypothesis, the basic unit of information processing in the brain is an assembly of cells, which can act briefly as a closed system, in response to a specific stimulus. This work presents a novel method of characterizing this supposed activity usin
Label: Neural Networks
Paper 6  Title: CNN: a Neural Architecture that Learns Multiple Transformations of Spatial Representations  
Abstract: Many of the lower-level areas in the mammalian visual system are organized retinotopically, that is, as maps which preserve to a certain degree the topography of the retina. A unit that is a part of such a retinotopic map normally responds selectively to stimulation in a well-delimited part of the visual field, referred to as its receptive field (RF). Receptive fields are probably the mo
Paper 7  Title: Residual Q-Learning Applied to Visual Attention  
Abstract: Foveal vision features imagers with graded acuity coupled with context sensitive sensor gaze control, analogous to that prevalent throughout vertebrate vision. Foveal vision operates more efficiently than uniform acuity vision because resolution is treated as a dynamically allocatable resource, but requires a more refined visual attention mechanism. We demonstrate that reinforcement lear
Paper 8  Title: Cortical Mechanisms of Visual Recognition and Learning: A Hierarchical Kalman Filter Model  
Abstract: We describe a biologically plausible model of dynamic recognition and learning in the visual cortex based on the statistical theory of Kalman filtering from optimal control theory. The model utilizes a hierarchical network whose successive levels implement Kalman filters operating over successively larger spatial and temporal scales. Each hierarchical level in the network predicts the cu
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1243...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We discuss the advantages of using overdetermined mixtures to improve upon blind source separation algorithms that are designed to extract sound sources from acoustic mixtures. A study of the nature of room impulse responses helps us choose an adaptive filter architecture. We use ideal inverses of acquired room impulse responses to compare the effectiveness of different-sized separating filter configurations of various filter lengths. Using a multi-channel blind least-mean-square algorithm (MBLMS), we show that, by adding additional sensors, we can improve upon the separation of signals mixed with real world filters. 
Title: Title: BLIND SEPARATION OF REAL WORLD AUDIO SIGNALS USING OVERDETERMINED MIXTURES  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Blind separation of delayed and convolved sources.  
Abstract: We address the difficult problem of separating multiple speakers with multiple microphones in a real room. We combine the work of Torkkola and Amari, Cichocki and Yang, to give Natural Gradient information maximisation rules for recurrent (IIR) networks, blindly adjusting delays, separating and deconvolving mixed signals. While they work well on simulated data, these rules fail in real r
Paper 3  Title: BLIND SEPARATION OF DELAYED SOURCES BASED ON INFORMATION MAXIMIZATION  
Abstract: Recently, Bell and Sejnowski have presented an approach to blind source separation based on the information maximization principle. We extend this approach into more general cases where the sources may have been delayed with respect to each other. We present a network architecture capable of coping with such sources, and we derive the adaptation equations for the delays and the weights i
Paper 4  Title: Analyzing Hyperspectral Data with Independent Component Analysis  
Abstract: Hyperspectral image sensors provide images with a large number of contiguous spectral channels per pixel and enable information about different materials within a pixel to be obtained. The problem of spectrally unmixing materials may be viewed as a specific case of the blind source separation problem where data consists of mixed signals (in this case minerals) and the goal is to determin
Paper 5  Title: Recognizing Handwritten Digits Using Mixtures of Linear Models  
Abstract: We construct a mixture of locally linear generative models of a collection of pixel-based images of digits, and use them for recognition. Different models of a given digit are used to capture different styles of writing, and new images are classified by evaluating their log-likelihoods under each model. We use an EM-based algorithm in which the M-step is computationally straightforward p
Label: Neural Networks
Paper 6  Title: A Context-Sensitive Generalization of ICA  
Abstract: Source separation arises in a surprising number of signal processing applications, from speech recognition to EEG analysis. In the square linear blind source separation problem without time delays, one must find an unmixing matrix which can detangle the result of mixing n unknown independent sources through an unknown n fi n mixing matrix. The recently introduced ICA blind source separat
Paper 7  Title: Independent Component Analysis of Electroencephalographic Data  
Abstract: Because of the distance between the skull and brain and their different resistivities, electroencephalographic (EEG) data collected from any point on the human scalp includes activity generated within a large brain area. This spatial smearing of EEG data by volume conduction does not involve significant time delays, however, suggesting that the Independent Component Analysis (ICA) algori
Paper 8  Title: A Blind Identification and Separation Technique via Multi-layer Neural Networks  
Abstract: This paper deals with the problem of blind identification and source separation which consists of estimation of the mixing matrix and/or the separation of a mixture of stochastically independent sources without a priori knowledge on the mixing matrix . The method we propose here estimates the mixture matrix by a recurrent Input-Output (IO) Identification using as inputs a nonlinear trans
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1152...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Keywords: Case-Based Reasoning, case retrieval, case representation This paper deals with the retrieval of useful cases in case-based reasoning. It focuses on the questions of what "useful" could mean and how the search for useful cases can be organized. We present the new search algorithm Fish and Shrink that is able to search quickly through the case base, even if the aspects that deflne usefulness are spontaneously combined at query time. We compare Fish and Shrink to other algorithms and show that most of them make an implicit closed world assumption. We flnally refer to a realization of the presented idea in the context of the prototype of the FABEL-Project 1 . The scenery is as follows. Previously collected cases are stored in a large scaled case base. An expert describes his problem and gives the aspects in which the requested case should be similar. The similarity measure thus given spontaneously shall now be used to explore the case base within a short time, shall present a required number of cases and make sure that none of the other cases is more similar. The question is now how to prepare the previously collected cases and how to deflne a retrieval algorithm which is able to deal with sponta neously user-deflned similarity measures.
Title: Title: Fish and Shrink. A next step towards e-cient case retrieval in large scaled case bases  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Case Retrieval Nets: Basic Ideas and Extensions  
Abstract: An efficient retrieval of a relatively small number of relevant cases from a huge case base is a crucial subtask of Case-Based Reasoning. In this article, we present Case Retrieval Nets (CRNs), a memory model that has recently been developed for this task. The main idea is to apply a spreading activation process to a net-like case memory in order to retrieve cases being similar to a pose
Label: Case Based
Paper 3  Title: Context-Based Similarity Applied to Retrieval of Relevant Cases  
Abstract: Retrieving relevant cases is a crucial component of case-based reasoning systems. The task is to use user-defined query to retrieve useful information, i.e., exact matches or partial matches which are close to query-defined request according to certain measures. The difficulty stems from the fact that it may not be easy (or it may be even impossible) to specify query requests precisely a
Label: Case Based
Paper 4  Title: Growing a Hypercubical Output Space in a Self-Organizing Feature Map  
Abstract: Recent studies on planning, comparing plan re-use and plan generation, have shown that both the above tasks may have the same degree of computational complexity, even if we deal with very similar problems. The aim of this paper is to show that the same kind of results apply also for diagnosis. We propose a theoretical complexity analysis coupled with some experimental tests, intended to 
Paper 5  Title: On the Usefulness of Re-using Diagnostic Solutions  
Abstract: Recent studies on planning, comparing plan re-use and plan generation, have shown that both the above tasks may have the same degree of computational complexity, even if we deal with very similar problems. The aim of this paper is to show that the same kind of results apply also for diagnosis. We propose a theoretical complexity analysis coupled with some experimental tests, intended to 
Label: Case Based
Paper 6  Title: ADAPtER: an Integrated Diagnostic System Combining Case-Based and Abductive Reasoning  
Abstract: The aim of this paper is to describe the ADAPtER system, a diagnostic architecture combining case-based reasoning with abductive reasoning and exploiting the adaptation of the solution of old episodes, in order to focus the reasoning process. Domain knowledge is represented via a logical model and basic mechanisms, based on abductive reasoning with consistency constraints, have been defi
Label: Case Based
Paper 7  Title: Lazy Induction Triggered by CBR  
Abstract: In recent years, case-based reasoning has been demonstrated to be highly useful for problem solving in complex domains. Also, mixed paradigm approaches emerged for combining CBR and induction techniques aiming at verifying the knowledge and/or building an efficient case memory. However, in complex domains induction over the whole problem space is often not possible or too time consuming.
Paper 8  Title: REPRO: Supporting Flowsheet Design by Case-Base Retrieval  
Abstract: Case-Based Reasoning (CBR) paradigm is very close to the designer behavior during the conceptual design, and seems to be a fruitable computer aided-design approach if a library of design cases is available. The goal of this paper is to presents the general framework of a case-based retrieval system: REPRO, that supports chemical process design. The crucial problems like the case represen
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 1020...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present a comparison of error-based and entropy-based methods for discretization of continuous features. Our study includes both an extensive empirical comparison as well as an analysis of scenarios where error minimization may be an inappropriate discretization criterion. We present a discretization method based on the C4.5 decision tree algorithm and compare it to an existing entropy-based discretization algorithm, which employs the Minimum Description Length Principle, and a recently proposed error-based technique. We evaluate these discretization methods with respect to C4.5 and Naive-Bayesian classifiers on datasets from the UCI repository and analyze the computational complexity of each method. Our results indicate that the entropy-based MDL heuristic outperforms error minimization on average. We then analyze the shortcomings of error-based approaches in comparison to entropy-based methods. 
Title: Title: Error-Based and Entropy-Based Discretization of Continuous Features  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Supervised and Unsupervised Discretization of Continuous Features  
Abstract: Many supervised machine learning algorithms require a discrete feature space. In this paper, we review previous work on continuous feature discretization, identify defining characteristics of the methods, and conduct an empirical evaluation of several methods. We compare binning, an unsupervised discretization method, to entropy-based and purity-based methods, which are supervised algori
Label: Theory
Paper 3  Title: Evolutionary Design of Neural Architectures A Preliminary Taxonomy and Guide to Literature  
Abstract: In this paper, we present a computation-ally efficient method for inducing selective Bayesian network classifiers. Our approach is to use information-theoretic metrics to efficiently select a subset of attributes from which to learn the classifier. We explore three conditional, information-theoretic met-rics that are extensions of metrics used extensively in decision tree learning, namel
Paper 4  Title: Efficient Learning of Selective Bayesian Network Classifiers  
Abstract: In this paper, we present a computation-ally efficient method for inducing selective Bayesian network classifiers. Our approach is to use information-theoretic metrics to efficiently select a subset of attributes from which to learn the classifier. We explore three conditional, information-theoretic met-rics that are extensions of metrics used extensively in decision tree learning, namel
Label: Probabilistic Methods
Paper 5  Title: Search-based Class Discretization  
Abstract: We present a methodology that enables the use of classification algorithms on regression tasks. We implement this method in system RECLA that transforms a regression problem into a classification one and then uses an existent classification system to solve this new problem. The transformation consists of mapping a continuous variable into an ordinal variable by grouping its values into a
Paper 6  Title: Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm  
Abstract: This paper introduces ICET, a new algorithm for costsensitive classification. ICET uses a genetic algorithm to evolve a population of biases for a decision tree induction algorithm. The fitness function of the genetic algorithm is the average cost of classification when using the decision tree, including both the costs of tests (features, measurements) and the costs of classification err
Label: Genetic Algorithms
Paper 7  Title: Pruning Decision Trees with Misclassification Costs  
Abstract: We describe an experimental study of pruning methods for decision tree classifiers when the goal is minimizing loss rather than error. In addition to two common methods for error minimization, CART's cost-complexity pruning and C4.5's error-based pruning, we study the extension of cost-complexity pruning to loss and one pruning variant based on the Laplace correction. We perform an empir
Paper 8  Title: Understanding Musical Sound with Forward Models and Physical Models  
Abstract: This paper introduces ICET, a new algorithm for costsensitive classification. ICET uses a genetic algorithm to evolve a population of biases for a decision tree induction algorithm. The fitness function of the genetic algorithm is the average cost of classification when using the decision tree, including both the costs of tests (features, measurements) and the costs of classification err
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Theory
Prediction:  Theory
Is prediction correct?  False

Prediction: 0
Processing index 975...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Genetic programming is distinguished from other evolutionary algorithms in that it uses tree representations of variable size instead of linear strings of fixed length. The flexible representation scheme is very important because it allows the underlying structure of the data to be discovered automatically. One primary difficulty, however, is that the solutions may grow too big without any improvement of their generalization ability. In this paper we investigate the fundamental relationship between the performance and complexity of the evolved structures. The essence of the parsimony problem is demonstrated empirically by analyzing error landscapes of programs evolved for neural network synthesis. We consider genetic programming as a statistical inference problem and apply the Bayesian model-comparison framework to introduce a class of fitness functions with error and complexity terms. An adaptive learning method is then presented that automatically balances the model-complexity factor to evolve parsimonious programs without losing the diversity of the population needed for achieving the desired training accuracy. The effectiveness of this approach is empirically shown on the induction of sigma-pi neural networks for solving a real-world medical diagnosis problem as well as benchmark tasks. 
Title: Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Balancing Accuracy and Parsimony in Genetic Programming 1  
Abstract: Genetic programming is distinguished from other evolutionary algorithms in that it uses tree representations of variable size instead of linear strings of fixed length. The flexible representation scheme is very important because it allows the underlying structure of the data to be discovered automatically. One primary difficulty, however, is that the solutions may grow too big without a
Paper 3  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Paper 4  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Label: Genetic Algorithms
Paper 5  Title: Spline Smoothing For Bivariate Data With Applications To Association Between Hormones  
Abstract: Standard methods for inducing both the structure and weight values of recurrent neural networks fit an assumed class of architectures to every task. This simplification is necessary because the interactions between network structure and function are not well understood. Evolutionary computation, which includes genetic algorithms and evolutionary programming, is a population-based search 
Paper 6  Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Abstract: Genetic algorithms have been used for neural networks in two main ways: to optimize the network architecture and to train the weights of a fixed architecture. While most previous work focuses on only one of these two options, this paper investigates an alternative evolutionary approach called Breeder Genetic Programming (BGP) in which the architecture and the weights are optimized simult
Paper 7  Title: An Evolutionary Algorithm that Constructs Recurrent Neural Networks  
Abstract: Standard methods for inducing both the structure and weight values of recurrent neural networks fit an assumed class of architectures to every task. This simplification is necessary because the interactions between network structure and function are not well understood. Evolutionary computation, which includes genetic algorithms and evolutionary programming, is a population-based search 
Paper 8  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract: In the field of Operation Research and Artificial Intelligence, several stochastic search algorithms have been designed based on the theory of global random search (Zhigljavsky 1991). Basically, those techniques iteratively sample the search space with respect to a probability distribution which is updated according to the result of previous samples and some predefined strategy. Genetic 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  False

Prediction: 0
Processing index 488...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present a new general-purpose algorithm for learning classes of [0; 1]-valued functions in a generalization of the prediction model, and prove a general upper bound on the expected absolute error of this algorithm in terms of a scale-sensitive generalization of the Vapnik dimension proposed by Alon, Ben-David, Cesa-Bianchi and Haussler. We give lower bounds implying that our upper bounds cannot be improved by more than a constant factor in general. We apply this result, together with techniques due to Haussler and to Benedek and Itai, to obtain new upper bounds on packing numbers in terms of this scale-sensitive notion of dimension. Using a different technique, we obtain new bounds on packing numbers in terms of Kearns and Schapire's fat-shattering function. We show how to apply both packing bounds to obtain improved general bounds on the sample complexity of agnostic learning. For each * &gt; 0, we establish weaker sufficient and stronger necessary conditions for a class of [0; 1]-valued functions to be agnostically learnable to within *, and to be an *-uniform Glivenko-Cantelli class. 
Title: Title: Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Simulating Access to Hidden Information while Learning  
Abstract: We introduce a new technique which enables a learner without access to hidden information to learn nearly as well as a learner with access to hidden information. We apply our technique to solve an open problem of Maass and Turan [18], showing that for any concept class F , the least number of queries sufficient for learning F by an algorithm which has access only to arbitrary equivalence
Paper 3  Title: Statistical Queries and Faulty PAC Oracles  
Abstract: In this paper we study learning in the PAC model of Valiant [18] in which the example oracle used for learning may be faulty in one of two ways: either by misclassifying the example or by distorting the distribution of examples. We first consider models in which examples are misclassified. Kearns [12] recently showed that efficient learning in a new model using statistical queries is a s
Paper 4  Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  
Abstract: We present an algorithm for improving the accuracy of algorithms for learning binary concepts. The improvement is achieved by combining a large number of hypotheses, each of which is generated by training the given learning algorithm on a different set of examples. Our algorithm is based on ideas presented by Schapire in his paper "The strength of weak learnability", and represents an im
Label: Theory
Paper 5  Title: General Bounds on Statistical Query Learning and PAC Learning with Noise via Hypothesis Boosting  
Abstract: We derive general bounds on the complexity of learning in the Statistical Query model and in the PAC model with classification noise. We do so by considering the problem of boosting the accuracy of weak learning algorithms which fall within the Statistical Query model. This new model was introduced by Kearns [12] to provide a general framework for efficient PAC learning in the presence o
Paper 6  Title: Predicting a binary sequence almost as well as the optimal biased coin  
Abstract: We apply the exponential weight algorithm, introduced and Littlestone and Warmuth [17] and by Vovk [24] to the problem of predicting a binary sequence almost as well as the best biased coin. We first show that for the case of the logarithmic loss, the derived algorithm is equivalent to the Bayes algorithm with Jeffrey's prior, that was studied by Xie and Barron under probabilistic assump
Paper 7  Title: Noise-Tolerant Parallel Learning of Geometric Concepts  
Abstract: We present several efficient parallel algorithms for PAC-learning geometric concepts in a constant-dimensional space that are robust even against malicious misclassification noise of any rate less than 1=2. In particular we consider the class of geometric concepts defined by a polynomial number of (d 1)-dimensional hyperplanes against an arbitrary distribution where each hyperplane has a
Label: Theory
Paper 8  Title: Theory and Applications of Agnostic PAC-Learning with Small Decision Trees  
Abstract: We exhibit a theoretically founded algorithm T2 for agnostic PAC-learning of decision trees of at most 2 levels, whose computation time is almost linear in the size of the training set. We evaluate the performance of this learning algorithm T2 on 15 common real-world datasets, and show that for most of these datasets T2 provides simple decision trees with little or no loss in predictive 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 1139...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The optimization of a single bit string by means of iterated mutation and selection of the best (a (1+1)-Genetic Algorithm) is discussed with respect to three simple fitness functions: The counting ones problem, a standard binary encoded integer, and a Gray coded integer optimization problem. A mutation rate schedule that is optimal with respect to the success probability of mutation is presented for each of the objective functions, and it turns out that the standard binary code can hamper the search process even in case of unimodal objective functions. While normally a mutation rate of 1=l (where l denotes the bit string length) is recommendable, our results indicate that a variation of the mutation rate is useful in cases where the fitness function is a multimodal pseudo-boolean function, where multimodality may be caused by the objective function as well as the encoding mechanism.
Title: Title: Optimal Mutation Rates in Genetic Search  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Evolutionary Approach to Combinatorial Optimization Problems  
Abstract: The paper reports on the application of genetic algorithms, probabilistic search algorithms based on the model of organic evolution, to NP-complete combinatorial optimization problems. In particular, the subset sum, maximum cut, and minimum tardy task problems are considered. Except for the fitness function, no problem-specific changes of the genetic algorithm are required in order to ac
Paper 3  Title: An Analysis of the MAX Problem in Genetic Programming hold only in some cases, in
Abstract: We present a detailed analysis of the evolution of genetic programming (GP) populations using the problem of finding a program which returns the maximum possible value for a given terminal and function set and a depth limit on the program tree (known as the MAX problem). We confirm the basic message of [ Gathercole and Ross, 1996 ] that crossover together with program size restrictions c
Label: Genetic Algorithms
Paper 4  Title: Genetic algorithms with multi-parent recombination  
Abstract: In this paper we investigate genetic algorithms where more than two parents are involved in the recombination operation. In particular, we introduce gene scanning as a reproduction mechanism that generalizes classical crossovers, such as n-point crossover or uniform crossover, and is applicable to an arbitrary number (two or more) of parents. We performed extensive tests for optimizing n
Paper 5  Title: Putting the Genetics back into Genetic Algorithms  
Abstract: In this paper we investigate genetic algorithms where more than two parents are involved in the recombination operation. In particular, we introduce gene scanning as a reproduction mechanism that generalizes classical crossovers, such as n-point crossover or uniform crossover, and is applicable to an arbitrary number (two or more) of parents. We performed extensive tests for optimizing n
Paper 6  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Paper 7  Title: Balancing Accuracy and Parsimony in Genetic Programming 1  
Abstract: Genetic programming is distinguished from other evolutionary algorithms in that it uses tree representations of variable size instead of linear strings of fixed length. The flexible representation scheme is very important because it allows the underlying structure of the data to be discovered automatically. One primary difficulty, however, is that the solutions may grow too big without a
Paper 8  Title: Graph Coloring with Adaptive Evolutionary Algorithms  
Abstract: This paper presents the results of an experimental investigation on solving graph coloring problems with Evolutionary Algorithms (EA). After testing different algorithm variants we conclude that the best option is an asexual EA using order-based representation and an adaptation mechanism that periodically changes the fitness function during the evolution. This adaptive EA is general, usi
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 954...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model is closely related to the Harmonium model defined by Smolensky [RM86][Ch.6]. In the first part of the paper we analyze properties of this distribution representation scheme. We show that arbitrary distributions of binary vectors can be approximated by the combination model. We show how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits. We compare the combination model with the mixture model and with principle component analysis. In the second part of the paper we present two algorithms for learning the combination model from examples. The first algorithm is based on gradient ascent. Here we give a closed form for this gradient that is significantly easier to compute than the corresponding gradient for the general Boltzmann machine. The second learning algorithm is a greedy method that creates the hidden units and computes their weights one at a time. This method is a variant of projection pursuit density estimation. In the third part of the paper we give experimental results for these learning methods on synthetic data and on natural data of handwritten digit images. 
Title: Title: Unsupervised learning of distributions on binary vectors using two layer networks  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Separating Formal Bounds from Practical Performance in Learning Systems  
Abstract: We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model is closely related to the Harmonium model defined by Smolensky [RM86][Ch.6]. In the first part of the paper we analyze properties of this distribution representation scheme. We sho
Paper 3  Title: On the Learnability and Usage of Acyclic Probabilistic Finite Automata  
Abstract: We propose and analyze a distribution learning algorithm for a subclass of Acyclic Probabilistic Finite Automata (APFA). This subclass is characterized by a certain distinguishability property of the automata's states. Though hardness results are known for learning distributions generated by general APFAs, we prove that our algorithm can efficiently learn distributions generated by the s
Paper 4  Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,
Abstract: Although probabilistic inference in a general Bayesian belief network is an NP-hard problem, inference computation time can be reduced in most practical cases by exploiting domain knowledge and by making appropriate approximations in the knowledge representation. In this paper we introduce the property of similarity of states and a new method for approximate knowledge representation whic
Label: Theory
Paper 5  Title: Training Algorithms for Hidden Markov Models Using Entropy Based Distance Functions  
Abstract: We present new algorithms for parameter estimation of HMMs. By adapting a framework used for supervised learning, we construct iterative algorithms that maximize the likelihood of the observations while also attempting to stay close to the current estimated parameters. We use a bound on the relative entropy between the two HMMs as a distance measure between them. The result is new iterat
Paper 6  Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  
Abstract: The work discussed in this paper is motivated by the need of building decision support systems for real-world problem domains. Our goal is to use these systems as a tool for supporting Bayes optimal decision making, where the action maximizing the expected utility, with respect to predicted probabilities of the possible outcomes, should be selected. For this reason, the models used need 
Paper 7  Title: Static Data Association with a Terrain-Based Prior Density  
Abstract: In recent years there has been a flurry of works on learning probabilistic belief networks. Current state of the art methods have been shown to be successful for two learning scenarios: learning both network structure and parameters from complete data, and learning parameters for a fixed network from incomplete datathat is, in the presence of missing values or hidden variables. However, 
Label: Probabilistic Methods
Paper 8  Title: Distribution Category:  Users Guide to the PGAPack Parallel Genetic Algorithm Library  
Abstract: The problem of modeling complicated data sequences, such as DNA or speech, often arises in practice. Most of the algorithms select a hypothesis from within a model class assuming that the observed sequence is the direct output of the underlying generation process. In this paper we consider the case when the output passes through a memoryless noisy channel before observation. In particula
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 1520...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Source separation consists in recovering a set of independent signals when only mixtures with unknown coefficients are observed. This paper introduces a class of adaptive algorithms for source separation which implements an adaptive version of equivariant estimation and is henceforth called EASI (Equivariant Adaptive Separation via Independence). The EASI algorithms are based on the idea of serial updating: this specific form of matrix updates systematically yields algorithms with a simple, parallelizable structure, for both real and complex mixtures. Most importantly, the performance of an EASI algorithm does not depend on the mixing matrix. In particular, convergence rates, stability conditions and interference rejection levels depend only on the (normalized) distributions of the source signals. Close form expressions of these quantities are given via an asymptotic performance analysis. This is completed by some numerical experiments illustrating the effectiveness of the proposed approach. 
Title: Title: Equivariant adaptive source separation  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Blind Identification and Separation Technique via Multi-layer Neural Networks  
Abstract: This paper deals with the problem of blind identification and source separation which consists of estimation of the mixing matrix and/or the separation of a mixture of stochastically independent sources without a priori knowledge on the mixing matrix . The method we propose here estimates the mixture matrix by a recurrent Input-Output (IO) Identification using as inputs a nonlinear trans
Paper 3  Title: A New Learning Algorithm for Blind Signal Separation  
Abstract: A new on-line learning algorithm which minimizes a statistical dependency among outputs is derived for blind separation of mixed signals. The dependency is measured by the average mutual information (MI) of the outputs. The source signals and the mixing matrix are unknown except for the number of the sources. The Gram-Charlier expansion instead of the Edgeworth expansion is used in evalu
Paper 4  Title: The Central Classifier Bound ANew Error Bound for the Classifier Chosen by Early Stopping Key
Abstract: A new on-line learning algorithm which minimizes a statistical dependency among outputs is derived for blind separation of mixed signals. The dependency is measured by the average mutual information (MI) of the outputs. The source signals and the mixing matrix are unknown except for the number of the sources. The Gram-Charlier expansion instead of the Edgeworth expansion is used in evalu
Paper 5  Title: A FAMILY OF FIXED-POINT ALGORITHMS FOR INDEPENDENT COMPONENT ANALYSIS  
Abstract: Independent Component Analysis (ICA) is a statistical signal processing technique whose main applications are blind source separation, blind deconvolution, and feature extraction. Estimation of ICA is usually performed by optimizing a 'contrast' function based on higher-order cumulants. In this paper, it is shown how almost any error function can be used to construct a contrast function 
Paper 6  Title: On the performance of orthogonal source separation algorithms  
Abstract: Source separation consists in recovering a set of n independent signals from m n observed instantaneous mixtures of these signals, possibly corrupted by additive noise. Many source separation algorithms use second order information in a whitening operation which reduces the non trivial part of the separation to determining a unitary matrix. Most of them further show a kind of invariance 
Paper 7  Title: SELF-ADAPTIVE NEURAL NETWORKS FOR BLIND SEPARATION OF SOURCES  
Abstract: Novel on-line learning algorithms with self adaptive learning rates (parameters) for blind separation of signals are proposed. The main motivation for development of new learning rules is to improve convergence speed and to reduce cross-talking, especially for non-stationary signals. Furthermore, we have discovered that under some conditions the proposed neural network models with associ
Paper 8  Title: BLIND SEPARATION OF DELAYED SOURCES BASED ON INFORMATION MAXIMIZATION  
Abstract: Recently, Bell and Sejnowski have presented an approach to blind source separation based on the information maximization principle. We extend this approach into more general cases where the sources may have been delayed with respect to each other. We present a network architecture capable of coping with such sources, and we derive the adaptation equations for the delays and the weights i
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 161...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: New methodology for fully Bayesian mixture analysis is developed, making use of reversible jump Markov chain Monte Carlo methods, that are capable of jumping between the parameter subspaces corresponding to different numbers of components in the mixture. A sample from the full joint distribution of all unknown variables is thereby generated, and this can be used as a basis for a thorough presentation of many aspects of the posterior distribution. The methodology is applied here to the analysis of univariate normal mixtures, using a hierarchical prior model that offers an approach to dealing with weak prior information while avoiding the mathematical pitfalls of using improper priors in the mixture context.
Title: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Hyperparameter estimation in Dirichlet process mixture models  
Abstract: In Bayesian density estimation and prediction using Dirichlet process mixtures of standard, exponential family distributions, the precision or total mass parameter of the mixing Dirichlet process is a critical hyperparame-ter that strongly influences resulting inferences about numbers of mixture components. This note shows how, with respect to a flexible class of prior distributions for 
Label: Probabilistic Methods
Paper 3  Title: Strategies for the Parallel Training of Simple Recurrent Neural Networks  
Abstract: In Bayesian density estimation and prediction using Dirichlet process mixtures of standard, exponential family distributions, the precision or total mass parameter of the mixing Dirichlet process is a critical hyperparame-ter that strongly influences resulting inferences about numbers of mixture components. This note shows how, with respect to a flexible class of prior distributions for 
Paper 4  Title: Bayesian Mixture Modeling by Monte Carlo Simulation  
Abstract: It is shown that Bayesian inference from data modeled by a mixture distribution can feasibly be performed via Monte Carlo simulation. This method exhibits the true Bayesian predictive distribution, implicitly integrating over the entire underlying parameter space. An infinite number of mixture components can be accommodated without difficulty, using a prior distribution for mixing propor
Paper 5  Title: In Advances in Neural Information Processing Systems 8  Gaussian Processes for Regression  
Abstract: The Bayesian analysis of neural networks is difficult because a simple prior over weights implies a complex prior distribution over functions. In this paper we investigate the use of Gaussian process priors over functions, which permit the predictive Bayesian analysis for fixed values of hyperparameters to be carried out exactly using matrix operations. Two methods, using optimization an
Paper 6  Title: Probabilistic Principal Component Analysis  
Abstract: Principal component analysis (PCA) is a ubiquitous technique for data analysis and processing, but one which is not based upon a probability model. In this paper we demonstrate how the principal axes of a set of observed data vectors may be determined through maximum-likelihood estimation of parameters in a latent variable model closely related to factor analysis. We consider the propert
Paper 7  Title: Bayesian Finite Mixtures for Nonlinear Modeling of Educational data  
Abstract: In this paper we discuss a Bayesian approach for finding latent classes in the data. In our approach we use finite mixture models to describe the underlying structure in the data, and demonstrate that the possibility to use full joint probability models raises interesting new prospects for exploratory data analysis. The concepts and methods discussed are illustrated with a case study usi
Paper 8  Title: Parallel Markov chain Monte Carlo sampling.  
Abstract: Markov chain Monte Carlo (MCMC) samplers have proved remarkably popular as tools for Bayesian computation. However, problems can arise in their application when the density of interest is high dimensional and strongly correlated. In these circumstances the sampler may be slow to traverse the state space and mixing is poor. In this article we offer a partial solution to this problem. The 
Label: Probabilistic Methods
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 1853...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: 6] Farach, M. and Thorup, M. 1993. Fast Comparison of Evolutionary Trees, Technical Report 93-46, DIMACS, Rutgers University, Piscataway, NJ. 
Title: Title: 99-113. Construction of Phylogenetic Trees, Science, Fitting the Gene Lineage Into Its Species Lineage. A
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: MML mixture modelling of multi-state, Poisson, von Mises circular and Gaussian distributions  
Abstract: 11] M.H. Overmars. A random approach to motion planning. Technical Report RUU-CS-92-32, Department of Computer Science, Utrecht University, October 1992. 
Paper 3  Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine
Abstract: Ourston and Mooney, 1990b ] D. Ourston and R. J. Mooney. Improving shared rules in multiple category domain theories. Technical Report AI90-150, Artificial Intelligence Labora tory, University of Texas, Austin, TX, December 1990. 
Paper 4  Title: A Neuro-Dynamic Programming Approach to Retailer Inventory Management 1  
Abstract: Miller, G. (1956). The magical number seven, plus or minus two: Some limits on our capacity for processing information. The Psychological Review, 63(2):81-97. Schmidhuber, J. (1990b). Towards compositional learning with dynamic neural networks. Technical Report FKI-129-90, Technische Universitat Munchen, Institut fu Informatik. Servan-Schreiber, D., Cleermans, A., and McClelland, J. (198
Label: Reinforcement Learning
Paper 5  Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages
Abstract: Miller, G. (1956). The magical number seven, plus or minus two: Some limits on our capacity for processing information. The Psychological Review, 63(2):81-97. Schmidhuber, J. (1990b). Towards compositional learning with dynamic neural networks. Technical Report FKI-129-90, Technische Universitat Munchen, Institut fu Informatik. Servan-Schreiber, D., Cleermans, A., and McClelland, J. (198
Paper 6  Title: Chunking in soar: The anatomy of a general learn ing mechanism. Machine Learning, 1(1). Learning
Abstract: gers University. Also appears as tech. report ML- TR-7. Minton, S. (1988). Quantitative results concerning the utility of explanation-based learning. In Proceedings of National Conference on Artificial Intelli gence, pages 564-569. St. Paul, MN. 
Paper 7  Title: Causal inference, path analysis, and recursive struc-tural equations models. In C. Clogg, editor, Sociological Methodology,
Abstract: Lipid Research Clinic Program 84] Lipid Research Clinic Program. The Lipid Research Clinics Coronary Primary Prevention Trial results, parts I and II. Journal of the American Medical Association, 251(3):351-374, January 1984. [Pearl 93] Judea Pearl. Aspects of graphical models connected with causality. Technical Report R-195-LL, Cognitive Systems Laboratory, UCLA, June 1993. Submitted to
Label: Probabilistic Methods
Paper 8  Title: "Linear Dependencies Represented by Chain Graphs," "Graphical Modelling With MIM," Manual. "Identifying Independence in Bayesian
Abstract: 8] Dori, D. and Tarsi, M., "A Simple Algorithm to Construct a Consistent Extension of a Partially Oriented Graph," Computer Science Department, Tel-Aviv University. Also Technical Report R-185, UCLA, Cognitive Systems Laboratory, October 1992. [14] Pearl, J. and Wermuth, N., "When Can Association Graphs Admit a Causal Interpretation?," UCLA, Cognitive Systems Laboratory, Technical Report
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 2591...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present and evaluate two methods for improving the performance of ILP systems. One of them is discretization of numerical attributes, based on Fayyad and Irani's text [9], but adapted and extended in such a way that it can cope with some aspects of discretization that only occur in relational learning problems (when indeterminate literals occur). The second technique is lookahead. It is a well-known problem in ILP that a learner cannot always assess the quality of a refinement without knowing which refinements will be enabled afterwards, i.e. without looking ahead in the refinement lattice. We present a simple method for specifying when lookahead is to be used, and what kind of lookahead is interesting. Both the discretization and lookahead techniques are evaluated experimentally. The results show that both techniques improve the quality of the induced theory, while computational costs are acceptable.
Title: Title: Lookahead and Discretization in ILP  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Using Qualitative Models to Guide Inductive Learning  
Abstract: This paper presents a method for using qualitative models to guide inductive learning. Our objectives are to induce rules which are not only accurate but also explainable with respect to the qualitative model, and to reduce learning time by exploiting domain knowledge in the learning process. Such ex-plainability is essential both for practical application of inductive technology, and fo
Paper 3  Title: Induction of decision trees using RELIEFF  
Abstract: In the context of machine learning from examples this paper deals with the problem of estimating the quality of attributes with and without dependencies between them. Greedy search prevents current inductive machine learning algorithms to detect significant dependencies between the attributes. Recently, Kira and Rendell developed the RELIEF algorithm for estimating the quality of attribu
Paper 4  Title: Structural Regression Trees  
Abstract: In many real-world domains the task of machine learning algorithms is to learn a theory predicting numerical values. In particular several standard test domains used in Inductive Logic Programming (ILP) are concerned with predicting numerical values from examples and relational and mostly non-determinate background knowledge. However, so far no ILP algorithm except one can predict number
Label: Rule Learning
Paper 5  Title: Learning by Refining Algorithm Sketches  
Abstract: In this paper we suggest a mechanism that improves significantly the performance of a top-down inductive logic programming (ILP) learning system. This improvement is achieved at the cost of giving to the system extra information that is not difficult to formulate. This information appears in the form of an algorithm sketch: an incomplete and somewhat vague representation of the computati
Paper 6  Title: Naive Bayesian classifier within ILP-R  
Abstract: When dealing with the classification problems, current ILP systems often lag behind state-of-the-art attributional learners. Part of the blame can be ascribed to a much larger hypothesis space which, therefore, cannot be as thoroughly explored. However, sometimes it is due to the fact that ILP systems do not take into account the probabilistic aspects of hypotheses when classifying unsee
Paper 7  Title: Multi-class problems and discretization in ICL Extended abstract  
Abstract: Handling multi-class problems and real numbers is important in practical applications of machine learning to KDD problems. While attribute-value learners address these problems as a rule, very few ILP systems do so. The few ILP systems that handle real numbers mostly do so by trying out all real values that are applicable, thus running into efficiency or overfitting problems. This paper 
Paper 8  Title: Linear Space Induction in First Order Logic with RELIEFF  
Abstract: Current ILP algorithms typically use variants and extensions of the greedy search. This prevents them to detect significant relationships between the training objects. Instead of myopic impurity functions, we propose the use of the heuristic based on RELIEF for guidance of ILP algorithms. At each step, in our ILP-R system, this heuristic is used to determine a beam of candidate literals.
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 2507...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper introduces the idea of clearning, of simultaneously cleaning data and learning the underlying structure. The cleaning step can be viewed as top-down processing (the model modifies the data), and the learning step can be viewed as bottom-up processing (where the data modifies the model). After discussing the statistical foundation of the proposed method from a maximum likelihood perspective, we apply clearning to a notoriously hard problem where benchmark performances are very well known: the prediction of foreign exchange rates. On the difficult 1993-1994 test period, clearning in conjunction with pruning yields an annualized return between 35 and 40% (out-of-sample), significantly better than an otherwise identical network trained without cleaning. The network was started with 69 inputs and 15 hidden units and ended up with only 39 non-zero weights between inputs and hidden units. The resulting ultra-sparse final architectures obtained with clearning and pruning are immune against overfitting, even on very noisy problems since the cleaned data allow for a simpler model. Apart from the very competitive performance, clearning gives insight into the data: we show how to estimate the overall signal-to-noise ratio of each input variable, and we show that error estimates for each pattern can be used to detect and remove outliers, and to replace missing or corrupted data by cleaned values. Clearning can be used in any nonlinear regression or classification problem.
Title: Title: The Observer-Observation Dilemma in Neuro-Forecasting: Reliable Models From Unreliable Data Through CLEARNING  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: WRAPPERS FOR PERFORMANCE ENHANCEMENT AND OBLIVIOUS DECISION GRAPHS  
Abstract: This paper introduces the idea of clearning, of simultaneously cleaning data and learning the underlying structure. The cleaning step can be viewed as top-down processing (the model modifies the data), and the learning step can be viewed as bottom-up processing (where the data modifies the model). After discussing the statistical foundation of the proposed method from a maximum likelihoo
Paper 3  Title: LEARNING MORE FROM LESS DATA: EXPERIMENTS WITH LIFELONG ROBOT LEARNING  
Abstract: Most connectionist modeling assumes noise-free inputs. This assumption is often violated. This paper introduces the idea of clearning, of simultaneously cleaning the data and learning the underlying structure. The cleaning step can be viewed as top-down processing (where the model modifies the data), and the learning step can be viewed as bottom-up processing (where the data modifies the
Paper 4  Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  
Abstract: Most connectionist modeling assumes noise-free inputs. This assumption is often violated. This paper introduces the idea of clearning, of simultaneously cleaning the data and learning the underlying structure. The cleaning step can be viewed as top-down processing (where the model modifies the data), and the learning step can be viewed as bottom-up processing (where the data modifies the
Paper 5  Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  
Abstract: Most connectionist modeling assumes noise-free inputs. This assumption is often violated. This paper introduces the idea of clearning, of simultaneously cleaning the data and learning the underlying structure. The cleaning step can be viewed as top-down processing (where the model modifies the data), and the learning step can be viewed as bottom-up processing (where the data modifies the
Paper 6  Title: Avoiding overfitting by locally matching the noise level of the data gating network discovers the
Abstract: When trying to forecast the future behavior of a real-world system, two of the key problems are nonstationarity of the process (e.g., regime switching) and overfitting of the model (particularly serious for noisy processes). This articles shows how gated experts can point to solutions to these problems. The architecture, also called society of experts and mixture of experts consists of a
Paper 7  Title: TO IMPROVE FORECASTING  
Abstract: Working Paper IS-97-007, Leonard N. Stern School of Business, New York University. In: Journal of Computational Intelligence in Finance 6 (1998) 14-23. (Special Issue on "Improving Generalization of Nonlinear Financial Forecasting Models".) http://www.stern.nyu.edu/~aweigend/Research/Papers/InteractionLayer Abstract. Predictive models for financial data are often based on a large number 
Label: Neural Networks
Paper 8  Title: Packet Routing and Reinforcement Learning: Estimating Shortest Paths in Dynamic Graphs  
Abstract: This article exposes problems of the commonly used technique of splitting the available data into training, validation, and test sets that are held fixed, warns about drawing too strong conclusions from such static splits, and shows potential pitfalls of ignoring variability across splits. Using a bootstrap or resampling method, we compare the uncertainty in the solution stemming from th
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 38...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: In most applications of neuro-evolution, each individual in the population represents a complete neural network. Recent work on the SANE system, however, has demonstrated that evolving individual neurons often produces a more efficient genetic search. This paper demonstrates that while SANE can solve easy tasks very quickly, it often stalls in larger problems. A hierarchical approach to neuro-evolution is presented that overcomes SANE's difficulties by integrating both a neuron-level exploratory search and a network-level exploitive search. In a robot arm manipulation task, the hierarchical approach outperforms both a neuron-based search and a network-based search. 
Title: Title: HOW TO EVOLVE AUTONOMOUS ROBOTS: DIFFERENT APPROACHES IN EVOLUTIONARY ROBOTICS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Hierarchical Evolution of Neural Networks  
Abstract: In most applications of neuro-evolution, each individual in the population represents a complete neural network. Recent work on the SANE system, however, has demonstrated that evolving individual neurons often produces a more efficient genetic search. This paper demonstrates that while SANE can solve easy tasks very quickly, it often stalls in larger problems. A hierarchical approach to 
Paper 3  Title: Machine Learning,  Efficient Reinforcement Learning through Symbiotic Evolution  
Abstract: This article presents a new reinforcement learning method called SANE (Symbiotic, Adaptive Neuro-Evolution), which evolves a population of neurons through genetic algorithms to form a neural network capable of performing a task. Symbiotic evolution promotes both cooperation and specialization, which results in a fast, efficient genetic search and discourages convergence to suboptimal sol
Paper 4  Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  
Abstract: Genetic algorithms have been used to solve hard optimization problems ranging from the Travelling Salesman problem to the Quadratic Assignment problem. We show that the Simple Genetic Algorithm can be used to solve an optimization problem derived from the 3-Conjunctive Normal Form problem. By separating the populations into small sub-populations, parallel genetic algorithms exploits the 
Paper 5  Title: A Cooperative Coevolutionary Approach to Function Optimization  
Abstract: A general model for the coevolution of cooperating species is presented. This model is instantiated and tested in the domain of function optimization, and compared with a traditional GA-based function optimizer. The results are encouraging in two respects. They suggest ways in which the performance of GA and other EA-based optimizers can be improved, and they suggest a new approach to ev
Label: Genetic Algorithms
Paper 6  Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Abstract: Genetic algorithms have been used for neural networks in two main ways: to optimize the network architecture and to train the weights of a fixed architecture. While most previous work focuses on only one of these two options, this paper investigates an alternative evolutionary approach called Breeder Genetic Programming (BGP) in which the architecture and the weights are optimized simult
Paper 7  Title: Toward a unified theory of spatiotemporal processing in the retina  
Abstract: Traditional evolutionary optimization algorithms assume a static evaluation function, according to which solutions are evolved. Incremental evolution is an approach through which a dynamic evaluation function is scaled over time in order to improve the performance of evolutionary optimization. In this paper, we present empirical results that demonstrate the effectiveness of this approach
Paper 8  Title: A Coevolutionary Approach to Learning Sequential Decision Rules  
Abstract: We present a coevolutionary approach to learning sequential decision rules which appears to have a number of advantages over non-coevolutionary approaches. The coevolutionary approach encourages the formation of stable niches representing simpler sub-behaviors. The evolutionary direction of each subbehavior can be controlled independently, providing an alternative to evolving complex beh
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2652...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Systems for automated design optimization of complex real-world objects can, in principle, be constructed by combining domain-independent numerical routines with existing domain-specific analysis and simulation programs. Unfortunately, such legacy analysis codes are frequently unsuitable for use in automated design. They may crash for large classes of input, be numerically unstable or locally non-smooth, or be highly sensitive to control parameters. To be useful, analysis programs must be modified to reduce or eliminate only the undesired behaviors, without altering the desired computation. To do this by direct modification of the programs is labor-intensive, and necessitates costly revalidation. We have implemented a high-level language and run-time environment that allow failure-handling strategies to be incorporated into existing Fortran and C analysis programs while preserving their computational integrity. Our approach relies on globally managing the execution of these programs at the level of discretely callable functions so that the computation is only affected when problems are detected. Problem handling procedures are constructed from a knowledge base of generic problem management strategies. We show that our approach is effective in improving analysis program robustness and design optimization performance in the domain of conceptual design of jet engine nozzles. 
Title: Title: Knowledge-Based Re-engineering of Legacy Programs for Robustness in Automated Design  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Program Synthesis and Transformation Techniques for Simpuation, Optimization and Constraint Satisfaction Deductive Synthesis of Numerical
Abstract: Scientists and engineers face recurring problems of constructing, testing and modifying numerical simulation programs. The process of coding and revising such simulators is extremely time-consuming, because they are almost always written in conventional programming languages. Scientists and engineers can therefore benefit from software that facilitates construction of programs for simula
Paper 3  Title: A Transformation System for Interactive Reformulation of Design Optimization Strategies  
Abstract: Automatic design optimization is highly sensitive to problem formulation. The choice of objective function, constraints and design parameters can dramatically impact the computational cost of optimization and the quality of the resulting design. The best formulation varies from one application to another. A design engineer will usually not know the best formulation in advance. In order t
Paper 4  Title: Intelligent Gradient-Based Search of Incompletely Defined Design Spaces  
Abstract: Gradient-based numerical optimization of complex engineering designs offers the promise of rapidly producing better designs. However, such methods generally assume that the objective function and constraint functions are continuous, smooth, and defined everywhere. Unfortunately, realistic simulators tend to violate these assumptions. We present a rule-based technique for intelligently co
Paper 5  Title: Using Modeling Knowledge to Guide Design Space Search  
Abstract: Automated search of a space of candidate designs seems an attractive way to improve the traditional engineering design process. To make this approach work, however, the automated design system must include both knowledge of the modeling limitations of the method used to evaluate candidate designs and also an effective way to use this knowledge to influence the search process. We suggest 
Label: Genetic Algorithms
Paper 6  Title: A Transformation System for Interactive Reformulation of Design Optimization Strategies  
Abstract: Numerical design optimization algorithms are highly sensitive to the particular formulation of the optimization problems they are given. The formulation of the search space, the objective function and the constraints will generally have a large impact on the duration of the optimization process as well as the quality of the resulting design. Furthermore, the best formulation will vary fr
Label: Genetic Algorithms
Paper 7  Title: Knowledge Compilation and Speedup Learning in Continuous Task Domains  
Abstract: Many techniques for speedup learning and knowledge compilation focus on the learning and optimization of macro-operators or control rules in task domains that can be characterized using a problem-space search paradigm. However, such a characterization does not fit well the class of task domains in which the problem solver is required to perform in a continuous manner. For example, in man
Paper 8  Title: Data Exploration with Reflective Adaptive Models  
Abstract: Case-Based Planning (CBP) provides a way of scaling up domain-independent planning to solve large problems in complex domains. It replaces the detailed and lengthy search for a solution with the retrieval and adaptation of previous planning experiences. In general, CBP has been demonstrated to improve performance over generative (from-scratch) planning. However, the performance improveme
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  False

Prediction: 0
Processing index 959...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This article describes a numerical method that may be used to efficiently locate and track underwater sonar targets in the near-field, with both bearing and range estimation, for the case of very large passive arrays. The approach used has no requirement for a priori knowledge about the source and uses only limited information about the receiver array shape. The role of sensor position uncertainty and the consequence of targets always being in the near-field are analysed and the problems associated with the manipulation of large matrices inherent in conventional eigenvalue type algorithms noted. A simpler numerical approach is then presented which reduces the problem to that of search optimization. When using this method the location of a target corresponds to finding the position of the maximum weighted sum of the output from all sensors. Since this search procedure can be dealt with using modern stochastic optimization methods, such as the genetic algorithm, the operational requirement that an acceptable accuracy be achieved in real time can usually be met. The array studied here consists of 225 elements positioned along a flexible cable towed behind a ship with 3.4m between sensors, giving an effective aperture of 761.6m. For such a long array, the far field assumption used in most beam-forming algorithms is no longer appropriate. The waves emitted by the targets then have to be considered as curved rather than plane. It is shown that, for simulated data, if no significant noise 
Title: Title: Numerical techniques for efficient sonar bearing and range searching in the near field using genetic algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Sequential Niche Technique for Multimodal Function Optimization  
Abstract: c fl UWCC COMMA Technical Report No. 93001, February 1993 x No part of this article may be reproduced for commercial purposes. Abstract A technique is described which allows unimodal function optimization methods to be extended to efficiently locate all optima of multimodal problems. We describe an algorithm based on a traditional genetic algorithm (GA). This involves iterating the GA, b
Paper 3  Title: Space-Frequency Localized Basis Function Networks for Nonlinear System Estimation and Control  
Abstract: Stable neural network control and estimation may be viewed formally as a merging of concepts from nonlinear dynamic systems theory with tools from multivariate approximation theory. This paper extends earlier results on adaptive control and estimation of nonlinear systems using gaussian radial basis functions to the on-line generation of irregularly sampled networks, using tools from mul
Label: Neural Networks
Paper 4  Title: A comparison of neural net and conventional techniques for lighting control  
Abstract: We compare two techniques for lighting control in an actual room equipped with seven banks of lights and photoresistors to detect the lighting level at four sensing points. Each bank of lights can be independently set to one of sixteen intensity levels. The task is to determine the device intensity levels that achieve a particular configuration of sensor readings. One technique we explor
Paper 5  Title: Data Reconciliation and Gross Error Detection for Dynamic Systems  
Abstract: Gross error detection plays a vital role in parameter estimation and data reconciliation for both dynamic and steady state systems. In particular, recent advances in process optimization now allow data reconciliation of dynamic systems and appropriate problem formulations need to be considered for them. Data errors due to either miscalibrated or faulty sensors or just random events nonre
Paper 6  Title: Bayesian Training of Backpropagation Networks by the Hybrid Monte Carlo Method  
Abstract: It is shown that Bayesian training of backpropagation neural networks can feasibly be performed by the "Hybrid Monte Carlo" method. This approach allows the true predictive distribution for a test case given a set of training cases to be approximated arbitrarily closely, in contrast to previous approaches which approximate the posterior weight distribution by a Gaussian. In this work, th
Paper 7  Title: A GENERAL METHOD FOR INCREMENTAL SELF-IMPROVEMENT AND MULTI-AGENT LEARNING  
Abstract: Process simulation has emerged as a valuable tool for process design, analysis and operation. In this work, we extend the capabilities of iterated linear programming (LP) for dealing with problems encountered in dynamic nonsmooth process simulation. A previously developed LP method is refined with the addition of a new descent strategy which combines line search with a trust region appro
Paper 8  Title: An Investigation of Marker-Passing Algorithms for Analogue Retrieval  
Abstract: If analogy and case-based reasoning systems are to scale up to very large case bases, it is important to analyze the various methods used for retrieving analogues to identify the features of the problem for which they are appropriate. This paper reports on one such analysis, a comparison of retrieval by marker passing or spreading activation in a semantic network with Knowledge-Directed 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 616...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: MORGAN is an integrated system for finding genes in vertebrate DNA sequences. MORGAN uses a variety of techniques to accomplish this task, the most distinctive of which is a decision tree classifier. The decision tree system is combined with new methods for identifying start codons, donor sites, and acceptor sites, and these are brought together in a frame-sensitive dynamic programming algorithm that finds the optimal segmentation of a DNA sequence into coding and noncoding regions (exons and introns). The optimal segmentation is dependent on a separate scoring function that takes a subsequence and assigns to it a score reflecting the probability that the sequence is an exon. The scoring functions in MORGAN are sets of decision trees that are combined to give a probability estimate. Experimental results on a database of 570 vertebrate DNA sequences show that MORGAN has excellent performance by many different measures. On a separate test set, it achieves an overall accuracy of 95%, with a correlation coefficient of 0.78 and a sensitivity and specificity for coding bases of 83% and 79%. In addition, MORGAN identifies 58% of coding exons exactly; i.e., both the beginning and end of the coding regions are predicted correctly. This paper describes the MORGAN system, including its decision tree routines and the algorithms for site recognition, and its performance on a benchmark database of vertebrate DNA. 
Title: Title: A Decision Tree System for Finding Genes in DNA  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Generalized Hidden Markov Model for the Recognition of Human Genes in DNA  
Abstract: We present a statistical model of genes in DNA. A Generalized Hidden Markov Model (GHMM) provides the framework for describing the grammar of a legal parse of a DNA sequence (Stormo & Haussler 1994). Probabilities are assigned to transitions between states in the GHMM and to the generation of each nucleotide base given a particular state. Machine learning techniques are applied to optimi
Paper 3  Title: Finding Genes in DNA with a Hidden Markov Model  
Abstract: This study describes a new Hidden Markov Model (HMM) system for segmenting uncharacterized genomic DNA sequences into exons, introns, and intergenic regions. Separate HMM modules were designed and trained for specific regions of DNA: exons, introns, intergenic regions, and splice sites. The models were then tied together to form a biologically feasible topology. The integrated HMM was tr
Paper 4  Title: Hidden Markov Models in Computational Biology: Applications to Protein Modeling UCSC-CRL-93-32 Keywords: Hidden Markov Models,
Abstract: Hidden Markov Models (HMMs) are applied to the problems of statistical modeling, database searching and multiple sequence alignment of protein families and protein domains. These methods are demonstrated on the globin family, the protein kinase catalytic domain, and the EF-hand calcium binding motif. In each case the parameters of an HMM are estimated from a training set of unaligned seq
Label: Neural Networks
Paper 5  Title: Dirichlet Mixtures: A Method for Improving Detection of Weak but Significant Protein Sequence Homology  
Abstract: UCSC Technical Report UCSC-CRL-96-09 Abstract This paper presents the mathematical foundations of Dirichlet mixtures, which have been used to improve database search results for homologous sequences, when a variable number of sequences from a protein family or domain are known. We present a method for condensing the information in a protein database into a mixture of Dirichlet densities.
Paper 6  Title: Face Recognition: A Hybrid Neural Network Approach  
Abstract: Faces represent complex, multidimensional, meaningful visual stimuli and developing a computational model for face recognition is difficult (Turk and Pentland, 1991). We present a hybrid neural network solution which compares favorably with other methods. The system combines local image sampling, a self-organizing map neural network, and a convolutional neural network. The self-organizin
Paper 7  Title: Learning to Predict Reading Frames in E. coli DNA Sequences  
Abstract: Two fundamental problems in analyzing DNA sequences are (1) locating the regions of a DNA sequence that encode proteins, and (2) determining the reading frame for each region. We investigate using artificial neural networks (ANNs) to find coding regions, determine reading frames, and detect frameshift errors in E. coli DNA sequences. We describe our adaptation of the approach used by Ube
Paper 8  Title: The megaprior heuristic for discovering protein sequence patterns  
Abstract: Several computer algorithms for discovering patterns in groups of protein sequences are in use that are based on fitting the parameters of a statistical model to a group of related sequences. These include hidden Markov model (HMM) algorithms for multiple sequence alignment, and the MEME and Gibbs sampler algorithms for discovering motifs. These algorithms are sometimes prone to producin
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 2049...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The paper investigates the possibilities for using simple recurrent networks as transducers which map sequential natural language input into non-sequential feature-based semantics. The networks perform well on sentences containing a single main predicate (encoded by transitive verbs or prepositions) applied to multiple-feature objects (encoded as noun-phrases with adjectival modifiers), and shows robustness against ungrammatical inputs. A second set of experiments deals with sentences containing embedded structures. Here the network is able to process multiple levels of sentence-final embeddings but only one level of center-embedding. This turns out to be a consequence of the network's inability to retain information that is not reflected in the outputs over intermediate phases of processing. Two extensions to Elman's [9] original recurrent network architecture are introduced. 
Title: Title: Learning Feature-based Semantics with Simple Recurrent Networks  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: TABLE DES MATI ERES 1 Apprentissage et approximation les techniques de regularisation 3 1.1 Introduction
Abstract: The paper investigates the possibilities for using simple recurrent networks as transducers which map sequential natural language input into non-sequential feature-based semantics. The networks perform well on sentences containing a single main predicate (encoded by transitive verbs or prepositions) applied to multiple-feature objects (encoded as noun-phrases with adjectival modifiers), 
Paper 3  Title: Subsymbolic Case-Role Analysis of Sentences with Embedded Clauses  
Abstract: A distributed neural network model called SPEC for processing sentences with recursive relative clauses is described. The model is based on separating the tasks of segmenting the input word sequence into clauses, forming the case-role representations, and keeping track of the recursive embeddings into different modules. The system needs to be trained only with the basic sentence construc
Paper 4  Title: Simple Synchrony Networks: Learning Generalisations across Syntactic Constituents  
Abstract: This paper describes a training algorithm for Simple Synchrony Networks (SSNs), and reports on experiments in language learning using a recursive grammar. The SSN is a new connectionist architecture combining a technique for learning about patterns across time, Simple Recurrent Networks (SRNs), with Temporal Synchrony Variable Binding (TSVB). The use of TSVB means the SSN can learn about
Paper 5  Title: Natural Language Grammatical Inference with Recurrent Neural Networks  
Abstract: This paper examines the inductive inference of a complex grammar with neural networks specifically, the task considered is that of training a network to classify natural language sentences as grammatical or ungrammatical, thereby exhibiting the same kind of discriminatory power provided by the Principles and Parameters linguistic framework, or Government-and-Binding theory. Neural networ
Paper 6  Title: Data-defined Problems and Multiversion Neural-net Systems  
Abstract: We inv estigate the applicability of an adaptive neural network to problems with time-dependent input by demonstrating that a deterministic parser for natural language inputs of significant syntactic complexity can be developed using recurrent connectionist architectures. The traditional stacking mechanism, known to be necessary for proper treatment of context-free languages in symbolic 
Paper 7  Title: On the Applicability of Neural Network and Machine Learning Methodologies to Natural Language Processing  
Abstract: We examine the inductive inference of a complex grammar specifically, we consider the task of training a model to classify natural language sentences as grammatical or ungrammatical, thereby exhibiting the same kind of discriminatory power provided by the Principles and Parameters linguistic framework, or Government-and-Binding theory. We investigate the following models: feed-forward ne
Paper 8  Title: Simple Synchrony Networks Learning to Parse Natural Language with Temporal Synchrony Variable Binding  
Abstract: The Simple Synchrony Network (SSN) is a new connectionist architecture, incorporating the insights of Temporal Synchrony Variable Binding (TSVB) into Simple Recurrent Networks. The use of TSVB means SSNs can output representations of structures, and can learn generalisations over the constituents of these structures (as required by systematicity). This paper describes the SSN and an asso
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1390...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: One of the open problems listed in [ Rivest and Schapire, 1989 ] is whether and how that the copies of L fl in their algorithm can be combined into one for better performance. This paper describes an algorithm called D fl that does that combination. The idea is to represent the states of the learned model using observable symbols as well as hidden symbols that are constructed during learning. These hidden symbols are created to reflect the distinct behaviors of the model states. The distinct behaviors are represented as local distinguishing experiments (LDEs) (not to be confused with global distinguishing sequences), and these LDEs are created when the learner's prediction mismatches the actual observation from the unknown machine. To synchronize the model with the environment, these LDEs can also be concatenated to form a homing sequence. It can be shown that D fl can learn, with probability 1 , a model that is an *-approximation of the unknown machine, in a number of actions polynomial in the size of the environment and 
Title: Title: Learning Finite Automata Using Local Distinguishing Experiments  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Online Learning with Random Representations  
Abstract: We consider the requirements of online learning|learning which must be done incrementally and in realtime, with the results of learning available soon after each new example is acquired. Despite the abundance of methods for learning from examples, there are few that can be used effectively for online learning, e.g., as components of reinforcement learning systems. Most of these few, incl
Paper 3  Title: Efficient Learning of Typical Finite Automata from Random Walks (Extended Abstract)  
Abstract: This paper describes new and efficient algorithms for learning deterministic finite automata. Our approach is primarily distinguished by two features: (1) the adoption of an average-case setting to model the "typical" labeling of a finite automaton, while retaining a worst-case model for the underlying graph of the automaton, along with (2) a learning model in which the learner is not pr
Paper 4  Title: Distribution Category:  Users Guide to the PGAPack Parallel Genetic Algorithm Library  
Abstract: The problem of modeling complicated data sequences, such as DNA or speech, often arises in practice. Most of the algorithms select a hypothesis from within a model class assuming that the observed sequence is the direct output of the underlying generation process. In this paper we consider the case when the output passes through a memoryless noisy channel before observation. In particula
Paper 5  Title: Using Errors to Create Piecewise Learnable Partitions  
Abstract: In this paper we describe an algorithm which exploits the error distribution generated by a learning algorithm in order to break up the domain which is being approximated into piecewise learnable partitions. Traditionally, the error distribution has been neglected in favor of a lump error measure such as RMS. By doing this, however, we lose a lot of important information. The error distr
Label: Theory
Paper 6  Title: Learning Markov chains with variable memory length from noisy output  
Abstract: The problem of modeling complicated data sequences, such as DNA or speech, often arises in practice. Most of the algorithms select a hypothesis from within a model class assuming that the observed sequence is the direct output of the underlying generation process. In this paper we consider the case when the output passes through a memoryless noisy channel before observation. In particula
Label: Theory
Paper 7  Title: Two Methods for Hierarchy Learning in Reinforcement Environments  
Abstract: This paper describes two methods for hierarchically organizing temporal behaviors. The first is more intuitive: grouping together common sequences of events into single units so that they may be treated as individual behaviors. This system immediately encounters problems, however, because the units are binary, meaning the behaviors must execute completely or not at all, and this hinders 
Paper 8  Title: Improving Generalization with Active Learning  
Abstract: Active learning differs from passive "learning from examples" in that the learning algorithm assumes at least some control over what part of the input domain it receives information about. In some situations, active learning is provably more powerful that learning from examples alone, giving better generalization for a fixed number of training examples. In this paper, we consider the pro
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 1519...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper reports on the development of a realistic knowledge-based application using the MOBAL system. Some problems and requirements resulting from industrial-caliber tasks are formulated. A step-by-step account of the construction of a knowledge base for such a task demonstrates how the interleaved use of several learning algorithms in concert with an inference engine and a graphical interface can fulfill those requirements. Design, analysis, revision, refinement and extension of a working model are combined in one incremental process. This illustrates the balanced cooperative modeling approach. The case study is taken from the telecommunications domain and more precisely deals with security management in telecommunications networks. MOBAL would be used as part of a security management tool for acquiring, validating and refining a security policy. The modeling approach is compared with other approaches, such as KADS and stand-alone machine learning. 
Title: Title: What online Machine Learning can do for Knowledge Acquisition A Case Study  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Adaptive Tuning of Numerical Weather Prediction Models: Simultaneous Estimation of Weighting, Smoothing and Physical Parameters 1  
Abstract: In recent years, case-based reasoning has been demonstrated to be highly useful for problem solving in complex domains. Also, mixed paradigm approaches emerged for combining CBR and induction techniques aiming at verifying the knowledge and/or building an efficient case memory. However, in complex domains induction over the whole problem space is often not possible or too time consuming.
Paper 3  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 4  Title: Diplomarbeit A Genetic Algorithm for the Topological Optimization of Neural Networks  
Abstract: We describe an integrated problem solving architecture named INBANCA in which Bayesian networks and case-based reasoning (CBR) work cooperatively on multiagent planning tasks. This includes two-team dynamic tasks, and this paper concentrates on simulated soccer as an example. Bayesian networks are used to characterize action selection whereas a case-based approach is used to determine ho
Label: Genetic Algorithms
Paper 5  Title: Rule Generation and Compaction in the wwtp  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 6  Title: Structural Similarity as Guidance in Case-Based Design  
Abstract: This paper presents a novel approach to determine structural similarity as guidance for adaptation in case-based reasoning (Cbr). We advance structural similarity assessment which provides not only a single numeric value but the most specific structure two cases have in common, inclusive of the modification rules needed to obtain this structure from the two cases. Our approach treats ret
Label: Case Based
Paper 7  Title: Lazy Induction Triggered by CBR  
Abstract: In recent years, case-based reasoning has been demonstrated to be highly useful for problem solving in complex domains. Also, mixed paradigm approaches emerged for combining CBR and induction techniques aiming at verifying the knowledge and/or building an efficient case memory. However, in complex domains induction over the whole problem space is often not possible or too time consuming.
Paper 8  Title: An Interactive Planning Architecture The Forest Fire Fighting case  
Abstract: This paper describes an interactive planning system that was developed inside an Intelligent Decision Support System aimed at supporting an operator when planning the initial attack to forest fires. The planning architecture rests on the integration of case-based reasoning techniques with constraint reasoning techniques exploited, mainly, for performing temporal reasoning on temporal met
Label: Case Based
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Case Based
Prediction:  Case Based
Is prediction correct?  False

Prediction: 0
Processing index 1485...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Quantization of the parameters of a Perceptron is a central problem in hardware implementation of neural networks using a numerical technology. An interesting property of neural networks used as classifiers is their ability to provide some robustness on input noise. This paper presents efficient learning algorithms for the maximization of the robustness of a Perceptron and especially designed to tackle the combinatorial problem arising from the discrete weights. 
Title: Title: Maximizing the Robustness of a Linear Threshold Classifier with Discrete Weights  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Provably Convergent Dynamic Training Method for Multilayer Perceptron Networks  
Abstract: This paper presents a new method for training multilayer perceptron networks called DMP1 (Dynamic Multilayer Perceptron 1). The method is based upon a divide and conquer approach which builds networks in the form of binary trees, dynamically allocating nodes and layers as needed. The individual nodes of the network are trained using a gentetic algorithm. The method is capable of handling
Label: Neural Networks
Paper 3  Title: Interpretable Neural Networks with BP-SOM  
Abstract: Interpretation of models induced by artificial neural networks is often a difficult task. In this paper we focus on a relatively novel neural network architecture and learning algorithm, bp-som, that offers possibilities to overcome this difficulty. It is shown that networks trained with bp-som show interesting regularities, in that hidden-unit activations become restricted to discrete v
Label: Neural Networks
Paper 4  Title: Feature Selection by Means of a Feature Weighting Approach  
Abstract: Selecting a set of features which is optimal for a given classification task is one of the central problems in machine learning. We address the problem using the flexible and robust filter technique EUBAFES. EUBAFES is based on a feature weighting approach which computes binary feature weights and therefore a solution in the feature selection sense and also gives detailed information abo
Paper 5  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Paper 6  Title: Improving RBF Networks by the Feature Selection Approach EUBAFES  
Abstract: The curse of dimensionality is one of the severest problems concerning the application of RBF networks. The number of RBF nodes and therefore the number of training examples needed grows exponentially with the intrinsic dimensionality of the input space. One way to address this problem is the application of feature selection as a data preprocessing step. In this paper we propose a two-st
Label: Neural Networks
Paper 7  Title: Analysis of Decision Boundaries Generated by Constructive Neural Network Learning Algorithms  
Abstract: Constructive learning algorithms offer an approach to incremental construction of near-minimal artificial neural networks for pattern classification. Examples of such algorithms include Tower, Pyramid, Upstart, and Tiling algorithms which construct multilayer networks of threshold logic units (or, multilayer perceptrons). These algorithms differ in terms of the topology of the networks t
Paper 8  Title: Adaptive Noise Injection for Input Variables Relevance Determination  
Abstract: In this paper we consider the application of training with noise in multi-layer perceptron to input variables relevance determination. Noise injection is modified in order to penalize irrelevant features. The proposed algorithm is attractive as it requires the tuning of a single parameter. This parameter controls the penalization of the inputs together with the complexity of the model. A
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1643...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Researchers in the field of Distributed Artificial Intelligence (DAI) have been developing efficient mechanisms to coordinate the activities of multiple autonomous agents. The need for coordination arises because agents have to share resources and expertise required to achieve their goals. Previous work in the area includes using sophisticated information exchange protocols, investigating heuristics for negotiation, and developing formal models of possibilities of conflict and cooperation among agent interests. In order to handle the changing requirements of continuous and dynamic environments, we propose learning as a means to provide additional possibilities for effective coordination. We use reinforcement learning techniques on a block pushing problem to show that agents can learn complimentary policies to follow a desired path without any knowledge about each other. We theoretically analyze and experimentally verify the effects of learning rate on system convergence, and demonstrate benefits of using learned coordination knowledge on similar problems. Reinforcement learning based coordination can be achieved in both cooperative and non-cooperative domains, and in domains with noisy communication channels and other stochastic characteristics that present a formidable challenge to using other coordination schemes. 
Title: Title: Learning to coordinate without sharing information  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract: We present a new approach to reinforcement learning in which the policies considered by the learning process are constrained by hierarchies of partially specified machines. This allows for the use of prior knowledge to reduce the search space and provides a framework in which knowledge can be transferred across problems and in which component solutions can be recombined to solve larger a
Paper 3  Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  
Abstract: The application of decision making and learning algorithms to multi-agent systems presents many interestingresearch challenges and opportunities. Among these is the ability for agents to learn how to act by observing or imitating other agents. We describe an algorithm, the IQ-algorithm, that integrates imitation with Q-learning. Roughly, a Q-learner uses the observations it has made of a
Paper 4  Title: Scaling Reinforcement Learning Algorithms by Learning Variable Temporal Resolution Models  
Abstract: The close connection between reinforcement learning (RL) algorithms and dynamic programming algorithms has fueled research on RL within the machine learning community. Yet, despite increased theoretical understanding, RL algorithms remain applicable to simple tasks only. In this paper I use the abstract framework afforded by the connection to dynamic programming to discuss the scaling is
Label: Reinforcement Learning
Paper 5  Title: Modeling the Student with Reinforcement Learning  
Abstract: We describe a methodology for enabling an intelligent teaching system to make high level strategy decisions on the basis of low level student modeling information. This framework is less costly to construct, and superior to hand coding teaching strategies as it is more responsive to the learner's needs. In order to accomplish this, reinforcement learning is used to learn to associate sup
Paper 6  Title: Evolving Cooperation Strategies  
Abstract: The identification, design, and implementation of strategies for cooperation is a central research issue in the field of Distributed Artificial Intelligence (DAI). We propose a novel approach to the construction of cooperation strategies for a group of problem solvers based on the Genetic Programming (GP) paradigm. GPs are a class of adaptive algorithms used to evolve solution structures
Paper 7  Title: Learning in Multi-Robot Systems  
Abstract: This paper 1 discusses why traditional reinforcement learning methods, and algorithms applied to those models, result in poor performance in dynamic, situated multi-agent domains characterized by multiple goals, noisy perception and action, and inconsistent reinforcement. We propose a methodology for designing the representation and the forcement functions that take advantage of implicit
Paper 8  Title: Learning Hierarchical Control Structures for Multiple Tasks and Changing Environments  
Abstract: While the need for hierarchies within control systems is apparent, it is also clear to many researchers that such hierarchies should be learned. Learning both the structure and the component behaviors is a difficult task. The benefit of learning the hierarchical structures of behaviors is that the decomposition of the control structure into smaller transportable chunks allows previously 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 469...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A traditional interpolation model is characterized by the choice of reg-ularizer applied to the interpolant, and the choice of noise model. Typically, the regularizer has a single regularization constant ff, and the noise model has a single parameter fi. The ratio ff=fi alone is responsible for determining globally all these attributes of the interpolant: its `complexity', `flexibility', `smoothness', `characteristic scale length', and `characteristic amplitude'. We suggest that interpolation models should be able to capture more than just one flavour of simplicity and complexity. We describe Bayesian models in which the interpolant has a smoothness that varies spatially. We emphasize the importance, in practical implementation, of the concept of `conditional convexity' when designing models with many hyperparameters. We apply the new models to the interpolation of neuronal spike data and demonstrate a substantial improvement in generalization error. 
Title: Title: Interpolation Models with Multiple  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Practical Bayesian Framework for Backprop Networks  
Abstract: A quantitative and practical Bayesian framework is described for learning of mappings in feedforward networks. The framework makes possible: (1) objective comparisons between solutions using alternative network architectures; (2) objective stopping rules for network pruning or growing procedures; (3) objective choice of magnitude and type of weight decay terms or additive regularisers (f
Paper 3  Title: Tempering Backpropagation Networks: Not All Weights are Created Equal approach yields hitherto unparalleled performance on
Abstract: Backpropagation learning algorithms typically collapse the network's structure into a single vector of weight parameters to be optimized. We suggest that their performance may be improved by utilizing the structural information instead of discarding it, and introduce a framework for tempering each weight accordingly. In the tempering model, activation and error signals are treated as app
Paper 4  Title: Bayesian Non-linear Modelling for the Prediction Competition  
Abstract: The 1993 energy prediction competition involved the prediction of a series of building energy loads from a series of environmental input variables. Non-linear regression using `neural networks' is a popular technique for such modeling tasks. Since it is not obvious how large a time-window of inputs is appropriate, or what preprocessing of inputs is best, this can be viewed as a regressio
Paper 5  Title: From Isolation to Cooperation: An Alternative View of a System of Experts  
Abstract: We introduce a constructive, incremental learning system for regression problems that models data by means of locally linear experts. In contrast to other approaches, the experts are trained independently and do not compete for data during learning. Only when a prediction for a query is required do the experts cooperate by blen ding their individual predictions. Each expert is trained by
Paper 6  Title: Wavelet Thresholding via a Bayesian Approach  
Abstract: We discuss a Bayesian formalism which gives rise to a type of wavelet threshold estimation in non-parametric regression. A prior distribution is imposed on the wavelet coefficients of the unknown response function, designed to capture the sparseness of wavelet expansion common to most applications. For the prior specified, the posterior median yields a thresholding procedure. Our prior m
Label: Probabilistic Methods
Paper 7  Title: Function Approximation with Neural Networks and Local Methods: Bias, Variance and Smoothness  
Abstract: We review the use of global and local methods for estimating a function mapping R m ) R n from samples of the function containing noise. The relationship between the methods is examined and an empirical comparison is performed using the multi-layer perceptron (MLP) global neural network model, the single nearest-neighbour model, a linear local approximation (LA) model, and the following 
Paper 8  Title: Choice of Thresholds for Wavelet Shrinkage Estimate of the Spectrum fff j g are level-dependent
Abstract: We study the problem of estimating the log spectrum of a stationary Gaussian time series by thresholding the empirical wavelet coefficients. We propose the use of thresholds t j;n depending on sample size n, wavelet basis and resolution level j. At fine resolution levels (j = 1; 2; :::), we propose The purpose of this thresholding level is to make the reconstructed log-spectrum as nearly
Label: Probabilistic Methods
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 2686...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Chaque parametre du modele est penalise individuellement. Le reglage de ces penalisations se fait automatiquement a partir de la definition d'un hyperparametre de regularisation globale. Cet hyperparametre, qui controle la complexite du regresseur, peut ^etre estime par des techniques de reechantillonnage. Nous montrons experimentalement les performances et la stabilite de la penalisation multiple adaptative dans le cadre de la regression lineaire. Nous avons choisi des problemes pour lesquels le probleme du controle de la complexite est particulierement crucial, comme dans le cadre plus general de l'estimation fonctionnelle. Les comparaisons avec les moindres carres regularises et la selection de variables nous permettent de deduire les conditions d'application de chaque algorithme de penalisation. Lors des simulations, nous testons egalement plusieurs techniques de reechantillonnage. Ces techniques sont utilisees pour selectionner la complexite optimale des estimateurs de la fonction de regression. Nous comparons les pertes occasionnees par chacune d'entre elles lors de la selection de modeles sous-optimaux. Nous regardons egalement si elles permettent de determiner l'estimateur de la fonction de regression minimisant l'erreur en generalisation parmi les differentes methodes de penalisation en competition. 
Title: Title: Penalisation multiple adaptative un nouvel algorithme de regression, la penalisation multiple adapta-tive. Cet algorithme represente
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: ALECSYS and the AutonoMouse: Learning to Control a Real Robot by Distributed Classifier Systems  
Abstract: Chaque parametre du modele est penalise individuellement. Le reglage de ces penalisations se fait automatiquement a partir de la definition d'un hyperparametre de regularisation globale. Cet hyperparametre, qui controle la complexite du regresseur, peut ^etre estime par des techniques de reechantillonnage. Nous montrons experimentalement les performances et la stabilite de la penalisatio
Paper 3  Title: Model Selection for Generalized Linear Models via GLIB, with Application to Epidemiology 1  
Abstract: 1 This is the first draft of a chapter for Bayesian Biostatistics, edited by Donald A. Berry and Darlene K. Strangl. Adrian E. Raftery is Professor of Statistics and Sociology, Department of Statistics, GN-22, University of Washington, Seattle, WA 98195, USA. Sylvia Richardson is Directeur de Recherche, INSERM Unite 170, 16 avenue Paul Vaillant Couturier, 94807 Villejuif CEDEX, France. R
Label: Probabilistic Methods
Paper 4  Title: A DISCUSSION ON SOME DESIGN PRINCIPLES FOR EFFICIENT CROSSOVER OPERATORS FOR GRAPH COLORING PROBLEMS  
Abstract: A year ago, a new metaheuristic for graph coloring problems was introduced by Costa, Hertz and Dubuis. They have shown, with computer experiments, some clear indication of the benefits of this approach. Graph coloring has many applications specially in the areas of scheduling, assignments and timetabling. The metaheuristic can be classified as a memetic algorithm since it is based on a p
Paper 5  Title: GAL: Networks that grow when they learn and shrink when they forget  
Abstract: Learning when limited to modification of some parameters has a limited scope; the capability to modify the system structure is also needed to get a wider range of the learnable. In the case of artificial neural networks, learning by iterative adjustment of synaptic weights can only succeed if the network designer predefines an appropriate network structure, i.e., number of hidden layers,
Paper 6  Title: GREQE a Diplome des Etudes Approfondies en Economie Mathematique et Econometrie A Genetic Algorithm for
Abstract: The purpose of this paper is to propose a refinement of the notion of innateness. If we merely identify innateness with bias, then we obtain a poor characterisation of this notion, since any learning device relies on a bias that makes it choose a given hypothesis instead of another. We show that our intuition of innateness is better captured by a characteristic of bias, related to isotro
Paper 7  Title: Adaptive Boosting of Neural Networks for Character Recognition  
Abstract: Technical Report #1072, D epartement d'Informatique et Recherche Op erationnelle, Universit e de Montr eal Abstract Boosting is a general method for improving the performance of any learning algorithm that consistently generates classifiers which need to perform only slightly better than random guessing. A recently proposed and very promising boosting algorithm is AdaBoost [5]. It has be
Label: Neural Networks
Paper 8  Title: Stochastic Hillclimbing as a Baseline Method for Evaluating Genetic Algorithms  
Abstract: We investigate the effectiveness of stochastic hillclimbing as a baseline for evaluating the performance of genetic algorithms (GAs) as combinatorial function optimizers. In particular, we address four problems to which GAs have been applied in the literature: the maximum cut problem, Koza's 11-multiplexer problem, MDAP (the Multiprocessor Document Allocation Problem), and the jobshop pr
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 417...
An error occurred at index 64: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /allenai/scibert_scivocab_uncased/resolve/main/1_Pooling/config.json (Caused by ProxyError('Cannot connect to proxy.', TimeoutError('_ssl.c:980: The handshake operation timed out')))"), '(Request ID: 30ca925c-7ecc-4929-bc59-abcf348f2101)')
Retrying in 0.2 seconds...
Processing index 417...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: In learning from examples it is often useful to expand an attribute-vector representation by intermediate concepts. The usual advantage of such structuring of the learning problem is that it makes the learning easier and improves the comprehensibility of induced descriptions. In this paper, we develop a technique for discovering useful intermediate concepts when both the class and the attributes are real-valued. The technique is based on a decomposition method originally developed for the design of switching circuits and recently extended to handle incompletely specified multi-valued functions. It was also applied to machine learning tasks. In this paper, we introduce modifications, needed to decompose real functions and to present them in symbolic form. The method is evaluated on a number of test functions. The results show that the method correctly decomposes fairly complex functions. The decomposition hierarchy does not depend on a given repertoir of basic functions (background knowledge). 
Title: Title: Constructing Intermediate Concepts by Decomposition of Real Functions  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: FONN: Combining First Order Logic with Connectionist Learning  
Abstract: This paper presents a neural network architecture that can manage structured data and refine knowledge bases expressed in a first order logic language. The presented framework is well suited to classification problems in which concept de scriptions depend upon numerical features of the data. In fact, the main goal of the neural architecture is that of refining the numerical part of the k
Paper 3  Title: Machine Learning by Function Decomposition  
Abstract: We present a new machine learning method that, given a set of training examples, induces a definition of the target concept in terms of a hierarchy of intermediate concepts and their definitions. This effectively decomposes the problem into smaller, less complex problems. The method is inspired by the Boolean function decomposition approach to the design of digital circuits. To cope with
Paper 4  Title: Evolving Compact Solutions in Genetic Programming: A Case Study  
Abstract: Genetic programming (GP) is a variant of genetic algorithms where the data structures handled are trees. This makes GP especially useful for evolving functional relationships or computer programs, as both can be represented as trees. Symbolic regression is the determination of a function dependence y = g(x) that approximates a set of data points (x i ; y i ). In this paper the feasibilit
Label: Genetic Algorithms
Paper 5  Title: Hidden Markov Model Analysis of Motifs in Steroid Dehydrogenases and their Homologs  
Abstract: Methods to build function approximators from example data have gained considerable interest in the past. Especially methodologies that build models that allow an interpretation have attracted attention. Most existing algorithms, however, are either complicated to use or infeasible for high-dimensional problems. This article presents an efficient and easy to use algorithm to construct fuz
Label: Neural Networks
Paper 6  Title: Using Qualitative Models to Guide Inductive Learning  
Abstract: This paper presents a method for using qualitative models to guide inductive learning. Our objectives are to induce rules which are not only accurate but also explainable with respect to the qualitative model, and to reduce learning time by exploiting domain knowledge in the learning process. Such ex-plainability is essential both for practical application of inductive technology, and fo
Paper 7  Title: First Order Regression: Applications in Real-World Domains  
Abstract: A first order regression algorithm capable of handling real-valued (continuous) variables is introduced and some of its applications are presented. Regressional learning assumes real-valued class and discrete or real-valued variables. The algorithm combines regressional learning with standard ILP concepts, such as first order concept description and background knowledge. A clause is gene
Paper 8  Title: Growing a Hypercubical Output Space in a Self-Organizing Feature Map  
Abstract: Recent studies on planning, comparing plan re-use and plan generation, have shown that both the above tasks may have the same degree of computational complexity, even if we deal with very similar problems. The aim of this paper is to show that the same kind of results apply also for diagnosis. We propose a theoretical complexity analysis coupled with some experimental tests, intended to 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Theory
Prediction:  Theory
Is prediction correct?  False

Prediction: 0
Processing index 2489...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Experience plays an important role in the development of human expertise. One computational model of how experience affects expertise is provided by research on case-based reasoning, which examines how stored cases encapsulating traces of specific prior problem-solving episodes can be retrieved and re-applied to facilitate new problem-solving. Much progress has been made in methods for accessing relevant cases, and case-based reasoning is receiving wide acceptance both as a technology for developing intelligent systems and as a cognitive model of a human reasoning process. However, one important aspect of case-based reasoning remains poorly understood: the process by which retrieved cases are adapted to fit new situations. The difficulty of encoding effective adaptation rules by hand is widely recognized as a serious impediment to the development of fully autonomous case-based reasoning systems. Consequently, an important question is how case-based reasoning systems might learn to improve their expertise at case adaptation. We present a framework for acquiring this expertise by using a combination of general adaptation rules, introspective reasoning, and case-based reasoning about the case adaptation task itself. 
Title: Title: BECOMING AN EXPERT CASE-BASED REASONER: LEARNING TO ADAPT PRIOR CASES  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Computer Evolution of Buildable Objects for Evolutionary Design by Computers  
Abstract: Experience plays an important role in the development of human expertise. One computational model of how experience affects expertise is provided by research on case-based reasoning, which examines how stored cases encapsulating traces of specific prior problem-solving episodes can be retrieved and re-applied to facilitate new problem-solving. Much progress has been made in methods for a
Label: Genetic Algorithms
Paper 3  Title: Combining Rules and Cases to Learn Case Adaptation  
Abstract: Computer models of case-based reasoning (CBR) generally guide case adaptation using a fixed set of adaptation rules. A difficult practical problem is how to identify the knowledge required to guide adaptation for particular tasks. Likewise, an open issue for CBR as a cognitive model is how case adaptation knowledge is learned. We describe a new approach to acquiring case adaptation knowl
Label: Case Based
Paper 4  Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  
Abstract: In current CBR systems, case adaptation is usually performed by rule-based methods that use task-specific rules hand-coded by the system developer. The ability to define those rules depends on knowledge of the task and domain that may not be available a priori, presenting a serious impediment to endowing CBR systems with the needed adaptation knowledge. This paper describes ongoing resea
Paper 5  Title: Acquiring Case Adaptation Knowledge: A Hybrid Approach  
Abstract: The ability of case-based reasoning (CBR) systems to apply cases to novel situations depends on their case adaptation knowledge. However, endowing CBR systems with adequate adaptation knowledge has proven to be a very difficult task. This paper describes a hybrid method for performing case adaptation, using a combination of rule-based and case-based reasoning. It shows how this approach 
Paper 6  Title: Learning Adaptation Strategies by Introspective Reasoning about Memory Search  
Abstract: In case-based reasoning systems, the case adaptation process is traditionally controlled by static libraries of hand-coded adaptation rules. This paper proposes a method for learning adaptation knowledge in the form of adaptation strategies of the type developed and hand-coded by Kass [90] . Adaptation strategies differ from standard adaptation rules in that they encode general memory se
Paper 7  Title: NESTED NETWORKS FOR ROBOT CONTROL  
Abstract: Case-based reasoning depends on multiple knowledge sources beyond the case library, including knowledge about case adaptation and criteria for similarity assessment. Because hand coding this knowledge accounts for a large part of the knowledge acquisition burden for developing CBR systems, it is appealing to acquire it by learning, and CBR is a promising learning method to apply. This ob
Label: Neural Networks
Paper 8  Title: A Case Study of Case-Based CBR  
Abstract: Case-based reasoning depends on multiple knowledge sources beyond the case library, including knowledge about case adaptation and criteria for similarity assessment. Because hand coding this knowledge accounts for a large part of the knowledge acquisition burden for developing CBR systems, it is appealing to acquire it by learning, and CBR is a promising learning method to apply. This ob
Label: Case Based
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 2331...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We extend Hoeffding bounds to develop superior probabilistic performance guarantees for accurate classifiers. The original Hoeffding bounds on classifier accuracy depend on the accuracy itself as a parameter. Since the accuracy is not known a priori, the parameter value that gives the weakest bounds is used. We present a method that loosely bounds the accuracy using the old method and uses the loose bound as an improved parameter value for tighter bounds. We show how to use the bounds in practice, and we generalize the bounds for individual classifiers to form uniform bounds over multiple classifiers. 
Title: Title: Improved Hoeffding-Style Performance Guarantees for Accurate Classifiers  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Improved Uniform Test Error Bounds  
Abstract: We derive distribution-free uniform test error bounds that improve on VC-type bounds for validation. We show how to use knowledge of test inputs to improve the bounds. The bounds are sharp, but they require intense computation. We introduce a method to trade sharpness for speed of computation. Also, we compute the bounds for several test cases. 
Label: Theory
Paper 3  Title: Validation of Voting Committees  
Abstract: This paper contains a method to bound the test errors of voting committees with members chosen from a pool of trained classifiers. There are so many prospective committees that validating them directly does not achieve useful error bounds. Because there are fewer classifiers than prospective committees, it is better to validate the classifiers individually, then use linear programming to
Label: Theory
Paper 4  Title: Self bounding learning algorithms  
Abstract: Most of the work which attempts to give bounds on the generalization error of the hypothesis generated by a learning algorithm is based on methods from the theory of uniform convergence. These bounds are a-priori bounds that hold for any distribution of examples and are calculated before any data is observed. In this paper we propose a different approach for bounding the generalization e
Label: Theory
Paper 5  Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  
Abstract: We present an algorithm for improving the accuracy of algorithms for learning binary concepts. The improvement is achieved by combining a large number of hypotheses, each of which is generated by training the given learning algorithm on a different set of examples. Our algorithm is based on ideas presented by Schapire in his paper "The strength of weak learnability", and represents an im
Label: Theory
Paper 6  Title: Using Qualitative Relationships for Bounding Probability Distributions  
Abstract: We exploit qualitative probabilistic relationships among variables for computing bounds of conditional probability distributions of interest in Bayesian networks. Using the signs of qualitative relationships, we can implement abstraction operations that are guaranteed to bound the distributions of interest in the desired direction. By evaluating incrementally improved approximate network
Label: Probabilistic Methods
Paper 7  Title: Anytime Influence Diagrams  
Abstract: In this paper we show that the posterior distribution for feedforward neural networks is asymptotically consistent. This paper extends earlier results on universal approximation properties of neural networks to the Bayesian setting. The proof of consistency embeds the problem in a density estimation problem, then uses bounds on the bracketing entropy to show that the posterior is consist
Label: Probabilistic Methods
Paper 8  Title: An Efficient Extension to Mixture Techniques for Prediction and Decision Trees  
Abstract: We present a method for maintaining mixtures of prunings of a prediction or decision tree that extends the "node-based" prunings of [Bun90, WST95, HS97] to the larger class of edge-based prunings. The method includes an efficient online weight allocation algorithm that can be used for prediction, compression and classification. Although the set of edge-based prunings of a given tree is m
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 1827...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Evolution is a stochastic process which operates on the DNA of species. The evolutionary process leaves tell-tale signs in the DNA which can be used to construct phylogenies, or evolutionary trees, for a set of species. Maximum Likelihood Estimations (MLE) methods seek the evolutionary tree which is most likely to have produced the DNA under consideration. While these methods are widely accepted and intellectually satisfying, they have been computationally intractable. In this paper, we address the intractability of MLE methods as follows. We introduce a metric on stochastic process models of evolution. We show that this metric is meaningful by proving that in order for any algorithm to distinguish between two stochatic models that are close according to this metric, it needs to be given a lot of observations. We complement this result with a simple and efficient algorithm for inverting the stochastic process of evolution, that is, for building the tree from observations on the DNA of the species. Our result can be viewed as a result on the PAC-learnability of the class of distributions produced by tree-like processes. Though there have been many heuristics suggested for this problem, our algorithm is the first one with a guaranteed convergence rate, and further, this rate is within a polynomial of the lower-bound rate we establish. Ours is also the the first polynomial-time algorithm which is guaranteed to converge at all to the correct tree. 
Title: Title: Efficient Algorithms for Inverting Evolution  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Fast Algorithm for the Computation and Enumeration of Perfect Phylogenies  
Abstract: The Perfect Phylogeny Problem is a classical problem in computational evolutionary biology, in which a set of species/taxa is described by a set of qualitative characters. In recent years, the problem has been shown to be NP-Complete in general, while the different fixed parameter versions can each be solved in polynomial time. In particular, Agarwala and Fernandez-Baca have developed an
Paper 3  Title: On the Sample Complexity of Learning Bayesian Networks  
Abstract: In recent years there has been an increasing interest in learning Bayesian networks from data. One of the most effective methods for learning such networks is based on the minimum description length (MDL) principle. Previous work has shown that this learning procedure is asymptotically successful: with probability one, it will converge to the target distribution, given a sufficient numbe
Label: Probabilistic Methods
Paper 4  Title: Theory and Applications of Agnostic PAC-Learning with Small Decision Trees  
Abstract: We exhibit a theoretically founded algorithm T2 for agnostic PAC-learning of decision trees of at most 2 levels, whose computation time is almost linear in the size of the training set. We evaluate the performance of this learning algorithm T2 on 15 common real-world datasets, and show that for most of these datasets T2 provides simple decision trees with little or no loss in predictive 
Paper 5  Title: Learning Bayesian Prototype Trees by Simulated Annealing  
Abstract: Given a set of samples of an unknown probability distribution, we study the problem of constructing a good approximative Bayesian network model of the probability distribution in question. This task can be viewed as a search problem, where the goal is to find a maximal probability network model, given the data. In this work, we do not make an attempt to learn arbitrarily complex multi-co
Label: Probabilistic Methods
Paper 6  Title: On the Learnability and Usage of Acyclic Probabilistic Finite Automata  
Abstract: We propose and analyze a distribution learning algorithm for a subclass of Acyclic Probabilistic Finite Automata (APFA). This subclass is characterized by a certain distinguishability property of the automata's states. Though hardness results are known for learning distributions generated by general APFAs, we prove that our algorithm can efficiently learn distributions generated by the s
Paper 7  Title: Constructing Computationally Efficient Bayesian Models via Unsupervised Clustering  Probabilistic Reasoning and Bayesian Belief Networks,  
Abstract: Given a set of samples of an unknown probability distribution, we study the problem of constructing a good approximative Bayesian network model of the probability distribution in question. This task can be viewed as a search problem, where the goal is to find a maximal probability network model, given the data. In this work, we do not make an attempt to learn arbitrarily complex multi-co
Paper 8  Title: A Fast, Bottom-Up Decision Tree Pruning Algorithm with Near-Optimal Generalization  
Abstract: In this work, we present a new bottom-up algorithm for decision tree pruning that is very efficient (requiring only a single pass through the given tree), and prove a strong performance guarantee for the generalization error of the resulting pruned tree. We work in the typical setting in which the given tree T may have been derived from the given training sample S, and thus may badly ove
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 1534...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Combinatorial explosion of inferences has always been a central problem in artificial intelligence. Although the inferences that can be drawn from a reasoner's knowledge and from available inputs is very large (potentially infinite), the inferential resources available to any reasoning system are limited. With limited inferential capacity and very many potential inferences, reasoners must somehow control the process of inference. Not all inferences are equally useful to a given reasoning system. Any reasoning system that has goals (or any form of a utility function) and acts based on its beliefs indirectly assigns utility to its beliefs. Given limits on the process of inference, and variation in the utility of inferences, it is clear that a reasoner ought to draw the inferences that will be most valuable to it. This paper presents an approach to this problem that makes the utility of a (potential) belief an explicit part of the inference process. The method is to generate explicit desires for knowledge. The question of focus of attention is thereby transformed into two related problems: How can explicit desires for knowledge be used to control inference and facilitate resource-constrained goal pursuit in general? and, Where do these desires for knowledge come from? We present a theory of knowledge goals, or desires for knowledge, and their use in the processes of understanding and learning. The theory is illustrated using two case studies, a natural language understanding program that learns by reading novel or unusual newspaper stories, and a differential diagnosis program that improves its accuracy with experience. 
Title: Title: The Use of Explicit Goals for Knowledge to Guide Inference and Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Goal-Based Approach to Intelligent Information Retrieval  
Abstract: Intelligent information retrieval (IIR) requires inference. The number of inferences that can be drawn by even a simple reasoner is very large, and the inferential resources available to any practical computer system are limited. This problem is one long faced by AI researchers. In this paper, we present a method used by two recent machine learning programs for control of inference that 
Paper 3  Title: Correcting Imperfect Domain Theories: A Knowledge-Level Analysis  
Abstract: Explanation-Based Learning [Mitchell et al., 1986; DeJong and Mooney, 1986] has shown promise as a powerful analytical learning technique. However, EBL is severely hampered by the requirement of a complete and correct domain theory for successful learning to occur. Clearly, in non-trivial domains, developing such a domain theory is a nearly impossible task. Therefore, much research has b
Paper 4  Title: Introduction to the Special Section on Knowledge-Based Construction of Probabilistic and Decision Models (IEEE Transactions
Abstract: Modeling techniques developed recently in the AI and uncertain reasoning communities permit significantly more flexible specifications of probabilistic knowledge. Specifically, graphical decision-modeling formalisms|belief networks, influence diagrams, and their variants|provide compact representation of probabilistic relationships, and support inference algorithms that automatically exp
Label: Probabilistic Methods
Paper 5  Title: Blocking Gibbs Sampling for Linkage Analysis in Large Pedigrees with Many Loops  
Abstract: Learning is a fundamental component of intelligence, and a key consideration in designing cognitive architectures such as Soar [ Laird et al., 1986 ] . This chapter considers the question of what constitutes an appropriate general-purpose learning mechanism. We are interested in mechanisms that might explain and reproduce the rich variety of learning capabilities of humans, ranging from 
Label: Probabilistic Methods
Paper 6  Title: Representing Self-knowledge for Introspection about Memory Search  
Abstract: This position paper sketches a framework for modeling introspective reasoning and discusses the relevance of that framework for modeling introspective reasoning about memory search. It argues that effective and flexible memory processing in rich memories should be built on five types of explicitly represented self-knowledge: knowledge about information needs, relationships between differ
Label: Case Based
Paper 7  Title: Learning Analytically and Inductively  
Abstract: Learning is a fundamental component of intelligence, and a key consideration in designing cognitive architectures such as Soar [ Laird et al., 1986 ] . This chapter considers the question of what constitutes an appropriate general-purpose learning mechanism. We are interested in mechanisms that might explain and reproduce the rich variety of learning capabilities of humans, ranging from 
Label: Reinforcement Learning
Paper 8  Title: On Decision-Theoretic Foundations for Defaults  
Abstract: In recent years, considerable effort has gone into understanding default reasoning. Most of this effort concentrated on the question of entailment, i.e., what conclusions are warranted by a knowledge-base of defaults. Surprisingly, few works formally examine the general role of defaults. We argue that an examination of this role is necessary in order to understand defaults, and suggest a
Label: Probabilistic Methods
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 1782...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Submitted to NIPS-98 TD() is a popular family of algorithms for approximate policy evaluation in large MDPs. TD() works by incrementally updating the value function after each observed transition. It has two major drawbacks: it makes inefficient use of data, and it requires the user to manually tune a stepsize schedule for good performance. For the case of linear value function approximations and = 0, the Least-Squares TD (LSTD) algorithm of Bradtke and Barto [5] eliminates all stepsize parameters and improves data efficiency. This paper extends Bradtke and Barto's work in three significant ways. First, it presents a simpler derivation of the LSTD algorithm. Second, it generalizes from = 0 to arbitrary values of ; at the extreme of = 1, the resulting algorithm is shown to be a practical formulation of supervised linear regression. Third, it presents a novel, intuitive interpretation of LSTD as a model-based reinforcement learning technique.
Title: Title: Least-Squares Temporal Difference Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Truncating Temporal Differences: On the Efficient Implementation of TD() for Reinforcement Learning  
Abstract: Temporal difference (TD) methods constitute a class of methods for learning predictions in multi-step prediction problems, parameterized by a recency factor . Currently the most important application of these methods is to temporal credit assignment in reinforcement learning. Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learnin
Paper 3  Title: Toward Learning Systems That Integrate Different Strategies and Representations TR93-22  
Abstract: Temporal difference (TD) methods constitute a class of methods for learning predictions in multi-step prediction problems, parameterized by a recency factor . Currently the most important application of these methods is to temporal credit assignment in reinforcement learning. Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learnin
Paper 4  Title: INCREMENTAL POLYNOMIAL CONTROLLER NETWORKS: two self-organising non-linear controllers  
Abstract: Temporal difference (TD) methods constitute a class of methods for learning predictions in multi-step prediction problems, parameterized by a recency factor . Currently the most important application of these methods is to temporal credit assignment in reinforcement learning. Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learnin
Label: Neural Networks
Paper 5  Title: Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta  
Abstract: Appropriate bias is widely viewed as the key to efficient learning and generalization. I present a new algorithm, the Incremental Delta-Bar-Delta (IDBD) algorithm, for the learning of appropriate biases based on previous learning experience. The IDBD algorithm is developed for the case of a simple, linear learning system|the LMS or delta rule with a separate learning-rate parameter for e
Label: Neural Networks
Paper 6  Title: Update rules for parameter estimation in Bayesian networks  
Abstract: This paper re-examines the problem of parameter estimation in Bayesian networks with missing values and hidden variables from the perspective of recent work in on-line learning [12]. We provide a unified framework for parameter estimation that encompasses both on-line learning, where the model is continuously adapted to new data cases as they arrive, and the more traditional batch learni
Paper 7  Title: Gas Identification System using Graded Temperature Sensor and Neural Net Interpretation  
Abstract: We present results for three new algorithms for setting the step-size parameters, ff and , of temporal-difference learning methods such as TD(). The overall task is that of learning to predict the outcome of an unknown Markov chain based on repeated observations of its state trajectories. The new algorithms select step-size parameters online in such a way as to eliminate the bias normall
Label: Neural Networks
Paper 8  Title: On Step-Size and Bias in Temporal-Difference Learning  
Abstract: We present results for three new algorithms for setting the step-size parameters, ff and , of temporal-difference learning methods such as TD(). The overall task is that of learning to predict the outcome of an unknown Markov chain based on repeated observations of its state trajectories. The new algorithms select step-size parameters online in such a way as to eliminate the bias normall
Label: Reinforcement Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 487...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Designers across a variety of domains engage in many of the same creative activities. Since much creativity stems from using old solutions in novel ways, we believe that case-based reasoning can be used to explain many creative design processes. 
Title: Title: Language as a dynamical system  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: CASE-BASED CREATIVE DESIGN  
Abstract: Designers across a variety of domains engage in many of the same creative activities. Since much creativity stems from using old solutions in novel ways, we believe that case-based reasoning can be used to explain many creative design processes. 
Paper 3  Title: Explaining Serendipitous Recognition in Design  
Abstract: Creative designers often see solutions to pending design problems in the everyday objects surrounding them. This can often lead to innovation and insight, sometimes revealing new functions and purposes for common design pieces in the process. We are interested in modeling serendipitous recognition of solutions to pending problems in the context of creative mechanical design. This paper c
Paper 4  Title: Belief Networks Revisited  
Abstract: Experiment design and execution is a central activity in the natural sciences. The SeqER system provides a general architecture for the integration of automated planning techniques with a variety of domain knowledge in order to plan scientific experiments. These planning techniques include rule-based methods and, especially, the use of derivational analogy. Derivational analogy allows pl
Label: Probabilistic Methods
Paper 5  Title: Towards More Creative Case-Based Design Systems  
Abstract: Case-based reasoning (CBR) has a great deal to offer in supporting creative design, particularly processes that rely heavily on previous design experience, such as framing the problem and evaluating design alternatives. However, most existing CBR systems are not living up to their potential. They tend to adapt and reuse old solutions in routine ways, producing robust but uninspired resul
Paper 6  Title: Creative Design: Reasoning and Understanding  
Abstract: This paper investigates memory issues that influence long- term creative problem solving and design activity, taking a case-based reasoning perspective. Our exploration is based on a well-documented example: the invention of the telephone by Alexander Graham Bell. We abstract Bell's reasoning and understanding mechanisms that appear time and again in long-term creative design. We identif
Paper 7  Title: Understanding Creativity: A Case-Based Approach  
Abstract: Dissatisfaction with existing standard case-based reasoning (CBR) systems has prompted us to investigate how we can make these systems more creative and, more broadly, what would it mean for them to be more creative. This paper discusses three research goals: understanding creative processes better, investigating the role of cases and CBR in creative problem solving, and understanding th
Paper 8  Title: Protein Sequencing Experiment Planning Using Analogy protein sequencing experiments. Planning is interleaved with experiment execution,
Abstract: Experiment design and execution is a central activity in the natural sciences. The SeqER system provides a general architecture for the integration of automated planning techniques with a variety of domain knowledge in order to plan scientific experiments. These planning techniques include rule-based methods and, especially, the use of derivational analogy. Derivational analogy allows pl
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Case Based
Prediction:  Case Based
Is prediction correct?  False

Prediction: 0
Processing index 928...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Initial Results Abstract. Conversational case-based reasoning (CBR) systems, which incrementally extract a query description through a user-directed conversation, are advertised for their ease of use. However, designing large case libraries that have good performance (i.e., precision and querying efficiency) is difficult. CBR vendors provide guidelines for designing these libraries manually, but the guidelines are difficult to apply. We describe an automated inductive approach that revises conversational case libraries to increase their conformance with design guidelines. Revision increased performance on three conversational case libraries.
Title: Title: Learning to Refine Case Libraries:  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Refining Conversational Case Libraries  
Abstract: Conversational case-based reasoning (CBR) shells (e.g., Inference's CBR Express) are commercially successful tools for supporting the development of help desk and related applications. In contrast to rule-based expert systems, they capture knowledge as cases rather than more problematic rules, and they can be incrementally extended. However, rather than eliminate the knowledge engineerin
Paper 3  Title: Towards More Creative Case-Based Design Systems  
Abstract: Case-based reasoning (CBR) has a great deal to offer in supporting creative design, particularly processes that rely heavily on previous design experience, such as framing the problem and evaluating design alternatives. However, most existing CBR systems are not living up to their potential. They tend to adapt and reuse old solutions in routine ways, producing robust but uninspired resul
Paper 4  Title: Belief Networks Revisited  
Abstract: Experiment design and execution is a central activity in the natural sciences. The SeqER system provides a general architecture for the integration of automated planning techniques with a variety of domain knowledge in order to plan scientific experiments. These planning techniques include rule-based methods and, especially, the use of derivational analogy. Derivational analogy allows pl
Label: Probabilistic Methods
Paper 5  Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  
Abstract: In current CBR systems, case adaptation is usually performed by rule-based methods that use task-specific rules hand-coded by the system developer. The ability to define those rules depends on knowledge of the task and domain that may not be available a priori, presenting a serious impediment to endowing CBR systems with the needed adaptation knowledge. This paper describes ongoing resea
Paper 6  Title: Protein Sequencing Experiment Planning Using Analogy protein sequencing experiments. Planning is interleaved with experiment execution,
Abstract: Experiment design and execution is a central activity in the natural sciences. The SeqER system provides a general architecture for the integration of automated planning techniques with a variety of domain knowledge in order to plan scientific experiments. These planning techniques include rule-based methods and, especially, the use of derivational analogy. Derivational analogy allows pl
Paper 7  Title: Data Exploration with Reflective Adaptive Models  
Abstract: Case-Based Planning (CBP) provides a way of scaling up domain-independent planning to solve large problems in complex domains. It replaces the detailed and lengthy search for a solution with the retrieval and adaptation of previous planning experiences. In general, CBP has been demonstrated to improve performance over generative (from-scratch) planning. However, the performance improveme
Paper 8  Title: NESTED NETWORKS FOR ROBOT CONTROL  
Abstract: Case-based reasoning depends on multiple knowledge sources beyond the case library, including knowledge about case adaptation and criteria for similarity assessment. Because hand coding this knowledge accounts for a large part of the knowledge acquisition burden for developing CBR systems, it is appealing to acquire it by learning, and CBR is a promising learning method to apply. This ob
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 1238...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Pruning a decision tree is considered by some researchers to be the most important part of tree building in noisy domains. While, there are many approaches to pruning, an alternative approach of averaging over decision trees has not received as much attention. We perform an empirical comparison of pruning with the approach of averaging over decision trees. For this comparison we use a computa-tionally efficient method of averaging, namely averaging over the extended fanned set of a tree. Since there are a wide range of approaches to pruning, we compare tree averaging with a traditional pruning approach, along with an optimal pruning approach.
Title: Title: On Pruning and Averaging Decision Trees  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Pruning Decision Trees with Misclassification Costs  
Abstract: We describe an experimental study of pruning methods for decision tree classifiers when the goal is minimizing loss rather than error. In addition to two common methods for error minimization, CART's cost-complexity pruning and C4.5's error-based pruning, we study the extension of cost-complexity pruning to loss and one pruning variant based on the Laplace correction. We perform an empir
Paper 3  Title: Building Classifiers using Bayesian Networks  
Abstract: Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes, is competitive with state of the art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we examine and evaluate approach
Label: Probabilistic Methods
Paper 4  Title: More Efficient Windowing  
Abstract: Windowing has been proposed as a procedure for efficient memory use in the ID3 decision tree learning algorithm. However, previous work has shown that windowing may often lead to a decrease in performance. In this work, we try to argue that separate-and-conquer rule learning algorithms are more appropriate for windowing than divide-and-conquer algorithms, because they learn rules indepen
Paper 5  Title: Decision Tree Induction: How Effective is the Greedy Heuristic?  
Abstract: Most existing decision tree systems use a greedy approach to induce trees | locally optimal splits are induced at every node of the tree. Although the greedy approach is suboptimal, it is believed to produce reasonably good trees. In the current work, we attempt to verify this belief. We quantify the goodness of greedy tree induction empirically, using the popular decision tree algorithm
Paper 6  Title: An Empirical Evaluation of Bagging and Boosting  
Abstract: An ensemble consists of a set of independently trained classifiers (such as neural networks or decision trees) whose predictions are combined when classifying novel instances. Previous research has shown that an ensemble as a whole is often more accurate than any of the single classifiers in the ensemble. Bagging (Breiman 1996a) and Boosting (Freund & Schapire 1996) are two relatively ne
Paper 7  Title: Improving Bagging Performance by Increasing Decision Tree Diversity  
Abstract: Ensembles of decision trees often exhibit greater predictive accuracy than single trees alone. Bagging and boosting are two standard ways of generating and combining multiple trees. Boosting has been empirically determined to be the more effective of the two, and it has recently been proposed that this may be because it produces more diverse trees than bagging. This paper reports empiric
Label: Theory
Paper 8  Title: Multivariate Decision Trees  
Abstract: COINS Technical Report 92-82 December 1992 Abstract Multivariate decision trees overcome a representational limitation of univariate decision trees: univariate decision trees are restricted to splits of the instance space that are orthogonal to the feature's axis. This paper discusses the following issues for constructing multivariate decision trees: representing a multivariate test, inc
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  False

Prediction: 0
Processing index 1081...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: When specializing a recursive predicate in order to exclude a set of negative examples without excluding a set of positive examples, it may not be possible to specialize or remove any of the clauses in a refutation of a negative example without excluding any positive exam ples. A previously proposed solution to this problem is to apply program transformation in order to obtain non-recursive target predicates from recursive ones. However, the application of this method prevents recursive specializations from being found. In this work, we present the algorithm spectre ii which is not limited to specializing non-recursive predicates. The key idea upon which the algorithm is based is that it is not enough to specialize or remove clauses in refutations of negative examples in order to obtain correct specializations, but it is sometimes necessary to specialize clauses that appear only in refutations of positive examples. In contrast to its predecessor spectre, the new algorithm is not limited to specializing clauses defining one predicate only, but may specialize clauses defining multiple predicates. Furthermore, the positive and negative examples are no longer required to be instances of the same predicate. It is proven that the algorithm produces a correct specialization when all positive examples are logical consequences of the original program, there is a finite number of derivations of positive and negative examples and when no positive and negative examples have the same sequence of input clauses in their refutations.
Title: Title: Specialization of Recursive Predicates  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Specialization of Logic Programs by Pruning SLD-Trees  
Abstract: program w.r.t. positive and negative examples can be viewed as the problem of pruning an SLD-tree such that all refutations of negative examples and no refutations of positive examples are excluded. It is shown that the actual pruning can be performed by applying unfolding and clause removal. The algorithm spectre is presented, which is based on this idea. The input to the algorithm is, 
Paper 3  Title: Predicate Invention and Learning from Positive Examples Only  
Abstract: Previous bias shift approaches to predicate invention are not applicable to learning from positive examples only, if a complete hypothesis can be found in the given language, as negative examples are required to determine whether new predicates should be invented or not. One approach to this problem is presented, MERLIN 2.0, which is a successor of a system in which predicate invention i
Label: Rule Learning
Paper 4  Title: Theory-Guided Induction of Logic Programs by Inference of Regular Languages recursive clauses. merlin on the
Abstract: resent allowed sequences of resolution steps for the initial theory. There are, however, many characterizations of allowed sequences of resolution steps that cannot be expressed by a set of resolvents. One approach to this problem is presented, the system mer-lin, which is based on an earlier technique for learning finite-state automata that represent allowed sequences of resolution step
Paper 5  Title: PAC-Learning PROLOG clauses with or without errors  
Abstract: In a nutshell we can describe a generic ILP problem as following: given a set E of (positive and negative) examples of a target predicate, and some background knowledge B about the world (usually a logic program including facts and auxiliary predicates), the task is to find a logic program H (our hypothesis) such that all positive examples can be deduced from B and H, while no negative e
Paper 6  Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some
Abstract: covering has been formalized and used extensively. In this work, the divide-and-conquer technique is formalized as well and compared to the covering technique in a logic programming framework. Covering works by repeatedly specializing an overly general hypothesis, on each iteration focusing on finding a clause with a high coverage of positive examples. Divide-and-conquer works by special
Label: Genetic Algorithms
Paper 7  Title: THE DISCOVERY OF ALGORITHMIC PROBABILITY  
Abstract: covering has been formalized and used extensively. In this work, the divide-and-conquer technique is formalized as well and compared to the covering technique in a logic programming framework. Covering works by repeatedly specializing an overly general hypothesis, on each iteration focusing on finding a clause with a high coverage of positive examples. Divide-and-conquer works by special
Paper 8  Title: The Challenge of Revising an Impure Theory  
Abstract: A pure rule-based program will return a set of answers to each query; and will return the same answer set even if its rules are re-ordered. However, an impure program, which includes the Prolog cut "!" and not() operators, can return different answers if the rules are re-ordered. There are also many reasoning systems that return only the first answer found for each query; these first ans
Label: Theory
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 403...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The evolution of a population can be guided by phenotypic traits acquired by members of that population during their lifetime. This phenomenon, known as the Baldwin Effect, can speed the evolutionary process as traits that are initially acquired become genetically specified in later generations. This paper presents conditions under which this genetic assimilation can take place. As well as the benefits that lifetime adaptation can give a population, there may be a cost to be paid for that adaptive ability. It is the evolutionary trade-off between these costs and benefits that provides the selection pressure for acquired traits to become genetically specified. It is also noted that genotypic space, in which evolution operates, and phenotypic space, on which adaptive processes (such as learning) operate, are, in general, of a different nature. To guarantee an acquired characteristic can become genetically specified, then these spaces must have the property of neighbourhood correlation which means that a small distance between two individuals in phenotypic space implies that there is a small distance between the same two individuals in genotypic space.
Title: Title: Landscapes, Learning Costs and Genetic Assimilation.  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The Evolutionary Cost of Learning  
Abstract: Traits that are acquired by members of an evolving population during their lifetime, through adaptive processes such as learning, can become genetically specified in later generations. Thus there is a change in the level of learning in the population over evolutionary time. This paper explores the idea that as well as the benefits to be gained from learning, there may also be costs to be
Paper 3  Title: Genes, Phenes and the Baldwin Effect: Learning and Evolution in a Simulated Population  
Abstract: The Baldwin Effect, first proposed in the late nineteenth century, suggests that the course of evolutionary change can be influenced by individually learned behavior. The existence of this effect is still a hotly debated topic. In this paper clear evidence is presented that learning-based plasticity at the phenotypic level can and does produce directed changes at the genotypic level. Thi
Paper 4  Title: Guiding or Hiding: Explorations into the Effects of Learning on the Rate of Evolution.  
Abstract: Individual lifetime learning can `guide' an evolving population to areas of high fitness in genotype space through an evolutionary phenomenon known as the Baldwin effect (Baldwin, 1896; Hin-ton & Nowlan, 1987). It is the accepted wisdom that this guiding speeds up the rate of evolution. By highlighting another interaction between learning and evolution, that will be termed the Hiding eff
Paper 5  Title: Modeling the Evolution of Motivation  
Abstract: In order for learning to improve the adaptiveness of an animal's behavior and thus direct evolution in the way Baldwin suggested, the learning mechanism must incorporate an innate evaluation of how the animal's actions influence its reproductive fitness. For example, many circumstances that damage an animal, or otherwise reduce its fitness are painful and tend to be avoided. We refer to 
Paper 6  Title: Mutation Rates as Adaptations  
Abstract: In order to better understand life, it is helpful to look beyond the envelop of life as we know it. A simple model of coevolution was implemented with the addition of a gene for the mutation rate of the individual. This allowed the mutation rate itself to evolve in a lineage. The model shows that when the individuals interact in a sort of zero-sum game, the lineages maintain relatively h
Label: Genetic Algorithms
Paper 7  Title: The Coevolution of Mutation Rates  
Abstract: In order to better understand life, it is helpful to look beyond the envelop of life as we know it. A simple model of coevolution was implemented with the addition of genes for longevity and mutation rate in the individuals. This made it possible for a lineage to evolve to be immortal. It also allowed the evolution of no mutation or extremely high mutation rates. The model shows that whe
Paper 8  Title: Generalist and Specialist Behavior Due to Individual Energy Extracting Abilities.  
Abstract: The emergence of generalist and specialist behavior in populations of neural networks is studied. Energy extracting ability is included as a property of an organism. In artificial life simulations with organisms living in an environment, the fitness score can be interpreted as the combination of an organisms behavior and the ability of the organism to extract energy from potential food s
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1680...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The Structure-Mapping Engine (SME) has successfully modeled several aspects of human consistent interpretations of an analogy. While useful for theoretical explorations, this aspect of the algorithm is both psychologically implausible and computationally inefficient. (2) SME contains no mechanism for focusing on interpretations relevant to an analogizer's goals. This paper describes modifications to SME which overcome these flaws. We describe a greedy merge algorithm which efficiently computes an approximate "best" interpretation, and can generate alternate interpretations when necessary. We describe pragmatic marking, a technique which focuses the mapping to produce relevant, yet novel, inferences. We illustrate these techniques via example and evaluate their performance using empirical data and theoretical analysis. analogical processing. However, it has two significant drawbacks: (1) SME constructs all structurally
Title: Title: Making SME greedy and pragmatic  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The Structure-Mapping Engine: Algorithm and Examples  
Abstract: This paper describes the Structure-Mapping Engine (SME), a program for studying analogical processing. SME has been built to explore Gentner's Structure-mapping theory of analogy, and provides a "tool kit" for constructing matching algorithms consistent with this theory. Its flexibility enhances cognitive simulation studies by simplifying experimentation. Furthermore, SME is very efficie
Paper 3  Title: MAC/FAC: A Model of Similarity-based Retrieval  
Abstract: We present a model of similarity-based retrieval which attempts to capture three psychological phenomena: (1) people are extremely good at judging similarity and analogy when given items to compare. (2) Superficial remindings are much more frequent than structural remindings. (3) People sometimes experience and use purely structural analogical re-mindings. Our model, called MAC/FAC (for 
Paper 4  Title: Double Censoring: Characterization and Computation of the Nonparametric Maximum Likelihood Estimator  
Abstract: In case-based planning (CBP), previously generated plans are stored as cases in memory and can be reused to solve similar planning problems in the future. CBP can save considerable time over planning from scratch (generative planning), thus offering a potential (heuristic) mechanism for handling intractable problems. One drawback of CBP systems has been the need for a highly structured m
Label: Probabilistic Methods
Paper 5  Title: Modeling Case-based Planning for Repairing Reasoning Failures  
Abstract: One application of models of reasoning behavior is to allow a reasoner to introspectively detect and repair failures of its own reasoning process. We address the issues of the transferability of such models versus the specificity of the knowledge in them, the kinds of knowledge needed for self-modeling and how that knowledge is structured, and the evaluation of introspective reasoning sy
Paper 6  Title: A Methodology for Processing Problem Constraints in Genetic Programming  
Abstract: Search mechanisms of artificial intelligence combine two elements: representation, which determines the search space, and a search mechanism, which actually explores the space. Unfortunately, many searches may explore redundant and/or invalid solutions. Genetic programming refers to a class of evolutionary algorithms based on genetic algorithms but utilizing a parameterized representatio
Paper 7  Title: Data Exploration with Reflective Adaptive Models  
Abstract: Case-Based Planning (CBP) provides a way of scaling up domain-independent planning to solve large problems in complex domains. It replaces the detailed and lengthy search for a solution with the retrieval and adaptation of previous planning experiences. In general, CBP has been demonstrated to improve performance over generative (from-scratch) planning. However, the performance improveme
Paper 8  Title: Proceedings of CogSci89 Structural Evaluation of Analogies: What Counts?  
Abstract: Judgments of similarity and soundness are important aspects of human analogical processing. This paper explores how these judgments can be modeled using SME, a simulation of Gentner's structure-mapping theory. We focus on structural evaluation, explicating several principles which psychologically plausible algorithms should follow. We introduce the Specificity Conjecture, which claims th
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

An error occurred at index 75: HTTPSConnectionPool(host='api.openai-hk.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))
Retrying in 0.2 seconds...
Processing index 1680...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The Structure-Mapping Engine (SME) has successfully modeled several aspects of human consistent interpretations of an analogy. While useful for theoretical explorations, this aspect of the algorithm is both psychologically implausible and computationally inefficient. (2) SME contains no mechanism for focusing on interpretations relevant to an analogizer's goals. This paper describes modifications to SME which overcome these flaws. We describe a greedy merge algorithm which efficiently computes an approximate "best" interpretation, and can generate alternate interpretations when necessary. We describe pragmatic marking, a technique which focuses the mapping to produce relevant, yet novel, inferences. We illustrate these techniques via example and evaluate their performance using empirical data and theoretical analysis. analogical processing. However, it has two significant drawbacks: (1) SME constructs all structurally
Title: Title: Making SME greedy and pragmatic  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The Structure-Mapping Engine: Algorithm and Examples  
Abstract: This paper describes the Structure-Mapping Engine (SME), a program for studying analogical processing. SME has been built to explore Gentner's Structure-mapping theory of analogy, and provides a "tool kit" for constructing matching algorithms consistent with this theory. Its flexibility enhances cognitive simulation studies by simplifying experimentation. Furthermore, SME is very efficie
Paper 3  Title: MAC/FAC: A Model of Similarity-based Retrieval  
Abstract: We present a model of similarity-based retrieval which attempts to capture three psychological phenomena: (1) people are extremely good at judging similarity and analogy when given items to compare. (2) Superficial remindings are much more frequent than structural remindings. (3) People sometimes experience and use purely structural analogical re-mindings. Our model, called MAC/FAC (for 
Paper 4  Title: Double Censoring: Characterization and Computation of the Nonparametric Maximum Likelihood Estimator  
Abstract: In case-based planning (CBP), previously generated plans are stored as cases in memory and can be reused to solve similar planning problems in the future. CBP can save considerable time over planning from scratch (generative planning), thus offering a potential (heuristic) mechanism for handling intractable problems. One drawback of CBP systems has been the need for a highly structured m
Label: Probabilistic Methods
Paper 5  Title: Modeling Case-based Planning for Repairing Reasoning Failures  
Abstract: One application of models of reasoning behavior is to allow a reasoner to introspectively detect and repair failures of its own reasoning process. We address the issues of the transferability of such models versus the specificity of the knowledge in them, the kinds of knowledge needed for self-modeling and how that knowledge is structured, and the evaluation of introspective reasoning sy
Paper 6  Title: A Methodology for Processing Problem Constraints in Genetic Programming  
Abstract: Search mechanisms of artificial intelligence combine two elements: representation, which determines the search space, and a search mechanism, which actually explores the space. Unfortunately, many searches may explore redundant and/or invalid solutions. Genetic programming refers to a class of evolutionary algorithms based on genetic algorithms but utilizing a parameterized representatio
Paper 7  Title: Data Exploration with Reflective Adaptive Models  
Abstract: Case-Based Planning (CBP) provides a way of scaling up domain-independent planning to solve large problems in complex domains. It replaces the detailed and lengthy search for a solution with the retrieval and adaptation of previous planning experiences. In general, CBP has been demonstrated to improve performance over generative (from-scratch) planning. However, the performance improveme
Paper 8  Title: Proceedings of CogSci89 Structural Evaluation of Analogies: What Counts?  
Abstract: Judgments of similarity and soundness are important aspects of human analogical processing. This paper explores how these judgments can be modeled using SME, a simulation of Gentner's structure-mapping theory. We focus on structural evaluation, explicating several principles which psychologically plausible algorithms should follow. We introduce the Specificity Conjecture, which claims th
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 395...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present an alternative to the cellular encoding technique [Gruau 1992] for evolving graph and network structures via genetic programming. The new technique, called edge encoding, uses edge operators rather than the node operators of cellular encoding. While both cellular encoding and edge encoding can produce all possible graphs, the two encodings bias the genetic search process in different ways; each may therefore be most useful for a different set of problems. The problems for which these techniques may be used, and for which we think edge encoding may be particularly useful, include the evolution of recurrent neural networks, finite automata, and graph-based queries to symbolic knowledge bases. In this preliminary report we present a technical description of edge encoding and an initial comparison to cellular encoding. Experimental investigation of the relative merits of these encoding schemes is currently in progress.
Title: Title: Evolving Graphs and Networks with Edge Encoding: Preliminary Report  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Study in Program Response and the Negative Effects of Introns in Genetic Programming  
Abstract: The standard method of obtaining a response in tree-based genetic programming is to take the value returned by the root node. In non-tree representations, alternate methods have been explored. One alternative is to treat a specific location in indexed memory as the response value when the program terminates. The purpose of this paper is to explore the applicability of this technique to t
Paper 3  Title: Induction of decision trees using RELIEFF  
Abstract: An investigation into the dynamics of Genetic Programming applied to chaotic time series prediction is reported. An interesting characteristic of adaptive search techniques is their ability to perform well in many problem domains while failing in others. Because of Genetic Programming's flexible tree structure, any particular problem can be represented in myriad forms. These representati
Paper 4  Title: Genetic Algorithms for Combinatorial Optimization: The Assembly Line Balancing Problem  
Abstract: Genetic algorithms are one example of the use of a random element within an algorithm for combinatorial optimization. We consider the application of the genetic algorithm to a particular problem, the Assembly Line Balancing Problem. A general description of genetic algorithms is given, and their specialized use on our test-bed problems is discussed. We carry out extensive computational t
Paper 5  Title: The Royal Road for Genetic Algorithms: Fitness Landscapes and GA Performance  
Abstract: Genetic algorithms (GAs) play a major role in many artificial-life systems, but there is often little detailed understanding of why the GA performs as it does, and little theoretical basis on which to characterize the types of fitness landscapes that lead to successful GA performance. In this paper we propose a strategy for addressing these issues. Our strategy consists of defining a set
Paper 6  Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Abstract: Holland's analysis of the sources of power of genetic algorithms has served as guidance for the applications of genetic algorithms for more than 15 years. The technique of applying a recombination operator (crossover) to a population of individuals is a key to that power. Neverless, there have been a number of contradictory results concerning crossover operators with respect to overall p
Label: Genetic Algorithms
Paper 7  Title: A Comparison of Crossover and Mutation in Genetic Programming  
Abstract: This paper presents a large and systematic body of data on the relative effectiveness of mutation, crossover, and combinations of mutation and crossover in genetic programming (GP). The literature of traditional genetic algorithms contains related studies, but mutation and crossover in GP differ from their traditional counterparts in significant ways. In this paper we present the results
Label: Genetic Algorithms
Paper 8  Title: Cultural Transmission of Information in Genetic Programming  
Abstract: This paper shows how the performance of a genetic programming system can be improved through the addition of mechanisms for non-genetic transmission of information between individuals (culture). Teller has previously shown how genetic programming systems can be enhanced through the addition of memory mechanisms for individual programs [Teller 1994]; in this paper we show how Teller's mem
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1130...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper describes a novel search algorithm, called dynamic hill climbing, that borrows ideas from genetic algorithms and hill climbing techniques. Unlike both genetic and hill climbing algorithms, dynamic hill climbing has the ability to dynamically change its coordinate frame during the course of an optimization. Furthermore, the algorithm moves from a coarse-grained search to a fine-grained search of the function space by changing its mutation rate and uses a diversity-based distance metric to ensure that it searches new regions of the space. Dynamic hill climbing is empirically compared to a traditional genetic algorithm using De Jong's well-known five function test suite [4] and is shown to vastly surpass the performance of the genetic algorithm, often finding better solutions using only 1% as many function evaluations. 
Title: Title: Dynamic Hill Climbing: Overcoming the limita- tions of optimization techniques  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Hybridized Crossover-Based Search Techniques for Program Discovery  
Abstract: In this paper we address the problem of program discovery as defined by Genetic Programming [10]. We have two major results: First, by combining a hierarchical crossover operator with two traditional single point search algorithms: Simulated Annealing and Stochastic Iterated Hill Climbing, we have solved some problems with fewer fitness evaluations and a greater probability of a success 
Label: Genetic Algorithms
Paper 3  Title: Toward a unified theory of spatiotemporal processing in the retina  
Abstract: Traditional evolutionary optimization algorithms assume a static evaluation function, according to which solutions are evolved. Incremental evolution is an approach through which a dynamic evaluation function is scaled over time in order to improve the performance of evolutionary optimization. In this paper, we present empirical results that demonstrate the effectiveness of this approach
Paper 4  Title: Improving the Performance of Evolutionary Optimization by Dynamically Scaling the Evaluation Function  
Abstract: Traditional evolutionary optimization algorithms assume a static evaluation function, according to which solutions are evolved. Incremental evolution is an approach through which a dynamic evaluation function is scaled over time in order to improve the performance of evolutionary optimization. In this paper, we present empirical results that demonstrate the effectiveness of this approach
Label: Genetic Algorithms
Paper 5  Title: Hierarchical Evolution of Neural Networks  
Abstract: In most applications of neuro-evolution, each individual in the population represents a complete neural network. Recent work on the SANE system, however, has demonstrated that evolving individual neurons often produces a more efficient genetic search. This paper demonstrates that while SANE can solve easy tasks very quickly, it often stalls in larger problems. A hierarchical approach to 
Paper 6  Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  
Abstract: Genetic algorithms have been used to solve hard optimization problems ranging from the Travelling Salesman problem to the Quadratic Assignment problem. We show that the Simple Genetic Algorithm can be used to solve an optimization problem derived from the 3-Conjunctive Normal Form problem. By separating the populations into small sub-populations, parallel genetic algorithms exploits the 
Paper 7  Title: A Study of Genetic Algorithms to Find Approximate Solutions to Hard 3CNF Problems  
Abstract: Genetic algorithms have been used to solve hard optimization problems ranging from the Travelling Salesman problem to the Quadratic Assignment problem. We show that the Simple Genetic Algorithm can be used to solve an optimization problem derived from the 3-Conjunctive Normal Form problem. By separating the populations into small sub-populations, parallel genetic algorithms exploits the 
Paper 8  Title: HOW TO EVOLVE AUTONOMOUS ROBOTS: DIFFERENT APPROACHES IN EVOLUTIONARY ROBOTICS  
Abstract: In most applications of neuro-evolution, each individual in the population represents a complete neural network. Recent work on the SANE system, however, has demonstrated that evolving individual neurons often produces a more efficient genetic search. This paper demonstrates that while SANE can solve easy tasks very quickly, it often stalls in larger problems. A hierarchical approach to 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1981...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: There is strong evidence that face processing is localized in the brain. The double dissociation between prosopagnosia, a face recognition deficit occurring after brain damage, and visual object agnosia, difficulty recognizing other kinds of complex objects, indicates that face and non-face object recognition may be served by partially independent mechanisms in the brain. Is neural specialization innate or learned? We suggest that this specialization could be the result of a competitive learning mechanism that, during development, devotes neural resources to the tasks they are best at performing. Further, we suggest that the specialization arises as an interaction between task requirements and developmental constraints. In this paper, we present a feed-forward computational model of visual processing, in which two modules compete to classify input stimuli. When one module receives low spatial frequency information and the other receives high spatial frequency information, and the task is to identify the faces while simply classifying the objects, the low frequency network shows a strong specialization for faces. No other combination of tasks and inputs shows this strong specialization. We take these results as support for the idea that an innately-specified face processing module is unnecessary.
Title: Title: Task and Spatial Frequency Effects on Face Specialization  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning a Specialization for Face Recognition: The Effect of Spatial Frequency  
Abstract: The double dissociation between prosopagnosia, a face recognition deficit occurring after brain damage, and visual object agnosia, difficulty recognizing other kinds of complex objects, indicates that face and non-face object recognition may be served by partially independent mechanisms in the brain. Such a dissociation could be the result of a competitive learning mechanism that, during
Label: Neural Networks
Paper 3  Title: Robust Parameter Learning in Bayesian Networks with Missing Data  
Abstract: There is strong evidence that face processing in the brain is localized. The double dissociation between prosopagnosia, a face recognition deficit occurring after brain damage, and visual object agnosia, difficulty recognizing other kinds of complex objects, indicates that face and non-face object recognition may be served by partially independent neural mechanisms. In this chapter, we u
Label: Probabilistic Methods
Paper 4  Title: Prosopagnosia in Modular Neural Network Models  
Abstract: There is strong evidence that face processing in the brain is localized. The double dissociation between prosopagnosia, a face recognition deficit occurring after brain damage, and visual object agnosia, difficulty recognizing other kinds of complex objects, indicates that face and non-face object recognition may be served by partially independent neural mechanisms. In this chapter, we u
Paper 5  Title: A Mixture of Experts Model Exhibiting Prosopagnosia  
Abstract: A considerable body of evidence from prosopagnosia, a deficit in face recognition dissociable from nonface object recognition, indicates that the visual system devotes a specialized functional area to mechanisms appropriate for face processing. We present a modular neural network composed of two expert networks and one mediating gate network with the task of learning to recognize the fac
Paper 6  Title: Efficient Visual Search: A Connectionist Solution  
Abstract: Searching for objects in scenes is a natural task for people and has been extensively studied by psychologists. In this paper we examine this task from a connectionist perspective. Computational complexity arguments suggest that parallel feed-forward networks cannot perform this task efficiently. One difficulty is that, in order to distinguish the target from distractors, a combination o
Paper 7  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract: A novel architecture and set of learning rules for cortical self-organization is proposed. The model is based on the idea that multiple information channels can modulate one another's plasticity. Features learned from bottom-up information sources can thus be influenced by those learned from contextual pathways, and vice versa. A maximum likelihood cost function allows this scheme to be 
Label: Neural Networks
Paper 8  Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  
Abstract: The map from eye to brain in vertebrates is topographic, i.e. neighbouring points in the eye map to neighbouring points in the brain. In addition, when two eyes innervate the same target structure, the two sets of fibres segregate to form ocular dominance stripes. Experimental evidence from the frog and goldfish suggests that these two phenomena may be subserved by the same mechanisms. W
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 499...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Mean field methods provide computationally efficient approximations to posterior probability distributions for graphical models. Simple mean field methods make a completely factorized approximation to the posterior, which is unlikely to be accurate when the posterior is multimodal. Indeed, if the posterior is multi-modal, only one of the modes can be captured. To improve the mean field approximation in such cases, we employ mixture models as posterior approximations, where each mixture component is a factorized distribution. We describe efficient methods for optimizing the parameters in these models. 
Title: Title: IMPROVING THE MEAN FIELD APPROXIMATION VIA THE USE OF MIXTURE DISTRIBUTIONS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A note on convergence rates of Gibbs sampling for nonparametric mixtures  
Abstract: We consider a mixture model where the mixing distribution is random and is given a Dirichlet process prior. We describe the general structure of two Gibbs sampling algorithms that are useful for approximating Bayesian inferences in this problem. When the kernel f(x j ) of the mixture is bounded, we show that the Markov chains resulting from the Gibbs sampling are uniformly ergodic, and w
Paper 3  Title: Factorial Hidden Markov Models  
Abstract: One of the basic probabilistic tools used for time series modeling is the hidden Markov model (HMM). In an HMM, information about the past of the time series is conveyed through a single discrete variable|the hidden state. We present a generalization of HMMs in which this state is factored into multiple state variables and is therefore represented in a distributed manner. Both inference 
Paper 4  Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  
Abstract: New methodology for fully Bayesian mixture analysis is developed, making use of reversible jump Markov chain Monte Carlo methods, that are capable of jumping between the parameter subspaces corresponding to different numbers of components in the mixture. A sample from the full joint distribution of all unknown variables is thereby generated, and this can be used as a basis for a thorough
Paper 5  Title: Gaussian Processes for Bayesian Classification via Hybrid Monte Carlo  
Abstract: The full Bayesian method for applying neural networks to a prediction problem is to set up the prior/hyperprior structure for the net and then perform the necessary integrals. However, these integrals are not tractable analytically, and Markov Chain Monte Carlo (MCMC) methods are slow, especially if the parameter space is high-dimensional. Using Gaussian processes we can approximate the 
Label: Neural Networks
Paper 6  Title: A variational approach to Bayesian logistic regression models and their extensions  
Abstract: We consider a logistic regression model with a Gaussian prior distribution over the parameters. We show that accurate variational techniques can be used to obtain a closed form posterior distribution over the parameters given the data thereby yielding a posterior predictive model. The results are readily extended to (binary) belief networks. For belief networks we also derive closed form
Paper 7  Title: Monte Carlo Implementation of Gaussian Process Models for Bayesian Regression and Classification  
Abstract: Technical Report No. 9702, Department of Statistics, University of Toronto Abstract. Gaussian processes are a natural way of defining prior distributions over functions of one or more input variables. In a simple nonparametric regression problem, where such a function gives the mean of a Gaussian distribution for an observed response, a Gaussian process model can easily be implemented us
Paper 8  Title: Inference in Dynamic Error-in-Variable-Measurement Problems  
Abstract: Efficient algorithms have been developed for estimating model parameters from measured data, even in the presence of gross errors. In addition to point estimates of parameters, however, assessments of uncertainty are needed. Linear approximations provide standard errors, but these can be misleading when applied to models that are substantially nonlinear. To overcome this difficulty, "pro
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 1183...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper describes the MAXQ method for hierarchical reinforcement learning based on a hierarchical decomposition of the value function and derives conditions under which the MAXQ decomposition can represent the optimal value function. We show that for certain execution models, the MAXQ decomposition will produce better policies than Feudal Q learning.
Title: Title: Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Approximating Value Trees in Structured Dynamic Programming  
Abstract: We propose and examine a method of approximate dynamic programming for Markov decision processes based on structured problem representations. We assume an MDP is represented using a dynamic Bayesian network, and construct value functions using decision trees as our function representation. The size of the representation is kept within acceptable limits by pruning these value trees so tha
Paper 3  Title: Constructive Neural Network Learning Algorithms for Multi-Category Real-Valued Pattern Classification  
Abstract: Prioritized sweeping is a model-based reinforcement learning method that attempts to focus an agent's limited computational resources to achieve a good estimate of the value of environment states. To choose effectively where to spend a costly planning step, classic prioritized sweeping uses a simple heuristic to focus computation on the states that are likely to have the largest errors. 
Paper 4  Title: Hierarchical Explanation-Based Reinforcement Learning  
Abstract: Explanation-Based Reinforcement Learning (EBRL) was introduced by Dietterich and Flann as a way of combining the ability of Reinforcement Learning (RL) to learn optimal plans with the generalization ability of Explanation-Based Learning (EBL) (Di-etterich & Flann, 1995). We extend this work to domains where the agent must order and achieve a sequence of subgoals in an optimal fashion. Hi
Paper 5  Title: Bayesian Methods for Adaptive Models  
Abstract: Almost all the work in Average-reward Re- inforcement Learning (ARL) so far has focused on table-based methods which do not scale to domains with large state spaces. In this paper, we propose two extensions to a model-based ARL method called H-learning to address the scale-up problem. We extend H-learning to learn action models and reward functions in the form of Bayesian networks, and a
Paper 6  Title: Value Function Approximations and Job-Shop Scheduling  
Abstract: We report a successful application of TD() with value function approximation to the task of job-shop scheduling. Our scheduling problems are based on the problem of scheduling payload processing steps for the NASA space shuttle program. The value function is approximated by a 2-layer feedforward network of sigmoid units. A one-step lookahead greedy algorithm using the learned evaluation 
Paper 7  Title: Using Path Diagrams as a Structural Equation Modelling Tool  
Abstract: Reinforcement learning is the problem of generating optimal behavior in a sequential decision-making environment given the opportunity of interacting with it. Many algorithms for solving reinforcement-learning problems work by computing improved estimates of the optimal value function. We extend prior analyses of reinforcement-learning algorithms and present a powerful new theorem that c
Label: Probabilistic Methods
Paper 8  Title: Learning to Achieve Goals  
Abstract: Temporal difference methods solve the temporal credit assignment problem for reinforcement learning. An important subproblem of general reinforcement learning is learning to achieve dynamic goals. Although existing temporal difference methods, such as Q learning, can be applied to this problem, they do not take advantage of its special structure. This paper presents the DG-learning algor
Label: Reinforcement Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 186...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper describes a self-learning control system for a mobile robot. Based on local sensor data, a robot is taught to avoid collisions with obstacles. The only feedback to the control system is a binary-valued external reinforcement signal, which indicates whether or not a collision has occured. A reinforcement learning scheme is used to find a correct mapping from input (sensor) space to output (steering signal) space. An adaptive quantisation scheme is introduced, through which the discrete division of input space is built up from scratch by the system itself. 
Title: Title: Adaptive state space quantisation: adding and removing neurons  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: LEARNING TO AVOID COLLISIONS: A REINFORCEMENT LEARNING PARADIGM FOR MOBILE ROBOT NAVIGATION  
Abstract: The paper describes a self-learning control system for a mobile robot. Based on sensor information the control system has to provide a steering signal in such a way that collisions are avoided. Since in our case no `examples' are available, the system learns on the basis of an external reinforcement signal which is negative in case of a collision and zero otherwise. We describe the adapt
Paper 3  Title: Adaptive state space quantisation for reinforcement learning of collision-free navigation  
Abstract: The paper describes a self-learning control system for a mobile robot. Based on sensor information the control system has to provide a steering signal in such a way that collisions are avoided. Since in our case no `examples' are available, the system learns on the basis of an external reinforcement signal which is negative in case of a collision and zero otherwise. Rules from Temporal D
Paper 4  Title: Evolving Obstacle Avoidance Behavior in a Robot Arm  
Abstract: Existing approaches for learning to control a robot arm rely on supervised methods where correct behavior is explicitly given. It is difficult to learn to avoid obstacles using such methods, however, because examples of obstacle avoidance behavior are hard to generate. This paper presents an alternative approach that evolves neural network controllers through genetic algorithms. No input
Paper 5  Title: Evolution of Homing Navigation in a Real Mobile Robot  
Abstract: In this paper we describe the evolution of a discrete-time recurrent neural network to control a real mobile robot. In all our experiments the evolutionary procedure is carried out entirely on the physical robot without human intervention. We show that the autonomous development of a set of behaviors for locating a battery charger and periodically returning to it can be achieved by lifti
Paper 6  Title: Automatic Generation of Adaptive Programs Automatic Generation of Adaptive Programs. In From Animals to Animats
Abstract: Fuzzy rules for control can be effectively tuned via reinforcement learning. Reinforcement learning is a weak learning method, which only requires information on the success or failure of the control application. The tuning process allows people to generate fuzzy rules which are unable to accurately perform control and have them tuned to be rules which provide smooth control. This paper 
Paper 7  Title: Biological metaphors and the design of modular artificial neural networks Master's thesis of  
Abstract: In this paper we describe a self-adjusting algorithm for packet routing in which a reinforcement learning method is embedded into each node of a network. Only local information is used at each node to keep accurate statistics on which routing policies lead to minimal routing times. In simple experiments involving a 36-node irregularly-connected network, this learning approach proves supe
Paper 8  Title: NEUROCONTROL BY REINFORCEMENT LEARNING  
Abstract: Reinforcement learning (RL) is a model-free tuning and adaptation method for control of dynamic systems. Contrary to supervised learning, based usually on gradient descent techniques, RL does not require any model or sensitivity function of the process. Hence, RL can be applied to systems that are poorly understood, uncertain, nonlinear or for other reasons untractable with conventional 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 504...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The use of artificial neural networks in the domain of autonomous vehicle navigation has produced promising results. ALVINN [Pomerleau, 1991] has shown that a neural system can drive a vehicle reliably and safely on many different types of roads, ranging from paved paths to interstate highways. Even with these impressive results, several areas within the neural paradigm for autonomous road following still need to be addressed. These include transparent navigation between roads of different type, simultaneous use of different sensors, and generalization to road types which the neural system has never seen. The system presented here addresses these issue with a modular neural architecture which uses pre-trained ALVINN networks and a connectionist superstructure to robustly drive on many dif ferent types of roads.
Title: Title: MANIAC: A Next Generation Neurally Based Autonomous Road Follower  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The BATmobile: Towards a Bayesian Automated Taxi  
Abstract: The problem of driving an autonomous vehicle in highway traffic engages many areas of AI research and has substantial economic significance. We describe work in progress on a new approach to this problem based on a decision-theoretic architecture using dynamic probabilistic networks. The architecture provides a sound solution to the problems of sensor noise, sensor failure, and uncertain
Label: Probabilistic Methods
Paper 3  Title: VECTOR ASSOCIATIVE MAPS: UNSUPERVISED REAL-TIME ERROR-BASED LEARNING AND CONTROL OF MOVEMENT TRAJECTORIES  
Abstract: ALVINN (Autonomous Land Vehicle in a Neural Net) is a Backpropagation trained neural network which is capable of autonomously steering a vehicle in road and highway environments. Although ALVINN is fairly robust, one of the problems with it has been the time it takes to train. As the vehicle is capable of on-line learning, the driver has to drive the car for about 2 minutes before the ne
Paper 4  Title: Automated Highway System  
Abstract: ALVINN (Autonomous Land Vehicle in a Neural Net) is a Backpropagation trained neural network which is capable of autonomously steering a vehicle in road and highway environments. Although ALVINN is fairly robust, one of the problems with it has been the time it takes to train. As the vehicle is capable of on-line learning, the driver has to drive the car for about 2 minutes before the ne
Paper 5  Title: Evolving Obstacle Avoidance Behavior in a Robot Arm  
Abstract: Existing approaches for learning to control a robot arm rely on supervised methods where correct behavior is explicitly given. It is difficult to learn to avoid obstacles using such methods, however, because examples of obstacle avoidance behavior are hard to generate. This paper presents an alternative approach that evolves neural network controllers through genetic algorithms. No input
Paper 6  Title: Using a Genetic Algorithm to Learn Strategies for Collision Avoidance and Local Navigation  
Abstract: Navigation through obstacles such as mine fields is an important capability for autonomous underwater vehicles. One way to produce robust behavior is to perform projective planning. However, real-time performance is a critical requirement in navigation. What is needed for a truly autonomous vehicle are robust reactive rules that perform well in a wide variety of situations, and that also
Paper 7  Title: A comparison of neural net and conventional techniques for lighting control  
Abstract: We compare two techniques for lighting control in an actual room equipped with seven banks of lights and photoresistors to detect the lighting level at four sensing points. Each bank of lights can be independently set to one of sixteen intensity levels. The task is to determine the device intensity levels that achieve a particular configuration of sensor readings. One technique we explor
Paper 8  Title: An Evolutionary Approach to Learning in Robots  
Abstract: Evolutionary learning methods have been found to be useful in several areas in the development of intelligent robots. In the approach described here, evolutionary algorithms are used to explore alternative robot behaviors within a simulation model as a way of reducing the overall knowledge engineering effort. This paper presents some initial results of applying the SAMUEL genetic learnin
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1903...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A new class of highspeed, self-adaptive, massively parallel computing models called ASOCS (Adaptive Self-Organizing Concurrent Systems) has been proposed. Current analysis suggests that there may be problems implementing ASOCS models in VLSI using the hierarchical network structures originally proposed. The problems are not inherent in the models, but rather in the technology used to implement them. This has led to the development of a new ASOCS model called DNA (Discriminant-Node ASOCS) that does not depend on a hierarchical node structure for success. Three areas of the DNA model are briefly discussed in this paper: DNA's flexible nodes, how DNA overcomes problems other models have allocating unused nodes, and how DNA operates during processing and learning. 
Title: Title: DNA: A New ASOCS Model With Improved Implementation Potential  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Word Perfect Corp. LIA: A Location-Independent Transformation for ASOCS Adaptive Algorithm 2  
Abstract: Most Artificial Neural Networks (ANNs) have a fixed topology during learning, and often suffer from a number of shortcomings as a result. ANNs that use dynamic topologies have shown ability to overcome many of these problems. Adaptive Self Organizing Concurrent Systems (ASOCS) are a class of learning models with inherently dynamic topologies. This paper introduces Location-Independent Tr
Label: Neural Networks
Paper 3  Title: A VLSI Implementation of a Parallel, Self-Organizing Learning Model  
Abstract: This paper presents a VLSI implementation of the Priority Adaptive Self-Organizing Concurrent System (PASOCS) learning model that is built using a multi-chip module (MCM) substrate. Many current hardware implementations of neural network learning models are direct implementations of classical neural network structures|a large number of simple computing nodes connected by a dense number o
Label: Neural Networks
Paper 4  Title: Word Perfect Corp. A TRANSFORMATION FOR IMPLEMENTING EFFICIENT DYNAMIC BACKPROPAGATION NEURAL NETWORKS  
Abstract: Most Artificial Neural Networks (ANNs) have a fixed topology during learning, and often suffer from a number of shortcomings as a result. Variations of ANNs that use dynamic topologies have shown ability to overcome many of these problems. This paper introduces Location-Independent Transformations (LITs) as a general strategy for implementing distributed feedforward networks that use dyn
Paper 5  Title: Word Perfect Corp. A TRANSFORMATION FOR IMPLEMENTING NEURAL NETWORKS WITH LOCALIST PROPERTIES  
Abstract: Most Artificial Neural Networks (ANNs) have a fixed topology during learning, and typically suffer from a number of shortcomings as a result. Variations of ANNs that use dynamic topologies have shown ability to overcome many of these problems. This paper introduces Location-Independent Transformations (LITs) as a general strategy for implementing feedforward networks that use dynamic top
Paper 6  Title: Digital Neural Networks  
Abstract: Demands for applications requiring massive parallelism in symbolic environments have given rebirth to research in models labeled as neura l networks. These models are made up of many simple nodes which are highly interconnected such that computation takes place as data flows amongst the nodes of the network. To present, most models have proposed nodes based on simple analog functions, wh
Paper 7  Title: ASOCS: A Multilayered Connectionist Network with Guaranteed Learning of Arbitrary Mappings  
Abstract: This paper reviews features of a new class of multilayer connectionist architectures known as ASOCS (Adaptive Self-Organizing Concurrent Systems). ASOCS is similar to most decision-making neural network models in that it attempts to learn an adaptive set of arbitrary vector mappings. However, it differs dramatically in its mechanisms. ASOCS is based on networks of adaptive digital elemen
Label: Neural Networks
Paper 8  Title: Connectionist Layered Object-Oriented Network Simulator (CLONES): User's Manual minimize the learning curve for using CLONES,
Abstract: CLONES is a object-oriented library for constructing, training and utilizing layered connectionist networks. The CLONES library contains all the object classes needed to write a simulator with a small amount of added source code (examples are included). The size of experimental ANN programs is greatly reduced by using an object-oriented library; at the same time these programs are easier
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper describes preliminary work that aims to apply some learning strategies to a medical follow-up study. An investigation of the application of three machine learning algorithms-1R, FOIL and InductH to identify risk factors that govern the colposuspension cure rate has been made. The goal of this study is to induce a generalised description or explanation of the classification attribute, colposuspension cure rate (completely cured, improved, unchanged and worse) from the 767 examples in the questionnaires. We looked for a set of rules that described which risk factors result in differences of cure rate. The results were encouraging, and indicate that machine learning can play a useful role in large scale medical problem solving. 
Title: Title: Applications of machine learning: a medical follow up study  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Machine Learning Methods for International Conflict Databases: A Case Study in Predicting Mediation Outcome  
Abstract: This paper tries to identify rules and factors that are predictive for the outcome of international conflict management attempts. We use C4.5, an advanced Machine Learning algorithm, for generating decision trees and prediction rules from cases in the CONFMAN database. The results show that simple patterns and rules are often not only more understandable, but also more reliable than comp
Paper 3  Title: Application of Neural Networks for the Classification of Diffuse Liver Disease by Quantitative Echography  
Abstract: Three different methods were investigated to determine their ability to detect and classify various categories of diffuse liver disease. A statistical method, i.e., discriminant analysis, a supervised neural network called backpropagation and a nonsupervised, self-organizing feature map were examined. The investigation was performed on the basis of a previously selected set of acoustic a
Paper 4  Title: Induction of decision trees and Bayesian classification applied to diagnosis of sport injuries  
Abstract: Machine learning techniques can be used to extract knowledge from data stored in medical databases. In our application, various machine learning algorithms were used to extract diagnostic knowledge to support the diagnosis of sport injuries. The applied methods include variants of the Assistant algorithm for top-down induction of decision trees, and variants of the Bayesian classifier. T
Paper 5  Title: Rule Generation and Compaction in the wwtp  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 6  Title: Drug design by machine learning: Modelling drug activity  
Abstract: This paper describes an approach to modelling drug activity using machine learning tools. Some experiments in modelling the quantitative structure-activity relationship (QSAR) using a standard, Hansch, method and a machine learning system Golem were already reported in the literature. The paper describes the results of applying two other machine learning systems, Magnus Assistant and Ret
Paper 7  Title: Simple Genetic Programming for Supervised Learning Problems  
Abstract: This paper presents an evolutionary approach to finding learning rules to several supervised tasks. In this approach potential solutions are represented as variable length mathematical LISP S-expressions. Thus, it is similar to Genetic Programming (GP) but it employs a fixed set of non-problem-specific functions to solve a variety of problems. In this paper three Monk's and parity proble
Paper 8  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 50...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Metacognition addresses the issues of knowledge about cognition and regulating cognition. We argue that the regulation process should be improved with growing experience. Therefore mental models are needed which facilitate the re-use of previous regulation processes. We will satisfy this requirement by describing a case-based approach to Introspection Planning which utilises previous experience obtained during reasoning at the meta-level and at the object level. The introspection plans used in this approach support various metacognitive tasks which are identified by the generation of self-questions. As an example of introspection planning, the metacognitive behaviour of our system, IULIAN, is described. 
Title: Title: Abstract  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Multi-Strategy Learning and Theory Revision  
Abstract: This paper presents the system WHY, which learns and updates a diagnostic knowledge base using domain knowledge and a set of examples. The a-priori knowledge consists of a causal model of the domain, stating the relationships among basic phenomena, and a body of phenomenological theory, describing the links between abstract concepts and their possible manifestations in the world. The phe
Paper 3  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 4  Title: Learning Concepts from Sensor Data of a Mobile Robot  
Abstract: Machine learning can be a most valuable tool for improving the flexibility and efficiency of robot applications. Many approaches to applying machine learning to robotics are known. Some approaches enhance the robot's high-level processing, the planning capabilities. Other approaches enhance the low-level processing, the control of basic actions. In contrast, the approach presented in thi
Paper 5  Title: Adaptive Tuning of Numerical Weather Prediction Models: Simultaneous Estimation of Weighting, Smoothing and Physical Parameters 1  
Abstract: In recent years, case-based reasoning has been demonstrated to be highly useful for problem solving in complex domains. Also, mixed paradigm approaches emerged for combining CBR and induction techniques aiming at verifying the knowledge and/or building an efficient case memory. However, in complex domains induction over the whole problem space is often not possible or too time consuming.
Paper 6  Title: Rule Generation and Compaction in the wwtp  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 7  Title: Computer-Supported Argumentation for Cooperative Design on the World-Wide Web  
Abstract: This paper describes an argumentation system for cooperative design applications on the Web. The system provides experts involved in such procedures means of expressing and weighing their individual arguments and preferences, in order to argue for or against the selection of a certain choice. It supports defeasible and qualitative reasoning in the presence of ill-structured information. 
Paper 8  Title: What online Machine Learning can do for Knowledge Acquisition A Case Study  
Abstract: This paper reports on the development of a realistic knowledge-based application using the MOBAL system. Some problems and requirements resulting from industrial-caliber tasks are formulated. A step-by-step account of the construction of a knowledge base for such a task demonstrates how the interleaved use of several learning algorithms in concert with an inference engine and a graphical
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 2534...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A quantitative model is provided for psychophysical data on the tracking of multiple visual elements (multielement tracking). The model employs an object-based attentional mechanism for constructing and updating object representations. The model selectively enhances neural activations to serially construct and update the internal representations of objects through correlation-based changes in synaptic weights. The correspondence problem between items in memory and elements in the visual input is resolved through a combination of top-down prediction signals and bottom-up grouping processes. Simulations of the model on image sequences used in multielement tracking experiments show that reported results are consistent with a serial tracking mechanism that is based on psychophysical and neurobiological findings. In addition, simulations show that observed effects of perceptual grouping on tracking accuracy may result from the interactions between attention-guided predictions of object location and motion and grouping processes involved in solving the motion correspondence problem. 
Title: Title: Data Value Prediction Methods and Performance  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Object-Based Neural Model of Serial Processing in Visual Multielement Tracking  
Abstract: A quantitative model is provided for psychophysical data on the tracking of multiple visual elements (multielement tracking). The model employs an object-based attentional mechanism for constructing and updating object representations. The model selectively enhances neural activations to serially construct and update the internal representations of objects through correlation-based chang
Paper 3  Title: Solving the Temporal Binding Problem: A Neural Theory for Constructing and Updating Object Files  
Abstract: Visual objects are perceived only if their parts are correctly identified and integrated. A neural network theory is proposed that seeks to explain how the human visual system binds together visual properties, dispersed over space and time, of multiple objects a problem known as the temporal binding problem [49, 30]. The proposed theory is based upon neural mechanisms that construct and 
Paper 4  Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  
Abstract: The sensorimotor integration system can be viewed as an observer attempting to estimate its own state and the state of the environment by integrating multiple sources of information. We describe a computational framework capturing this notion, and some specific models of integration and adaptation that result from it. Psychophysical results from two sensorimotor systems, subserving the i
Paper 5  Title: Cortical Mechanisms of Visual Recognition and Learning: A Hierarchical Kalman Filter Model  
Abstract: We describe a biologically plausible model of dynamic recognition and learning in the visual cortex based on the statistical theory of Kalman filtering from optimal control theory. The model utilizes a hierarchical network whose successive levels implement Kalman filters operating over successively larger spatial and temporal scales. Each hierarchical level in the network predicts the cu
Paper 6  Title: A Theory of Visual Relative Motion Perception: Grouping, Binding, and Gestalt Organization  
Abstract: The human visual system is more sensitive to the relative motion of objects than to their absolute motion. An understanding of motion perception requires an understanding of how neural circuits can group moving visual elements relative to one another, based upon hierarchical reference frames. We have modeled visual relative motion perception using a neural network architecture that group
Paper 7  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract: A novel architecture and set of learning rules for cortical self-organization is proposed. The model is based on the idea that multiple information channels can modulate one another's plasticity. Features learned from bottom-up information sources can thus be influenced by those learned from contextual pathways, and vice versa. A maximum likelihood cost function allows this scheme to be 
Label: Neural Networks
Paper 8  Title: Priming, Perceptual Reversal, and Circular Reaction in a Neural Network Model of Schema-Based Vision  
Abstract: VISOR is a neural network system for object recognition and scene analysis that learns visual schemas from examples. Processing in VISOR is based on cooperation, competition, and parallel bottom-up and top-down activation of schema representations. Similar principles appear to underlie much of human visual processing, and VISOR can therefore be used to model various perceptual phenomena.
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 122...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Previous neural network learning algorithms for sequence processing are computationally expensive and perform poorly when it comes to long time lags. This paper first introduces a simple principle for reducing the descriptions of event sequences without loss of information. A consequence of this principle is that only unexpected inputs can be relevant. This insight leads to the construction of neural architectures that learn to `divide and conquer' by recursively decomposing sequences. I describe two architectures. The first functions as a self-organizing multi-level hierarchy of recurrent networks. The second, involving only two recurrent networks, tries to collapse a multi-level predictor hierarchy into a single recurrent net. Experiments show that the system can require less computation per time step and many fewer training sequences than conventional training algorithms for recurrent nets.
Title: Title: Tilt Aftereffects in a Self-Organizing Model of the Primary Visual Cortex  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: LEARNING COMPLEX, EXTENDED SEQUENCES USING THE PRINCIPLE OF HISTORY COMPRESSION (Neural Computation, 4(2):234-242, 1992)  
Abstract: Previous neural network learning algorithms for sequence processing are computationally expensive and perform poorly when it comes to long time lags. This paper first introduces a simple principle for reducing the descriptions of event sequences without loss of information. A consequence of this principle is that only unexpected inputs can be relevant. This insight leads to the construct
Paper 3  Title: Object Selection Based on Oscillatory Correlation  
Abstract: 1 Technical Report: OSU-CISRC-12/96 - TR67, 1996 Abstract One of the classical topics in neural networks is winner-take-all (WTA), which has been widely used in unsupervised (competitive) learning, cortical processing, and attentional control. Because of global connectivity, WTA networks, however, do not encode spatial relations in the input, and thus cannot support sensory and perceptua
Label: Neural Networks
Paper 4  Title: LEARNING TO CONTROL FAST-WEIGHT MEMORIES: AN ALTERNATIVE TO DYNAMIC RECURRENT NETWORKS (Neural Computation, 4(1):131-139, 1992)  
Abstract: Previous algorithms for supervised sequence learning are based on dynamic recurrent networks. This paper describes an alternative class of gradient-based systems consisting of two feedforward nets that learn to deal with temporal sequences using fast weights: The first net learns to produce context dependent weight changes for the second net whose weights may vary very quickly. The metho
Paper 5  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract: A novel architecture and set of learning rules for cortical self-organization is proposed. The model is based on the idea that multiple information channels can modulate one another's plasticity. Features learned from bottom-up information sources can thus be influenced by those learned from contextual pathways, and vice versa. A maximum likelihood cost function allows this scheme to be 
Label: Neural Networks
Paper 6  Title: Using Many-Particle Decomposition to get a Parallel Self-Organising Map  
Abstract: We propose a method for decreasing the computational complexity of self-organising maps. The method uses a partitioning of the neurons into disjoint clusters. Teaching of the neurons occurs on a cluster-basis instead of on a neuron-basis. For teaching an N-neuron network with N 0 samples, the computational complexity decreases from O(N 0 N) to O(N 0 log N). Furthermore, we introduce a me
Paper 7  Title: Distributed Patterns as Hierarchical Structures  
Abstract: Recursive Auto-Associative Memory (RAAM) structures show promise as a general representation vehicle that uses distributed patterns. However training is often difficult, which explains, at least in part, why only relatively small networks have been studied. We show a technique for transforming any collection of hierarchical structures into a set of training patterns for a sequential RAAM
Label: Neural Networks
Paper 8  Title: Generative Models for Discovering Sparse Distributed Representations  
Abstract: We describe a hierarchical, generative model that can be viewed as a non-linear generalization of factor analysis and can be implemented in a neural network. The model uses bottom-up, top-down and lateral connections to perform Bayesian perceptual inference correctly. Once perceptual inference has been performed the connection strengths can be updated using a very simple learning rule th
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 2335...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We review the use of global and local methods for estimating a function mapping R m ) R n from samples of the function containing noise. The relationship between the methods is examined and an empirical comparison is performed using the multi-layer perceptron (MLP) global neural network model, the single nearest-neighbour model, a linear local approximation (LA) model, and the following commonly used datasets: the Mackey-Glass chaotic time series, the Sunspot time series, British English Vowel data, TIMIT speech phonemes, building energy prediction data, and the sonar dataset. We find that the simple local approximation models often outperform the MLP. No criterion such as classification/prediction, size of the training set, dimensionality of the training set, etc. can be used to distinguish whether the MLP or the local approximation method will be superior. However, we find that if we consider histograms of the k-NN density estimates for the training datasets then we can choose the best performing method a priori by selecting local approximation when the spread of the density histogram is large and choosing the MLP otherwise. This result correlates with the hypothesis that the global MLP model is less appropriate when the characteristics of the function to be approximated varies throughout the input space. We discuss the results, the smoothness assumption often made in function approximation, and the bias/variance dilemma. 
Title: Title: Function Approximation with Neural Networks and Local Methods: Bias, Variance and Smoothness  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Comparing Predictive Inference Methods for Discrete Domains  
Abstract: Predictive inference is seen here as the process of determining the predictive distribution of a discrete variable, given a data set of training examples and the values for the other problem domain variables. We consider three approaches for computing this predictive distribution, and assume that the joint probability distribution for the variables belongs to a set of distributions deter
Label: Probabilistic Methods
Paper 3  Title: A Bootstrap Evaluation of the Effect of Data Splitting on Financial Time Series  
Abstract: This article exposes problems of the commonly used technique of splitting the available data into training, validation, and test sets that are held fixed, warns about drawing too strong conclusions from such static splits, and shows potential pitfalls of ignoring variability across splits. Using a bootstrap or resampling method, we compare the uncertainty in the solution stemming from th
Paper 4  Title: Packet Routing and Reinforcement Learning: Estimating Shortest Paths in Dynamic Graphs  
Abstract: This article exposes problems of the commonly used technique of splitting the available data into training, validation, and test sets that are held fixed, warns about drawing too strong conclusions from such static splits, and shows potential pitfalls of ignoring variability across splits. Using a bootstrap or resampling method, we compare the uncertainty in the solution stemming from th
Paper 5  Title: Comparison of Kernel Estimators, Perceptrons, and Radial-Basis Functions for OCR and Speech Classification  
Abstract: We compare kernel estimators, single and multi-layered perceptrons and radial-basis functions for the problems of classification of handwritten digits and speech phonemes. By taking two different applications and employing many techniques, we report here a two-dimensional study whereby a domain-independent assessment of these learning methods can be possible. We consider a feed-forward n
Paper 6  Title: What Size Neural Network Gives Optimal Generalization? Convergence Properties of Backpropagation  
Abstract: Technical Report UMIACS-TR-96-22 and CS-TR-3617 Institute for Advanced Computer Studies University of Maryland College Park, MD 20742 Abstract One of the most important aspects of any machine learning paradigm is how it scales according to problem size and complexity. Using a task with known optimal training error, and a pre-specified maximum number of training updates, we investigate th
Paper 7  Title: Cross-Validation and the Bootstrap: Estimating the Error Rate of a Prediction Rule  
Abstract: A training set of data has been used to construct a rule for predicting future responses. What is the error rate of this rule? The traditional answer to this question is given by cross-validation. The cross-validation estimate of prediction error is nearly unbiased, but can be highly variable. This article discusses bootstrap estimates of prediction error, which can be thought of as smoo
Paper 8  Title: First experiments using a mixture of nonlinear experts for time series prediction  
Abstract: This paper investigates the advantages and disadvantages of the mixture of experts (ME) model (introduced to the connectionist community in [JJNH91] and applied to time series analysis in [WM95]) on two time series where the dynamics is well understood. The first series is a computer-generated series, consisting of a mixture between a noise-free process (the quadratic map) and a noisy pr
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 540...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We analyze the blame-assignment task in the context of experience-based design and redesign of physical devices. We identify three types of blame-assignment tasks that differ in the types of information they take as input: the design does not achieve a desired behavior of the device, the design results in an undesirable behavior, a specific structural element in the design misbehaves. We then describe a model-based approach for solving the blame-assignment task. This approach uses structure-behavior-function models that capture a designer's comprehension of the way a device works in terms of causal explanations of how its structure results in its behaviors. We also address the issue of indexing the models in memory. We discuss how the three types of blame-assignment tasks require different types of indices for accessing the models. Finally we describe the KRITIK2 system that implements and evaluates this model-based approach to blame assignment.
Title: Title: A Model-Based Approach to Blame-Assignment in Design  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning Problem-Solving Concepts by Reflecting on Problem Solving  
Abstract: Learning and problem solving are intimately related: problem solving determines the knowledge requirements of the reasoner which learning must fulfill, and learning enables improved problem-solving performance. Different models of problem solving, however, recognize different knowledge needs, and, as a result, set up different learning tasks. Some recent models analyze problem solving in
Paper 3  Title: Functional Representation as Design Rationale  
Abstract: Design rationale is a record of design activity: of alternatives available, choices made, the reasons for them, and explanations of how a proposed design is intended to work. We describe a representation called the Functional Representation (FR) that has been used to represent how a device's functions arise causally from the functions of its components and their interconnections. We prop
Paper 4  Title: Use of Mental Models for Constraining Index Learning in Experience-Based Design  
Abstract: The power of the case-based method comes from the ability to retrieve the "right" case when a new problem is specified. This implies that learning the "right" indices to a case before storing it for potential reuse is crucial for the success of the method. A hierarchical organization of the case memory raises two distinct but related issues in index learning: learning the indexing vocabu
Label: Case Based
Paper 5  Title: Generic Teleological Mechanisms and their Use in Case Adaptation  
Abstract: In experience-based (or case-based) reasoning, new problems are solved by retrieving and adapting the solutions to similar problems encountered in the past. An important issue in experience-based reasoning is to identify different types of knowledge and reasoning useful for different classes of case-adaptation tasks. In this paper, we examine a class of non-routine case-adaptation tasks 
Paper 6  Title: GIT-CC-92/60 A Model-Based Approach to Analogical Reasoning and Learning in Design  
Abstract: A major issue in case-basedsystems is retrieving the appropriate cases from memory to solve a given problem. This implies that a case should be indexed appropriately when stored in memory. A case-based system, being dynamic in that it stores cases for reuse, needs to learn indices for the new knowledge as the system designers cannot envision that knowledge. Irrespective of the type of in
Paper 7  Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  
Abstract: Mixed-initiative systems present the challenge of finding an effective level of interaction between humans and computers. Machine learning presents a promising approach to this problem in the form of systems that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive assistant for crisis sched
Paper 8  Title: Learning to Predict User Operations for Adaptive Scheduling  
Abstract: Mixed-initiative systems present the challenge of finding an effective level of interaction between humans and computers. Machine learning presents a promising approach to this problem in the form of systems that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive assistant for crisis sched
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 537...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: DIMACS Technical Report 96-56 December 1996 
Title: Title: Adaptive Global Optimization with Local Search  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning and evolution in neural networks  
Abstract: DIMACS Technical Report 96-56 December 1996 
Paper 3  Title: Design of Optimization Criteria for Multiple Sequence Alignment  
Abstract: DIMACS Technical Report 96-53 January 1997 
Paper 4  Title: Constructive Training Methods for Feedforward Neural Networks with Binary Weights  
Abstract: DIMACS Technical Report 95-35 August 1995 
Label: Neural Networks
Paper 5  Title: DNA Sequence Classification Using Compression-Based Induction  
Abstract: DIMACS Technical Report 95-04 April 1995 
Paper 6  Title: Dimension of Recurrent Neural Networks  
Abstract: DIMACS Technical Report 96-56 December 1996 
Label: Neural Networks
Paper 7  Title: of nucleotide sites needed to accurately reconstruct large evolutionary trees 1  
Abstract: DIMACS Technical Report 96-19 July 1996 
Paper 8  Title: Average-Case Analysis of a Nearest Neighbor Algorithm  
Abstract: Eugenic Evolution for Combinatorial Optimization John William Prior Report AI98-268 May 1998 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 2265...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Air Traffic Control is involved in the real-time planning of aircraft trajectories. This is a heavily constrained optimization problem. We concentrate on free-route planning, in which aircraft are not required to fly over way points. The choice of a proper representation for this real-world problem is non-trivial. We propose a two level representation: one level on which the evolutionary operators work, and a derived level on which we do calculations. Furthermore we show that a specific choice of the fitness function is important for finding good solutions to large problem instances. We use a hybrid approach in the sense that we use knowledge about air traffic control by using a number of heuristics. We have built a prototype of a planning tool, and this resulted in a flexible tool for generating a free-route planning of low cost, for a number of aircraft. 
Title: Title: AN APPROACH TO A PROBLEM IN NETWORK DESIGN USING GENETIC ALGORITHMS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Evolutionary Computation in Air Traffic Control Planning  
Abstract: Air Traffic Control is involved in the real-time planning of aircraft trajectories. This is a heavily constrained optimization problem. We concentrate on free-route planning, in which aircraft are not required to fly over way points. The choice of a proper representation for this real-world problem is non-trivial. We propose a two level representation: one level on which the evolutionary
Paper 3  Title: Evolution of Pseudo-colouring Algorithms for Image Enhancement with Interactive Genetic Programming  
Abstract: Technical Report: CSRP-97-5 School of Computer Science The University of Birmingham Abstract In this paper we present an approach to the interactive development of programs for image enhancement with Genetic Programming (GP) based on pseudo-colour transformations. In our approach the user drives GP by deciding which individual should be the winner in tournament selection. The presence of
Label: Genetic Algorithms
Paper 4  Title: Genetic Algorithm based Scheduling in a Dynamic Manufacturing Environment  
Abstract: The application of adaptive optimization strategies to scheduling in manufacturing systems has recently become a research topic of broad interest. Population based approaches to scheduling predominantly treat static data models, whereas real-world scheduling tends to be a dynamic problem. This paper briefly outlines the application of a genetic algorithm to the dynamic job shop problem a
Paper 5  Title: Adaptation of Genetic Algorithms for Engineering Design Optimization  
Abstract: Genetic algorithms have been extensively used in different domains as a means of doing global optimization in a simple yet reliable manner. However, in some realistic engineering design optimization domains it was observed that a simple classical implementation of the GA based on binary encoding and bit mutation and crossover was sometimes inefficient and unable to reach the global optim
Paper 6  Title: The Application of a Parallel Genetic Algorithm to the n=m=P=C max Flowshop Problem  
Abstract: Hard combinatorial problems in sequencing and scheduling led recently into further research of genetic algorithms. Canonical coding of the symmetric TSP can be modified into a coding of the n-job m-machine flowshop problem, which configurates the solution space in a different way. We show that well known genetic operators act intelligently on this coding scheme. They implecitely prefer a
Label: Genetic Algorithms
Paper 7  Title: PRONOUNCING NAMES BY A COMBINATION OF RULE-BASED AND CASE-BASED REASONING  
Abstract: We describe the design and tuning of a controller for enforcing compliance with a prescribed velocity profile for a rail-based transportation system. This requires following a trajectory, rather than fixed set-points (as in automobiles). We synthesize a fuzzy controller for tracking the velocity profile, while providing a smooth ride and staying within the prescribed speed limits. We use
Paper 8  Title: Genetic Algorithms for Automated Tuning of Fuzzy Controllers: A Transportation Application  
Abstract: We describe the design and tuning of a controller for enforcing compliance with a prescribed velocity profile for a rail-based transportation system. This requires following a trajectory, rather than fixed set-points (as in automobiles). We synthesize a fuzzy controller for tracking the velocity profile, while providing a smooth ride and staying within the prescribed speed limits. We use
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2205...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Augmenting genetic algorithms with local search heuristics is a promising approach to the solution of combinatorial optimization problems. In this paper, a genetic local search approach to the quadratic assignment problem (QAP) is presented. New genetic operators for realizing the approach are described, and its performance is tested on various QAP instances containing between 30 and 256 facilities/locations. The results indicate that the proposed algorithm is able to arrive at high quality solutions in a relatively short time limit: for the largest publicly known prob lem instance, a new best solution could be found.
Title: Title: A Genetic Local Search Approach to the Quadratic Assignment Problem  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Evolutionary Approach to Combinatorial Optimization Problems  
Abstract: The paper reports on the application of genetic algorithms, probabilistic search algorithms based on the model of organic evolution, to NP-complete combinatorial optimization problems. In particular, the subset sum, maximum cut, and minimum tardy task problems are considered. Except for the fitness function, no problem-specific changes of the genetic algorithm are required in order to ac
Paper 3  Title: A Genetic Algorithm for Continuous Design Space Search  
Abstract: Genetic algorithms (GAs) have been extensively used as a means for performing global optimization in a simple yet reliable manner. However, in some realistic engineering design optimization domains the simple, classical implementation of a GA based on binary encoding and bit mutation and crossover is often inefficient and unable to reach the global optimum. In this paper we describe a GA
Label: Genetic Algorithms
Paper 4  Title: A GENETIC ALGORITHM FOR FRAGMENT ALLOCATION IN A DISTRIBUTED DATABASE SYSTEM  
Abstract: In this paper we explore the distributed database allocation problem, which is intractable. We also discuss genetic algorithms and how they have been used successfully to solve combinatorial problems. Our experimental results show the GA to be far superior to the greedy heuristic in obtaining optimal and near optimal fragment placements for the allocation problem with various data sets.
Label: Genetic Algorithms
Paper 5  Title: An evolutionary tabu search algorithm and the NHL scheduling problem  
Abstract: We present in this paper a new evolutionary procedure for solving general optimization problems that combines efficiently the mechanisms of genetic algorithms and tabu search. In order to explore the solution space properly interaction phases are interspersed with periods of optimization in the algorithm. An adaptation of this search principle to the National Hockey League (NHL) problem 
Paper 6  Title: Adaptation of Genetic Algorithms for Engineering Design Optimization  
Abstract: Genetic algorithms have been extensively used in different domains as a means of doing global optimization in a simple yet reliable manner. However, in some realistic engineering design optimization domains it was observed that a simple classical implementation of the GA based on binary encoding and bit mutation and crossover was sometimes inefficient and unable to reach the global optim
Paper 7  Title: An Evolutionary Approach to Time Constrained Routing Problems  
Abstract: Routing problems are an important class of planning problems. Usually there are many different constraints and optimization criteria involved, and it is difficult to find general methods for solving routing problems. We propose an evolutionary solver for such planning problems. An instance of this solver has been tested on a specific routing problem with time constraints. The performance
Label: Genetic Algorithms
Paper 8  Title: Graph Coloring with Adaptive Evolutionary Algorithms  
Abstract: This paper presents the results of an experimental investigation on solving graph coloring problems with Evolutionary Algorithms (EA). After testing different algorithm variants we conclude that the best option is an asexual EA using order-based representation and an adaptation mechanism that periodically changes the fitness function during the evolution. This adaptive EA is general, usi
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2143...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Posner and Raichle's Images of Mind is an excellent educational book and very well written. Some aws as a scientific publication are: (a) the accuracy of the linear subtraction method used in PET is subject to scrutiny by further research at finer spatial-temporal resolutions; (b) lack of accuracy of the experimental paradigm used for EEG complementary studies. Images (Posner & Raichle, 1994) is an excellent introduction to interdisciplinary research in cognitive and imaging science. Well written and illustrated, it presents concepts in a manner well suited both to the layman/undergraduate and to the technical nonexpert/graduate student and postdoctoral researcher. Many, not all, people involved in interdisciplinary neuroscience research agree with the P & R's statements on page 33, on the importance of recognizing emergent properties of brain function from assemblies of neurons. It is clear from the sparse references that this book was not intended as a standalone review of a broad field. There are some aws in the scientific development, but this must be expected in such a pioneering venture. P & R hav e proposed many cognitive mechanisms deserving further study with imaging tools yet to be developed which can yield better spatial-temporal resolutions. 
Title: Title: MULTIPLE SCALES OF BRAIN-MIND INTERACTIONS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  
Abstract: Neural computation, also called connectionism, parallel distributed processing, neural network modeling or brain-style computation, has grown rapidly in the last decade. Despite this explosion, and ultimately because of impressive applications, there has been a dire need for a concise introduction from a theoretical perspective, analyzing the strengths and weaknesses of connectionist app
Paper 3  Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of
Abstract: The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exis
Label: Neural Networks
Paper 4  Title: Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems  
Abstract: The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exis
Paper 5  Title: NONLINEAR NONEQUILIBRIUM NONQUANTUM NONCHAOTIC STATISTICAL MECHANICS OF NEOCORTICAL INTERACTIONS  
Abstract: The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exis
Paper 6  Title: New Roles for Machine Learning in Design for Design of Educational Computing New roles for
Abstract: Research on machine learning in design has concentrated on the use and development of techniques that can solve simple well-defined problems. Invariably, this effort, while important at the early stages of the development of the field, cannot scale up to address real design problems since all existing techniques are based on simplifying assumptions that do not hold for real design. In pa
Paper 7  Title: Book Review New Kids on the Block way in the field of connectionist modeling. The
Abstract: Connectionist Models is a collection of forty papers representing a wide variety of research topics in connectionism. The book is distinguished by a single feature: the papers are almost exclusively contributions of graduate students active in the field. The students were selected by a rigorous review process and participated in a two week long summer school devoted to connectionism 2 . 
Label: Neural Networks
Paper 8  Title: A Brief History of Connectionism  
Abstract: Connectionist research is firmly established within the scientific community, especially within the multi-disciplinary field of cognitive science. This diversity, however, has created an environment which makes it difficult for connectionist researchers to remain aware of recent advances in the field, let alone understand how the field has developed. This paper attempts to address this p
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 763...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: PREENS a Parallel Research Execution Environment for Neural Systems is a distributed neurosimulator, targeted on networks of workstations and transputer systems. As current applications of neural networks often contain large amounts of data and as the neural networks involved in tasks such as vision are very large, high requirements on memory and computational resources are imposed on the target execution platforms. PREENS can be executed in a distributed environment, i.e. tools and neural network simulation programs can be running on any machine connectable via TCP/IP. Using this approach, larger tasks and more data can be examined using an efficient coarse grained parallelism. Furthermore, the design of PREENS allows for neural networks to be running on any high performance MIMD machine such as a trans-puter system. In this paper, the different features and design concepts of PREENS are discussed. These can also be used for other applications, like image processing.
Title: Title: PREENS, a Parallel Research Execution Environment for Neural Systems  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: CuPit-2: Portable and Efficient High-Level Parallel Programming of Neural Networks for the Systems Analysis Modelling
Abstract: CuPit-2 is a special-purpose programming language designed for expressing dynamic neural network learning algorithms. It provides most of the flexibility of general-purpose languages such as C or C ++ , but is more expressive. It allows writing much clearer and more elegant programs, in particular for algorithms that change the network topology dynamically (constructive algorithms, pruni
Paper 3  Title: University of Nevada Reno Design Strategies for Evolutionary Robotics  
Abstract: CuPit-2 is a special-purpose programming language designed for expressing dynamic neural network learning algorithms. It provides most of the flexibility of general-purpose languages such as C or C ++ , but is more expressive. It allows writing much clearer and more elegant programs, in particular for algorithms that change the network topology dynamically (constructive algorithms, pruni
Label: Genetic Algorithms
Paper 4  Title: Quicknet on MultiSpert: Fast Parallel Neural Network Training  
Abstract: The MultiSpert parallel system is a straight-forward extension of the Spert workstation accelerator, which is predominantly used in speech recognition research at ICSI. In order to deliver high performance for Artificial Neural Network training without requiring changes to the user interfaces, the exisiting Quicknet ANN library was modified to run on MultiSpert. In this report, we presen
Paper 5  Title: Connectionist Layered Object-Oriented Network Simulator (CLONES): User's Manual minimize the learning curve for using CLONES,
Abstract: CLONES is a object-oriented library for constructing, training and utilizing layered connectionist networks. The CLONES library contains all the object classes needed to write a simulator with a small amount of added source code (examples are included). The size of experimental ANN programs is greatly reduced by using an object-oriented library; at the same time these programs are easier
Paper 6  Title: A Supercomputer for Neural Computation  
Abstract: The requirement to train large neural networks quickly has prompted the design of a new massively parallel supercomputer using custom VLSI. This design features 128 processing nodes, communicating over a mesh network connected directly to the processor chip. Studies show peak performance in the range of 160 billion arithmetic operations per second. This paper presents the case for custom
Label: Neural Networks
Paper 7  Title: Programming Environment for a High Performance Parallel Supercomputer with Intelligent Communication  
Abstract: At the Electronics Lab of the Swiss Federal Institute of Techology (ETH) in Zurich, the high performance Parallel Supercomputer MUSIC (MUlti processor System with Intelligent Communication) has beed developed. As applications in neural network simulation and molecular dynamics show, the Electronics Lab Supercomputer is absolutely on a par with those of conventional supercomputers, but el
Paper 8  Title: 17 Massively Parallel Genetic Programming  
Abstract: As the field of Genetic Programming (GP) matures and its breadth of application increases, the need for parallel implementations becomes absolutely necessary. The transputer-based system presented in the chapter by Koza and Andre ([11]) is one of the rare such parallel implementations. Until today, no implementation has been proposed for parallel GP using a SIMD architecture, except for 
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 732...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: In this paper we study learning in the PAC model of Valiant [18] in which the example oracle used for learning may be faulty in one of two ways: either by misclassifying the example or by distorting the distribution of examples. We first consider models in which examples are misclassified. Kearns [12] recently showed that efficient learning in a new model using statistical queries is a sufficient condition for PAC learning with classification noise. We show that efficient learning with statistical queries is sufficient for learning in the PAC model with malicious error rate proportional to the required statistical query accuracy. One application of this result is a new lower bound for tolerable malicious error in learning monomials of k literals. This is the first such bound which is independent of the number of irrelevant attributes n. We also use the statistical query model to give sufficient conditions for using distribution specific algorithms on distributions outside their prescribed domains. A corollary of this result expands the class of distributions on which we can weakly learn monotone Boolean formulae. We also consider new models of learning in which examples are not chosen according to the distribution on which the learner will be tested. We examine three variations of distribution noise and give necessary and sufficient conditions for polynomial time learning with such noise. We show containments and separations between the various models of faulty oracles. Finally, we examine hypothesis boosting algorithms in the context of learning with distribution noise, and show that Schapire's result regarding the strength of weak learnabil-ity [17] is in some sense tight in requiring the weak learner to be nearly distribution free. 
Title: Title: Statistical Queries and Faulty PAC Oracles  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: On Learning from Noisy and Incomplete Examples  
Abstract: We investigate learnability in the PAC model when the data used for learning, attributes and labels, is either corrupted or incomplete. In order to prove our main results, we define a new complexity measure on statistical query (SQ) learning algorithms. The view of an SQ algorithm is the maximum over all queries in the algorithm, of the number of input bits on which the query depends. We
Label: Theory
Paper 3  Title: Improved Noise-Tolerant Learning and Generalized Statistical Queries  
Abstract: The statistical query learning model can be viewed as a tool for creating (or demonstrating the existence of) noise-tolerant learning algorithms in the PAC model. The complexity of a statistical query algorithm, in conjunction with the complexity of simulating SQ algorithms in the PAC model with noise, determine the complexity of the noise-tolerant PAC algorithms produced. Although rough
Paper 4  Title: General Bounds on Statistical Query Learning and PAC Learning with Noise via Hypothesis Boosting  
Abstract: We derive general bounds on the complexity of learning in the Statistical Query model and in the PAC model with classification noise. We do so by considering the problem of boosting the accuracy of weak learning algorithms which fall within the Statistical Query model. This new model was introduced by Kearns [12] to provide a general framework for efficient PAC learning in the presence o
Paper 5  Title: Learning Switching Concepts  
Abstract: We consider learning in situations where the function used to classify examples may switch back and forth between a small number of different concepts during the course of learning. We examine several models for such situations: oblivious models in which switches are made independent of the selection of examples, and more adversarial models in which a single adversary controls both the c
Paper 6  Title: Simulating Access to Hidden Information while Learning  
Abstract: We introduce a new technique which enables a learner without access to hidden information to learn nearly as well as a learner with access to hidden information. We apply our technique to solve an open problem of Maass and Turan [18], showing that for any concept class F , the least number of queries sufficient for learning F by an algorithm which has access only to arbitrary equivalence
Paper 7  Title: 25 Learning in Hybrid Noise Environments Using Statistical Queries  
Abstract: We consider formal models of learning from noisy data. Specifically, we focus on learning in the probability approximately correct model as defined by Valiant. Two of the most widely studied models of noise in this setting have been classification noise and malicious errors. However, a more realistic model combining the two types of noise has not been formalized. We define a learning env
Paper 8  Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  
Abstract: We present an algorithm for improving the accuracy of algorithms for learning binary concepts. The improvement is achieved by combining a large number of hypotheses, each of which is generated by training the given learning algorithm on a different set of examples. Our algorithm is based on ideas presented by Schapire in his paper "The strength of weak learnability", and represents an im
Label: Theory
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 837...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: When designing a (deductive) database, the designer has to decide for each predicate (or relation) whether it should be defined extensionally or intensionally, and what the definition should look like. An intelligent system is presented to assist the designer in this task. It starts from an example database in which all predicates are defined extensionally. It then tries to compact the database by transforming extensionally defined predicates into intensionally defined ones. The intelligent system employs techniques from the area of inductive logic programming. 
Title: Title: Inductive Database Design  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Applications of a logical discovery engine  
Abstract: The clausal discovery engine claudien is presented. claudien discovers regularities in data and is a representative of the inductive logic programming paradigm. As such, it represents data and regularities by means of first order clausal theories. Because the search space of clausal theories is larger than that of attribute value representation, claudien also accepts as input a declarati
Label: Rule Learning
Paper 3  Title: Constructing Intermediate Concepts by Decomposition of Real Functions  
Abstract: In learning from examples it is often useful to expand an attribute-vector representation by intermediate concepts. The usual advantage of such structuring of the learning problem is that it makes the learning easier and improves the comprehensibility of induced descriptions. In this paper, we develop a technique for discovering useful intermediate concepts when both the class and the at
Paper 4  Title: FONN: Combining First Order Logic with Connectionist Learning  
Abstract: This paper presents a neural network architecture that can manage structured data and refine knowledge bases expressed in a first order logic language. The presented framework is well suited to classification problems in which concept de scriptions depend upon numerical features of the data. In fact, the main goal of the neural architecture is that of refining the numerical part of the k
Paper 5  Title: Inductive Constraint Logic and the Mutagenesis Problem  
Abstract: A novel approach to learning first order logic formulae from positive and negative examples is incorporated in a system named ICL (Inductive Constraint Logic). In ICL, examples are viewed as interpretations which are true or false for the target theory, whereas in present inductive logic programming systems, examples are true and false ground facts (or clauses). Furthermore, ICL uses a c
Paper 6  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 7  Title: Rule Generation and Compaction in the wwtp  
Abstract: In this paper we discuss our approach to learning classification rules from data. We sketch out two modules of our architecture, namely LINNEO + and GAR. LINNEO + , which is a knowledge acquisition tool for ill-structured domains automatically generating classes from examples that incrementally works with an unsupervised strategy. LINNEO + 's output, a representation of the conceptual st
Paper 8  Title: Multi-Strategy Learning and Theory Revision  
Abstract: This paper presents the system WHY, which learns and updates a diagnostic knowledge base using domain knowledge and a set of examples. The a-priori knowledge consists of a causal model of the domain, stating the relationships among basic phenomena, and a body of phenomenological theory, describing the links between abstract concepts and their possible manifestations in the world. The phe
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 103...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Reinforcement learning (RL) is a model-free tuning and adaptation method for control of dynamic systems. Contrary to supervised learning, based usually on gradient descent techniques, RL does not require any model or sensitivity function of the process. Hence, RL can be applied to systems that are poorly understood, uncertain, nonlinear or for other reasons untractable with conventional methods. In reinforcement learning, the overall controller performance is evaluated by a scalar measure, called reinforcement. Depending on the type of the control task, reinforcement may represent an evaluation of the most recent control action or, more often, of an entire sequence of past control moves. In the latter case, the RL system learns how to predict the outcome of each individual control action. This prediction is then used to adjust the parameters of the controller. The mathematical background of RL is closely related to optimal control and dynamic programming. This paper gives a comprehensive overview of the RL methods and presents an application to the attitude control of a satellite. Some well known applications from the literature are reviewed as well. 
Title: Title: NEUROCONTROL BY REINFORCEMENT LEARNING  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Modeling the Student with Reinforcement Learning  
Abstract: We describe a methodology for enabling an intelligent teaching system to make high level strategy decisions on the basis of low level student modeling information. This framework is less costly to construct, and superior to hand coding teaching strategies as it is more responsive to the learner's needs. In order to accomplish this, reinforcement learning is used to learn to associate sup
Paper 3  Title: AVERAGED REWARD REINFORCEMENT LEARNING APPLIED TO FUZZY RULE TUNING  
Abstract: Fuzzy rules for control can be effectively tuned via reinforcement learning. Reinforcement learning is a weak learning method, which only requires information on the success or failure of the control application. The tuning process allows people to generate fuzzy rules which are unable to accurately perform control and have them tuned to be rules which provide smooth control. This paper 
Paper 4  Title: INCREMENTAL POLYNOMIAL CONTROLLER NETWORKS: two self-organising non-linear controllers  
Abstract: Temporal difference (TD) methods constitute a class of methods for learning predictions in multi-step prediction problems, parameterized by a recency factor . Currently the most important application of these methods is to temporal credit assignment in reinforcement learning. Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learnin
Label: Neural Networks
Paper 5  Title: Automatic Generation of Adaptive Programs Automatic Generation of Adaptive Programs. In From Animals to Animats
Abstract: Fuzzy rules for control can be effectively tuned via reinforcement learning. Reinforcement learning is a weak learning method, which only requires information on the success or failure of the control application. The tuning process allows people to generate fuzzy rules which are unable to accurately perform control and have them tuned to be rules which provide smooth control. This paper 
Paper 6  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract: In the field of Operation Research and Artificial Intelligence, several stochastic search algorithms have been designed based on the theory of global random search (Zhigljavsky 1991). Basically, those techniques iteratively sample the search space with respect to a probability distribution which is updated according to the result of previous samples and some predefined strategy. Genetic 
Paper 7  Title: Toward Learning Systems That Integrate Different Strategies and Representations TR93-22  
Abstract: Temporal difference (TD) methods constitute a class of methods for learning predictions in multi-step prediction problems, parameterized by a recency factor . Currently the most important application of these methods is to temporal credit assignment in reinforcement learning. Well known reinforcement learning algorithms, such as AHC or Q-learning, may be viewed as instances of TD learnin
Paper 8  Title: Category: Control, Navigation and Planning Preference: Oral presentation Exploiting Model Uncertainty Estimates for Safe Dynamic
Abstract: Model learning combined with dynamic programming has been shown to be effective for learning control of continuous state dynamic systems. The simplest method assumes the learned model is correct and applies dynamic programming to it, but many approximators provide uncertainty estimates on the fit. How can they be exploited? This paper addresses the case where the system must be prevented
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 1257...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Holland's Schema Theorem is widely taken to be the foundation for explanations of the power of genetic algorithms (GAs). Yet some dissent has been expressed as to its implications. Here, dissenting arguments are reviewed and elaborated upon, explaining why the Schema Theorem has no implications for how well a GA is performing. Interpretations of the Schema Theorem have implicitly assumed that a correlation exists between parent and offspring fitnesses, and this assumption is made explicit in results based on Price's Covariance and Selection Theorem. Schemata do not play a part in the performance theorems derived for representations and operators in general. However, schemata re-emerge when recombination operators are used. Using Geiringer's recombination distribution representation of recombination operators, a "missing" schema theorem is derived which makes explicit the intuition for when a GA should perform well. Finally, the method of "adaptive landscape" analysis is examined and counterexamples offered to the commonly used correlation statistic. Instead, an alternative statistic | the transmission function in the fitness domain | is proposed as the optimal statistic for estimating GA performance from limited samples.
Title: Title: The Schema Theorem and Price's Theorem  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The Troubling Aspects of a Building Block Hypothesis for Genetic Programming  
Abstract: In this paper we carefully formulate a Schema Theorem for Genetic Programming (GP) using a schema definition that accounts for the variable length and the non-homologous nature of GP's representation. In a manner similar to early GA research, we use interpretations of our GP Schema Theorem to obtain a GP Building Block definition and to state a "classical" Building Block Hypothesis (BBH)
Paper 3  Title: The Role of Development in Genetic Algorithms  
Abstract: Technical Report Number CS94-394 Computer Science and Engineering, U.C.S.D. Abstract The developmental mechanisms transforming genotypic to phenotypic forms are typically omitted in formulations of genetic algorithms (GAs) in which these two representational spaces are identical. We argue that a careful analysis of developmental mechanisms is useful when understanding the success of seve
Paper 4  Title: Submitted to Circuits, Systems and Signal Processing Neural Network Constructive Algorithms: Trading Generalization for Learning Efficiency?  
Abstract: There are currently several types of constructive, or growth, algorithms available for training a feed-forward neural network. This paper describes and explains the main ones, using a fundamental approach to the multi-layer perceptron problem-solving mechanisms. The claimed convergence properties of the algorithms are verified using just two mapping theorems, which consequently enables a
Paper 5  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Label: Genetic Algorithms
Paper 6  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract: Several evolutionary algorithms make use of hierarchical representations of variable size rather than linear strings of fixed length. Variable complexity of the structures provides an additional representational power which may widen the application domain of evolutionary algorithms. The price for this is, however, that the search space is open-ended and solutions may grow to arbitrarily
Paper 7  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract: In the field of Operation Research and Artificial Intelligence, several stochastic search algorithms have been designed based on the theory of global random search (Zhigljavsky 1991). Basically, those techniques iteratively sample the search space with respect to a probability distribution which is updated according to the result of previous samples and some predefined strategy. Genetic 
Paper 8  Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Abstract: Holland's analysis of the sources of power of genetic algorithms has served as guidance for the applications of genetic algorithms for more than 15 years. The technique of applying a recombination operator (crossover) to a population of individuals is a key to that power. Neverless, there have been a number of contradictory results concerning crossover operators with respect to overall p
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1147...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We propose a methodology for Bayesian model determination in decomposable graphical Gaussian models. To achieve this aim we consider a hyper inverse Wishart prior distribution on the concentration matrix for each given graph. To ensure compatibility across models, such prior distributions are obtained by marginalisation from the prior conditional on the complete graph. We explore alternative structures for the hyperparameters of the latter, and their consequences for the model. Model determination is carried out by implementing a reversible jump MCMC sampler. In particular, the dimension-changing move we propose involves adding or dropping an edge from the graph. We characterise the set of moves which preserve the decomposability of the graph, giving a fast algorithm for maintaining the junction tree representation of the graph at each sweep. As state variable, we propose to use the incomplete variance-covariance matrix, containing only the elements for which the corresponding element of the inverse is nonzero. This allows all computations to be performed locally, at the clique level, which is a clear advantage for the analysis of large and complex data-sets. Finally, the statistical and computational performance of the procedure is illustrated by means of both artificial and real multidimensional data-sets. 
Title: Title: Decomposable graphical Gaussian model determination  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: On MCMC Sampling in Hierarchical Longitudinal Models  SUMMARY  
Abstract: Markov chain Monte Carlo (MCMC) algorithms have revolutionized Bayesian practice. In their simplest form (i.e., when parameters are updated one at a time) they are, however, often slow to converge when applied to high-dimensional statistical models. A remedy for this problem is to block the parameters into groups, which are then updated simultaneously using either a Gibbs or Metropolis-H
Paper 3  Title: Reparameterisation Issues in Mixture Modelling and their bearing on MCMC algorithms  
Abstract: There is increasing need for efficient estimation of mixture distributions, especially following the explosion in the use of these as modelling tools in many applied fields. We propose in this paper a Bayesian noninformative approach for the estimation of normal mixtures which relies on a reparameterisation of the secondary components of the mixture in terms of divergence from the main c
Paper 4  Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  
Abstract: New methodology for fully Bayesian mixture analysis is developed, making use of reversible jump Markov chain Monte Carlo methods, that are capable of jumping between the parameter subspaces corresponding to different numbers of components in the mixture. A sample from the full joint distribution of all unknown variables is thereby generated, and this can be used as a basis for a thorough
Paper 5  Title: Empirical Entropy Manipulation for Real-World Problems  
Abstract: No finite sample is sufficient to determine the density, and therefore the entropy, of a signal directly. Some assumption about either the functional form of the density or about its smoothness is necessary. Both amount to a prior over the space of possible density functions. By far the most common approach is to assume that the density has a parametric form. By contrast we derive a diff
Paper 6  Title: FROM METROPOLIS TO DIFFUSIONS: GIBBS STATES AND OPTIMAL SCALING  
Abstract: This paper investigates the behaviour of the random walk Metropolis algorithm in high dimensional problems. Here we concentrate on the case where the components in the target density is a spatially homogeneous Gibbs distribution with finite range. The performance of the algorithm is strongly linked to the presence or absence of phase transition for the Gibbs distribution; the convergence
Paper 7  Title: Wavelet Thresholding via a Bayesian Approach  
Abstract: We discuss a Bayesian formalism which gives rise to a type of wavelet threshold estimation in non-parametric regression. A prior distribution is imposed on the wavelet coefficients of the unknown response function, designed to capture the sparseness of wavelet expansion common to most applications. For the prior specified, the posterior median yields a thresholding procedure. Our prior m
Label: Probabilistic Methods
Paper 8  Title: Bayesian Regression Filters and the Issue of Priors  
Abstract: We propose a Bayesian framework for regression problems, which covers areas which are usually dealt with by function approximation. An online learning algorithm is derived which solves regression problems with a Kalman filter. Its solution always improves with increasing model complexity, without the risk of over-fitting. In the infinite dimension limit it approaches the true Bayesian po
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Accuracy: 0.78
Wrong indexes: [1759, 474, 2470, 1021, 955, 2648, 1020, 975, 1853, 2652, 1519, 469, 2686, 417, 1827, 1534, 487, 928, 1238, 1, 2534, 537]
Wrong list: [2, 5, 16, 30, 31, 35, 43, 44, 50, 54, 59, 62, 63, 64, 67, 68, 70, 71, 72, 84, 86, 90]
Wrong indexes length: 22
