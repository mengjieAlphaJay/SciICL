experName ....  24.4.17-2100-sciemd-size_5-test
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /allenai/scibert_scivocab_uncased/resolve/main/1_Pooling/config.json (Caused by ProxyError('Cannot connect to proxy.', TimeoutError('_ssl.c:980: The handshake operation timed out')))"), '(Request ID: 78b801fe-b031-4f6b-9d59-022d19de3458)')
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
experName ....  24.4.17-2100-sciemd-size_5-test
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
An error occurred at index 0: name 'sc' is not defined
Retrying in 0.2 seconds...
Processing index 1794...
experName ....  24.4.17-2100-sciemd-size_5-test
Processing index 1794...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: NONLINEAR NONEQUILIBRIUM NONQUANTUM NONCHAOTIC STATISTICAL MECHANICS OF NEOCORTICAL INTERACTIONS  
Abstract: Abstract: The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exists an interdisciplinary multidimensional gradation on published studies of neocortex, with one primary dimension of mathematical physics represented by two extremes. At one extreme, there is much scientifically unsupported talk of chaos and quantum physics being responsible for many important macroscopic neocortical processes (involving many thousands to millions of neurons) (Wilczek, 1994). At another extreme, many non-mathematically trained neuroscientists uncritically lump all neocortical mathematical theory into one file, and consider only statistical averages of citations for opinions on the quality of that research (Nunez, 1995). In this context, it is important to appreciate that Wright and Liley (W&L) report on their scientifically sound studies on macroscopic neocortical function, based on simulation and a blend of sound theory and reproducible experiments. However, their pioneering work, given the absence of much knowledge of neocortex at this time, is open to criticism, especially with respect to their present inferences and conclusions. Their conclusion that EEG data exhibit linear near-equilibrium dynamics may very well be true, but only in the sense of focusing only on one local minima, possibly with individual-specific and physiological-state dependent 
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 3:  <Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of.   Abstract:  The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exis>
Label: Neural Networks
Paper 4:  <Title: Replicability of Neural Computing Experiments  .   Abstract:  If an experiment requires statistical analysis to establish a result, then one should do a better experiment. Ernest Rutherford, 1930 Most proponents of cold fusion reporting excess heat from their electrolysis experiments were claiming that one of the main characteristics of cold fusion was its irreproducibility | J.R. Huizenga, Cold Fusion, 1993, p. 78 Abstract Amid the ever increasing>
Label: Neural Networks
Paper 6:  <Title: Statistical mechanics of neocortical interactions: Training and testing canonical momenta indicators of EEG  .   Abstract:  A series of papers has developed a statistical mechanics of neocortical interactions (SMNI), deriving aggregate behavior of experimentally observed columns of neurons from statistical electrical-chemical properties of synaptic interactions. While not useful to yield insights at the single neuron level, SMNI has demonstrated its capability in describing large-scale properties of short-ter>
Label: Neural Networks
Paper 2:  <Title: Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems  .   Abstract:  The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exis>
Paper 5:  <Title: MULTIPLE SCALES OF BRAIN-MIND INTERACTIONS  .   Abstract:  Posner and Raichle's Images of Mind is an excellent educational book and very well written. Some aws as a scientific publication are: (a) the accuracy of the linear subtraction method used in PET is subject to scrutiny by further research at finer spatial-temporal resolutions; (b) lack of accuracy of the experimental paradigm used for EEG complementary studies. Images (Posner & Raichle, >
Paper 7:  <Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  .   Abstract:  Neural computation, also called connectionism, parallel distributed processing, neural network modeling or brain-style computation, has grown rapidly in the last decade. Despite this explosion, and ultimately because of impressive applications, there has been a dire need for a concise introduction from a theoretical perspective, analyzing the strengths and weaknesses of connectionist app>
Paper 8:  <Title: Studies of Neurological Transmission Analysis using Hierarchical Bayesian Mixture Models  .   Abstract:  Hierarchically structured mixture models are studied in the context of data analysis and inference on neural synaptic transmission characteristics in mammalian, and other, central nervous systems. Mixture structures arise due to uncertainties about the stochastic mechanisms governing the responses to electro-chemical stimulation of individual neuro-transmitter release sites at nerve junc>
Paper 9:  <Title: Coevolving Communicative Behavior in a Linear Pursuer-Evader Game  .   Abstract:  The pursuer-evader (PE) game is recognized as an important domain in which to study the coevolution of robust adaptive behavior and protean behavior (Miller and Cliff, 1994). Nevertheless, the potential of the game is largely unrealized due to methodological hurdles in coevolutionary simulation raised by PE; versions of the game that have optimal solutions (Isaacs, 1965) are closed-ended>
Paper 10:  <Title: A Brief History of Connectionism  .   Abstract:  Connectionist research is firmly established within the scientific community, especially within the multi-disciplinary field of cognitive science. This diversity, however, has created an environment which makes it difficult for connectionist researchers to remain aware of recent advances in the field, let alone understand how the field has developed. This paper attempts to address this p>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 455...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Learning from an Automated Training Agent  
Abstract: Abstract: A learning agent employing reinforcement learning is hindered because it only receives the critic's sparse and weakly informative training information. We present an approach in which an automated training agent may also provide occasional instruction to the learner in the form of actions for the learner to perform. The learner has access to both the critic's feedback and the trainer's instruction. In the experiments, we vary the level of the trainer's interaction with the learner, from allowing the trainer to instruct the learner at almost every time step, to not allowing the trainer to respond at all. We also vary a parameter that controls how the learner incorporates the trainer's actions. The results show significant reductions in the average number of training trials necessary to learn to perform the task.
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 7:  <Title: Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email  .   Abstract:  This paper describes a novel method by which a dialogue agent can learn to choose an optimal dialogue strategy. While it is widely agreed that dialogue strategies should be formulated in terms of communicative intentions, there has been little work on automatically optimizing an agent's choices when there are multiple ways to realize a communicative intention. Our method is based on a co>
Label: Reinforcement Learning
Paper 2:  <Title: An Introspection Approach to Querying a Trainer  .   Abstract:  Technical Report 96-13 January 22, 1996 Abstract This paper introduces the Introspection Approach, a method by which a learning agent employing reinforcement learning can decide when to ask a training agent for instruction. When using our approach, we find that the same number of trainer's responses produced significantly faster learners than by having the learner ask for aid randomly. G>
Paper 3:  <Title: Modeling the Student with Reinforcement Learning  .   Abstract:  We describe a methodology for enabling an intelligent teaching system to make high level strategy decisions on the basis of low level student modeling information. This framework is less costly to construct, and superior to hand coding teaching strategies as it is more responsive to the learner's needs. In order to accomplish this, reinforcement learning is used to learn to associate sup>
Paper 4:  <Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  .   Abstract:  The application of decision making and learning algorithms to multi-agent systems presents many interestingresearch challenges and opportunities. Among these is the ability for agents to learn how to act by observing or imitating other agents. We describe an algorithm, the IQ-algorithm, that integrates imitation with Q-learning. Roughly, a Q-learner uses the observations it has made of a>
Paper 5:  <Title: Machine Learning,  Creating Advice-Taking Reinforcement Learners  .   Abstract:  Learning from reinforcements is a promising approach for creating intelligent agents. However, reinforcement learning usually requires a large number of training episodes. We present and evaluate a design that addresses this shortcoming by allowing a connectionist Q-learner to accept advice given, at any time and in a natural manner, by an external observer. In our approach, the advice-g>
Paper 6:  <Title: Improving Generalization with Active Learning  .   Abstract:  Active learning differs from passive "learning from examples" in that the learning algorithm assumes at least some control over what part of the input domain it receives information about. In some situations, active learning is provably more powerful that learning from examples alone, giving better generalization for a fixed number of training examples. In this paper, we consider the pro>
Paper 8:  <Title: Learning to Predict User Operations for Adaptive Scheduling  .   Abstract:  Mixed-initiative systems present the challenge of finding an effective level of interaction between humans and computers. Machine learning presents a promising approach to this problem in the form of systems that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive assistant for crisis sched>
Paper 9:  <Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  .   Abstract:  Mixed-initiative systems present the challenge of finding an effective level of interaction between humans and computers. Machine learning presents a promising approach to this problem in the form of systems that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive assistant for crisis sched>
Paper 10:  <Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,.   Abstract:  We have recently introduced a neural network mobile robot controller (NETMORC) that autonomously learns the forward and inverse odometry of a differential drive robot through an unsupervised learning-by-doing cycle. After an initial learning phase, the controller can move the robot to an arbitrary stationary or moving target while compensating for noise and other forms of disturbance, su>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Label: Reinforcement Learning
Prediction:  Label: Reinforcement Learning
Is prediction correct?  False

Prediction: 0
Processing index 1759...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Belief Maintenance in Bayesian Networks  
Abstract: Abstract: Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these features a reduced ring representation (RRR) of the local environment is derived. As the robot navigates, it learns the RRR signatures of all the new environment types it encounters. For purpose of identification, a ring matching criteria is proposed where the robot tries to match the RRR from the sensory input to one of the RRRs in its library. The second issue addressed is that of learning hill climbing control laws in the local environments. Unlike conventional neuro-controllers, a reinforcement learning framework, where the robot first learns a model of the environment and then learns the control law in terms of a neural network is proposed here. The reinforcement function is generated from the sensory inputs of the robot before and after a control action is taken. Three key results shown in this work are that (1) The robot is able to build its library of RRR signatures perfectly even with significant sensor noise for eight different local environ-mets, (2) It was able to identify its local environment with an accuracy of more than 96%, once the library is build, and (3) the robot was able to learn adequate hill climbing control laws which take it to the distinctive state of the local environment for five different environment types.
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 5:  <Title: Exploration and Model Building in Mobile Robot Domains  .   Abstract:  I present first results on COLUMBUS, an autonomous mobile robot. COLUMBUS operates in initially unknown, structured environments. Its task is to explore and model the environment efficiently while avoiding collisions with obstacles. COLUMBUS uses an instance-based learning technique for modeling its environment. Real-world experiences are generalized via two artificial neural networks th>
Label: Reinforcement Learning
Paper 10:  <Title: Incremental Class Learning approach and its application to Handwritten Digit Recognition  .   Abstract:  Incremental Class Learning (ICL) provides a feasible framework for the development of scalable learning systems. Instead of learning a complex problem at once, ICL focuses on learning subproblems incrementally, one at a time | using the results of prior learning for subsequent learning | and then combining the solutions in an appropriate manner. With respect to multi-class classification>
Label: Neural Networks
Paper 2:  <Title: Simultaneous Learning of Control Laws and Local Environment Representations for Intelligent Navigation Robots  .   Abstract:  Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these fe>
Paper 3:  <Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,.   Abstract:  We have recently introduced a neural network mobile robot controller (NETMORC) that autonomously learns the forward and inverse odometry of a differential drive robot through an unsupervised learning-by-doing cycle. After an initial learning phase, the controller can move the robot to an arbitrary stationary or moving target while compensating for noise and other forms of disturbance, su>
Paper 4:  <Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  .   Abstract:  This paper demonstrates the exploitation of certain vision processing techniques to index into a case base of surfaces. The surfaces are the result of reinforcement learning and represent the optimum choice of actions to achieve some goal from anywhere in the state space. This paper shows how strong features that occur in the interaction of the system with its environment can be detected>
Paper 6:  <Title: A Modular Q-Learning Architecture for Manipulator Task Decomposition `Data storage in the cerebellar model ar.   Abstract:  Compositional Q-Learning (CQ-L) (Singh 1992) is a modular approach to learning to perform composite tasks made up of several elemental tasks by reinforcement learning. Skills acquired while performing elemental tasks are also applied to solve composite tasks. Individual skills compete for the right to act and only winning skills are included in the decomposition of the composite task. We>
Paper 7:  <Title: A Simulation of Adaptive Agents in a Hostile Environment  .   Abstract:  In this paper we use the genetic programming technique to evolve programs to control an autonomous agent capable of learning how to survive in a hostile environment. In order to facilitate this goal, agents are run through random environment configurations. Randomly generated programs, which control the interaction of the agent with its environment, are recombined to form better programs>
Paper 8:  <Title: Dynamic Automatic Model Selection  .   Abstract:  COINS Technical Report 92-30 February 1992 Abstract The problem of how to learn from examples has been studied throughout the history of machine learning, and many successful learning algorithms have been developed. A problem that has received less attention is how to select which algorithm to use for a given learning task. The ability of a chosen algorithm to induce a good generalizatio>
Paper 9:  <Title: Robot Shaping: Developing Situated Agents through Learning  .   Abstract:  Learning plays a vital role in the development of situated agents. In this paper, we explore the use of reinforcement learning to "shape" a robot to perform a predefined target behavior. We connect both simulated and real robots to A LECSYS, a parallel implementation of a learning classifier system with an extended genetic algorithm. After classifying different kinds of Animat-like behav>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

An error occurred at index 2: Expecting value: line 1 column 1 (char 0)
Retrying in 0.2 seconds...
Processing index 1759...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Belief Maintenance in Bayesian Networks  
Abstract: Abstract: Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these features a reduced ring representation (RRR) of the local environment is derived. As the robot navigates, it learns the RRR signatures of all the new environment types it encounters. For purpose of identification, a ring matching criteria is proposed where the robot tries to match the RRR from the sensory input to one of the RRRs in its library. The second issue addressed is that of learning hill climbing control laws in the local environments. Unlike conventional neuro-controllers, a reinforcement learning framework, where the robot first learns a model of the environment and then learns the control law in terms of a neural network is proposed here. The reinforcement function is generated from the sensory inputs of the robot before and after a control action is taken. Three key results shown in this work are that (1) The robot is able to build its library of RRR signatures perfectly even with significant sensor noise for eight different local environ-mets, (2) It was able to identify its local environment with an accuracy of more than 96%, once the library is build, and (3) the robot was able to learn adequate hill climbing control laws which take it to the distinctive state of the local environment for five different environment types.
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 5:  <Title: Exploration and Model Building in Mobile Robot Domains  .   Abstract:  I present first results on COLUMBUS, an autonomous mobile robot. COLUMBUS operates in initially unknown, structured environments. Its task is to explore and model the environment efficiently while avoiding collisions with obstacles. COLUMBUS uses an instance-based learning technique for modeling its environment. Real-world experiences are generalized via two artificial neural networks th>
Label: Reinforcement Learning
Paper 10:  <Title: Incremental Class Learning approach and its application to Handwritten Digit Recognition  .   Abstract:  Incremental Class Learning (ICL) provides a feasible framework for the development of scalable learning systems. Instead of learning a complex problem at once, ICL focuses on learning subproblems incrementally, one at a time | using the results of prior learning for subsequent learning | and then combining the solutions in an appropriate manner. With respect to multi-class classification>
Label: Neural Networks
Paper 2:  <Title: Simultaneous Learning of Control Laws and Local Environment Representations for Intelligent Navigation Robots  .   Abstract:  Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these fe>
Paper 3:  <Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,.   Abstract:  We have recently introduced a neural network mobile robot controller (NETMORC) that autonomously learns the forward and inverse odometry of a differential drive robot through an unsupervised learning-by-doing cycle. After an initial learning phase, the controller can move the robot to an arbitrary stationary or moving target while compensating for noise and other forms of disturbance, su>
Paper 4:  <Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  .   Abstract:  This paper demonstrates the exploitation of certain vision processing techniques to index into a case base of surfaces. The surfaces are the result of reinforcement learning and represent the optimum choice of actions to achieve some goal from anywhere in the state space. This paper shows how strong features that occur in the interaction of the system with its environment can be detected>
Paper 6:  <Title: A Modular Q-Learning Architecture for Manipulator Task Decomposition `Data storage in the cerebellar model ar.   Abstract:  Compositional Q-Learning (CQ-L) (Singh 1992) is a modular approach to learning to perform composite tasks made up of several elemental tasks by reinforcement learning. Skills acquired while performing elemental tasks are also applied to solve composite tasks. Individual skills compete for the right to act and only winning skills are included in the decomposition of the composite task. We>
Paper 7:  <Title: A Simulation of Adaptive Agents in a Hostile Environment  .   Abstract:  In this paper we use the genetic programming technique to evolve programs to control an autonomous agent capable of learning how to survive in a hostile environment. In order to facilitate this goal, agents are run through random environment configurations. Randomly generated programs, which control the interaction of the agent with its environment, are recombined to form better programs>
Paper 8:  <Title: Dynamic Automatic Model Selection  .   Abstract:  COINS Technical Report 92-30 February 1992 Abstract The problem of how to learn from examples has been studied throughout the history of machine learning, and many successful learning algorithms have been developed. A problem that has received less attention is how to select which algorithm to use for a given learning task. The ability of a chosen algorithm to induce a good generalizatio>
Paper 9:  <Title: Robot Shaping: Developing Situated Agents through Learning  .   Abstract:  Learning plays a vital role in the development of situated agents. In this paper, we explore the use of reinforcement learning to "shape" a robot to perform a predefined target behavior. We connect both simulated and real robots to A LECSYS, a parallel implementation of a learning classifier system with an extended genetic algorithm. After classifying different kinds of Animat-like behav>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

An error occurred at index 2: Expecting value: line 1 column 1 (char 0)
Retrying in 0.2 seconds...
Processing index 1759...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Belief Maintenance in Bayesian Networks  
Abstract: Abstract: Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these features a reduced ring representation (RRR) of the local environment is derived. As the robot navigates, it learns the RRR signatures of all the new environment types it encounters. For purpose of identification, a ring matching criteria is proposed where the robot tries to match the RRR from the sensory input to one of the RRRs in its library. The second issue addressed is that of learning hill climbing control laws in the local environments. Unlike conventional neuro-controllers, a reinforcement learning framework, where the robot first learns a model of the environment and then learns the control law in terms of a neural network is proposed here. The reinforcement function is generated from the sensory inputs of the robot before and after a control action is taken. Three key results shown in this work are that (1) The robot is able to build its library of RRR signatures perfectly even with significant sensor noise for eight different local environ-mets, (2) It was able to identify its local environment with an accuracy of more than 96%, once the library is build, and (3) the robot was able to learn adequate hill climbing control laws which take it to the distinctive state of the local environment for five different environment types.
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 5:  <Title: Exploration and Model Building in Mobile Robot Domains  .   Abstract:  I present first results on COLUMBUS, an autonomous mobile robot. COLUMBUS operates in initially unknown, structured environments. Its task is to explore and model the environment efficiently while avoiding collisions with obstacles. COLUMBUS uses an instance-based learning technique for modeling its environment. Real-world experiences are generalized via two artificial neural networks th>
Label: Reinforcement Learning
Paper 10:  <Title: Incremental Class Learning approach and its application to Handwritten Digit Recognition  .   Abstract:  Incremental Class Learning (ICL) provides a feasible framework for the development of scalable learning systems. Instead of learning a complex problem at once, ICL focuses on learning subproblems incrementally, one at a time | using the results of prior learning for subsequent learning | and then combining the solutions in an appropriate manner. With respect to multi-class classification>
Label: Neural Networks
Paper 2:  <Title: Simultaneous Learning of Control Laws and Local Environment Representations for Intelligent Navigation Robots  .   Abstract:  Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these fe>
Paper 3:  <Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,.   Abstract:  We have recently introduced a neural network mobile robot controller (NETMORC) that autonomously learns the forward and inverse odometry of a differential drive robot through an unsupervised learning-by-doing cycle. After an initial learning phase, the controller can move the robot to an arbitrary stationary or moving target while compensating for noise and other forms of disturbance, su>
Paper 4:  <Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  .   Abstract:  This paper demonstrates the exploitation of certain vision processing techniques to index into a case base of surfaces. The surfaces are the result of reinforcement learning and represent the optimum choice of actions to achieve some goal from anywhere in the state space. This paper shows how strong features that occur in the interaction of the system with its environment can be detected>
Paper 6:  <Title: A Modular Q-Learning Architecture for Manipulator Task Decomposition `Data storage in the cerebellar model ar.   Abstract:  Compositional Q-Learning (CQ-L) (Singh 1992) is a modular approach to learning to perform composite tasks made up of several elemental tasks by reinforcement learning. Skills acquired while performing elemental tasks are also applied to solve composite tasks. Individual skills compete for the right to act and only winning skills are included in the decomposition of the composite task. We>
Paper 7:  <Title: A Simulation of Adaptive Agents in a Hostile Environment  .   Abstract:  In this paper we use the genetic programming technique to evolve programs to control an autonomous agent capable of learning how to survive in a hostile environment. In order to facilitate this goal, agents are run through random environment configurations. Randomly generated programs, which control the interaction of the agent with its environment, are recombined to form better programs>
Paper 8:  <Title: Dynamic Automatic Model Selection  .   Abstract:  COINS Technical Report 92-30 February 1992 Abstract The problem of how to learn from examples has been studied throughout the history of machine learning, and many successful learning algorithms have been developed. A problem that has received less attention is how to select which algorithm to use for a given learning task. The ability of a chosen algorithm to induce a good generalizatio>
Paper 9:  <Title: Robot Shaping: Developing Situated Agents through Learning  .   Abstract:  Learning plays a vital role in the development of situated agents. In this paper, we explore the use of reinforcement learning to "shape" a robot to perform a predefined target behavior. We connect both simulated and real robots to A LECSYS, a parallel implementation of a learning classifier system with an extended genetic algorithm. After classifying different kinds of Animat-like behav>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  False

Prediction: 0
Processing index 512...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Fault-Tolerant Implementation of Finite-State Automata in Recurrent Neural Networks  
Abstract: Abstract: Recently, we have proven that the dynamics of any deterministic finite-state automata (DFA) with n states and m input symbols can be implemented in a sparse second-order recurrent neural network (SORNN) with n + 1 state neurons and O(mn) second-order weights and sigmoidal discriminant functions [5]. We investigate how that constructive algorithm can be extended to fault-tolerant neural DFA implementations where faults in an analog implementation of neurons or weights do not affect the desired network performance. We show that tolerance to weight perturbation can be achieved easily; tolerance to weight and/or neuron stuck-at-zero faults, however, requires duplication of the network resources. This result has an impact on the construction of neural DFAs with a dense internal representation of DFA states.
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2:  <Title: Constructing Deterministic Finite-State Automata in Recurrent Neural Networks  .   Abstract:  Recurrent neural networks that are trained to behave like deterministic finite-state automata (DFAs) can show deteriorating performance when tested on long strings. This deteriorating performance can be attributed to the instability of the internal representation of the learned DFA states. The use of a sigmoidal discriminant function together with the recurrent structure contribute to th>
Label: Neural Networks
Paper 4:  <Title: Constructive Learning of Recurrent Neural Networks: Limitations of Recurrent Casade Correlation and a Simple Solution  .   Abstract:  It is often difficult to predict the optimal neural network size for a particular application. Constructive or destructive methods that add or subtract neurons, layers, connections, etc. might offer a solution to this problem. We prove that one method, Recurrent Cascade Correlation, due to its topology, has fundamental limitations in representation and thus in its learning capabilities. >
Label: Neural Networks
Paper 10:  <Title: Networks of Spiking Neurons: The Third Generation of Neural Network Models  .   Abstract:  The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e. threshold gates) respectively sigmoidal gates. In particular it is shown that networks of spiking neurons are computationally more powerful than these other neural network models. A concrete biologically relevant function is >
Label: Neural Networks
Paper 3:  <Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  .   Abstract:  This work describes an approach for inferring Deterministic Context-free (DCF) Grammars in a Connectionist paradigm using a Recurrent Neural Network Pushdown Automaton (NNPDA). The NNPDA consists of a recurrent neural network connected to an external stack memory through a common error function. We show that the NNPDA is able to learn the dynamics of an underlying pushdown automaton from>
Paper 5:  <Title: Even with Arbitrary Transfer Functions, RCC Cannot Compute Certain FSA  .   Abstract:  Category: algorithms and architectures | recurrent networks. No part of this paper has been submitted elsewhere. Preference: poster. Abstract Existing proofs demonstrating the computational limitations of the Recurrent Cascade Correlation (RCC) Network (Fahlman, 1991) explicitly limit their results to units having sigmoidal or hard-threshold transfer functions (Giles et al., 1995; and Kr>
Paper 6:  <Title: An Analytical Framework for Local Feedforward Networks  .   Abstract:  Interference in neural networks occurs when learning in one area of the input space causes unlearning in another area. Networks that are less susceptible to interference are referred to as spatially local networks. To understand these properties, a theoretical framework, consisting of a measure of interference and a measure of network localization, is developed. These measures incorporat>
Paper 7:  <Title: Local Feedforward Networks  .   Abstract:  Although feedforward neural networks are well suited to function approximation, in some applications networks experience problems when learning a desired function. One problem is interference which occurs when learning in one area of the input space causes unlearning in another area. Networks that are less susceptible to interference are referred to as spatially local networks. To unders>
Paper 8:  <Title: Pruning Recurrent Neural Networks for Improved Generalization Performance  .   Abstract:  Determining the architecture of a neural network is an important issue for any learning task. For recurrent neural networks no general methods exist that permit the estimation of the number of layers of hidden neurons, the size of layers or the number of weights. We present a simple pruning heuristic which significantly improves the generalization performance of trained recurrent network>
Paper 9:  <Title: Extraction of Rules from Discrete-Time Recurrent Neural Networks  .   Abstract:  The extraction of symbolic knowledge from trained neural networks and the direct encoding of (partial) knowledge into networks prior to training are important issues. They allow the exchange of information between symbolic and connectionist knowledge representations. The focus of this paper is on the quality of the rules that are extracted from recurrent neural networks. Discrete-time re>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Category: Neural Networks
Prediction:  Category: Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 1191...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms  
Abstract: Abstract: The term "bias" is widely used|and with different meanings|in the fields of machine learning and statistics. This paper clarifies the uses of this term and shows how to measure and visualize the statistical bias and variance of learning algorithms. Statistical bias and variance can be applied to diagnose problems with machine learning bias, and the paper shows four examples of this. Finally, the paper discusses methods of reducing bias and variance. Methods based on voting can reduce variance, and the paper compares Breiman's bagging method and our own tree randomization method for voting decision trees. Both methods uniformly improve performance on data sets from the Irvine repository. Tree randomization yields perfect performance on the Letter Recognition task. A weighted nearest neighbor algorithm based on the infinite bootstrap is also introduced. In general, decision tree algorithms have moderate-to-high variance, so an important implication of this work is that variance|rather than appropriate or inappropriate machine learning bias|is an important cause of poor performance for decision tree algorithms. 
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2:  <Title: An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants  .   Abstract:  Methods for voting classification algorithms, such as Bagging and AdaBoost, have been shown to be very successful in improving the accuracy of certain classifiers for artificial and real-world datasets. We review these algorithms and describe a large empirical study comparing several variants in conjunction with a decision tree inducer (three variants) and a Naive-Bayes inducer. The purp>
Label: Theory
Paper 8:  <Title: Bias and the Quantification of Stability Bias and the Quantification of Stability Bias and the.   Abstract:  Research on bias in machine learning algorithms has generally been concerned with the impact of bias on predictive accuracy. We believe that there are other factors that should also play a role in the evaluation of bias. One such factor is the stability of the algorithm; in other words, the repeatability of the results. If we obtain two sets of data from the same phenomenon, with the sam>
Label: Theory
Paper 10:  <Title: Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods  .   Abstract:  One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect>
Label: Theory
Paper 3:  <Title: BOOSTING AND NAIVE BAYESIAN LEARNING  .   Abstract:  Although so-called naive Bayesian classification makes the unrealistic assumption that the values of the attributes of an example are independent given the class of the example, this learning method is remarkably successful in practice, and no uniformly better learning method is known. Boosting is a general method of combining multiple classifiers due to Yoav Freund and Rob Schapire. Thi>
Paper 4:  <Title: Experiments with a New Boosting Algorithm  .   Abstract:  In an earlier paper, we introduced a new boosting algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that consistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a pseudo-loss which is a method for forcing a learning algorithm of multi-label >
Paper 5:  <Title: Error-Correcting Output Coding Corrects Bias and Variance  .   Abstract:  Previous research has shown that a technique called error-correcting output coding (ECOC) can dramatically improve the classification accuracy of supervised learning algorithms that learn to classify data points into one of k 2 classes. This paper presents an investigation of why the ECOC technique works, particularly when employed with decision-tree learning algorithms. It shows that th>
Paper 6:  <Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  .   Abstract:  In the past, nearest neighbor algorithms for learning from examples have worked best in domains in which all features had numeric values. In such domains, the examples can be treated as points and distance metrics can use standard definitions. In symbolic domains, a more sophisticated treatment of the feature space is required. We introduce a nearest neighbor algorithm for learning in do>
Paper 7:  <Title: Simultaneous Evolution of Programs and their Control Structures Simultaneous Evolution of Programs and their Control.   Abstract:  Previous research has shown that a technique called error-correcting output coding (ECOC) can dramatically improve the classification accuracy of supervised learning algorithms that learn to classify data points into one of k 2 classes. This paper presents an investigation of why the ECOC technique works, particularly when employed with decision-tree learning algorithms. It shows that th>
Paper 9:  <Title: Why Does Bagging Work? A Bayesian Account and its Implications bagging's success, both in a.   Abstract:  The error rate of decision-tree and other classification learners can often be much reduced by bagging: learning multiple models from bootstrap samples of the database, and combining them by uniform voting. In this paper we empirically test two alternative explanations for this, both based on Bayesian learning theory: (1) bagging works because it is an approximation to the optimal proced>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Label: Theory
Prediction:  Label: Theory
Is prediction correct?  False

Prediction: 0
Accuracy: 0.2
Wrong indexes: [455, 1759, 512, 1191]
Wrong list: [1, 2, 3, 4]
Wrong indexes length: 4
experName ....  24.4.17-2100-sciemd-size_5-test
Processing index 1794...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: NONLINEAR NONEQUILIBRIUM NONQUANTUM NONCHAOTIC STATISTICAL MECHANICS OF NEOCORTICAL INTERACTIONS  
Abstract: Abstract: The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exists an interdisciplinary multidimensional gradation on published studies of neocortex, with one primary dimension of mathematical physics represented by two extremes. At one extreme, there is much scientifically unsupported talk of chaos and quantum physics being responsible for many important macroscopic neocortical processes (involving many thousands to millions of neurons) (Wilczek, 1994). At another extreme, many non-mathematically trained neuroscientists uncritically lump all neocortical mathematical theory into one file, and consider only statistical averages of citations for opinions on the quality of that research (Nunez, 1995). In this context, it is important to appreciate that Wright and Liley (W&L) report on their scientifically sound studies on macroscopic neocortical function, based on simulation and a blend of sound theory and reproducible experiments. However, their pioneering work, given the absence of much knowledge of neocortex at this time, is open to criticism, especially with respect to their present inferences and conclusions. Their conclusion that EEG data exhibit linear near-equilibrium dynamics may very well be true, but only in the sense of focusing only on one local minima, possibly with individual-specific and physiological-state dependent 
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 3:  <Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of.   Abstract:  The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exis>
Label: Neural Networks
Paper 4:  <Title: Replicability of Neural Computing Experiments  .   Abstract:  If an experiment requires statistical analysis to establish a result, then one should do a better experiment. Ernest Rutherford, 1930 Most proponents of cold fusion reporting excess heat from their electrolysis experiments were claiming that one of the main characteristics of cold fusion was its irreproducibility | J.R. Huizenga, Cold Fusion, 1993, p. 78 Abstract Amid the ever increasing>
Label: Neural Networks
Paper 6:  <Title: Statistical mechanics of neocortical interactions: Training and testing canonical momenta indicators of EEG  .   Abstract:  A series of papers has developed a statistical mechanics of neocortical interactions (SMNI), deriving aggregate behavior of experimentally observed columns of neurons from statistical electrical-chemical properties of synaptic interactions. While not useful to yield insights at the single neuron level, SMNI has demonstrated its capability in describing large-scale properties of short-ter>
Label: Neural Networks
Paper 2:  <Title: Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems  .   Abstract:  The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exis>
Paper 5:  <Title: MULTIPLE SCALES OF BRAIN-MIND INTERACTIONS  .   Abstract:  Posner and Raichle's Images of Mind is an excellent educational book and very well written. Some aws as a scientific publication are: (a) the accuracy of the linear subtraction method used in PET is subject to scrutiny by further research at finer spatial-temporal resolutions; (b) lack of accuracy of the experimental paradigm used for EEG complementary studies. Images (Posner & Raichle, >
Paper 7:  <Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  .   Abstract:  Neural computation, also called connectionism, parallel distributed processing, neural network modeling or brain-style computation, has grown rapidly in the last decade. Despite this explosion, and ultimately because of impressive applications, there has been a dire need for a concise introduction from a theoretical perspective, analyzing the strengths and weaknesses of connectionist app>
Paper 8:  <Title: Studies of Neurological Transmission Analysis using Hierarchical Bayesian Mixture Models  .   Abstract:  Hierarchically structured mixture models are studied in the context of data analysis and inference on neural synaptic transmission characteristics in mammalian, and other, central nervous systems. Mixture structures arise due to uncertainties about the stochastic mechanisms governing the responses to electro-chemical stimulation of individual neuro-transmitter release sites at nerve junc>
Paper 9:  <Title: Coevolving Communicative Behavior in a Linear Pursuer-Evader Game  .   Abstract:  The pursuer-evader (PE) game is recognized as an important domain in which to study the coevolution of robust adaptive behavior and protean behavior (Miller and Cliff, 1994). Nevertheless, the potential of the game is largely unrealized due to methodological hurdles in coevolutionary simulation raised by PE; versions of the game that have optimal solutions (Isaacs, 1965) are closed-ended>
Paper 10:  <Title: A Brief History of Connectionism  .   Abstract:  Connectionist research is firmly established within the scientific community, especially within the multi-disciplinary field of cognitive science. This diversity, however, has created an environment which makes it difficult for connectionist researchers to remain aware of recent advances in the field, let alone understand how the field has developed. This paper attempts to address this p>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 455...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Learning from an Automated Training Agent  
Abstract: Abstract: A learning agent employing reinforcement learning is hindered because it only receives the critic's sparse and weakly informative training information. We present an approach in which an automated training agent may also provide occasional instruction to the learner in the form of actions for the learner to perform. The learner has access to both the critic's feedback and the trainer's instruction. In the experiments, we vary the level of the trainer's interaction with the learner, from allowing the trainer to instruct the learner at almost every time step, to not allowing the trainer to respond at all. We also vary a parameter that controls how the learner incorporates the trainer's actions. The results show significant reductions in the average number of training trials necessary to learn to perform the task.
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 7:  <Title: Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email  .   Abstract:  This paper describes a novel method by which a dialogue agent can learn to choose an optimal dialogue strategy. While it is widely agreed that dialogue strategies should be formulated in terms of communicative intentions, there has been little work on automatically optimizing an agent's choices when there are multiple ways to realize a communicative intention. Our method is based on a co>
Label: Reinforcement Learning
Paper 2:  <Title: An Introspection Approach to Querying a Trainer  .   Abstract:  Technical Report 96-13 January 22, 1996 Abstract This paper introduces the Introspection Approach, a method by which a learning agent employing reinforcement learning can decide when to ask a training agent for instruction. When using our approach, we find that the same number of trainer's responses produced significantly faster learners than by having the learner ask for aid randomly. G>
Paper 3:  <Title: Modeling the Student with Reinforcement Learning  .   Abstract:  We describe a methodology for enabling an intelligent teaching system to make high level strategy decisions on the basis of low level student modeling information. This framework is less costly to construct, and superior to hand coding teaching strategies as it is more responsive to the learner's needs. In order to accomplish this, reinforcement learning is used to learn to associate sup>
Paper 4:  <Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  .   Abstract:  The application of decision making and learning algorithms to multi-agent systems presents many interestingresearch challenges and opportunities. Among these is the ability for agents to learn how to act by observing or imitating other agents. We describe an algorithm, the IQ-algorithm, that integrates imitation with Q-learning. Roughly, a Q-learner uses the observations it has made of a>
Paper 5:  <Title: Machine Learning,  Creating Advice-Taking Reinforcement Learners  .   Abstract:  Learning from reinforcements is a promising approach for creating intelligent agents. However, reinforcement learning usually requires a large number of training episodes. We present and evaluate a design that addresses this shortcoming by allowing a connectionist Q-learner to accept advice given, at any time and in a natural manner, by an external observer. In our approach, the advice-g>
Paper 6:  <Title: Improving Generalization with Active Learning  .   Abstract:  Active learning differs from passive "learning from examples" in that the learning algorithm assumes at least some control over what part of the input domain it receives information about. In some situations, active learning is provably more powerful that learning from examples alone, giving better generalization for a fixed number of training examples. In this paper, we consider the pro>
Paper 8:  <Title: Learning to Predict User Operations for Adaptive Scheduling  .   Abstract:  Mixed-initiative systems present the challenge of finding an effective level of interaction between humans and computers. Machine learning presents a promising approach to this problem in the form of systems that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive assistant for crisis sched>
Paper 9:  <Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  .   Abstract:  Mixed-initiative systems present the challenge of finding an effective level of interaction between humans and computers. Machine learning presents a promising approach to this problem in the form of systems that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive assistant for crisis sched>
Paper 10:  <Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,.   Abstract:  We have recently introduced a neural network mobile robot controller (NETMORC) that autonomously learns the forward and inverse odometry of a differential drive robot through an unsupervised learning-by-doing cycle. After an initial learning phase, the controller can move the robot to an arbitrary stationary or moving target while compensating for noise and other forms of disturbance, su>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 1759...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Belief Maintenance in Bayesian Networks  
Abstract: Abstract: Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these features a reduced ring representation (RRR) of the local environment is derived. As the robot navigates, it learns the RRR signatures of all the new environment types it encounters. For purpose of identification, a ring matching criteria is proposed where the robot tries to match the RRR from the sensory input to one of the RRRs in its library. The second issue addressed is that of learning hill climbing control laws in the local environments. Unlike conventional neuro-controllers, a reinforcement learning framework, where the robot first learns a model of the environment and then learns the control law in terms of a neural network is proposed here. The reinforcement function is generated from the sensory inputs of the robot before and after a control action is taken. Three key results shown in this work are that (1) The robot is able to build its library of RRR signatures perfectly even with significant sensor noise for eight different local environ-mets, (2) It was able to identify its local environment with an accuracy of more than 96%, once the library is build, and (3) the robot was able to learn adequate hill climbing control laws which take it to the distinctive state of the local environment for five different environment types.
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 5:  <Title: Exploration and Model Building in Mobile Robot Domains  .   Abstract:  I present first results on COLUMBUS, an autonomous mobile robot. COLUMBUS operates in initially unknown, structured environments. Its task is to explore and model the environment efficiently while avoiding collisions with obstacles. COLUMBUS uses an instance-based learning technique for modeling its environment. Real-world experiences are generalized via two artificial neural networks th>
Label: Reinforcement Learning
Paper 10:  <Title: Incremental Class Learning approach and its application to Handwritten Digit Recognition  .   Abstract:  Incremental Class Learning (ICL) provides a feasible framework for the development of scalable learning systems. Instead of learning a complex problem at once, ICL focuses on learning subproblems incrementally, one at a time | using the results of prior learning for subsequent learning | and then combining the solutions in an appropriate manner. With respect to multi-class classification>
Label: Neural Networks
Paper 2:  <Title: Simultaneous Learning of Control Laws and Local Environment Representations for Intelligent Navigation Robots  .   Abstract:  Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these fe>
Paper 3:  <Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,.   Abstract:  We have recently introduced a neural network mobile robot controller (NETMORC) that autonomously learns the forward and inverse odometry of a differential drive robot through an unsupervised learning-by-doing cycle. After an initial learning phase, the controller can move the robot to an arbitrary stationary or moving target while compensating for noise and other forms of disturbance, su>
Paper 4:  <Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  .   Abstract:  This paper demonstrates the exploitation of certain vision processing techniques to index into a case base of surfaces. The surfaces are the result of reinforcement learning and represent the optimum choice of actions to achieve some goal from anywhere in the state space. This paper shows how strong features that occur in the interaction of the system with its environment can be detected>
Paper 6:  <Title: A Modular Q-Learning Architecture for Manipulator Task Decomposition `Data storage in the cerebellar model ar.   Abstract:  Compositional Q-Learning (CQ-L) (Singh 1992) is a modular approach to learning to perform composite tasks made up of several elemental tasks by reinforcement learning. Skills acquired while performing elemental tasks are also applied to solve composite tasks. Individual skills compete for the right to act and only winning skills are included in the decomposition of the composite task. We>
Paper 7:  <Title: A Simulation of Adaptive Agents in a Hostile Environment  .   Abstract:  In this paper we use the genetic programming technique to evolve programs to control an autonomous agent capable of learning how to survive in a hostile environment. In order to facilitate this goal, agents are run through random environment configurations. Randomly generated programs, which control the interaction of the agent with its environment, are recombined to form better programs>
Paper 8:  <Title: Dynamic Automatic Model Selection  .   Abstract:  COINS Technical Report 92-30 February 1992 Abstract The problem of how to learn from examples has been studied throughout the history of machine learning, and many successful learning algorithms have been developed. A problem that has received less attention is how to select which algorithm to use for a given learning task. The ability of a chosen algorithm to induce a good generalizatio>
Paper 9:  <Title: Robot Shaping: Developing Situated Agents through Learning  .   Abstract:  Learning plays a vital role in the development of situated agents. In this paper, we explore the use of reinforcement learning to "shape" a robot to perform a predefined target behavior. We connect both simulated and real robots to A LECSYS, a parallel implementation of a learning classifier system with an extended genetic algorithm. After classifying different kinds of Animat-like behav>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  False

Prediction: 0
Processing index 512...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Fault-Tolerant Implementation of Finite-State Automata in Recurrent Neural Networks  
Abstract: Abstract: Recently, we have proven that the dynamics of any deterministic finite-state automata (DFA) with n states and m input symbols can be implemented in a sparse second-order recurrent neural network (SORNN) with n + 1 state neurons and O(mn) second-order weights and sigmoidal discriminant functions [5]. We investigate how that constructive algorithm can be extended to fault-tolerant neural DFA implementations where faults in an analog implementation of neurons or weights do not affect the desired network performance. We show that tolerance to weight perturbation can be achieved easily; tolerance to weight and/or neuron stuck-at-zero faults, however, requires duplication of the network resources. This result has an impact on the construction of neural DFAs with a dense internal representation of DFA states.
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2:  <Title: Constructing Deterministic Finite-State Automata in Recurrent Neural Networks  .   Abstract:  Recurrent neural networks that are trained to behave like deterministic finite-state automata (DFAs) can show deteriorating performance when tested on long strings. This deteriorating performance can be attributed to the instability of the internal representation of the learned DFA states. The use of a sigmoidal discriminant function together with the recurrent structure contribute to th>
Label: Neural Networks
Paper 4:  <Title: Constructive Learning of Recurrent Neural Networks: Limitations of Recurrent Casade Correlation and a Simple Solution  .   Abstract:  It is often difficult to predict the optimal neural network size for a particular application. Constructive or destructive methods that add or subtract neurons, layers, connections, etc. might offer a solution to this problem. We prove that one method, Recurrent Cascade Correlation, due to its topology, has fundamental limitations in representation and thus in its learning capabilities. >
Label: Neural Networks
Paper 10:  <Title: Networks of Spiking Neurons: The Third Generation of Neural Network Models  .   Abstract:  The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e. threshold gates) respectively sigmoidal gates. In particular it is shown that networks of spiking neurons are computationally more powerful than these other neural network models. A concrete biologically relevant function is >
Label: Neural Networks
Paper 3:  <Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  .   Abstract:  This work describes an approach for inferring Deterministic Context-free (DCF) Grammars in a Connectionist paradigm using a Recurrent Neural Network Pushdown Automaton (NNPDA). The NNPDA consists of a recurrent neural network connected to an external stack memory through a common error function. We show that the NNPDA is able to learn the dynamics of an underlying pushdown automaton from>
Paper 5:  <Title: Even with Arbitrary Transfer Functions, RCC Cannot Compute Certain FSA  .   Abstract:  Category: algorithms and architectures | recurrent networks. No part of this paper has been submitted elsewhere. Preference: poster. Abstract Existing proofs demonstrating the computational limitations of the Recurrent Cascade Correlation (RCC) Network (Fahlman, 1991) explicitly limit their results to units having sigmoidal or hard-threshold transfer functions (Giles et al., 1995; and Kr>
Paper 6:  <Title: An Analytical Framework for Local Feedforward Networks  .   Abstract:  Interference in neural networks occurs when learning in one area of the input space causes unlearning in another area. Networks that are less susceptible to interference are referred to as spatially local networks. To understand these properties, a theoretical framework, consisting of a measure of interference and a measure of network localization, is developed. These measures incorporat>
Paper 7:  <Title: Local Feedforward Networks  .   Abstract:  Although feedforward neural networks are well suited to function approximation, in some applications networks experience problems when learning a desired function. One problem is interference which occurs when learning in one area of the input space causes unlearning in another area. Networks that are less susceptible to interference are referred to as spatially local networks. To unders>
Paper 8:  <Title: Pruning Recurrent Neural Networks for Improved Generalization Performance  .   Abstract:  Determining the architecture of a neural network is an important issue for any learning task. For recurrent neural networks no general methods exist that permit the estimation of the number of layers of hidden neurons, the size of layers or the number of weights. We present a simple pruning heuristic which significantly improves the generalization performance of trained recurrent network>
Paper 9:  <Title: Extraction of Rules from Discrete-Time Recurrent Neural Networks  .   Abstract:  The extraction of symbolic knowledge from trained neural networks and the direct encoding of (partial) knowledge into networks prior to training are important issues. They allow the exchange of information between symbolic and connectionist knowledge representations. The focus of this paper is on the quality of the rules that are extracted from recurrent neural networks. Discrete-time re>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1191...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Title: Title: Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms  
Abstract: Abstract: The term "bias" is widely used|and with different meanings|in the fields of machine learning and statistics. This paper clarifies the uses of this term and shows how to measure and visualize the statistical bias and variance of learning algorithms. Statistical bias and variance can be applied to diagnose problems with machine learning bias, and the paper shows four examples of this. Finally, the paper discusses methods of reducing bias and variance. Methods based on voting can reduce variance, and the paper compares Breiman's bagging method and our own tree randomization method for voting decision trees. Both methods uniformly improve performance on data sets from the Irvine repository. Tree randomization yields perfect performance on the Letter Recognition task. A weighted nearest neighbor algorithm based on the infinite bootstrap is also introduced. In general, decision tree algorithms have moderate-to-high variance, so an important implication of this work is that variance|rather than appropriate or inappropriate machine learning bias|is an important cause of poor performance for decision tree algorithms. 
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2:  <Title: An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants  .   Abstract:  Methods for voting classification algorithms, such as Bagging and AdaBoost, have been shown to be very successful in improving the accuracy of certain classifiers for artificial and real-world datasets. We review these algorithms and describe a large empirical study comparing several variants in conjunction with a decision tree inducer (three variants) and a Naive-Bayes inducer. The purp>
Label: Theory
Paper 8:  <Title: Bias and the Quantification of Stability Bias and the Quantification of Stability Bias and the.   Abstract:  Research on bias in machine learning algorithms has generally been concerned with the impact of bias on predictive accuracy. We believe that there are other factors that should also play a role in the evaluation of bias. One such factor is the stability of the algorithm; in other words, the repeatability of the results. If we obtain two sets of data from the same phenomenon, with the sam>
Label: Theory
Paper 10:  <Title: Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods  .   Abstract:  One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect>
Label: Theory
Paper 3:  <Title: BOOSTING AND NAIVE BAYESIAN LEARNING  .   Abstract:  Although so-called naive Bayesian classification makes the unrealistic assumption that the values of the attributes of an example are independent given the class of the example, this learning method is remarkably successful in practice, and no uniformly better learning method is known. Boosting is a general method of combining multiple classifiers due to Yoav Freund and Rob Schapire. Thi>
Paper 4:  <Title: Experiments with a New Boosting Algorithm  .   Abstract:  In an earlier paper, we introduced a new boosting algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that consistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a pseudo-loss which is a method for forcing a learning algorithm of multi-label >
Paper 5:  <Title: Error-Correcting Output Coding Corrects Bias and Variance  .   Abstract:  Previous research has shown that a technique called error-correcting output coding (ECOC) can dramatically improve the classification accuracy of supervised learning algorithms that learn to classify data points into one of k 2 classes. This paper presents an investigation of why the ECOC technique works, particularly when employed with decision-tree learning algorithms. It shows that th>
Paper 6:  <Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  .   Abstract:  In the past, nearest neighbor algorithms for learning from examples have worked best in domains in which all features had numeric values. In such domains, the examples can be treated as points and distance metrics can use standard definitions. In symbolic domains, a more sophisticated treatment of the feature space is required. We introduce a nearest neighbor algorithm for learning in do>
Paper 7:  <Title: Simultaneous Evolution of Programs and their Control Structures Simultaneous Evolution of Programs and their Control.   Abstract:  Previous research has shown that a technique called error-correcting output coding (ECOC) can dramatically improve the classification accuracy of supervised learning algorithms that learn to classify data points into one of k 2 classes. This paper presents an investigation of why the ECOC technique works, particularly when employed with decision-tree learning algorithms. It shows that th>
Paper 9:  <Title: Why Does Bagging Work? A Bayesian Account and its Implications bagging's success, both in a.   Abstract:  The error rate of decision-tree and other classification learners can often be much reduced by bagging: learning multiple models from bootstrap samples of the database, and combining them by uniform voting. In this paper we empirically test two alternative explanations for this, both based on Bayesian learning theory: (1) bagging works because it is an approximation to the optimal proced>
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Accuracy: 0.8
Wrong indexes: [1759]
Wrong list: [2]
Wrong indexes length: 1
