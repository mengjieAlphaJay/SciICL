experName ....  24.4.3-1400-sciemd-size_100-compress.5-test
Processing index 1794...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The work in progress reported by Wright & Liley shows great promise, primarily because of their experimental and simulation paradigms. However, their tentative conclusion that macroscopic neocortex may be considered (approximately) a linear near-equilibrium system is premature and does not correspond to tentative conclusions drawn from other studies of neocortex. At this time, there exists an interdisciplinary multidimensional gradation on published studies of neocortex, with one primary dimension of mathematical physics represented by two extremes. At one extreme, there is much scientifically unsupported talk of chaos and quantum physics being responsible for many important macroscopic neocortical processes (involving many thousands to millions of neurons) (Wilczek, 1994). At another extreme, many non-mathematically trained neuroscientists uncritically lump all neocortical mathematical theory into one file, and consider only statistical averages of citations for opinions on the quality of that research (Nunez, 1995). In this context, it is important to appreciate that Wright and Liley (W&L) report on their scientifically sound studies on macroscopic neocortical function, based on simulation and a blend of sound theory and reproducible experiments. However, their pioneering work, given the absence of much knowledge of neocortex at this time, is open to criticism, especially with respect to their present inferences and conclusions. Their conclusion that EEG data exhibit linear near-equilibrium dynamics may very well be true, but only in the sense of focusing only on one local minima, possibly with individual-specific and physiological-state dependent 
Title: Title: NONLINEAR NONEQUILIBRIUM NONQUANTUM NONCHAOTIC STATISTICAL MECHANICS OF NEOCORTICAL INTERACTIONS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems  
Abstract The work in progress reported Wright & Liley shows great promise primarily However their tentative conclusion macroscopic neocortex may considered (approximately a linear near-equilibrium system premature does correspond tentative conclusions At exis
Paper 3  Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of
Abstract The work in progress reported Wright & Liley shows great promise primarily However their tentative conclusion macroscopic neocortex may considered (approximately a linear near-equilibrium system premature does correspond tentative conclusions At exis
Label: Neural Networks
Paper 4  Title: Replicability of Neural Computing Experiments  
Abstract If an experiment requires statistical analysis establish a result one do a better experiment Ernest Rutherford 1930 Most proponents cold fusion reporting excess heat their electrolysis experiments claiming one its irreproducibility | 1993 78 Abstract Amid ever
Label: Neural Networks
Paper 5  Title: MULTIPLE SCALES OF BRAIN-MIND INTERACTIONS  
Abstract Posner and Raichle's Images Mind and very Some aws as a scientific publication: ( the accuracy the linear subtraction method PET is subject scrutiny further research at finer spatial-temporal resolutions accuracy the experimental paradigm EEG complementary studies Images (Posner
Paper 6  Title: Statistical mechanics of neocortical interactions: Training and testing canonical momenta indicators of EEG  
Abstract A series papers developed a statistical mechanics neocortical interactionsSMNI deriving aggregate behavior experimentally observed columns statistical electrical-chemical properties synaptic interactions While not useful yield insights at the single neuron level SMNI describing short-ter
Label: Neural Networks
Paper 7  Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  
Abstract Neural computation, also connectionism parallel distributed processing neural network modeling or brain-style computation grown Despite this explosion and ultimately impressive applications a dire need a concise introduction from a theoretical perspective analyzing the strengths connectionist app
Paper 8  Title: Studies of Neurological Transmission Analysis using Hierarchical Bayesian Mixture Models  
Abstract Hierarchically structured mixture studied inference on neural synaptic transmission characteristics mammalian, Mixture structures arise due uncertainties governing electro-chemical stimulation individual neuro-transmitter release sites at nerve junc
Paper 9  Title: Coevolving Communicative Behavior in a Linear Pursuer-Evader Game  
Abstract The pursuer-evader (PE) game recognized an important domain robust adaptive behavior protean behavior (Miller Cliff 1994 Nevertheless the potential the game largely unrealized due methodological hurdles in coevolutionary simulation raised PE; versions optimal solutions (Isaacs 1965 closed
Paper 10  Title: A Brief History of Connectionism  
Abstract: Connectionist research firmly within especially cognitive science This diversity, however created which makes connectionist researchers remain aware recent advances let understand the field developed This paper attempts address this p
Paper 11  Title: Models of perceptual learning in vernier hyperacuity  
Abstract Performance human subjects early visual processing tasks improves practice HyperBF networks (Poggio Girosi 1990 constitute understanding such improvement or perceptual learning the class tasks known visual hyperacuity The present article two issues raised the rece
Paper 12  Title: Computational Learning in Humans and Machines  
Abstract In research machine learning computational models We focus initially concept induction examining five main approaches then consider learning sequential behaviors After this compare the rhetoric that sometimes the machine learning and psychological literature with
Label: Case Based
Paper 13  Title: Perceptual Development and Learning: From Behavioral, Neurophysiological, and Morphological Evidence To Computational Models  
Abstract An intelligent system has to adapting It therefore, ought capable learning its perceptual interactions This requires plasticity its structure Any attempt model the perceptual capabilities a living system or, construct a synthetic system comparable
Paper 14  Title: In Defense of C4.5: Notes on Learning One-Level Decision Trees  
Abstract We discuss Holte's recently-published article which demonstrated on the most commonly used data very simple classification rules almost as decision trees produced Quinlan's C4.5 consider, what the future top-down induction To an extent Holte questioned the sen
Paper 15  Title: On the Computational Utility of Consciousness  
Abstract We propose human consciousness This framework integrates many existing theoretical perspectives yet sufficiently concrete simulation experiments We do attempt explain qualia (subjective experience ask differences the cognitive information processing system when consc
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 455...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A learning agent employing reinforcement learning is hindered because it only receives the critic's sparse and weakly informative training information. We present an approach in which an automated training agent may also provide occasional instruction to the learner in the form of actions for the learner to perform. The learner has access to both the critic's feedback and the trainer's instruction. In the experiments, we vary the level of the trainer's interaction with the learner, from allowing the trainer to instruct the learner at almost every time step, to not allowing the trainer to respond at all. We also vary a parameter that controls how the learner incorporates the trainer's actions. The results show significant reductions in the average number of training trials necessary to learn to perform the task.
Title: Title: Learning from an Automated Training Agent  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Introspection Approach to Querying a Trainer  
Abstract: Technical Report 9613 January 22 Abstract introduces the Introspection Approach employing decide ask instruction When using our approach find trainer's responses produced significantly faster learners by having ask aid randomly G
Paper 3  Title: Modeling the Student with Reinforcement Learning  
Abstract We describe a methodology enabling an intelligent teaching system make high level strategy decisions on low level student modeling information This framework less costly construct superior hand coding teaching strategies as responsive In order accomplish reinforcement learning associate sup
Paper 4  Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  
Abstract The application decision making learning algorithms presents many interestingresearch challenges Among these the ability agents learn act by or We describe, the IQ-algorithm integrates imitation Q-learning, a Q-learner uses the observations it
Paper 5  Title: Machine Learning,  Creating Advice-Taking Reinforcement Learners  
Abstract Learning reinforcements creating intelligent agents However reinforcement learning usually training episodes We present and a design addresses allowing a connectionist Q-learner accept advice given, a natural manner In our approach advice-g
Paper 6  Title: Improving Generalization with Active Learning  
Abstract Active learning differs " from examples assumes what part receives information In some situations active learning provably that learning examples alone giving better generalization for a fixed number training examples In this paper consider pro
Paper 7  Title: Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email  
Abstract by a dialogue agent learn choose an optimal dialogue strategy While it widely agreed dialogue strategies should formulated terms communicative intentions little work automatically optimizing an agent's choices when there multiple ways realize Our method a co
Label: Reinforcement Learning
Paper 8  Title: Learning to Predict User Operations for Adaptive Scheduling  
Abstract Mixed-initiative systems present the challenge finding an effective level interaction humans computers Machine learning presents in systems automatically adapt accommodate different users In learning user models an adaptive assistant crisis sched
Paper 9  Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  
Abstract Mixed-initiative systems present the challenge finding an effective level interaction humans computers Machine learning presents in systems automatically adapt accommodate different users In learning user models an adaptive assistant crisis sched
Paper 10  Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,
Abstract We introduced a neural network mobile robot controllerNETMORC the forward and inverse odometry a differential drive robot through After an initial learning phase the controller move the robot an arbitrary stationary or moving target while noise other forms disturbance su
Paper 11  Title: Exploration and Model Building in Mobile Robot Domains  
Abstract I present first results COLUMBUS an autonomous mobile robot operates initially unknown, structured environments Its task explore model efficiently collisions obstacles uses an instance-based learning technique modeling its environment generalized via th
Label: Reinforcement Learning
Paper 12  Title: Abstract  
Abstract We describe (ATS dynamically models a students processes can specialized tutoring adapted a students knowledge state and learning style The student modeling component, ML-Modeler uses ( emulate the students novice transition ML-Modeler infers w
Paper 13  Title: Abstract  
Abstract We describe (ATS dynamically models a students processes can specialized tutoring adapted a students knowledge state and learning style The student modeling component, ML-Modeler uses ( emulate the students novice transition ML-Modeler infers w
Paper 14  Title: Accounting for Context in Plan Recognition, with Application to Traffic Monitoring  
Abstract Typical approaches plan recognition start a representation an agent's possible plans reason evidentially observations to assess the various candidates A more expansive view the task (consistent accounts the context the plan generated the mental state and planning process the age
Paper 15  Title: AN EMPIRICAL APPROACH TO SOLVING THE GENERAL UTILITY PROBLEM IN SPEEDUP LEARNING  
Abstract The utility problem speedup learning describes a common behavior the eventual degradation increasing amounts learned knowledge The shape (cost using number training examples) over several domains suggests a parameterized model relating performance learned knowledge
Label: Case Based
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 1759...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Two issues of an intelligent navigation robot have been addressed in this work. First is the robot's ability to learn a representation of the local environment and use this representation to identify which local environment it is in. This is done by first extracting features from the sensors which are more informative than just distances of obstacles in various directions. Using these features a reduced ring representation (RRR) of the local environment is derived. As the robot navigates, it learns the RRR signatures of all the new environment types it encounters. For purpose of identification, a ring matching criteria is proposed where the robot tries to match the RRR from the sensory input to one of the RRRs in its library. The second issue addressed is that of learning hill climbing control laws in the local environments. Unlike conventional neuro-controllers, a reinforcement learning framework, where the robot first learns a model of the environment and then learns the control law in terms of a neural network is proposed here. The reinforcement function is generated from the sensory inputs of the robot before and after a control action is taken. Three key results shown in this work are that (1) The robot is able to build its library of RRR signatures perfectly even with significant sensor noise for eight different local environ-mets, (2) It was able to identify its local environment with an accuracy of more than 96%, once the library is build, and (3) the robot was able to learn adequate hill climbing control laws which take it to the distinctive state of the local environment for five different environment types.
Title: Title: Belief Maintenance in Bayesian Networks  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Simultaneous Learning of Control Laws and Local Environment Representations for Intelligent Navigation Robots  
Abstract Two issues an intelligent navigation robot First is the robot's ability learn a representation use identify which local environment This done first extracting features the sensors which more informative just distances of obstacles in various directions Using these fe
Paper 3  Title: An unsupervised neural network for low-level control of a wheeled mobile robot: noise resistance, stability,
Abstract We introduced a neural network mobile robot controllerNETMORC the forward and inverse odometry a differential drive robot through After an initial learning phase the controller move the robot an arbitrary stationary or moving target while noise other forms disturbance su
Paper 4  Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  
Abstract demonstrates the exploitation certain vision processing index into a case base surfaces The surfaces the result reinforcement learning represent the optimum choice actions achieve some goal from anywhere This paper how strong features that occur the system
Paper 5  Title: Exploration and Model Building in Mobile Robot Domains  
Abstract I present first results COLUMBUS an autonomous mobile robot operates initially unknown, structured environments Its task explore model efficiently collisions obstacles uses an instance-based learning technique modeling its environment generalized via th
Label: Reinforcement Learning
Paper 6  Title: A Modular Q-Learning Architecture for Manipulator Task Decomposition `Data storage in the cerebellar model ar
Abstract Compositional Q-Learning (Singh 1992 composite tasks made several elemental tasks by Skills acquired while performing elemental tasks applied solve composite tasks Individual skills compete act only winning skills included the decomposition the composite task We
Paper 7  Title: A Simulation of Adaptive Agents in a Hostile Environment  
Abstract In use the genetic programming technique evolve programs control an autonomous agent capable learning how survive In order facilitate this goal agents run random environment configurations Randomly programs control the interaction the agent recombined better programs
Paper 8  Title: Dynamic Automatic Model Selection  
Abstract COINS Technical Report 9230 February Abstract The problem how learn examples has studied throughout machine learning many successful learning algorithms A problem received how select which algorithm a given learning task The ability a chosen algorithm induce a good generalizatio
Paper 9  Title: Robot Shaping: Developing Situated Agents through Learning  
Abstract Learning plays situated agents In reinforcement learning "shape a robot a predefined target behavior We connect both simulated and real robots A LECSYS a parallel implementation a learning classifier system with an extended genetic algorithm After classifying different kinds Animat-like behav
Paper 10  Title: Incremental Class Learning approach and its application to Handwritten Digit Recognition  
Abstract Incremental Class Learning provides a feasible framework scalable learning systems Instead learning a complex problem at ICL focuses learning subproblems incrementally one a time | using the results prior learning for combining With respect multi-class classification
Label: Neural Networks
Paper 11  Title: Learning Concepts from Sensor Data of a Mobile Robot  
Abstract Machine learning the flexibility robot applications Many approaches applying robotics known Some approaches enhance the planning capabilities. Other approaches enhance the control basic actions. In contrast the approach presented thi
Paper 12  Title: NEUROCONTROL BY REINFORCEMENT LEARNING  
Abstract: Reinforcement learningRL a model-free tuning adaptation method control dynamic systems Contrary supervised learning based usually gradient descent techniques RL does any model or sensitivity function of Hence RL can applied systems poorly uncertain nonlinear for untractable with
Paper 13  Title: Modeling the Student with Reinforcement Learning  
Abstract We describe a methodology enabling an intelligent teaching system make high level strategy decisions on low level student modeling information This framework less costly construct superior hand coding teaching strategies as responsive In order accomplish reinforcement learning associate sup
Paper 14  Title: VECTOR ASSOCIATIVE MAPS: UNSUPERVISED REAL-TIME ERROR-BASED LEARNING AND CONTROL OF MOVEMENT TRAJECTORIES  
Abstract: ALVINN (Autonomous Land Vehicle in a Neural Net a Backpropagation trained neural network which steering road and highway environments Although ALVINN fairly robust one has the time train As the vehicle is capable online learning has drive for the ne
Paper 15  Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  
Abstract The work discussed motivated of building decision support systems Our goal use these systems supporting Bayes optimal decision making where the action maximizing the expected utility, with respect predicted probabilities should selected For the models need
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 512...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Recently, we have proven that the dynamics of any deterministic finite-state automata (DFA) with n states and m input symbols can be implemented in a sparse second-order recurrent neural network (SORNN) with n + 1 state neurons and O(mn) second-order weights and sigmoidal discriminant functions [5]. We investigate how that constructive algorithm can be extended to fault-tolerant neural DFA implementations where faults in an analog implementation of neurons or weights do not affect the desired network performance. We show that tolerance to weight perturbation can be achieved easily; tolerance to weight and/or neuron stuck-at-zero faults, however, requires duplication of the network resources. This result has an impact on the construction of neural DFAs with a dense internal representation of DFA states.
Title: Title: Fault-Tolerant Implementation of Finite-State Automata in Recurrent Neural Networks  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Constructing Deterministic Finite-State Automata in Recurrent Neural Networks  
Abstract Recurrent neural networks that behaveDFAs show deteriorating performance tested long strings This deteriorating performance can the instability the internal representation the learned DFA states The use a sigmoidal discriminant function together the recurrent structure contribute th
Label: Neural Networks
Paper 3  Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  
Abstract Deterministic Context-free (DCF) Grammars a Connectionist paradigm a Recurrent Neural Network Pushdown AutomatonNNPDA The NNPDA consists a recurrent neural network connected an external stack memory through a common error function We show the NNPDA able learn the dynamics an underlying pushdown automaton
Paper 4  Title: Constructive Learning of Recurrent Neural Networks: Limitations of Recurrent Casade Correlation and a Simple Solution  
Abstract It often predict the optimal neural network size a particular application Constructive or destructive methods that add neurons layers connections might offer We prove one method, Recurrent Cascade Correlation due its topology has fundamental limitations representation thus its learning capabilities
Label: Neural Networks
Paper 5  Title: Even with Arbitrary Transfer Functions, RCC Cannot Compute Certain FSA  
Abstract Category algorithms architectures | recurrent. No part submitted elsewhere Preference poster Abstract Existing proofs demonstrating the computational limitations explicitly limit their results units having or hard-threshold transfer functionsGiles and Kr
Paper 6  Title: An Analytical Framework for Local Feedforward Networks  
Abstract: Interference occurs learning in one area the input space unlearning Networks less susceptible interference referred spatially local networks To these properties a theoretical framework, consisting a measure interference network localization developed These measures incorporat
Paper 7  Title: Local Feedforward Networks  
Abstract Although feedforward neural networks function approximation in some applications networks experience a desired function One problem interference which learning in the input space causes unlearning Networks less susceptible interference referred spatially local networks To unders
Paper 8  Title: Pruning Recurrent Neural Networks for Improved Generalization Performance  
Abstract Determining the architecture any learning task For recurrent neural networks no general methods permit the estimation layers hidden neurons the size layers weights We present a simple pruning heuristic which significantly the generalization performance trained recurrent network
Paper 9  Title: Extraction of Rules from Discrete-Time Recurrent Neural Networks  
Abstract The extraction symbolic knowledge trained neural networks and the direct encoding (partial) knowledge networks prior are important issues They allow the exchange symbolic and connectionist knowledge representations The focus the quality the rules extracted recurrent neural networks Discrete-time re
Paper 10  Title: Networks of Spiking Neurons: The Third Generation of Neural Network Models  
Abstract The computational power formal models for networks spiking neurons compared based McCulloch Pitts neuronsi.e. threshold gates respectively sigmoidal gates In particular it shown networks spiking neurons computationally powerful these other neural network models A concrete biologically relevant function
Label: Neural Networks
Paper 11  Title: Localist Attractor Networks  
Abstract Attractor networks map a continuous input space pattern completion cleaning noisy or features. However designing a net have a given set attractors notoriously; training procedures CPU produce spurious attractors ill-conditioned attractor basins These difficulties occur
Paper 12  Title: A Unified Gradient-Descent/Clustering Architecture for Finite State Machine Induction  
Abstract Although recurrent neural nets moderately learning emulate finite-state machinesFSMs the continuous internal state dynamics are matched the discrete behavior We describe an architecture, called DOLCE discrete states evolve a net as learning dolce consists a standard recurrent neural ne
Paper 13  Title: First-Order vs. Second-Order Single Layer Recurrent Neural Networks  
Abstract We examine the representational capabilities first-order and second-order Single Layer Recurrent Neural Networks hard-limiting neurons We show a second-order SLRNN strictly more However if the first-order SLRNN augmented output layers feedforward neurons implement any finite-state recognizer but only if sta
Paper 14  Title: ASOCS: A Multilayered Connectionist Network with Guaranteed Learning of Arbitrary Mappings  
Abstract features a new class multilayer connectionist architectures known ASOCS ASOCS is similar most decision-making neural network models attempts learn an adaptive set arbitrary vector mappings However differs dramatically its mechanisms ASOCS is based networks adaptive digital elemen
Label: Neural Networks
Paper 15  Title: LEARNING TO CONTROL FAST-WEIGHT MEMORIES: AN ALTERNATIVE TO DYNAMIC RECURRENT NETWORKS (Neural Computation, 4(1):131-139, 1992)  
Abstract Previous algorithms supervised sequence learning dynamic recurrent networks This paper an alternative class gradient-based systems consisting two feedforward nets learn deal temporal sequences using fast weights produce context dependent weight changes whose weights may very The metho
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1191...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The term "bias" is widely used|and with different meanings|in the fields of machine learning and statistics. This paper clarifies the uses of this term and shows how to measure and visualize the statistical bias and variance of learning algorithms. Statistical bias and variance can be applied to diagnose problems with machine learning bias, and the paper shows four examples of this. Finally, the paper discusses methods of reducing bias and variance. Methods based on voting can reduce variance, and the paper compares Breiman's bagging method and our own tree randomization method for voting decision trees. Both methods uniformly improve performance on data sets from the Irvine repository. Tree randomization yields perfect performance on the Letter Recognition task. A weighted nearest neighbor algorithm based on the infinite bootstrap is also introduced. In general, decision tree algorithms have moderate-to-high variance, so an important implication of this work is that variance|rather than appropriate or inappropriate machine learning bias|is an important cause of poor performance for decision tree algorithms. 
Title: Title: Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Empirical Comparison of Voting Classification Algorithms: Bagging, Boosting, and Variants  
Abstract Methods for voting classification algorithms, such Bagging AdaBoost successful improving certain classifiers We review these algorithms describe a large empirical study comparing several variants conjunction a decision tree inducerthree variants a Naive-Bayes inducer The purp
Label: Theory
Paper 3  Title: BOOSTING AND NAIVE BAYESIAN LEARNING  
Abstract Although so-called naive Bayesian classification makes the unrealistic assumption the values the attributes an example given this learning method remarkably practice no uniformly better learning method Boosting is a general method combining multiple classifiers due Yoav Freund Rob Schapire Thi
Paper 4  Title: Experiments with a New Boosting Algorithm  
Abstract In introduced a new boosting algorithm AdaBoost, theoretically significantly any learning algorithm consistently classifiers whose performance a little random guessing We also introduced the related notion a pseudoloss which forcing a learning algorithm of multilabel
Paper 5  Title: Error-Correcting Output Coding Corrects Bias and Variance  
Abstract Previous research a technique error output coding dramatically the classification accuracy that learn data points into one k 2 classes This paper an investigation why the ECOC technique works particularly employed decision-tree learning algorithms It shows th
Paper 6  Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  
Abstract nearest neighbor algorithms learning examples worked domains all features had numeric values such domains the examples can treated points distance metrics can use standard definitions symbolic domains a more sophisticated treatment the feature space We introduce a nearest neighbor learning in do
Paper 7  Title: Simultaneous Evolution of Programs and their Control Structures Simultaneous Evolution of Programs and their Control
Abstract Previous research a technique error output coding dramatically the classification accuracy that learn data points into one k 2 classes This paper an investigation why the ECOC technique works particularly employed decision-tree learning algorithms It shows th
Paper 8  Title: Bias and the Quantification of Stability Bias and the Quantification of Stability Bias and the
Abstract: Research bias machine learning algorithms generally concerned the impact predictive accuracy We believe there other factors should also the evaluation bias One such factor the stability the algorithm; in repeatability If we obtain two sets the same phenomenon with the sam
Label: Theory
Paper 9  Title: Why Does Bagging Work? A Bayesian Account and its Implications bagging's success, both in a
Abstract The error rate decision-tree and other classification learners can often much reduced bagging: learning multiple models bootstrap samples the database combining by uniform voting In two alternative explanations this, works an approximation optimal proced
Paper 10  Title: Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods  
Abstract One the surprising recurring phenomena observed experiments boosting is the test error the generated classifier usually does increase its size very often observed even the training error reaches In this paper this phenomenon related the distribution margins the training examples with
Label: Theory
Paper 11  Title: Irrelevant Features and the Subset Selection Problem  
Abstract We address finding a subset features allows a supervised induction induce small high-accuracy concepts We examine notions relevance show the definitions the machine learning literature partition the features into We present definitions irrelevance for two de
Label: Theory
Paper 12  Title: Regression Can Build Predictive Causal Models  
Abstract Covariance information an algorithm search predictive causal models estimate This information should discarded after conditional independence constraints identified is usual contemporary causal induction algorithms Our fbd algorithm combines covariance information an effective heuristic build ca
Paper 13  Title: The Power of Decision Tables  
Abstract We evaluate decision tables a hypothesis space Decision tables one the simplest hypothesis spaces possible usually they easy Experimental results on artificial and real-world domains containing only discrete features IDTM, an algorithm inducing decision tables sometimes
Paper 14  Title: On Learning Multiple Descriptions of a Concept  
Abstract In sparse data environments greater classification accuracy learning several concept descriptions combining their classifications Stochastic search a general tool which generate many good concept descriptions (rule sets each class Bayesian probability theory offers an optimal strategy combining classifications o
Paper 15  Title: Classifiers: A Theoretical and Empirical Study  
Abstract a competitive tree learning derived first principles The algorithm approximates the Bayesian decision theoretic solution the learning task Comparative experiments the algorithm the several mature AI and statistical families tree learning algorithms currently show the derived Bayesian algorithm consistently as
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 474...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We introduce a parallel approach, "DT-Select," for selecting features used by inductive learning algorithms to predict protein secondary structure. DT-Select is able to rapidly choose small, nonredundant feature sets from pools containing hundreds of thousands of potentially useful features. It does this by building a decision tree, using features from the pool, that classifies a set of training examples. The features included in the tree provide a compact description of the training data and are thus suitable for use as inputs to other inductive learning algorithms. Empirical experiments in the protein secondary-structure task, in which sets of complex features chosen by DT-Select are used to augment a standard artificial neural network representation, yield surprisingly little performance gain, even though features are selected from very large feature pools. We discuss some possible reasons for this result. 1 
Title: Title: Protein Structure Prediction: Selecting Salient Features from Large Candidate Pools  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Evolution, Learning, and Instinct: 100 Years of the Baldwin Effect Using Learning to Facilitate the
Abstract a hybrid methodology integrates genetic algorithms decision tree learning evolve useful subsets discriminatory features for recognizing complex visual concepts A genetic algorithm (GA search the space all possible subsets candidate discrimination features Candidate feature subsets evaluated using C4.5
Label: Genetic Algorithms
Paper 3  Title: Maximum A Posteriori Classification of DNA Structure from Sequence Information  
Abstract We introduce, lllama simple pattern recognizers into estimating the entropy Each pattern recognizer exploits a partial match subsequences build Since the primary features interest biological sequence domains subsequences small variations exact composition lllama part
Label: Neural Networks
Paper 4  Title: Feature Generation for Sequence Categorization  
Abstract The problem sequence categorization to from a corpus labeled sequences procedures for accurately labeling future unlabeled sequences The choice representation sequences can this task background knowledge a good representation known straightforward representations far optimal We propo
Paper 5  Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  
Abstract With computational costs without accuracy describe two algorithms find sets prototypes nearest neighbor classification Here the term prototypes the reference instances a nearest neighbor computation the instances with respect which similarity assessed assign a new data item Both algorithms re
Paper 6  Title: Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology  
Abstract In the wrapper approach feature subset selection a search the induction algorithm as The estimated future performance the algorithm the heuristic guiding Statistical methods feature subset selection including forward selection backward elimination their stepwise variants can viewed as simple hill
Paper 7  Title: Stochastic Propositionalization of Non-Determinate Background Knowledge  
Abstract It propositional learning algorithms require "good" features perform So a major step data engineering inductive learning the construction good features by These features often represent properties structured objects typically the occurrence having certain properti
Paper 8  Title: Compression-Based Feature Subset Selection  Keywords: Minimum Description Length Principle, Cross Validation, Noise  
Abstract Irrelevant and redundant features reduce both predictive accuracy comprehensibility induced concepts Most common Machine approaches selecting a good subset relevant features rely cross As present a particular Minimum Description Length (MDL) measure feature subset selection Using the MDL prin
Paper 9  Title: The role of afferent excitatory and lateral inhibitory synaptic plasticity in visual cortical ocular dominance
Abstract The boosting algorithm AdaBoost Freund Schapire exhibited several benchmark problems when C4.5 as to be " Like other ensemble learning approaches constructs a composite hypothesis by voting many individual hypotheses practice the large amount memory these hypotheses c
Label: Neural Networks
Paper 10  Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  
Abstract nearest neighbor algorithms learning examples worked domains all features had numeric values such domains the examples can treated points distance metrics can use standard definitions symbolic domains a more sophisticated treatment the feature space We introduce a nearest neighbor learning in do
Paper 11  Title: On Learning Multiple Descriptions of a Concept  
Abstract In sparse data environments greater classification accuracy learning several concept descriptions combining their classifications Stochastic search a general tool which generate many good concept descriptions (rule sets each class Bayesian probability theory offers an optimal strategy combining classifications o
Paper 12  Title: Irrelevant Features and the Subset Selection Problem  
Abstract We address finding a subset features allows a supervised induction induce small high-accuracy concepts We examine notions relevance show the definitions the machine learning literature partition the features into We present definitions irrelevance for two de
Label: Theory
Paper 13  Title: A System for Induction of Oblique Decision Trees  
Abstract a new system induction oblique decision trees This system, OC1 combines deterministic hill-climbing two forms randomization to find a good oblique split (in a hyperplane a decision tree Oblique decision tree methods tuned especially domains the attributes numeric although adapted sy
Paper 14  Title: Hybrid Learning Using Genetic Algorithms and Decision Trees for Pattern Classification  
Abstract introduces a hybrid learning methodology genetic algorithmsGAs decision learningID3 evolve optimal subsets discriminatory features robust pattern classification A GA is used search the space all possible subsets candidate discrimination features For a given feature subset ID3 invoked produce a d
Paper 15  Title: PLEASE: A prototype learning system using genetic algorithms  
Abstract Prototypes have representation concepts used effectively humans Developing computational schemes generating prototypes from examples however We present a novel genetic algorithm based prototype learning system PLEASE constructing appropriate prototypes classified training instances After constructing
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  False

Prediction: 0
Processing index 1065...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: IlliGAL Report No. 97003 May 1997 
Title: Title: A Survey of Parallel Genetic Algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Genetic Algorithms, Tournament Selection, and the Effects of Noise  
Abstract IlliGAL Report July 1995
Paper 3  Title: The Bayesian Approach to Tree-Structured Regression  
Abstract: TECHNICAL REPORT NO 967 August
Paper 4  Title: Finding Analogues for Innovative Design  
Abstract: Knowledge Systems Laboratory March Report KSL 95
Paper 5  Title: Environments with Classifier Systems (Experiments on Adding Memory to XCS)  
Abstract: Pier Luca Lanzi Technical Report N. 97.45 October th
Paper 6  Title: The Role of Transfer in Learning (extended abstract)  
Abstract Technical Report 670 December 1997
Label: Reinforcement Learning
Paper 7  Title: Model of the Environment to Avoid Local Learning  
Abstract: Pier Luca Lanzi Technical Report N. 97.46 December 20 th
Paper 8  Title: A Comparison of Selection Schemes used in Genetic Algorithms  
Abstract: TIK-Report Nr 11 December Version2 Edition)
Label: Genetic Algorithms
Paper 9  Title: Heuristic for Improved Genetic Bin Packing  
Abstract University Tulsa Technical Report UTULSA-MCS-938 May Submitted Information Processing Letters May, 1993
Label: Genetic Algorithms
Paper 10  Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  
 NO 947 June 5
Paper 11  Title: Classification of EEG Signals Using a Sparse Polynomial Builder  
Abstract Edward S. Orosz Charles Anderson Technical Report CS-94111 April
Paper 12  Title: Applications and extensions of MCMC in IRT: Multiple item types, missing data, and rated responses  
Abstract Technical Report 670 December 1997
Paper 13  Title: Approximate Bayes Factors and Accounting for Model Uncertainty in Generalized Linear Models  
Abstract Technical Report no 255 Department Statistics August 1993 Revised March
Paper 14  Title: Inference in Model-Based Cluster Analysis  
Abstract Technical Report no 285 Department Statistics University March 1995
Paper 15  Title: Learning an Optimally Accurate Representational System  
Abstract Multigrid Q-Learning Charles W. Anderson Stewart G. CS-94121 October
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2561...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Given a problem, a case-based reasoning (CBR) system will search its case memory and use the stored cases to find the solution, possibly modifying retrieved cases to adapt to the required input specifications. In discrete domains CBR reasoning can be based on a rigorous Bayesian probability propagation algorithm. Such a Bayesian CBR system can be implemented as a probabilistic feedforward neural network with one of the layers representing the cases. In this paper we introduce a Minimum Description Length (MDL) based learning algorithm to obtain the proper network structure with the associated conditional probabilities. This algorithm together with the resulting neural network implementation provide a massively parallel architecture for solving the efficiency bottleneck in case-based reasoning. 
Title: Title: MDL Learning of Probabilistic Neural Networks for Discrete Problem Domains  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Bayesian Case-Based Reasoning with Neural Networks  
Abstract Given a problem a case-based reasoning (CBR) system will search its case memory use the stored cases find possibly modifying retrieved cases adapt the required input specifications In efficient case-based reasoning We show a rigorous Bayesian probability propagation as
Label: Probabilistic Methods
Paper 3  Title: Adaptive Tuning of Numerical Weather Prediction Models: Simultaneous Estimation of Weighting, Smoothing and Physical Parameters 1  
Abstract In case-based reasoning demonstrated problem complex domains Also mixed paradigm approaches emerged combining CBR and induction techniques aiming verifying the knowledge building an efficient case memory However in complex domains induction over the whole problem space often or too time
Paper 4  Title: Massively Parallel Case-Based Reasoning with Probabilistic Similarity Metrics  
Abstract We propose a probabilistic case-space metric the case matching case adaptation tasks Central a probability propagation adopted Bayesian reasoning systems The same probability propagation mechanism actually offers a uniform solution both the c
Label: Probabilistic Methods
Paper 5  Title: FONN: Combining First Order Logic with Connectionist Learning  
Abstract a neural network architecture manage structured data refine knowledge bases expressed a first order logic language The presented framework well classification problems concept de scriptions depend numerical features In fact the main goal the neural architecture that refining the numerical part the k
Paper 6  Title: ADAPtER: an Integrated Diagnostic System Combining Case-Based and Abductive Reasoning  
Abstract the ADAPtER system a diagnostic architecture combining case-based reasoning abductive reasoning exploiting the adaptation the solution old episodes focus the reasoning process Domain knowledge represented via a logical model basic mechanisms based abductive reasoning with consistency constraints have defi
Label: Case Based
Paper 7  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 8  Title: Lazy Induction Triggered by CBR  
Abstract In case-based reasoning demonstrated problem complex domains Also mixed paradigm approaches emerged combining CBR and induction techniques aiming verifying the knowledge building an efficient case memory However in complex domains induction over the whole problem space often or too time
Paper 9  Title: Case-Based Probability Factoring in Bayesian Belief Networks  
Abstract Bayesian network inference formulated concerning in the computation an optimal factoring for represented the net Since the determination an optimal factoring is heuristic greedy strategies able find usually adopted In
Paper 10  Title: Rule Generation and Compaction in the wwtp  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 11  Title: Massively Parallel Matching of Knowledge Structures  
Abstract: As knowledge bases used AI systems increase access relevant information the dominant factor the cost inference This especially analogical (or case-based) reasoning in the ability perform inference efficient and flexible access a large base exemplars (cases judged likely relevant solving proble
Paper 12  Title: A Provably Convergent Dynamic Training Method for Multilayer Perceptron Networks  
Abstract training multilayer perceptron networks called DMP1 1 The method based upon builds networks in binary trees dynamically allocating layers as The individual nodes trained using a gentetic algorithm The method capable handling
Label: Neural Networks
Paper 13  Title: Pointer Adaptation and Pruning of Min-Max Fuzzy Inference and Estimation  
Abstract a partial-memory incremental learning method based the AQ15c inductive learning system The method maintains a representative set past training examples used together new examples appropriately modify the currently held hypotheses Incremental learning evoked feedback or Such a method useful appli
Paper 14  Title: A Preprocessing Model for Integrating CBR and Prototype-Based Neural Networks  
Abstract Some important factors play the performances a CBR (Case-Based Reasoning) system the complexity the accuracy the retrieval phase Both flat memory inductive approaches suffer serious drawbacks In the first approach search time increases when dealing large scale memory base while modification of
Paper 15  Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  
Abstract Deterministic Context-free (DCF) Grammars a Connectionist paradigm a Recurrent Neural Network Pushdown AutomatonNNPDA The NNPDA consists a recurrent neural network connected an external stack memory through a common error function We show the NNPDA able learn the dynamics an underlying pushdown automaton
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 2676...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Performance of human subjects in a wide variety of early visual processing tasks improves with practice. HyperBF networks (Poggio and Girosi, 1990) constitute a mathematically well-founded framework for understanding such improvement in performance, or perceptual learning, in the class of tasks known as visual hyperacuity. The present article concentrates on two issues raised by the recent psychophysical and computational findings reported in (Poggio et al., 1992b; Fahle and Edelman, 1992). First, we develop a biologically plausible extension of the HyperBF model that takes into account basic features of the functional architecture of early vision. Second, we explore various learning modes that can coexist within the HyperBF framework and focus on two unsupervised learning rules which may be involved in hyperacuity learning. Finally, we report results of psychophysical experiments that are consistent with the hypothesis that activity-dependent presynaptic amplification may be involved in perceptual learning in hyperacuity. 
Title: Title: Models of perceptual learning in vernier hyperacuity  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Cortical Mechanisms of Visual Recognition and Learning: A Hierarchical Kalman Filter Model  
Abstract dynamic recognition based the statistical theory Kalman filtering from optimal control theory The model utilizes a hierarchical network whose successive levels implement Kalman filters operating successively spatial Each hierarchical level predicts the cu
Paper 3  Title: A Model of Invariant Object Recognition in the Visual System  
Abstract: Neurons the ventral stream the primate visual system exhibit responses the images objects which invariant with natural transformations such translation size view Anatomical and neurophysiological evidence this is achieved hierarchical processing areas In elucidate the manner such representation
Paper 4  Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  
Abstract The sensorimotor integration system can viewed an observer attempting estimate its own state integrating multiple sources We describe a computational framework capturing this notion some specific models integration adaptation result Psychophysical results two sensorimotor systems subserving the i
Paper 5  Title: A Neural Network Model of Memory Consolidation  
Abstract Some forms memory rely temporarily a system brain structures located includes The recall recent events one task relies crucially As the event becomes recent the medial temporal lobe becomes critical the recall the recollection appears rely mor
Paper 6  Title: Multiassociative Memory  
Abstract how implement connectionist models Traditional symbolic approaches wield explicit representation all alternatives via stored links or implicitly enumerative algorithms Classical pattern association models ignore the issue generating multiple outputs
Paper 7  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract A novel architecture and set learning rules The model based the idea multiple information channels modulate plasticity Features learned bottom-up information sources can thus influenced those learned contextual pathways vice A maximum likelihood cost function allows this scheme
Label: Neural Networks
Paper 8  Title: VISIT: An Efficient Computational Model of Human Visual Attention  
Abstract: One for models cognitive phenomena the development efficient and exible interfaces low level sensory information For visual processing researchers argued an attentional mechanism perform many high level vision This thesis presents VISIT, a connectionist model covert vi
Label: Neural Networks
Paper 9  Title: Objective Function Formulation of the BCM Theory of Visual Cortical Plasticity: Statistical Connections, Stability Conditions  
Abstract In an objective function formulation the BCM theory visual cortical plasticity permits demonstrate the connection the unsupervised BCM learning procedure various statistical methods in that of Projection Pursuit This formulation provides a general method stability analysis the fixed points the theory enables
Paper 10  Title: 3D Object Recognition Using Unsupervised Feature Extraction  
Abstract Intrator (1990 proposed a feature extraction method related recent statistical theoryHuber 1985 Friedman a biologically motivated modelBienenstock 1982 This method has recently applied feature extraction in the context recognizing 3D objects single 2D views (Intrator Gold, 1991 Here we descri
Paper 11  Title: Optimising Local Hebbian Learning: use the ffi-rule  
Abstract Many the lower-level areas the mammalian visual system organized retinotopically that as maps which preserve to A unit that such a retinotopic map normally responds selectively stimulation a well-delimited part referred its receptive fieldRF Receptive fields probably the mo
Label: Neural Networks
Paper 12  Title: A Neural Network Model of Visual Tilt Aftereffects  
Abstract RF-LISSOM, laterally connected orientation maps in the psychological phenomenon known the tilt aftereffect The same self-organizing processes are the map its lateral connections shown result tilt aftereffects over in the adult. The
Paper 13  Title: CNN: a Neural Architecture that Learns Multiple Transformations of Spatial Representations  
Abstract Many the lower-level areas the mammalian visual system organized retinotopically that as maps which preserve to A unit that such a retinotopic map normally responds selectively stimulation a well-delimited part referred its receptive fieldRF Receptive fields probably the mo
Paper 14  Title: Combining Neural Network Forecasts on Wavelet-Transformed Time Series  
Abstract Many the lower-level areas the mammalian visual system organized retinotopically that as maps which preserve to A unit that such a retinotopic map normally responds selectively stimulation a well-delimited part referred its receptive fieldRF Receptive fields probably the mo
Label: Neural Networks
Paper 15  Title: On the Computational Utility of Consciousness  
Abstract We propose human consciousness This framework integrates many existing theoretical perspectives yet sufficiently concrete simulation experiments We do attempt explain qualia (subjective experience ask differences the cognitive information processing system when consc
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 2612...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper overviews a proposed architecture for adaptive parallel logic referred to as ASOCS (Adaptive Self-Organizing Concurrent System). The ASOCS approach is based on an adaptive network composed of many simple computing elements which operate in a parallel asynchronous fashion. Problem specification is given to the system by presenting if-then rules in the form of boolean conjunctions. Rules are added incrementally and the system adapts to the changing rule-base. Adaptation and data processing form two separate phases of operation. During processing the system acts as a parallel hardware circuit. The adaptation process is distributed amongst the computing elements and efficiently exploits parallelism. Adaptation is done in a self-organizing fashion and takes place in time linear with the depth of the network. This paper summarizes the overall ASOCS concept and overviews three specific architectures. 
Title: Title: Models of Parallel Adaptive Logic  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Self-Adjusting Dynamic Logic Module  
Abstract: an ASOCS (Adaptive Self-Organizing Concurrent System massively parallel processing incrementally defined rule systems such areas adaptive logic robotics logical inference dynamic control An ASOCS is an adaptive network composed many simple computing elements operating This paper focuses Adaptive Algorit
Paper 3  Title: A Self-Organizing Binary Decision Tree For Incrementally Defined Rule Based  
Abstract: an ASOCS (adaptive self-organizing concurrent system massively parallel processing incrementally defined rule systems such areas adaptive logic robotics logical inference dynamic control An ASOCS is an adaptive network composed many simple computing elements operating This paper focuses adaptive algorit
Paper 4  Title: Digital Neural Networks  
Abstract: Demands applications requiring massive parallelism symbolic environments given rebirth research models labeled neura l networks These models many simple nodes highly interconnected such that computation data amongst To present, most models proposed nodes based simple analog functions wh
Paper 5  Title: ASOCS: A Multilayered Connectionist Network with Guaranteed Learning of Arbitrary Mappings  
Abstract features a new class multilayer connectionist architectures known ASOCS ASOCS is similar most decision-making neural network models attempts learn an adaptive set arbitrary vector mappings However differs dramatically its mechanisms ASOCS is based networks adaptive digital elemen
Label: Neural Networks
Paper 6  Title: Priority ASOCS  ASOCS models have two significant advantages over other learning models:  
Abstract an ASOCS (Adaptive Self-Organizing Concurrent System massively parallel processing incrementally defined rule systems such areas adaptive logic robotics logical inference dynamic control An ASOCS is an adaptive network composed many simple computing elements operating An ASOCS can operate either a data
Paper 7  Title: A VLSI Implementation of a Parallel, Self-Organizing Learning Model  
Abstract a VLSI implementation the Priority Adaptive Self-Organizing Concurrent System learning model built a multi-chip module (MCM) substrate Many current hardware implementations neural network learning models direct implementations structures|a large number simple computing nodes connected a dense number o
Label: Neural Networks
Paper 8  Title: Massively Parallel Matching of Knowledge Structures  
Abstract: As knowledge bases used AI systems increase access relevant information the dominant factor the cost inference This especially analogical (or case-based) reasoning in the ability perform inference efficient and flexible access a large base exemplars (cases judged likely relevant solving proble
Paper 9  Title: Planning by Incremental Dynamic Programming  
Abstract the basic results ideas dynamic programming as they most the concerns planning AI These form the theoretical basis the incremental planning methods the integrated architecture Dyna. These incremental planning methods continually an evaluation function the situation-action mapping a reactive syst
Paper 10  Title: Multiple Network Systems (Minos) Modules: Task Division and Module Discrimination 1  
Abstract It considered an ultimate connectionist objective incorporate neural networks intelligent systems These systems intended possess a varied repertoire enabling adaptable interaction The first step this direction develop various neural network algorithms models combine such networks int
Paper 11  Title: A Multi-Chip Module Implementation of a Neural Network  
Abstract The requirement dense interconnect in artificial neural network systems led seek This paper an implementation using multi-chip modules the interconnect medium The specific system described self parallel dynamic learning model which requires a dense interconnect technology effective
Label: Neural Networks
Paper 12  Title: EVOLVING NEURAL NETWORKS WITH COLLABORATIVE SPECIES  
Abstract We a coevolutionary architecture solving decomposable problems and apply the evolution Although this work preliminary it non-coevolutionary approaches The coevolutionary approach utilizes in species representing simpler subtasks evolved separate insta
Paper 13  Title: A Neural Network Architecture for Syntax Analysis  
Abstract: Artificial neural networks due potential fault tolerance offer an attractive paradigm robust and efficient implementations large modern database and knowledge base systems This paper explores efficient implementation a database query system The application the proposed model a high-speed library query
Label: Neural Networks
Paper 14  Title: Towards a General Distributed Platform for Learning and Generalization and Word Perfect Corp. 1 Introduction
Abstract Different learning models employ generalization on novel inputs This paper the need multiple styles generalization support a broad application base The Priority ASOCS model overviewed a potential platform which multiple generalization styles PASOCS is an adaptiv
Paper 15  Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  
Abstract Deterministic Context-free (DCF) Grammars a Connectionist paradigm a Recurrent Neural Network Pushdown AutomatonNNPDA The NNPDA consists a recurrent neural network connected an external stack memory through a common error function We show the NNPDA able learn the dynamics an underlying pushdown automaton
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 34...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper demonstrates the exploitation of certain vision processing techniques to index into a case base of surfaces. The surfaces are the result of reinforcement learning and represent the optimum choice of actions to achieve some goal from anywhere in the state space. This paper shows how strong features that occur in the interaction of the system with its environment can be detected early in the learning process. Such features allow the system to identify when an identical, or very similar, task has been solved previously and to retrieve the relevant surface. This results in an orders of magnitude increase in learning rate. 
Title: Title: Using a Case Base of Surfaces to Speed-Up Reinforcement Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Expectation-Based Selective Attention for Visual Monitoring and Control of a Robot Vehicle  
Abstract: Reliable vision-based control an autonomous vehicle focus an input scene Previous work with an autonomous lane following system ALVINN [Pomerleau 1993 yielded This paper based learning approach handling difficult scenes which will co
Label: Neural Networks
Paper 3  Title: Finding Structure in Reinforcement Learning  
Abstract Reinforcement learning addresses select actions order unknown environments To scale reinforcement learning complex real-world tasks such typically studied AI one ultimately be discover the structure in in abstract the myriad details to operate more tractable problem
Paper 4  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract We reinforcement learning the policies considered the learning process constrained hierarchies partially specified machines This allows for prior knowledge reduce the search space provides a framework in transferred problems in component solutions recombined larger a
Paper 5  Title: Experiments on the Transfer of Knowledge between Neural Networks Reprinted from: Computational Learning Theory and
Abstract This chapter three studies which address neural network learning via the incorporation information extracted other networks This general problem network transfer encompasses relationships source target networks Our focus the utilization weights from source networks which solve a sub
Paper 6  Title: Modeling the Student with Reinforcement Learning  
Abstract We describe a methodology enabling an intelligent teaching system make high level strategy decisions on low level student modeling information This framework less costly construct superior hand coding teaching strategies as responsive In order accomplish reinforcement learning associate sup
Paper 7  Title: Using Mixtures of Factor Analyzers for Segmentation and Pose Estimation  Category: Visual Processing Preference: Oral  
Abstract To read a hand-written digit string it segment separate digits Bottom-up segmentation heuristics often neighboring digits substantially We describe has each digit class we the only knowledge required segmentation The system uses Gibbs sampling construct a percept
Label: Neural Networks
Paper 8  Title: Learning One More Thing  
Abstract Most research machine learning scenarios faces a single, isolated learning task The lifelong learning framework assumes encounters a multitude related learning tasks over providing the opportunity the transfer among these. This paper studies lifelong learning binary classification
Paper 9  Title: Learning Viewpoint Invariant Face Representations from Visual Experience by Temporal Association  
Abstract natural visual experience different views face tend appear close temporal proximity A set simulations presented demonstrate how viewpoint invariant representations faces developed visual experience by capturing the input patterns The simulations explored temporal smoothing activi
Paper 10  Title: Planning by Incremental Dynamic Programming  
Abstract the basic results ideas dynamic programming as they most the concerns planning AI These form the theoretical basis the incremental planning methods the integrated architecture Dyna. These incremental planning methods continually an evaluation function the situation-action mapping a reactive syst
Paper 11  Title: Solving Combinatorial Optimization Tasks by Reinforcement Learning: A General Methodology Applied to Resource-Constrained Scheduling  
Abstract introduces a methodology solving through reinforcement learning methods The approach can cases several similar instances a combinatorial optimization problem must The key idea analyze a set "training problem instances learn a search control policy solving new problem
Paper 12  Title: Scaling Reinforcement Learning Algorithms by Learning Variable Temporal Resolution Models  
Abstract The close connection reinforcement dynamic programming algorithms fueled research RL within Yet increased theoretical understanding RL algorithms applicable simple tasks only In the abstract framework afforded the connection to dynamic programming the scaling is
Label: Reinforcement Learning
Paper 13  Title: Learning Concepts from Sensor Data of a Mobile Robot  
Abstract Machine learning the flexibility robot applications Many approaches applying robotics known Some approaches enhance the planning capabilities. Other approaches enhance the control basic actions. In contrast the approach presented thi
Paper 14  Title: Evolution, Learning, and Instinct: 100 Years of the Baldwin Effect Using Learning to Facilitate the
Abstract a hybrid methodology integrates genetic algorithms decision tree learning evolve useful subsets discriminatory features for recognizing complex visual concepts A genetic algorithm (GA search the space all possible subsets candidate discrimination features Candidate feature subsets evaluated using C4.5
Label: Genetic Algorithms
Paper 15  Title: Learning in Continuous Domains with Delayed Rewards  
Abstract Much done learning techniques delayed reward problems worlds the actions states approximated discrete representations Although acceptable some applications there such an approximation difficult unnatural For instance applications robotic,s where real machines the re
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 1082...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: program w.r.t. positive and negative examples can be viewed as the problem of pruning an SLD-tree such that all refutations of negative examples and no refutations of positive examples are excluded. It is shown that the actual pruning can be performed by applying unfolding and clause removal. The algorithm spectre is presented, which is based on this idea. The input to the algorithm is, besides a logic program and positive and negative examples, a computation rule, which determines the shape of the SLD-tree that is to be pruned. It is shown that the generality of the resulting specialization is dependent on the computation rule, and experimental results are presented from using three different computation rules. The experiments indicate that the computation rule should be formulated so that the number of applications of unfolding is kept as low as possible. The algorithm, which uses a divide-and-conquer method, is also compared with a covering algorithm. The experiments show that a higher predictive accuracy can be achieved if the focus is on discriminating positive from negative examples rather than on achieving a high coverage of positive examples only. 
Title: Title: Specialization of Logic Programs by Pruning SLD-Trees  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Specialization of Recursive Predicates  
Abstract When specializing a recursive predicate order exclude a set negative examples without excluding may not specialize or remove the clauses a refutation any positive exam ples A previously proposed solution apply program transformation in order obtain nonrecurs
Paper 3  Title: Theory-Guided Induction of Logic Programs by Inference of Regular Languages recursive clauses. merlin on the
Abstract resent allowed sequences resolution steps the initial theory There, many characterizations allowed sequences resolution steps expressed a set resolvents One approach presented, the system mer-lin an earlier technique learning finite-state automata that represent allowed sequences resolution step
Paper 4  Title: Predicate Invention and Learning from Positive Examples Only  
Abstract: Previous bias shift approaches predicate invention applicable learning positive examples only if a complete hypothesis found the given language as negative examples required determine new predicates should One approach presented, MERLIN a successor a system in predicate invention i
Label: Rule Learning
Paper 5  Title: Bottom-up induction of logic programs with more than one recursive clause  
Abstract In a bottom-up algorithm called MRI induce logic programs from their examples This method induce programs with a base clause from examples MRI based saturations examples It first generates a path structure a stream processed predicates
Label: Rule Learning
Paper 6  Title: Learning Decision Trees from Decision Rules:  
Abstract: A method and initial results from ABSTRACT A standard approach determining decision trees learn them examples A disadvantage once a decision tree learned modify different decision making situations Such problems arise, for an attribute assigned some node measured
Label: Rule Learning
Paper 7  Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some
Abstract covering has In well and compared the covering technique a logic programming framework Covering works repeatedly specializing an overly general hypothesis on each iteration focusing finding a clause a high coverage positive examples Divide- works special
Label: Genetic Algorithms
Paper 8  Title: THE DISCOVERY OF ALGORITHMIC PROBABILITY  
Abstract covering has In well and compared the covering technique a logic programming framework Covering works repeatedly specializing an overly general hypothesis on each iteration focusing finding a clause a high coverage positive examples Divide- works special
Paper 9  Title: Covering vs. Divide-and-Conquer for Top-Down Induction of Logic Programs  
Abstract covering has In well and compared the covering technique a logic programming framework Covering works repeatedly specializing an overly general hypothesis on each iteration focusing finding a clause a high coverage positive examples Divide- works special
Paper 10  Title: ILP with Noise and Fixed Example Size: A Bayesian Approach  
Abstract Current inductive logic programming systems limited noise employ a greedy covering approach constructing the hypothesis one clause This approach also causes difficulty learning recursive predicates Additionally many current systems an implicit expectation the cardinality reflect the "prop
Paper 11  Title: Structural Regression Trees  
Abstract many real domains the task a theory predicting numerical values particular several standard test domains used Inductive Logic Programming concerned predicting numerical values examples relational and mostly non-determinate background knowledge However so far no ILP algorithm except can number
Label: Rule Learning
Paper 12  Title: Constructing Intermediate Concepts by Decomposition of Real Functions  
Abstract In learning from examples it expand an attribute-vector representation intermediate concepts The usual advantage such structuring of the learning problem easier improves the comprehensibility induced descriptions In develop discovering useful intermediate concepts when both class at
Paper 13  Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,
Abstract Although probabilistic inference a general Bayesian belief network inference computation time reduced most practical cases exploiting domain knowledge by making the knowledge representation In this paper the property similarity states a new method approximate knowledge representation whic
Label: Theory
Paper 14  Title: Machine Learning 27(1):51-68, 1997. Predicting nearly as well as the best pruning of a decision tree  
Abstract Many algorithms inferring a decision tree involve grown which typically ends "over To reduce overfitting in the tree using one available methods The final tree then output and used classification on test data In this paper suggest an alte
Label: Theory
Paper 15  Title: Symposium Title: Tutorial Discourse What Makes Human Explanations Effective?  
Abstract Many state ILP systems require large numbers negative examples avoid This a considerable disadvantage many ILP applications namely indu ctive program synthesis where relativelly small and sparse example sets a more realistic scenario Integrity constraints first order clauses play negative examples
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 2082...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract:  
Title: Title: %A L. Ingber %T Adaptive simulated annealing (ASA): Lessons learned %J Control and Cybernetics Annealing
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Genetic Algorithms, Tournament Selection, and the Effects of Noise  
Abstract IlliGAL Report July 1995
Paper 3  Title: CABeN: A Collection of Algorithms for Belief Networks  Correspond with:  
Abstract: Portions this report the Fifteenth Annual Symposium Computer Applications in Medical CareNovember, 1991
Paper 4  Title: A Survey of Parallel Genetic Algorithms  
Abstract IlliGAL Report May 1997
Paper 5  Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  
 NO 947 June 5
Paper 6  Title: Cognitive Computation (Extended Abstract)  
Abstract: Cognitive computation discussed a discipline links together neurobiology
Paper 7  Title: MML mixture modelling of multi-state, Poisson, von Mises circular and Gaussian distributions  
Abstract 11] Overmars. A random approach motion planning Technical Report RUU-CS-92-32, Department October 1992
Paper 8  Title: References Linear Controller Design, Limits of Performance, "The parallel projection operators of a nonlinear feedback
Abstract 13] Yang Sussmann Sontag linear systems bounded controls Proc Nonlinear Control Systems Design Symp., Bordeaux June 1992 Fliess Ed IFAC Publications pp 1520 Journal version to appear IEEE Trans Autom. Control.
Paper 9  Title: 99-113. Construction of Phylogenetic Trees, Science, Fitting the Gene Lineage Into Its Species Lineage. A
Abstract 6] Farach and Thorup, 1993. Fast Comparison Evolutionary Trees, Technical Report 9346 DIMACS Rutgers University
Paper 10  Title: OBSERVABILITY IN RECURRENT NEURAL NETWORKS  
Abstract Report SYCON-92-07rev ABSTRACT We obtain a characterization observability appear neural networks research
Paper 11  Title: Environments with Classifier Systems (Experiments on Adding Memory to XCS)  
Abstract: Pier Luca Lanzi Technical Report N. 97.45 October th
Paper 12  Title: Learning an Optimally Accurate Representational System  
Abstract Multigrid Q-Learning Charles W. Anderson Stewart G. CS-94121 October
Paper 13  Title: Use of Analogy in Automated Theorem Proving  
Abstract: Technical Report ATP-90, Artificial Intelligence Laboratory University Texas
Paper 14  Title: NEURAL NETS AS SYSTEMS MODELS AND CONTROLLERS suitability of "neural nets" as models for dynamical
Abstract briefly surveys relevant
Paper 15  Title: Classification of EEG Signals Using a Sparse Polynomial Builder  
Abstract Edward S. Orosz Charles Anderson Technical Report CS-94111 April
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 466...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Following terminology used in adaptive control, we distinguish between indirect learning methods, which learn explicit models of the dynamic structure of the system to be controlled, and direct learning methods, which do not. We compare an existing indirect method, which uses a conventional dynamic programming algorithm, with a closely related direct reinforcement learning method by applying both methods to an infinite horizon Markov decision problem with unknown state-transition probabilities. The simulations show that although the direct method requires much less space and dramatically less computation per control action, its learning ability in this task is superior to, or compares favorably with, that of the more complex indirect method. Although these results do not address how the methods' performances compare as problems become more difficult, they suggest that given a fixed amount of computational power available per control action, it may be better to use a direct reinforcement learning method augmented with indirect techniques than to devote all available resources to a computation-ally costly indirect method. Comprehensive answers to the questions raised by this study depend on many factors making up the eco nomic context of the computation.
Title: Title: On the Computational Economics of Reinforcement Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Reinforcement Learning Algorithms for Average-Payoff Markovian Decision Processes  
Abstract Reinforcement learningRL become solving learning-control problems robotics RL researchers focussed almost problems where the controller maximize the discounted sum payoffs However as emphasized Schwartz (1993 in many problems those for the optimal behavior a limit cycle
Label: Reinforcement Learning
Paper 3  Title: A Teaching Strategy for Memory-Based Control  
Abstract Combining different machine learning algorithms in benefits above either method alone This paper demonstrates genetic algorithms conjunction lazy learning solve examples a difficult class delayed reinforcement learning problems better either method This class, the class differentia
Paper 4  Title: Toward Learning Systems That Integrate Different Strategies and Representations TR93-22  
Abstract Temporal difference (TD) methods constitute learning predictions multi-step prediction problems parameterized a recency factor. Currently the most important application these methods temporal credit assignment reinforcement learning Well known reinforcement learning algorithms AHC Q-learning may viewed instances TD learnin
Paper 5  Title: A Statistical Approach to Solving the EBL Utility Problem  
Abstract Many "learning from systems use information problem solving experiences modify a performance element PE forming PE 0 solve more However transformations that improve one set problems degrade the new PE 0 is better
Paper 6  Title: Machine Learning,  Reinforcement Learning with Replacing Eligibility Traces  
Abstract The eligibility trace one used reinforcement learning handle delayed reward In this paper introduce eligibility trace the replacing trace analyze it theoretically results faster, more reliable learning Both kinds trace assign credit prior events according how recently occu
Label: Reinforcement Learning
Paper 7  Title: Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems  
Abstract Increasing attention reinforcement learning algorithms partly successes the theoretical analysis their behavior Markov environments If the Markov assumption removed however neither generally the algorithms the analyses continue usable We propose and analyze a new learning algorithm solve a certain class non-Markov d
Paper 8  Title: NEUROCONTROL BY REINFORCEMENT LEARNING  
Abstract: Reinforcement learningRL a model-free tuning adaptation method control dynamic systems Contrary supervised learning based usually gradient descent techniques RL does any model or sensitivity function of Hence RL can applied systems poorly uncertain nonlinear for untractable with
Paper 9  Title: Gain Adaptation Beats Least Squares?  
Abstract I present computational results suggesting gain-adaptation algorithms based in connectionist learning methods improve over least squares other classical parameter-estimation methods The new algorithms evaluated with respect classical methods along requ
Label: Neural Networks
Paper 10  Title: INCREMENTAL POLYNOMIAL CONTROLLER NETWORKS: two self-organising non-linear controllers  
Abstract Temporal difference (TD) methods constitute learning predictions multi-step prediction problems parameterized a recency factor. Currently the most important application these methods temporal credit assignment reinforcement learning Well known reinforcement learning algorithms AHC Q-learning may viewed instances TD learnin
Label: Neural Networks
Paper 11  Title: Truncating Temporal Differences: On the Efficient Implementation of TD() for Reinforcement Learning  
Abstract Temporal difference (TD) methods constitute learning predictions multi-step prediction problems parameterized a recency factor. Currently the most important application these methods temporal credit assignment reinforcement learning Well known reinforcement learning algorithms AHC Q-learning may viewed instances TD learnin
Paper 12  Title: Modeling the Student with Reinforcement Learning  
Abstract We describe a methodology enabling an intelligent teaching system make high level strategy decisions on low level student modeling information This framework less costly construct superior hand coding teaching strategies as responsive In order accomplish reinforcement learning associate sup
Paper 13  Title: PUSH-PULL SHUNTING MODEL OF GANGLION CELLS Simulations of X and Y retinal ganglion cell behavior
Abstract We three new algorithms setting ff, temporal-difference learning methods such TD(). The overall task that learning predict an unknown Markov chain based repeated observations its state trajectories The new algorithms select step-size parameters online normall
Label: Neural Networks
Paper 14  Title: Gas Identification System using Graded Temperature Sensor and Neural Net Interpretation  
Abstract We three new algorithms setting ff, temporal-difference learning methods such TD(). The overall task that learning predict an unknown Markov chain based repeated observations its state trajectories The new algorithms select step-size parameters online normall
Label: Neural Networks
Paper 15  Title: Online Learning with Random Representations  
Abstract We consider the requirements online learning|learning which must done incrementally realtime the results learning available soon each new example acquired Despite the abundance methods learning from examples effectively online learning as components reinforcement learning systems Most of these few, incl
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 2598...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Research into the utility of non-coding segments, or introns, in genetic-based encodings has shown that they expedite the evolution of solutions in domains by protecting building blocks against destructive crossover. We consider a genetic programming system where non-coding segments can be removed, and the resultant chromosomes returned into the population. This parsimonious repair leads to premature convergence, since as we remove the naturally occurring non-coding segments, we strip away their protective backup feature. We then duplicate the coding segments in the repaired chromosomes, and place the modified chromosomes into the population. The duplication method significantly improves the learning rate in the domain we have considered. We also show that this method can be applied to other domains.
Title: Title: Duplication of Coding Segments in Genetic Programming  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Recognizing Handwritten Digit Strings Using Modular Spatio-temporal Connectionist Networks  
Abstract: Research the utility non-coding segments, introns genetic-based encodings expedite solutions domains by protecting building against destructive crossover We consider a genetic programming system where removed the resultant chromosomes returned This parsimonious repair leads
Paper 3  Title: A comparison of the fixed and floating building block representation in the genetic algorithm  
Abstract compares the traditional, fixed problem representation style a genetic algorithmGA a new floating representation in not specific locations the individuals of In addition the effects non-coding segments both of these representations is studied Non-coding segments a computational mode
Paper 4  Title: Hybridized Crossover-Based Search Techniques for Program Discovery  
Abstract In address program discovery as Genetic Programming [10 We two major results by combining a hierarchical crossover operator two traditional single point search algorithms: Simulated Annealing Stochastic Iterated Hill Climbing solved some problems fewer fitness evaluations a greater probability a success
Label: Genetic Algorithms
Paper 5  Title: Empirical studies of the genetic algorithm with non-coding segments  
Abstract The genetic algorithm (GA a problem solving method modelled after the process We interested studying the GA: non-coding segments GA performance Non-coding segments segments bits an individual that provide no contribution, positive the fitness that individual Previous research
Label: Genetic Algorithms
Paper 6  Title: Testing the Robustness of the Genetic Algorithm on the Floating Building Block Representation.  
Abstract Recent studies on a floating building block representation for the genetic algorithm (GA suggest there many advantages This paper investigates the behavior the GA on floating representation problems response three different types pressures reduction genetic material during the problem
Label: Genetic Algorithms
Paper 7  Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  
Abstract Genetic algorithms solve hard optimization problems ranging the Travelling Salesman problem the Quadratic Assignment problem We show the Simple Genetic Algorithm solve derived the 3-Conjunctive Normal Form problem By separating the populations into small sub parallel genetic algorithms exploits
Paper 8  Title: Culling Teaching -1 Culling and Teaching in Neuro-evolution  
Abstract: The evolving population neural nets contains information not in genes the collection behaviors of the population members Such information thought culture of the population Two ways exploiting that culture explored Culling overlarge litters: Generate offspring different crossovers q
Label: Genetic Algorithms
Paper 9  Title: Induction of decision trees using RELIEFF  
Abstract An investigation the dynamics Genetic Programming applied chaotic time series prediction reported An interesting characteristic adaptive search techniques perform well many problem domains while failing Because Genetic Programming's flexible tree structure any particular problem represented myriad forms These representati
Paper 10  Title: Learning Representations for Evolutionary Computation an example from the domain of two-dimensional shape designs. In
Abstract: Evolutionary systems used applications turbine design scheduling problems The basic algorithms similar all these applications the representation always problem specific Unfortunately the search time evolutionary systems very much efficient codings using problem specific domain knowledge reduce the size
Paper 11  Title: A Study of Genetic Algorithms to Find Approximate Solutions to Hard 3CNF Problems  
Abstract Genetic algorithms solve hard optimization problems ranging the Travelling Salesman problem the Quadratic Assignment problem We show the Simple Genetic Algorithm solve derived the 3-Conjunctive Normal Form problem By separating the populations into small sub parallel genetic algorithms exploits
Paper 12  Title: Balancing Accuracy and Parsimony in Genetic Programming 1  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 13  Title: Dynamics of Co-evolutionary Learning  
Abstract Co-evolutionary learning, the embedding adaptive learning agents a fitness environment which dynamically responds their progress a potential solution many technological chicken and at several recent and surprising successes Sim's artificial robot Tesauro's backgammon player We recently solved the two spirals
Paper 14  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 15  Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Abstract Holland's analysis the sources power of genetic algorithms served guidance the applications The technique applying a recombination operatorcrossover a population individuals a key that power Neverless there contradictory results concerning crossover operators with respect overall p
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1217...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A control law is constructed for a linear time varying system by solving a two player zero sum differential game on a moving horizon, the game being that which is used to construct an H 1 controller on a finite horizon. Conditions are given under which this controller results in a stable system and satisfies an infinite horizon H 1 norm bound. A risk sensitive formulation is used to provide a state estimator in the observation feedback case.
Title: Title: A game theoretic approach to moving horizon control  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Robust performance and adaptation using receding horizon H 1 control of time varying systems.  
Abstract construct suboptimal H 1 controllers which satisfy a new robust performance condition the receding horizon technique A method H 1 controllers online making the exact plant model only on a finite interval extending based the two Riccati differential equation solution to the finite horizon H
Paper 3  Title: Adaptive Wavelet Control of Nonlinear Systems  
Abstract considers the design analysis adaptive wavelet control algorithms uncertain nonlinear dynamical systems The Lyapunov synthesis approach a state-feedback adaptive control scheme nonlinearly parametrized wavelet network models Semi-global stability results obtained under the key assumption the system uncertainty satisfies a "matc
Paper 4  Title: CONTROL-LYAPUNOV FUNCTIONS FOR TIME-VARYING SET STABILIZATION  
Abstract shows, time varying systems global asymptotic controllability to a given closed subset the state space equivalent the existence a continuous control-Lyapunov function respect.
Paper 5  Title: On Finite Gain Stabilizability of Linear Systems Subject to Input Saturation  
Abstract deals (global) finite-gain input/output stabilization linear systems saturated controls For neutrally stable systems shown the linear feedback law suggested the passivity approach indeed stability respect every L p -norm. Explicit bounds closed-loop gains obtained, related the norms the respective system
Paper 6  Title: Avoiding Saturation By Trajectory Reparameterization  
Abstract The problem trajectory tracking the presence input constraints considered The desired trajectory reparameterized on a slower time scale in input saturation that the reparameterizing function derived. The deviation the nominal trajectory minimized formulating an optimal control problem
Paper 7  Title: Identification in H 1 with Nonuniformly Spaced Frequency Response Measurements  
Abstract the problem "system identification in H 1 " when the given frequency response data necessarily on A large class robustly convergent identification algorithms derived A particular algorithm further examined explicit worst error boundsin the H 1 norm derived both disc
Paper 8  Title: Incremental methods for computing bounds in partially observable Markov decision processes  
Abstract Partially observable Markov decision processes allow one model complex dynamic decision or control include both action outcome uncertainty imperfect observabil-ity The control problem formulated combining costs or rewards from In, analyse various increm
Label: Reinforcement Learning
Paper 9  Title: An Optimal Weighting Criterion of Case Indexing for Both Numeric and Symbolic Attributes  
Abstract A General Result on Linear Systems Bounded Controls 1 ABSTRACT We controllers globally stabilize subject control saturation We allow essentially arbitrary saturation functions The only conditions imposed the system the obvious necessary ones the uncontrolled system
Paper 10  Title: Rapid Quality Estimation of Neural Network Input Representations  
Abstract: FURTHER RESULTS CONTROLLABILITY PROPERTIES DISCRETE-TIME NONLINEAR SYSTEMS fl ABSTRACT Controllability questions In particular continue the search conditions the group-like notion transitivity implies the stronger and semigroup-like property forward accessibility We show this implicatio
Label: Neural Networks
Paper 11  Title: PAC Adaptive Control of Linear Systems  
Abstract We consider reinforcement learning where the environment can described The states the environment the actions the agent perform represented real vectors the system dynamic given The problem equivalent the so-called linear quadratic regulator problem studied the opt
Paper 12  Title: Journal of Convex Analysis (accepted for publication) A HYBRID PROJECTION-PROXIMAL POINT ALGORITHM  
Abstract We propose a modification the classical proximal point algorithm finding a maximal monotone operator In particular an approximate proximal point iteration construct strictly separates the current iterate the solution set This step then a projection the current iterate onto the separ
Label: Neural Networks
Paper 13  Title: A REMARK ON ROBUST STABILIZATION OF GENERAL ASYMPTOTICALLY CONTROLLABLE SYSTEMS  
Abstract It shown recently by Clarke Ledyaev Sontag Subbotin any asymptotically controllable system stabilized means a certain type discontinuous feedback The feedback laws constructed that work robust with actuator errors as to perturbations the system dynamics A drawback, they may highly errors
Paper 14  Title: Worst-Case Identification of Nonlinear Fading Memory Systems  
Abstract the problem for a class fading memory systems bounded noise studied For any experiment the worst-case error characterized in the diameter set Optimal inputs that minimize the radius uncertainty studied characterized Finally, a convergent algorithm does re
Paper 15  Title: OPTIMAL ASYMPTOTIC IDENTIFICATION UNDER BOUNDED DISTURBANCES  
Abstract the intrinsic limitation worst-case identification LTI systems data corrupted bounded disturbances when the unknown plant belong This done analyzing achievable performing experiments any bounded inputs estimating the plant using any identification
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Category: Reinforcement Learning
Prediction:  Category: Reinforcement Learning
Is prediction correct?  False

Prediction: 0
Processing index 2470...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We describe recent extensions to our framework for the automatic generation of music-making programs. We have previously used genetic programming techniques to produce music-making programs that satisfy user-provided critical criteria. In this paper we describe new work on the use of connectionist techniques to automatically induce musical structure from a corpus. We show how the resulting neural networks can be used as critics that drive our genetic programming system. We argue that this framework can potentially support the induction and recapitulation of deep structural features of music. We present some initial results produced using neural and hybrid symbolic/neural critics, and we discuss directions for future work.
Title: Title: Induction and Recapitulation of Deep Musical Structure  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: ILA: Combining Inductive Learning with Prior Knowledge and Reasoning  
Abstract recent extensions our framework the automatic generation music-making programs We previously used genetic programming techniques music-making programs satisfy user-provided critical criteria In new work connectionist techniques automatically induce musical structure from. We show resulti
Label: Case Based
Paper 3  Title: Cultural Transmission of Information in Genetic Programming  
Abstract shows the performance a genetic programming system through the addition mechanisms non-genetic transmission information (culture Teller has previously shown genetic programming systems enhanced through the addition memory mechanisms for individual programs [Teller 1994 in mem
Paper 4  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract We reinforcement learning the policies considered the learning process constrained hierarchies partially specified machines This allows for prior knowledge reduce the search space provides a framework in transferred problems in component solutions recombined larger a
Paper 5  Title: Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email  
Abstract by a dialogue agent learn choose an optimal dialogue strategy While it widely agreed dialogue strategies should formulated terms communicative intentions little work automatically optimizing an agent's choices when there multiple ways realize Our method a co
Label: Reinforcement Learning
Paper 6  Title: Knowledge Acquisition with a Knowledge-Intensive Machine Learning System  
Abstract In the integration knowledge acquisition machine learning techniques. We argue existing machine learning techniques made as knowledge acquisition tools allowing the expert have and interaction We describe a number extensions FOCLa multistrategy Horn-clause learning prog
Label: Rule Learning
Paper 7  Title: Robot Shaping: Developing Situated Agents through Learning  
Abstract Learning plays situated agents In reinforcement learning "shape a robot a predefined target behavior We connect both simulated and real robots A LECSYS a parallel implementation a learning classifier system with an extended genetic algorithm After classifying different kinds Animat-like behav
Paper 8  Title: Evolution of Mapmaking: Learning, planning, and memory using Genetic Programming  
Abstract: An essential component an intelligent agent observe encode use Traditional approaches Genetic Programming have evolving functional or reactive programs with only a minimal use state This paper investigating the evolution learning, planning memory Genetic Programming The
Paper 9  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 10  Title: Evolution of Pseudo-colouring Algorithms for Image Enhancement with Interactive Genetic Programming  
Abstract: Technical Report CSRP-97-5 School The University Birmingham Abstract In the interactive development programs image enhancement Genetic Programming pseudo-colour transformations In our approach the user drives GP by deciding should the winner tournament selection The presence
Label: Genetic Algorithms
Paper 11  Title: Learning Search-Control Heuristics for Logic Programs: Applications to Speedup Learning and Language Acquisition  
Abstract, learning search-control heuristics logic programs improve both the efficiency accuracy knowledge-based systems expressed definite-clause logic programs The approach combines techniques explanation-based learning recent advances inductive logic programming learn clause-selection heuristics guid
Paper 12  Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  
Abstract Mixed-initiative systems present the challenge finding an effective level interaction humans computers Machine learning presents in systems automatically adapt accommodate different users In learning user models an adaptive assistant crisis sched
Paper 13  Title: Adaptive Strategy Selection for Concept Learning  
Abstract In explore genetic algorithms ( construct called GABIL that continually learns concept classification rules from its interac - tion The performance this system compared two other concept learnersNEWGEM C4.5 a suite target concepts From this comparison identify strategies respo
Paper 14  Title: Evolution, Learning, and Instinct: 100 Years of the Baldwin Effect Using Learning to Facilitate the
Abstract a hybrid methodology integrates genetic algorithms decision tree learning evolve useful subsets discriminatory features for recognizing complex visual concepts A genetic algorithm (GA search the space all possible subsets candidate discrimination features Candidate feature subsets evaluated using C4.5
Label: Genetic Algorithms
Paper 15  Title: Experiments on the Transfer of Knowledge between Neural Networks Reprinted from: Computational Learning Theory and
Abstract This chapter three studies which address neural network learning via the incorporation information extracted other networks This general problem network transfer encompasses relationships source target networks Our focus the utilization weights from source networks which solve a sub
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 600...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The place fields of hippocampal cells in old animals sometimes change when an animal is removed from and then returned to an environment [ Barnes et al., 1997 ] . The ensemble correlation between two sequential visits to the same environment shows a strong bimodality for old animals (near 0, indicative of remapping, and greater than 0.7, indicative of a similar representation between experiences), but a strong unimodality for young animals (greater than 0.7, indicative of a similar representation between experiences). One explanation for this is the multi-map hypothesis in which multiple maps are encoded in the hippocampus: old animals may sometimes be returning to the wrong map. A theory proposed by Samsonovich and McNaughton (1997) suggests that the Barnes et al. experiment implies that the maps are pre-wired in the CA3 region of hippocampus. Here, we offer an alternative explanation in which orthogonalization properties in the dentate gyrus (DG) region of hippocampus interact with errors in self-localization (reset of the path integrator on re-entry into the environment) to produce the bimodality. 
Title: Title: Separating hippocampal maps  Spatial Functions of the Hippocampal Formation and the  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Model of Visually Guided Plasticity of the Auditory Spatial Map in the Barn Owl  
Abstract In the barn owl the auditory map of space in the external nucleusICx strongly vision the nature this interaction In this paper a biologically plausible and mini-malistic model ICx self-organization where receives a learn signal based the owl's visual attention When the
Label: Neural Networks
Paper 3  Title: Learning Harmonic Progression Using Markov Models EECS545 Project  
Abstract It argued the memorization events situations ( requires the rapid formation neural circuits responsive binding errors binding matches While the formation circuits responsive binding matches modeled associative learning mechanisms the rapid formation binding errors difficult given their seem
Paper 4  Title: Learning Viewpoint Invariant Representations of Faces in an Attractor Network  
Abstract natural visual experience different views tend appear close temporal proximity as an animal We investigated an attractor network acquire view invariant visual representations by first neighbors a pattern sequence The pattern sequence contains successive views faces ten individual
Paper 5  Title: Task and Spatial Frequency Effects on Face Specialization  
Abstract There face processing localized The double dissociation a face recognition deficit occurring after brain damage visual object agnosia difficulty recognizing other kinds complex objects indicates face and non-face object recognition served partially independent mechanisms in Is neural speci
Paper 6  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract A novel architecture and set learning rules The model based the idea multiple information channels modulate plasticity Features learned bottom-up information sources can thus influenced those learned contextual pathways vice A maximum likelihood cost function allows this scheme
Label: Neural Networks
Paper 7  Title: Rapid learning of binding-match and binding-error detector circuits via long-term potentiation  
Abstract It argued the memorization events situations ( requires the rapid formation neural circuits responsive binding errors binding matches While the formation circuits responsive binding matches modeled associative learning mechanisms the rapid formation binding errors difficult given their seem
Paper 8  Title: A Neural Network Model of Visual Tilt Aftereffects  
Abstract RF-LISSOM, laterally connected orientation maps in the psychological phenomenon known the tilt aftereffect The same self-organizing processes are the map its lateral connections shown result tilt aftereffects over in the adult. The
Paper 9  Title: A Neural Network Model of Memory Consolidation  
Abstract Some forms memory rely temporarily a system brain structures located includes The recall recent events one task relies crucially As the event becomes recent the medial temporal lobe becomes critical the recall the recollection appears rely mor
Paper 10  Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  
Abstract The map from eye brain in topographic i.e. neighbouring points to In addition when two eyes innervate the same target structure the two sets fibres segregate ocular dominance stripes Experimental evidence the frog goldfish suggests these two phenomena subserved W
Paper 11  Title: Composite Geometric Concepts and Polynomial Predictability  
Abstract In representational and methodological issues a attractor network model the mapping from orthography semantics based [Plaut 1995 We find, contrary psycholinguistic studies the response time concrete wordsrepresented more 1 bits the output pattern slower This model also predicts response t
Paper 12  Title: Self-Organization and Segmentation in a Laterally Connected Orientation Map of Spiking Neurons  
Abstract The RF-SLISSOM model integrates two separate lines computational modeling Laterally connected self-organizing maps model how afferent structures such orientation columns simultaneously self through input-driven Hebbian adaptation Spiking neurons with leaky integrator synapses be
Label: Neural Networks
Paper 13  Title: Hidden Markov Modeling of simultaneously recorded cells in the Associative cortex of behaving monkeys  
Abstract A widely held idea regarding information processing the cell-assembly hypothesis suggested Hebb in 1949 According this hypothesis the basic unit information processing an assembly cells can act briefly a closed system in This work presents characterizing this supposed activity usin
Label: Neural Networks
Paper 14  Title: Learning Viewpoint Invariant Face Representations from Visual Experience by Temporal Association  
Abstract natural visual experience different views face tend appear close temporal proximity A set simulations presented demonstrate how viewpoint invariant representations faces developed visual experience by capturing the input patterns The simulations explored temporal smoothing activi
Paper 15  Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  
Abstract The sensorimotor integration system can viewed an observer attempting estimate its own state integrating multiple sources We describe a computational framework capturing this notion some specific models integration adaptation result Psychophysical results two sensorimotor systems subserving the i
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 2647...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Dynamic programming provides a methodology to develop planners and controllers for nonlinear systems. However, general dynamic programming is computationally intractable. We have developed procedures that allow more complex planning and control problems to be solved. We use second order local trajectory optimization to generate locally optimal plans and local models of the value function and its derivatives. We maintain global consistency of the local models of the value function, guaranteeing that our locally optimal plans are actually globally optimal, up to the resolution of our search procedures.
Title: Title: Using Local Trajectory Optimizers To Speed Up Global Optimization In Dynamic Programming  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Approximating Value Trees in Structured Dynamic Programming  
Abstract and examine approximate dynamic programming Markov decision processes structured problem representations We assume an MDP represented using a dynamic Bayesian network construct value functions decision trees our function representation The size the representation kept pruning these value trees tha
Paper 3  Title: Generalized Queries on Probabilistic Context-Free Grammars  on Pattern Analysis and Machine Intelligence  
Abstract methods efficiently better solutions control problems continuous state spaces We provide algorithms exploit online search boost very approximate value functions discovered We examine local searches where the agent a finite-depth lookahead search global sea
Paper 4  Title: Incremental methods for computing bounds in partially observable Markov decision processes  
Abstract Partially observable Markov decision processes allow one model complex dynamic decision or control include both action outcome uncertainty imperfect observabil-ity The control problem formulated combining costs or rewards from In, analyse various increm
Label: Reinforcement Learning
Paper 5  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract We reinforcement learning the policies considered the learning process constrained hierarchies partially specified machines This allows for prior knowledge reduce the search space provides a framework in transferred problems in component solutions recombined larger a
Paper 6  Title: Applying Online Search Techniques to Continuous-State Reinforcement Learning key to the success of the local
Abstract methods efficiently better solutions control problems continuous state spaces We provide algorithms exploit online search boost very approximate value functions discovered We examine local searches where the agent a finite-depth lookahead search global sea
Paper 7  Title: Spurious Solutions to the Bellman Equation  
Abstract Reinforcement learning algorithms often work finding functions satisfy the Bellman equation This yields prediction with for controlling a Markov decision process states actions This approach frequently Markov chains MDPs with infinite states We show, Bellma
Paper 8  Title: Intelligent Gradient-Based Search of Incompletely Defined Design Spaces  
Abstract Gradient-based numerical optimization complex engineering designs offers rapidly producing However such methods generally assume the objective function and constraint functions continuous smooth defined everywhere Unfortunately realistic simulators violate present intelligently co
Paper 9  Title: Exploiting Structure in Policy Construction  
Abstract Markov decision processes recently applied the problem modeling decision-theoretic planning While traditional methods solving MDPs practical small states spaces their effectiveness large AI planning problems We present an algorithm, structured policy iteration constructs optimal policies without explicit e
Label: Probabilistic Methods
Paper 10  Title: Structured Reachability Analysis for Markov Decision Processes  
Abstract Recent research decision theoretic planning focussed making the solution Markov decision processes ( feasible We develop a family algorithms structured reachability analysis MDPs that suitable when an initial state (or set Using compact, structured representations MDPs our methods, vary
Paper 11  Title: Planning by Incremental Dynamic Programming  
Abstract the basic results ideas dynamic programming as they most the concerns planning AI These form the theoretical basis the incremental planning methods the integrated architecture Dyna. These incremental planning methods continually an evaluation function the situation-action mapping a reactive syst
Paper 12  Title: Constructive Neural Network Learning Algorithms for Multi-Category Real-Valued Pattern Classification  
Abstract Prioritized sweeping attempts focus achieve a good estimate environment states To choose effectively where a costly planning step classic prioritized sweeping uses a simple heuristic focus computation the states the largest errors
Paper 13  Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  
Abstract Genetic algorithms solve hard optimization problems ranging the Travelling Salesman problem the Quadratic Assignment problem We show the Simple Genetic Algorithm solve derived the 3-Conjunctive Normal Form problem By separating the populations into small sub parallel genetic algorithms exploits
Paper 14  Title: Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems  
Abstract Increasing attention reinforcement learning algorithms partly successes the theoretical analysis their behavior Markov environments If the Markov assumption removed however neither generally the algorithms the analyses continue usable We propose and analyze a new learning algorithm solve a certain class non-Markov d
Paper 15  Title: A Study of Genetic Algorithms to Find Approximate Solutions to Hard 3CNF Problems  
Abstract Genetic algorithms solve hard optimization problems ranging the Travelling Salesman problem the Quadratic Assignment problem We show the Simple Genetic Algorithm solve derived the 3-Conjunctive Normal Form problem By separating the populations into small sub parallel genetic algorithms exploits
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 335...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper outlines some problems that may occur with Reduced Error Pruning in relational learning algorithms, most notably efficiency. Thereafter a new method, Incremental Reduced Error Pruning, is proposed that attempts to address all of these problems. Experiments show that in many noisy domains this method is much more efficient than alternative algorithms, along with a slight gain in accuracy. However, the experiments show as well that the use of the algorithm cannot be recommended for domains which require a very specific concept description.
Title: Title: Incremental Reduced Error Pruning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Incremental Reduced Error Pruning  
Abstract outlines some problems occur Reduced Error Pruning Inductive Logic Programming most notably efficiency Thereafter a new method, Incremental Reduced Error Pruning attempts address all Experiments show in many noisy domains this method much alternative algorithms along a slight gain a
Paper 3  Title: More Efficient Windowing  
Abstract Windowing has proposed a procedure efficient memory use the ID3 decision tree learning However previous work windowing may often a decrease performance In this work try argue separate-and-conquer rule learning algorithms more appropriate windowing learn rules indepen
Paper 4  Title: Top-Down Pruning in Relational Learning  
Abstract Pruning dealing noise Machine Learning Recently pruning algorithms, in particular Reduced Error Pruning also attracted Inductive Logic Programming However has shown these methods inefficient most is for generating clauses explain noisy examples subsequently p
Paper 5  Title: Instance Pruning Techniques  
Abstract The nearest neighbor algorithm and often quite successful learning a concept and providing on subsequent input vectors However these techniques often retain the entire training memory resulting large memory requirements a sensitivity noise This paper
Paper 6  Title: Fossil: A Robust Relational Learner  
Abstract The research reported describes Fossil, an ILP system uses a search heuristic based statistical correlation This algorithm implements learning useful concepts the presence noise In contrast Foil's stopping criterion allows theories grow the size propose
Paper 7  Title: The Utility of Feature Weighting in Nearest-Neighbor Algorithms  
Abstract Nearest-neighbor algorithms known depend their distance metric In a weighted Euclidean metric which for comes options We describe Diet, an algorithm directs search through a space discrete weights using as its evaluation function Although a large set
Paper 8  Title: Rule Induction with CN2: Some Recent Improvements  
Abstract The CN2 algorithm induces an ordered list classification rules from examples using entropy its search heuristic In this short paper two improvements this algorithm Firstly present the Laplacian error estimate secondly unordered as ordered rules generated We experimentally demonst
Paper 9  Title: Chapter 1 Reinforcement Learning for Planning and Control  
Abstract In a method feature subset selection Information Theory Initially a framework defining theoretically optimal, computation-ally intractable, method feature subset selection presented We show our goal should eliminate a feature if gives beyond subsumed the remaining featur
Paper 10  Title: Associative Reinforcement Learning: A Generate and Test Algorithm  
Abstract An agent must learn act the world by trial faces the reinforcement learning problem quite standard concept learning Although good algorithms exist this problem in quite inefficient do exhibit generalization One strategy find restricted classes action policies learned more eff
Paper 11  Title: Regression Can Build Predictive Causal Models  
Abstract Covariance information an algorithm search predictive causal models estimate This information should discarded after conditional independence constraints identified is usual contemporary causal induction algorithms Our fbd algorithm combines covariance information an effective heuristic build ca
Paper 12  Title: Learning Approximate Control Rules Of High Utility  
Abstract One the area explanation based learning the utility problem; learning too many rules of low utility swamping degradation performance This paper introduces improving the utility learned rules The first technique combine EBL inductive learning techniques a better set control rules;
Paper 13  Title: Using Partitioning to Speed Up Specific-to-General Rule Induction  
Abstract RISEDomingos 1995 in a rule induction proceeds gradually generalizing rules, starting per example This has several advantages compared gradually specializing initially null rules has lead significant accuracy gains algorithms C4.5RULES CN2 in application doma
Paper 14  Title: The Effective Size of a Neural Network: A Principal Component Approach  
Abstract Often learning from data attaches a penalty term prefer simple models and prevent Current penalty terms neural networks however often take account weight interaction This a critical drawback since the effective number parameters usually differs dramatically poss
Paper 15  Title: Extending Theory Refinement to M-of-N Rules  
Abstract In machine learning research started addressing a problem known theory refinement The goal a theory refinement learner modify an incomplete or incorrect rule base representing a domain theory consistent input training examples This paper a major revision the Either propositional theory refinement system Two issues ar
Label: Rule Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 815...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The application of adaptive optimization strategies to scheduling in manufacturing systems has recently become a research topic of broad interest. Population based approaches to scheduling predominantly treat static data models, whereas real-world scheduling tends to be a dynamic problem. This paper briefly outlines the application of a genetic algorithm to the dynamic job shop problem arising in production scheduling. First we sketch a genetic algorithm which can handle release times of jobs. In a second step a preceding simulation method is used to improve the performance of the algorithm. Finally the job shop is regarded as a nondeterministic optimization problem arising from the occurrence of job releases. Temporal Decomposition leads to a scheduling control that interweaves both simulation in time and genetic search.
Title: Title: Genetic Algorithm based Scheduling in a Dynamic Manufacturing Environment  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Value Function Based Production Scheduling  
Abstract Production scheduling the problem sequentially a factory forecasted demands throughout The requirement maintaining product inventories unpredictable demand stochastic factory output makes standard scheduling models job-shop, inadequate. Currently applied algorithms simulated
Paper 3  Title: An evolutionary tabu search algorithm and the NHL scheduling problem  
Abstract We in a new evolutionary procedure solving combines efficiently the mechanisms genetic algorithms tabu search In explore the solution space properly interaction phases periods optimization An adaptation this search principle to National Hockey problem
Paper 4  Title: On Genetic Programming of Fuzzy Rule-Based Systems for Intelligent Control  
Abstract Fuzzy logic evolutionary computation proven convenient tools handling designing control systems respectively An approach is presented attributes for developing intelligent control systems The potential the genetic programming paradigm (GP learning rules use fuzzy logic controll
Paper 5  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract In Operation Research and Artificial Intelligence several stochastic search algorithms designed based global random searchZhigljavsky Basically those techniques iteratively sample the search space with respect a probability distribution which updated according previous samples some predefined strategy Genetic
Paper 6  Title: Solving Combinatorial Optimization Tasks by Reinforcement Learning: A General Methodology Applied to Resource-Constrained Scheduling  
Abstract introduces a methodology solving through reinforcement learning methods The approach can cases several similar instances a combinatorial optimization problem must The key idea analyze a set "training problem instances learn a search control policy solving new problem
Paper 7  Title: A Genetic Algorithm for Continuous Design Space Search  
Abstract Genetic algorithms ( extensively performing global optimization a simple yet reliable manner However some realistic engineering design optimization domains the simple, classical implementation a GA based binary encoding bit mutation and crossover often inefficient unable reach the global optimum In a GA
Label: Genetic Algorithms
Paper 8  Title: AN APPROACH TO A PROBLEM IN NETWORK DESIGN USING GENETIC ALGORITHMS  
Abstract Air Traffic Control involved the real-time planning aircraft trajectories This a heavily constrained optimization problem We concentrate free-route planning in aircraft not way points The choice a proper representation this real-world problem non We propose a two level representation: one level on evolutionary
Paper 9  Title: Evolutionary Computation in Air Traffic Control Planning  
Abstract Air Traffic Control involved the real-time planning aircraft trajectories This a heavily constrained optimization problem We concentrate free-route planning in aircraft not way points The choice a proper representation this real-world problem non We propose a two level representation: one level on evolutionary
Paper 10  Title: Adaptation of Genetic Algorithms for Engineering Design Optimization  
Abstract Genetic algorithms extensively different domains as doing global optimization However some realistic engineering design optimization domains was observed a simple classical implementation the GA based binary encoding bit mutation and crossover sometimes inefficient unable reach
Paper 11  Title: A GENETIC ALGORITHM FOR FRAGMENT ALLOCATION IN A DISTRIBUTED DATABASE SYSTEM  
Abstract In explore the distributed database allocation problem intractable. We also discuss genetic algorithms have successfully Our experimental results the GA to far the greedy heuristic obtaining optimal and near optimal fragment placements the allocation problem with various data sets
Label: Genetic Algorithms
Paper 12  Title: A Genetic Local Search Approach to the Quadratic Assignment Problem  
Abstract Augmenting genetic algorithms local search heuristics the solution In this paper a genetic local search approach the quadratic assignment problemQAP New genetic operators for realizing the approach described, its performance tested various QAP instances containing between 256
Paper 13  Title: Balancing Accuracy and Parsimony in Genetic Programming 1  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 14  Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 15  Title: Signal Path Oriented Approach for Generation of Dynamic Process Models  
Abstract The article at hand a tool automatic generation structured models complex dynamic processes means genetic programming In contrast other techniques genetic programming find an appropriate arithmetic expression order describe this tool a block oriented approach with a transparent descript
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1841...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Reinforcement learning (RL) algorithms provide a sound theoretical basis for building learning control architectures for embedded agents. Unfortunately all of the theory and much of the practice (see Barto et al., 1983, for an exception) of RL is limited to Marko-vian decision processes (MDPs). Many real-world decision tasks, however, are inherently non-Markovian, i.e., the state of the environment is only incompletely known to the learning agent. In this paper we consider only partially observable MDPs (POMDPs), a useful class of non-Markovian decision processes. Most previous approaches to such problems have combined computationally expensive state-estimation techniques with learning control. This paper investigates learning in POMDPs without resorting to any form of state estimation. We present results about what TD(0) and Q-learning will do when applied to POMDPs. It is shown that the conventional discounted RL framework is inadequate to deal with POMDPs. Finally we develop a new framework for learning without state-estimation in POMDPs by including stochastic policies in the search space, and by defining the value or utility of a dis tribution over states.
Title: Title: Learning Without State-Estimation in Partially Observable Markovian Decision Processes  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems  
Abstract Increasing attention reinforcement learning algorithms partly successes the theoretical analysis their behavior Markov environments If the Markov assumption removed however neither generally the algorithms the analyses continue usable We propose and analyze a new learning algorithm solve a certain class non-Markov d
Paper 3  Title: Generalized Markov Decision Processes: Dynamic-programming and Reinforcement-learning Algorithms  
Abstract The problem maximizing the expected total discounted reward a completely observable Markovian environmentmdp models a particular class sequential decision problems Algorithms have making optimal decisions mdps given either an mdp specification the opportunity interact over Recently, other sequen
Label: Reinforcement Learning
Paper 4  Title: Approximating Optimal Policies for Partially Observable Stochastic Domains  
Abstract The problem making optimal decisions uncertain conditions central Artificial Intelligence If the state the world known all times can modeled a Markov Decision Process MDPs studied many methods known determining optimal courses or policies The more realistic case where state information only par
Paper 5  Title: Parallel Search for Neural Network  Under the guidance of  
Abstract The problem making optimal decisions uncertain conditions central Artificial Intelligence If the state the world known all times can modeled a Markov Decision Process MDPs studied many methods known determining optimal courses or policies The more realistic case where state information only par
Paper 6  Title: Connectionist Modeling of the Fast Mapping Phenomenon  
Abstract The problem making optimal decisions uncertain conditions central Artificial Intelligence If the state the world known all times can modeled a Markov Decision Process MDPs studied many methods known determining optimal courses or policies The more realistic case where state information only par
Paper 7  Title: TD Models: Modeling the World at a Mixture of Time Scales  
Abstract Temporal-difference (TD) learning can not rewards as is commonly states, to learn a model the world's dynamics We present theory algorithms intermixing TD models the world at different levels temporal abstraction within a single structure Such multi-scale TD models model-b
Paper 8  Title: Between MDPs and Semi-MDPs: Learning, Planning, and Representing Knowledge at Multiple Temporal Scales  
Abstract Learning, planning representing knowledge at temporal abstraction key challenges AI In this paper develop these problems based the mathematical framework reinforcement learning Markov decision processes We extend the usual notion action options|whole courses behavior temporally extended sto
Label: Reinforcement Learning
Paper 9  Title: Planning with Closed-Loop Macro Actions  
Abstract: Planning learning at temporal abstraction In summarize an approach based the mathematical framework Markov decision processes reinforcement learning Conventional model-based reinforcement learning uses primitive actions last one time step that modeled independentl
Label: Reinforcement Learning
Paper 10  Title: Markov games as a framework for multi-agent reinforcement learning  
Abstract In the Markov decision process (MDP) formalization reinforcement learning single adaptive agent interacts defined In this solipsistic view secondary agents only part the environment fixed The framework Markov games allows widen this view multiple adaptive
Paper 11  Title: Reinforcement Learning Algorithms for Average-Payoff Markovian Decision Processes  
Abstract Reinforcement learningRL become solving learning-control problems robotics RL researchers focussed almost problems where the controller maximize the discounted sum payoffs However as emphasized Schwartz (1993 in many problems those for the optimal behavior a limit cycle
Label: Reinforcement Learning
Paper 12  Title: Learning policies for partially observable environments: Scaling up  
Abstract Partially observable Markov decision processespomdp's) model decision problems which tries maximize limited and/or noisy sensor feedback While the study pomdp's is motivated address realistic problems existing techniques finding optimal behavior appear scale and unable find satisfactory policies
Paper 13  Title: Exploiting Structure in Policy Construction  
Abstract Markov decision processes recently applied the problem modeling decision-theoretic planning While traditional methods solving MDPs practical small states spaces their effectiveness large AI planning problems We present an algorithm, structured policy iteration constructs optimal policies without explicit e
Label: Probabilistic Methods
Paper 14  Title: Learning Conventions in Multiagent Stochastic Domains using Likelihood Estimates  
Abstract Fully cooperative multiagent systemsthose in a joint utility modelis of AI A key problem of ensuring the actions individual agents especially settings autonomous decision makers We investigate approaches learning coordinated strategies where no
Paper 15  Title: Learning Curve Bounds for Markov Decision Processes with Undiscounted Rewards  
Abstract Markov decision processes with undis-counted rewards represent problems and The goal learning in these MDPs find a policy yields per In large state spaces computing these averages directly is the agent estimate them stochastic exploration the state spa
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 658...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Simple modification of standard hill climbing optimization algorithm by taking into account learning features is discussed. Basic concept of this approach is the socalled probability vector, its single entries determine probabilities of appearance of '1' entries in n-bit vectors. This vector is used for the random generation of n-bit vectors that form a neighborhood (specified by the given probability vector). Within the neighborhood a few best solutions (with smallest functional values of a minimized function) are recorded. The feature of learning is introduced here so that the probability vector is updated by a formal analogue of Hebbian learning rule, well-known in the theory of artificial neural networks. The process is repeated until the probability vector entries are close either to zero or to one. The resulting probability vector unambiguously determines an n-bit vector which may be interpreted as an optimal solution of the given optimization task. Resemblance with genetic algorithms is discussed. Effectiveness of the proposed method is illustrated by an example of looking for global minima of a highly multimodal function. 
Title: Title: Hill Climbing with Learning (An Abstraction of Genetic Algorithm)  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Towards Automatic Discovery of Building Blocks in Genetic Programming  
Abstract an algorithm the discovery building genetic programmingGP called adaptive representation through learningARL The central idea ARL the adaptation the problem representation, extending terminals functions with The set extracts common knowledge emerging during the evolutiona
Paper 3  Title: Genetic Programming and Redundancy  
Abstract The Genetic Programming optimization method elaborated John Koza [ Koza 1992 The search space the problem domain consists computer programs represented parse trees the crossover operator realized an exchange subtrees Empirical analyses show large parts those trees never used or evaluated which t
Paper 4  Title: 21 Using n 2 classifier in constructive induction  
Abstract In constructive induction The idea an improvement classification accuracy based iterative modification input data space This process independently repeated n classes Finally gives (n 2 n)/2 input data subspaces of attributes dedicated optimal discrimination appropriate pairs cla
Label: Theory
Paper 5  Title: Optimal Mutation Rates in Genetic Search  
Abstract The optimization a single bit string means iterated mutation and selection the best (a (1+1)-Genetic Algorithm discussed with three simple fitness functions The counting ones problem a standard binary encoded integer a Gray coded integer optimization problem A mutation rate schedule that optimal with the success probability mutation
Paper 6  Title: Control of Parallel Population Dynamics by Social-Like Behavior of GA-Individuals  
Abstract A frequently observed difficulty the application genetic algorithms optimization arises premature convergence In preserve genotype diversity develop for individuals In this model a population member an active individual assumes social-like behavior patterns Different individuals living po
Paper 7  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 8  Title: A Generalized Permutation Approach to Job Shop Scheduling with Genetic Algorithms  
Abstract order sequence the tasks a job shop problemJSP on machines related the technological machine order jobs a new representation technique mathematically knownpermutation with repetition The main advantage this single chromosome representation in analogy the permutation scheme the traveling salesman problemTSP it p
Label: Genetic Algorithms
Paper 9  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Label: Genetic Algorithms
Paper 10  Title: [12] J. Whittaker. Graphical Models in Applied Mathematical Multivariate Statis-  
Abstract Self-organizing feature maps usually the low-level neural and parallel distributed processes An external supervisor finds whose weight vector closest in Euclidian distance the neighborhood weight adaptation The weights changed proportional biologically more plausible im
Paper 11  Title: Simple Genetic Programming for Supervised Learning Problems  
Abstract finding learning rules to several supervised tasks In this approach potential solutions represented variable length mathematical LISP S-expressions Thus similar Genetic ProgrammingGP but employs non-problem-specific functions In this paper three Monk's and parity proble
Paper 12  Title: Stochastic Decomposition of DNA Sequences Using Hidden Markov Models  
Abstract for characterizing an important property natural DNA sequences compositional inhomogeneity Compositional segments often correspond meaningful biological units Taking into such inhomogeneity is successful recognition functional features DNA sequences Here p
Label: Neural Networks
Paper 13  Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Abstract Genetic algorithms neural networks two main ways optimize train the weights a fixed architecture While most previous work focuses only of these two options investigates an alternative evolutionary approach called Breeder Genetic Programming the architecture and the weights optimized simult
Paper 14  Title: Hyperplane Dynamics as a Means to Understanding Back-Propagation Learning and Network Plasticity  
Abstract The processing performed interpreted through use decision hyperplanes at each layer The adaptation process however normally explained the picture gradient descent of an error landscape In the dynamics the decision hyperplanes used A electro-mechanical analogy whe
Paper 15  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract In Operation Research and Artificial Intelligence several stochastic search algorithms designed based global random searchZhigljavsky Basically those techniques iteratively sample the search space with respect a probability distribution which updated according previous samples some predefined strategy Genetic
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1733...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We provide a generic Monte Carlo method to find the alternative of maximum expected utility in a decision analysis. We define an artificial distribution on the product space of alternatives and states, and show that the optimal alternative is the mode of the implied marginal distribution on the alternatives. After drawing a sample from the artificial distribution, we may use exploratory data analysis tools to approximately identify the optimal alternative. We illustrate our method for some important types of influence diagrams. (Decision Analysis, Influence Diagrams, Markov chain Monte Carlo, Simulation) 
Title: Title: Decision Analysis by Augmented Probability Simulation  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Chaos, Fractals, and Genetic Algorithms  
Abstract exact solutions and convergent approximations inferences associated finitely generated convex sets distributions Robust Bayesian inference the calculation bounds posterior values given The paper presents exact inference algorithms analyzes the circumstances exact bec
Label: Genetic Algorithms
Paper 3  Title: Maximum Working Likelihood Inference with Markov Chain Monte Carlo  
Abstract Maximum working likelihood (MWL) inference the presence missing data can quite the intractability the associated marginal likelihood This problem can further the number parameters involved We propose using first obtain both the MWL estimator the working Fisher information matrix an
Label: Probabilistic Methods
Paper 4  Title: Estimating Bayes Factors via Posterior Simulation with the Laplace-Metropolis Estimator  
Abstract The key quantity needed Bayesian hypothesis testing and model selection the marginal likelihood for, also the integrated likelihood the data In a way posterior simulation output marginal likelihoods We describe the basic Laplace-Metropolis estimator models without random effects For m
Label: Probabilistic Methods
Paper 5  Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  
Abstract New methodology fully Bayesian mixture analysis developed making reversible jump Markov chain Monte Carlo methods that capable jumping between the parameter subspaces corresponding different numbers components A sample from the full joint distribution all unknown variables thereby generated this can a thorough
Paper 6  Title: Robustness Analysis of Bayesian Networks with Finitely Generated Convex Sets of Distributions  
Abstract exact solutions and convergent approximations inferences associated finitely generated convex sets distributions Robust Bayesian inference the calculation bounds posterior values given The paper presents exact inference algorithms analyzes the circumstances exact bec
Label: Probabilistic Methods
Paper 7  Title: Markov Chain Monte Carlo Model Determination for Hierarchical and Graphical Log-linear Models  
Abstract comparing models involves calculating For high-dimensional contingency tables the set plausible models very We focus attention reversible jump Markov chain Monte Carlo (Green 1995 develop strategies calculating hierarchical, graphical or decomposable log-linea
Label: Probabilistic Methods
Paper 8  Title: Adaptive Markov Chain Monte Carlo through Regeneration  Summary  
Abstract evaluating expectations functions interest under. This done calculating averages the sample path having as its stationary distribution For computational efficiency should rapidly mixing This can sometimes achieved only careful design the transition kernel
Paper 9  Title: Von Mises type statistics for single site updated local interaction random fields  
Abstract: Random field models image analysis spatial statistics usually local interactions They simulated Markov chains which update a single site The updating rules typically condition on only a few neighboring sites If approximate the expectation a bounded function can the simulations through We
Paper 10  Title: Bayesian Mixture Modeling by Monte Carlo Simulation  
Abstract It shown from modeled a mixture distribution feasibly via This method exhibits the true Bayesian predictive distribution implicitly integrating over An infinite number mixture components without difficulty a prior distribution mixing propor
Paper 11  Title: Outperforming the Gibbs sampler empirical estimator for nearest neighbor random fields  
Abstract Given a Markov chain sampling scheme does the standard empirical estimator make We show this so and construct better estimators We restrict attention nearest neighbor random fields Gibbs samplers deterministic sweep applies reversible variableat updating with The str
Label: Probabilistic Methods
Paper 12  Title: MARKOV CHAIN MONTE CARLO SAMPLING FOR EVALUATING MULTIDIMENSIONAL INTEGRALS WITH APPLICATION TO BAYESIAN COMPUTATION  
Abstract Recently sampling methods determining properties a posterior distribution Alternative to the Gibbs sampler we elaborate the Hit-and-Run sampler its generalization, a black sampling to generate a posterior distribution The proof convergence and its applications B
Paper 13  Title: Adaptation for Self Regenerative MCMC  SUMMARY  
Abstract The self regenerative MCMC a tool constructing a given stationary distribution by constructing. Elements the auxiliary chain picked a suitable random number so the stationary distribution, Sahu and Zhigljavsky In provide a generic ad
Paper 14  Title: Auxiliary Variable Methods for Markov Chain Monte Carlo with Applications  
Abstract Suppose one sample the density (x using An auxiliary variable u and its conditional distributionujx giving the joint distributionx; = A MCMC scheme samples over this joint distribution can lead substantial gains efficiency compared standard approaches The revolutionary algorithm Swendsen
Label: Probabilistic Methods
Paper 15  Title: GIBBS-MARKOV MODELS  
Abstract building parameterized context-dependent probabilities Gibbs distributions used model state transitions output generation parameter estimation carried an EM algorithm where the M-step uses a generalized iterative scaling procedure We discuss relations certain classes stochastic feedf
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 2597...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Instance-based learning techniques typically handle continuous and linear input values well, but often do not handle nominal input attributes appropriately. The Value Difference Metric (VDM) was designed to find reasonable distance values between nominal attribute values, but it largely ignores continuous attributes, requiring discretization to map continuous values into nominal values. This paper proposes three new heterogeneous distance functions, called the Heterogeneous Value Difference Metric (HVDM), the Interpolated Value Difference Metric (IVDM), and the Windowed Value Difference Metric (WVDM). These new distance functions are designed to handle applications with nominal attributes, continuous attributes, or both. In experiments on 48 applications the new distance metrics achieve higher classification accuracy on average than three previous distance functions on those datasets that have both nominal and continuous attributes.
Title: Title: Improved Heterogeneous Distance Functions  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Optimal Weighting Criterion of Case Indexing for Both Numeric and Symbolic Attributes  
Abstract Indexing cases is Memory-Based Reasoning(MBR One key problem how assign weights attributes cases Although several weighting methods some methods handle numeric attributes directly so discretize numeric values by classification Furthermore existing methods no theoretical background little ca
Label: Case Based
Paper 3  Title: A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features  
Abstract nearest neighbor algorithms learning examples worked domains all features had numeric values such domains the examples can treated points distance metrics can use standard definitions symbolic domains a more sophisticated treatment the feature space We introduce a nearest neighbor learning in do
Paper 4  Title: AN EFFICIENT METRIC FOR HETEROGENEOUS INDUCTIVE LEARNING APPLICATIONS IN THE ATTRIBUTE-VALUE LANGUAGE 1  
Abstract Many inductive learning problems expressed the classical attribute-value language In learn and to generalize learning systems often some measure similarity their current knowledge base The attribute-value language defines a heterogeneous multidimensional input space some attributes nominal linear Defining
Label: Case Based
Paper 5  Title: Continuous-valued Xof-N Attributes Versus Nominal Xof-N Attributes for Constructive Induction: A Case Study  
Abstract An Xof-N is For a given instance its value corresponds its attribute-value pairs that true In explore performance continuous-valued Xof-N attributes versus constructive induction Nominal Xof-Ns more representationally powerful continu
Paper 6  Title: A Review and Empirical Evaluation of Feature Weighting Methods for a Class of Lazy Learning Algorithms  
Abstract Many lazy learning algorithms derivatives uses generate predictions from stored instances Several studies k-NN's performance highly sensitive the definition its distance function Many k-NN variants proposed reduce this sensitivity parameterizing the distance function w
Paper 7  Title: Supervised and Unsupervised Discretization of Continuous Features  
Abstract Many supervised machine learning algorithms require a discrete feature space In this paper review continuous feature discretization identify defining characteristics the methods conduct several methods We compare binning, entropy-based and purity-based methods supervised algori
Label: Theory
Paper 8  Title: Constructing Nominal Xof-N Attributes  
Abstract Most constructive induction researchers focus only new boolean attributes This paper a new constructive induction algorithm called XofN constructs new nominal attributes An Xof-N containing For a given instance its value corresponds its attribute-value pairs that tru
Paper 9  Title: Search-based Class Discretization  
Abstract We a methodology enables classification algorithms on regression tasks We implement system RECLA that transforms a regression problem classification one and an existent classification system solve The transformation consists mapping a continuous variable grouping
Paper 10  Title: Using Real-Valued Genetic Algorithms to Evolve Rule Sets for Classification  
Abstract In use a genetic algorithm evolve classification rules with real-valued attributes We show real-valued attribute ranges encoded present a new uniform method representing do cares the rules We view supervised classification an optimization problem evolve rule sets maximize correct class
Label: Genetic Algorithms
Paper 11  Title: Effects of Different Types of New Attribute on Constructive Induction  
Abstract studies on decision tree learning constructing four types attribute (conjunctive Mof-N Xof-N representations To reduce effects other factors tree learning methods new attribute search strategies evaluation functions stopping criteria a single tree learning With different option settings c
Paper 12  Title: The Utility of Feature Weighting in Nearest-Neighbor Algorithms  
Abstract Nearest-neighbor algorithms known depend their distance metric In a weighted Euclidean metric which for comes options We describe Diet, an algorithm directs search through a space discrete weights using as its evaluation function Although a large set
Paper 13  Title: In Proceedings of the 1997 Sian Kaan International Workshop on Neural Networks and Neurocontrol. Real-Valued
Abstract 2 Neural Network & Laboratory Computer Science Department Brigham Young University Provo 84602 Abstract. Many neural network models must finding yield high accuracy on Other learning models require weights on input attributes yield high lea
Paper 14  Title: Bayesian Network Classification with Continuous Attributes: Getting the Best of Both Discretization and Parametric Fitting  
Abstract In Friedman, Geiger Goldszmidt [8 introduced a classifier Bayesian networks called Tree Augmented Naive Bayes performs competitively C4.5 other state methods This classifier has several advantages including robustness polynomial computational complexity One limitation the TAN classifier i
Label: Probabilistic Methods
Paper 15  Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  
Abstract With computational costs without accuracy describe two algorithms find sets prototypes nearest neighbor classification Here the term prototypes the reference instances a nearest neighbor computation the instances with respect which similarity assessed assign a new data item Both algorithms re
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 11...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper presents an evolutionary approach to finding learning rules to several supervised tasks. In this approach potential solutions are represented as variable length mathematical LISP S-expressions. Thus, it is similar to Genetic Programming (GP) but it employs a fixed set of non-problem-specific functions to solve a variety of problems. In this paper three Monk's and parity problems are tested. The results indicate the usefulness of the encoding schema in discovering learning rules for supervised learning problems with the emphasis on hard learning problems. The problems and future research directions are discussed within the context of GP practices. 
Title: Title: Simple Genetic Programming for Supervised Learning Problems  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Evolving Compact Solutions in Genetic Programming: A Case Study  
Abstract Genetic programmingGP genetic algorithms where handled trees This makes GP especially evolving functional relationships or computer programs both represented trees Symbolic regression the determination a function dependence y = g(x thatx i ; In this paper the feasibilit
Label: Genetic Algorithms
Paper 3  Title: "What is the best thing to do right now?": getting beyond greedy exploration  
Abstract: Genetic programming a methodology program development consisting a special form genetic algorithm capable handling parse trees representing programs that has successfully In this paper a new approach the construction genetic programming A linear chromosome combined a graph represen
Paper 4  Title: Knowledge-Based Genetic Learning  
Abstract Genetic algorithms proven within the area However there some classes problems where they seem scarcely applicable the solution consists several parts influence In that case the classic genetic operators cross mutation do work very thus preventing a good p
Paper 5  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 6  Title: Towards Automatic Discovery of Building Blocks in Genetic Programming  
Abstract an algorithm the discovery building genetic programmingGP called adaptive representation through learningARL The central idea ARL the adaptation the problem representation, extending terminals functions with The set extracts common knowledge emerging during the evolutiona
Paper 7  Title: Using generative models for handwritten digit recognition  
Abstract Genetic Programming program discovery consisting a special kind capable operating nonlinear chromosomesparse trees representing programs and an interpreter which run being optimised This paper PDGP (Parallel Distributed Genetic Programming which suitable
Label: Neural Networks
Paper 8  Title: Evolution of the Topology and the Weights of Neural Networks using Genetic Programming with a
Abstract: Genetic programming a methodology program development consisting a special form genetic algorithm capable handling parse trees representing programs that has successfully In this paper a new approach the construction genetic programming A linear chromosome combined a graph represen
Paper 9  Title: Genetic Programming and Redundancy  
Abstract The Genetic Programming optimization method elaborated John Koza [ Koza 1992 The search space the problem domain consists computer programs represented parse trees the crossover operator realized an exchange subtrees Empirical analyses show large parts those trees never used or evaluated which t
Paper 10  Title: An evolutionary tabu search algorithm and the NHL scheduling problem  
Abstract We in a new evolutionary procedure solving combines efficiently the mechanisms genetic algorithms tabu search In explore the solution space properly interaction phases periods optimization An adaptation this search principle to National Hockey problem
Paper 11  Title: An Overview of Genetic Algorithms Part 1, Fundamentals  
Abstract Mathematical programming approaches will described: feature selection robust representation The feature selection problem considered discriminating while recognizing irrelevant and redundant features suppressing creates a lean model often generalizes better new unseen data
Paper 12  Title: A Cooperative Coevolutionary Approach to Function Optimization  
Abstract: A general model the coevolution cooperating species This model instantiated and tested the domain function optimization compared a traditional GA-based function optimizer The results encouraging in two respects They suggest ways the performance GA and other EA-based optimizers they ev
Label: Genetic Algorithms
Paper 13  Title: Adaptation of Genetic Algorithms for Engineering Design Optimization  
Abstract Genetic algorithms extensively different domains as doing global optimization However some realistic engineering design optimization domains was observed a simple classical implementation the GA based binary encoding bit mutation and crossover sometimes inefficient unable reach
Paper 14  Title: A Hypothesis-driven Constructive Induction Approach to Expanding Neural Networks  
Abstract With most machine learning methods if the given knowledge representation space inadequate then This also true methods using neural networks the form the representation space To overcome an automatic construction method This paper the BP-HCI method a hypothesis-driven constr
Paper 15  Title: Discovery of Symbolic, Neuro-Symbolic and Neural Networks with Parallel Distributed Genetic Programming  
Abstract: Technical Report CSRP-9614 August 1996 Abstract Genetic Programming is program discovery consisting a special kind capable operating parse trees representing programs and an interpreter run being optimised This paper Parallel Distributed Genetic Programming sui
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 728...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Traditionally, genetic algorithms have relied upon 1 and 2-point crossover operators. Many recent empirical studies, however, have shown the benefits of higher numbers of crossover points. Some of the most intriguing recent work has focused on uniform crossover, which involves on the average L/2 crossover points for strings of length L. Theoretical results suggest that, from the view of hyperplane sampling disruption, uniform crossover has few redeeming features. However, a growing body of experimental evidence suggests otherwise. In this paper, we attempt to reconcile these opposing views of uniform crossover and present a framework for understanding its virtues.
Title: Title: On the Virtues of Parameterized Uniform Crossover  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Adapting Crossover in a Genetic Algorithm  
Abstract Traditionally genetic algorithms relied upon 1 and 2-point crossover operators Many recent empirical studies, the benefits higher numbers crossover points Some the most intriguing recent work uniform crossover, on the average L/2 crossover points for strings length L. Despite theoretical analysis however d
Label: Genetic Algorithms
Paper 3  Title: A Comparison of Crossover and Mutation in Genetic Programming  
Abstract a large and systematic body data mutation, crossover combinations mutation genetic programming (GP The literature of traditional genetic algorithms contains related studies mutation and crossover in GP differ their traditional counterparts In this paper
Label: Genetic Algorithms
Paper 4  Title: An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms  
Abstract In the interacting roles population size crossover genetic algorithms We summarize recent theoretical results the disruptive effect two forms multi-point crossover n-point crossover uniform crossover We then show empirically disruption analysis alone selecting appropriate
Paper 5  Title: Crossover or Mutation?  
Abstract Genetic algorithms rely two genetic operators crossover mutation Although exists conventional wisdom crossover mutation these roles captured a theoretical fashion For example it never theoretically shown mutation in "less powerful crossover vice This paper so
Paper 6  Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Abstract Holland's analysis the sources power of genetic algorithms served guidance the applications The technique applying a recombination operatorcrossover a population individuals a key that power Neverless there contradictory results concerning crossover operators with respect overall p
Label: Genetic Algorithms
Paper 7  Title: Issues in Using Function Approximation for Reinforcement Learning  
Abstract Reinforcement learning techniques address select actions unknown, dynamic environments It widely to of complex domains reinforcement learning techniques combined generalizing function approximation methods such artificial neural networks Little, however understood the theoretical properties such
Paper 8  Title: Performance Enhanced Genetic Programming  
Abstract Genetic Programming increasing the basis learning However the technique to date successfully modest tasks because the performance overheads evolving a large number data structures many do correspond a valid program We address this problem directly and demonstrate evolutionary
Paper 9  Title: Generation Gaps Revisited  
Abstract There recent interest so-called "steady state" genetic algorithmsGAs, among replace only a few individualstypically 1 each from a fixed size population size N. Understanding the advantages and/or replacing only a fraction each generationrather was a goal s
Label: Genetic Algorithms
Paper 10  Title: The Role of Development in Genetic Algorithms  
Abstract Technical Report Number CS94394 Computer Science Abstract The developmental mechanisms transforming to typically omitted formulationsGAs these two representational spaces identical We argue developmental mechanisms useful understanding the success seve
Paper 11  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 12  Title: The Royal Road for Genetic Algorithms: Fitness Landscapes and GA Performance  
Abstract Genetic algorithms ( play many artificial-life systems often little detailed understanding why the GA performs as it little theoretical basis on characterize the types fitness landscapes lead successful GA performance In this paper addressing these issues Our strategy consists defining
Paper 13  Title: A Computational View of Population Genetics (preliminary version)  
Abstract contributes the study from These systems inherently more their linear counterparts (such Markov chains had a wide impact in Computer Science seem likely play. However there as no general techniques available handling the comput
Paper 14  Title: An Analysis of the Effects of Neighborhood Size and Shape on Local Selection Algorithms  
Abstract The increasing availability finely-grained parallel architectures resulted evolutionary algorithms (EAs in the population spatially local selection algorithms operate on small, overlapping neighborhoods The effects design choices regarding the particular type local selection algorithm as the size shape
Label: Genetic Algorithms
Paper 15  Title: How good are genetic algorithms at finding large cliques: an experimental study  
Abstract the power genetic algorithms at solving the MAX-CLIQUE problem We measure a standard genetic algorithm an elementary set problem instances consisting embedded cliques random graphs We indicate the need improvement introduce the multi-phase annealed GA, exhibits
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2027...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Combinating reactivity with planning has been proposed as a means of compensating for potentially slow response times of planners while still making progress toward long term goals. The demands of rapid response and the complexity of many environments make it difficult to decompose, tune and coordinate reactive behaviors while ensuring consistency. Neural networks can address the tuning problem, but are less useful for decomposition and coordination. We hypothesize that interacting reactions can be decomposed into separate behaviors resident in separate networks and that the interaction can be coordinated through the tuning mechanism and a higher level controller. To explore these issues, we have implemented a neural network architecture as the reactive component of a two layer control system for a simulated race car. By varying the architecture, we test whether decomposing reactivity into separate behaviors leads to superior overall performance, coordination and learning convergence. 
Title: Title: Coordinating Reactive Behaviors  keywords: reactive systems, planning and learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: REINFORCEMENT LEARNING FOR COORDINATED REACTIVE CONTROL  
Abstract The demands rapid response many environments decompose, tune coordinate reactive behaviors while ensuring consistency Reinforcement learning networks address the tuning problem do decomposition coordination We hypothesize interacting reactions often decomposed separate control tas
Paper 3  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract We reinforcement learning the policies considered the learning process constrained hierarchies partially specified machines This allows for prior knowledge reduce the search space provides a framework in transferred problems in component solutions recombined larger a
Paper 4  Title: Learning to coordinate without sharing information  
Abstract Researchers Distributed Artificial Intelligence efficient mechanisms coordinate the activities multiple autonomous agents The need coordination arises agents share resources expertise required achieve Previous work in includes using sophisticated information exchange protocols investigatin
Paper 5  Title: A Model for Projection and Action  
Abstract In designing autonomous agents that deal competently issues involving time there to guaranteed response-time reactions on flexibility expressiveness We propose action with probabilistic reasoning and decision analytic evaluation use a layered control architecture Our model well
Paper 6  Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  
Abstract Mixed-initiative systems present the challenge finding an effective level interaction humans computers Machine learning presents in systems automatically adapt accommodate different users In learning user models an adaptive assistant crisis sched
Paper 7  Title: Emergent Hierarchical Control Structures: Learning Reactive/Hierarchical Relationships in Reinforcement Environments  
Abstract The use externally imposed hierarchical structures reduce learning control common However acknowledged learning the hierarchical structure itself more general (learning of many things as required bounded specified) Presented this paper a reinforcement learning alg
Paper 8  Title: Learning Hierarchical Control Structures for Multiple Tasks and Changing Environments  
Abstract While the need hierarchies within control systems apparent to should learned Learning both the structure the component behaviors is The benefit learning the hierarchical structures behaviors the decomposition the control structure smaller transportable chunks allows previously
Paper 9  Title: Learning to Race: Experiments with a Simulated Race Car  
Abstract implemented as the reactive component We separating has expedited gradually improving competition mult-agent interaction We ran experiments the tuning, decomposition coordination the low level behaviors We then extended our control system t
Paper 10  Title: Automated Decomposition of Model-based Learning Problems  
Abstract A new generation sensor rich massively autonomous systems has unprecedented performance such smart buildings reconfigurable factories adaptive traffic systems remote earth ecosystem monitoring To achieve high performance these massive systems accurately model themselves from sensor inf
Paper 11  Title: USING A GENETIC ALGORITHM TO LEARN BEHAVIORS FOR AUTONOMOUS VEHICLES  
Abstract Truly autonomous vehicles both projec - tive planning and reactive components in perform robustly Projective components needed replanning where explicit reasoning about future states Reactive components allow always have some action available themselves exhibit robust behavior lack
Label: Reinforcement Learning
Paper 12  Title: Modeling Case-based Planning for Repairing Reasoning Failures  
Abstract One application models reasoning behavior allow a reasoner introspectively detect repair failures We address the transferability such models versus the specificity the knowledge in them the kinds needed self-modeling structured the evaluation introspective reasoning sy
Paper 13  Title: Diplomarbeit A Genetic Algorithm for the Topological Optimization of Neural Networks  
Abstract We describe an integrated problem architecture named INBANCA Bayesian networks case-based reasoning ( work multiagent planning tasks This includes two-team dynamic tasks this paper simulated soccer as Bayesian networks characterize action selection whereas determine ho
Label: Genetic Algorithms
Paper 14  Title: TECHNIQUES FOR REDUCING THE DISRUPTION OF SUPERIOR BUILDING BLOCKS IN GENETIC ALGORITHMS  
Abstract We describe an integrated problem architecture named INBANCA Bayesian networks case-based reasoning ( work multiagent planning tasks This includes two-team dynamic tasks this paper simulated soccer as Bayesian networks characterize action selection whereas determine ho
Paper 15  Title: Robot Shaping: Developing Situated Agents through Learning  
Abstract Learning plays situated agents In reinforcement learning "shape a robot a predefined target behavior We connect both simulated and real robots A LECSYS a parallel implementation a learning classifier system with an extended genetic algorithm After classifying different kinds Animat-like behav
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 46...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: In IEEE Transactions on Neural Networks, 7(1):97-106, 1996 Also available as GMD report #794 
Title: Title: The Pandemonium System of Reflective Agents  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning from Examples, Agent Teams and the Concept of Reflection  
Abstract In International Journal AI272 1996 Also GMD report #766
Label: Neural Networks
Paper 3  Title: The Role of Development in Genetic Algorithms  
Abstract A Genetic Algorithm Tutorial Darrell Whitley Technical Report CS-93103 1993
Paper 4  Title: What should be minimized in a decision tree: A re-examination  
Abstract Computer Science Department University Massachusetts CMPSCI Technical Report 9520 September 6
Paper 5  Title: Extended Selection Mechanisms in Genetic Algorithms  
Abstract A Genetic Algorithm Tutorial Darrell Whitley Technical Report CS-93103 1993
Paper 6  Title: Experiments with the Cascade-Correlation Algorithm  
Abstract: Technical Report # 9116 July
Paper 7  Title: Neural Learning of Chaotic Dynamics: The Error Propagation Algorithm trains a neural network to identify
Abstract: Technical Report UMIACS-TR-97-77 and CS-TR-3843 Abstract
Paper 8  Title: The Design and Evaluation of a Rule Induction Algorithm  
Abstract: technical report BYUCS-93 June
Paper 9  Title: Hierarchical priors and mixture models, with application in regression and density estimation  
Abstract A Genetic Algorithm Tutorial Darrell Whitley Technical Report CS-93103 1993
Paper 10  Title: CABeN: A Collection of Algorithms for Belief Networks  Correspond with:  
Abstract: Portions this report the Fifteenth Annual Symposium Computer Applications in Medical CareNovember, 1991
Paper 11  Title: Chunking in soar: The anatomy of a general learn ing mechanism. Machine Learning, 1(1). Learning
Abstract: gers University. Also appears tech. report ML- TR-7 Minton (1988 Quantitative results concerning explanation-based learning. Proceedings National Conference Artificial Intelli gence pages
Paper 12  Title: Causal inference, path analysis, and recursive struc-tural equations models. In C. Clogg, editor, Sociological Methodology,
Abstract: Lipid Research Clinic Program 84. The Lipid Research Clinics Coronary Primary Prevention Trial results parts I Journal374 1984 [Pearl 93 Judea Pearl. Aspects graphical models connected causality Technical Report R-195-LL Cognitive Systems Laboratory UCLA June 1993 Submitted
Label: Probabilistic Methods
Paper 13  Title: Environments with Classifier Systems (Experiments on Adding Memory to XCS)  
Abstract: Pier Luca Lanzi Technical Report N. 97.45 October th
Paper 14  Title: Identification and Control of Nonlinear Systems Using Neural Network Models: Design and Stability Analysis  
Abstract: Report 9109 September 1991revised May
Paper 15  Title: Support Vector Machines, Reproducing Kernel Hilbert Spaces and the Randomized GACV 1  
Abstract 1 Prepared the NIPS 97 Workshop Support Vector Machines Research sponsored in under Grant DMS-9704758 in NEI Grant R01 EY09946 This a second revised and corrected version of the same number title dated
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 833...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper presents the results of an experimental investigation on solving graph coloring problems with Evolutionary Algorithms (EA). After testing different algorithm variants we conclude that the best option is an asexual EA using order-based representation and an adaptation mechanism that periodically changes the fitness function during the evolution. This adaptive EA is general, using no domain specific knowledge, except, of course, from the decoder (fitness function). We compare this adaptive EA to a powerful traditional graph coloring technique DSatur and the Grouping GA on a wide range of problem instances with different size, topology and edge density. The results show that the adaptive EA is superior to the Grouping GA and outperforms DSatur on the hardest problem instances. Furthermore, it scales up better with the problem size than the other two algorithms and indicates a linear computational complexity. 
Title: Title: Graph Coloring with Adaptive Evolutionary Algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Feature Selection Methods: Genetic Algorithms vs. Greedy-like Search  
Abstract: two feature selection methods the Importance Score (IS which a greedy-like search and a genetic algorithm-based (GA) method in order better their strengths limitations and their area The results our experiments a very strong relation the nature the data the behavior both sy
Paper 3  Title: An Evolutionary Approach to Combinatorial Optimization Problems  
Abstract The paper reports genetic algorithms, based the model organic evolution NP-complete combinatorial optimization problems In particular the subset sum, maximum cut minimum tardy task problems considered Except the fitness function no problem-specific changes of the genetic algorithm ac
Paper 4  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 5  Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Abstract Genetic algorithms neural networks two main ways optimize train the weights a fixed architecture While most previous work focuses only of these two options investigates an alternative evolutionary approach called Breeder Genetic Programming the architecture and the weights optimized simult
Paper 6  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Label: Genetic Algorithms
Paper 7  Title: Genetic algorithms with multi-parent recombination  
Abstract In genetic algorithms where more than two parents the recombination operation In particular introduce gene scanning a reproduction mechanism generalizes classical crossovers n-point crossover uniform crossover applicable an arbitrary number (two parents We performed extensive tests optimizing n
Paper 8  Title: Incremental Co-evolution of Organisms: A New Approach for Optimization and Discovery of Strategies  
Abstract In optimization techniques some very efficient and promising tools like Hill-Climbing have designed In this same field the Evolving Non-Determinism (END) model presented proposes an inventive way explore the space states, using simulated "incremental co some organisms remedi
Paper 9  Title: Adaptation of Genetic Algorithms for Engineering Design Optimization  
Abstract Genetic algorithms extensively different domains as doing global optimization However some realistic engineering design optimization domains was observed a simple classical implementation the GA based binary encoding bit mutation and crossover sometimes inefficient unable reach
Paper 10  Title: Putting the Genetics back into Genetic Algorithms  
Abstract In genetic algorithms where more than two parents the recombination operation In particular introduce gene scanning a reproduction mechanism generalizes classical crossovers n-point crossover uniform crossover applicable an arbitrary number (two parents We performed extensive tests optimizing n
Paper 11  Title: A Case Study on Tuning of Genetic Algorithms by Using Performance Evaluation Based on Experimental Design  
Abstract proposes four performance measures a genetic algorithm (GA which enable compare different GAs for an op timization problem different choices their parameters' values The performance measures defined observations simulation such the frequency optimal solutions fitness values the frequency evolution leaps genera
Paper 12  Title: Evolving Non-Determinism: An Inventive and Efficient Tool for Optimization and Discovery of Strategies  
Abstract In the field optimization techniques some very efficient and promising tools like Hill-Climbing have designed In this same field the Evolving Non-Determinism (END) model proposes an inventive way explore the space states, combined simulated co remedies some drawbacks these previous techn
Label: Genetic Algorithms
Paper 13  Title: Evolution of Non-Deterministic Incremental Algorithms as a New Approach for Search in State Spaces  
Abstract Let call a non-deterministic incremental algorithm one able construct any solution by selecting incrementally an ordered sequence choices defines this solution each choice made non In that case the state space can represented a tree a solution a path a leaf This paper
Paper 14  Title: On the Effectiveness of Evolutionary Search in High-Dimensional NK-Landscapes  
Abstract NK-landscapes offer assess the performance evolutionary algorithms problems different degrees epistasis In study six algorithms NK-landscapes low and high dimension while keeping the amount epistatic interactions The results show compared genetic local search algorithms performance standa
Paper 15  Title: Optimal Mutation Rates in Genetic Search  
Abstract The optimization a single bit string means iterated mutation and selection the best (a (1+1)-Genetic Algorithm discussed with three simple fitness functions The counting ones problem a standard binary encoded integer a Gray coded integer optimization problem A mutation rate schedule that optimal with the success probability mutation
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1021...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Here we show a similar construction for multiple-output systems, with some modifications. Let = (A; B; C) s be a discrete-time sign-linear system with state space IR n and p outputs. Perform a change of ; where A 1 (n 1 fi n 1 ) is invertible and A 2 (n 2 fi n 2 ) is nilpotent. If (A; B) is a reachable pair and (A; C) is an observable pair, then is minimal in the sense that any other sign-linear system with the same input/output behavior has dimension at least n. But, if n 1 &lt; n, then det A = 0 and is not observable and hence not canonical. Let us find another system ~ (necessarily not sign-linear) which has the same input/output behavior as , but is canonical. Let i be the relative degree of the ith row of the Markov sequence A, and = minf i : i = 1; : : : ; pg. Let the initial state be x. There is a difference between the case when the smallest relative degree is greater or equal to n 2 and the case when &lt; n 2 . Roughly speaking, when n 2 the outputs of the sign-linear system give us information about sign (Cx), sign (CAx), : : : , sign (CA 1 x), which are the first outputs of the sys tem. After that, we can use the inputs and outputs to learn only about x 1 (the first n 1 components of x). When &lt; n 2 , we may be able to use some controls to learn more about x 2 (the last n 2 components of x) before time n 2 when the nilpotency of A 2 has finally Lemma 2.4 Two states x and z are indistinguishable for if and only if (x) = (z). Proof. In the case n 2 , we have only the equations x 1 = z 1 and the equality of the 's. The first ` output terms for are exactly the terms of . So these equalities are satisfied if and only if the first ` output terms coincide for x and z, for any input. Equality of everything but the first n 1 components is equivalent to the first n 2 output terms coinciding for x and z, since the jth row of the qth output, for initial state x, for example, is either sign (c j A q x) if j &gt; q, or sign (c j A q x + + A j j u q j +1 + ) if j q in which case we may use the control u q j +1 to identify c j A q x (using Remark 3.3 in [1]). 
Title: Title: Lemma 2.3 The system is reachable and observable and realizes the same input/output behavior as
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Inserting the best known bounds for weighted bipar tite matching [11], with 1=2 p polynomial-time
Abstract we apply the reduction to their two core children the total sum their matching weights becomes O(n if for each comparison a spine node a critical node we of With regards the O( 2 ) comparisons of two critical nodes their sum exceed O n in total weigh
Label: Theory
Paper 3  Title: 82 Lag-space estimation in time-series modelling keep track of cases where the estimation of P
Abstract When m = (no delays set A 0 (ffi; ; j 6= kg such P m ( depends *. The estimated probabilities above become noisy elements set A m For estimate P m (*jffi Notice this estimate the empirical averageeither given couple satisfied t
Paper 4  Title: ABSTRACTION CONSIDERED HARMFUL: LAZY LEARNING OF LANGUAGE PROCESSING  
Abstract When m = (no delays set A 0 (ffi; ; j 6= kg such P m ( depends *. The estimated probabilities above become noisy elements set A m For estimate P m (*jffi Notice this estimate the empirical averageeither given couple satisfied t
Paper 5  Title: j  
Abstract So applying Corollary the second equation (47 From38 we then get jg(y n + ~ k y (51 we From we54 bounded. Since the system _ y = A 1 y k( yb jyj ev N :55 Now lim sup t!1 &gt; 0 Then jyj ev 2 Since j k(y)j Ljyj and using56~ ev
Paper 6  Title: A Computer Scientist's View of Life, the Universe, and Everything  
Abstract Is the universe computable If so much cheaper in information requirements compute all computable universes instead just ours I apply basic concepts the set chat perceived and true randomness life generalization learning Assumptions. A long time ago, the Great Progra
Label: Reinforcement Learning
Paper 7  Title: NP-Completeness of Searches for Smallest Possible Feature Sets a subset of the set of all
Abstract In many learning problems presented values features actually irrelevant it The FOCUS algorithm due Almuallim and Dietterich performs an explicit search the smallest possible input feature set S that permits a consistent mapping from The FOCUS algorithm can b
Paper 8  Title: Vapnik-Chervonenkis entropy of the spherical perceptron  
Abstract Perceptron learning of randomly labeled patterns analyzed a Gibbs distribution on realizable labelings The entropy this distribution an extension VapnikChervonenkis (VC reducing it exactly in infinite temperature The close relationship the VC and Gardner entropies within the replica formalis
Paper 9  Title: The Challenge of Revising an Impure Theory  
Abstract A pure rule-based program will return answers; and set even its rules re However, an impure program the Prolog cut "!" not() operators return different answers re There also many reasoning systems return found for first ans
Label: Theory
Paper 10  Title: Finding Promising Exploration Regions by Weighting Expected Navigation Costs continuous environments, some first-order approximations to
Abstract In many learning tasks data-query is neither free of constant cost Often the cost a query depends the distance in state space This easiest visualize robotics environments must physically to learn something there The cost this learning the time
Paper 11  Title: A Six-Point Condition for Ordinal Matrices  keywords: additive, algorithm, evolution, ordinal, phylogeny  
Abstract Ordinal assertions in an evolutionary context of the form "species s is more similar x can a distance matrix M of interspecies dissimilarities [s; &lt Given species x the ordinal binary character c xy of M defined (s if and M [s; &lt; M[s for all species s. In this paper pres
Paper 12  Title: learning easier tasks. More work is necessary in order to determine more precisely the relationship
Abstract We attempted obtain a stronger correlation the relationship G 0 performance. This has included studying the variance the fitnesses the members observing the rate convergence the GP with G 1 when evolved for G 0 13 Unfortunately obtain a significant cor
Paper 13  Title: Vapnik-Chervonenkis Dimension of Recurrent Neural Networks  
Abstract: Most the Vapnik-Chervonenkis dimension neural networks feedforward networks However recurrent networks also widely learning applications in when time a relevant parameter This paper provides lower and upper bounds the VC dimension such networks Several types activation functions discussed thresh
Paper 14  Title: Constructing New Attributes for Decision Tree Learning  
Abstract: The Longest common subsequence problem examined from parameterized computational complexity There in parameters enter the problem, such sequences to analyzed the common subsequence the alphabet Lower bounds the complexity this basic problem imply lower bounds a number o
Paper 15  Title: Using Precepts to Augment Training Set Learning an input whose value is don't-care in some
Abstract are used turn approximate A. good results TSL [8 However TSL several drawbacks Training set learners ( typically slow as may require many passes Also there, given an arbitrary training set the system find enough good critical features get
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 955...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model is closely related to the Harmonium model defined by Smolensky [RM86][Ch.6]. In the first part of the paper we analyze properties of this distribution representation scheme. We show that arbitrary distributions of binary vectors can be approximated by the combination model. We show how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits. We compare the combination model with the mixture model and with principle component analysis. In the second part of the paper we present two algorithms for learning the combination model from examples. The first algorithm is based on gradient ascent. Here we give a closed form for this gradient that is significantly easier to compute than the corresponding gradient for the general Boltzmann machine. The second learning algorithm is a greedy method that creates the hidden units and computes their weights one at a time. This method is a variant of projection pursuit density estimation. In the third part of the paper we give experimental results for these learning methods on synthetic data and on natural data of handwritten digit images. 
Title: Title: Separating Formal Bounds from Practical Performance in Learning Systems  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Unsupervised learning of distributions on binary vectors using two layer networks  
Abstract We a distribution model binary vectors called the influence combination model and show as feature selection The model closely the Harmonium model defined Smolensky [RM86][Ch.6 In the first part the paper analyze properties this distribution representation scheme We sho
Paper 3  Title: On the Learnability and Usage of Acyclic Probabilistic Finite Automata  
Abstract propose and analyze a distribution learning a subclass This subclass characterized a certain distinguishability property the automata's states Though hardness results are known learning distributions generated general APFAs prove our algorithm efficiently the s
Paper 4  Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,
Abstract Although probabilistic inference a general Bayesian belief network inference computation time reduced most practical cases exploiting domain knowledge by making the knowledge representation In this paper the property similarity states a new method approximate knowledge representation whic
Label: Theory
Paper 5  Title: Distribution Category:  Users Guide to the PGAPack Parallel Genetic Algorithm Library  
Abstract The problem modeling complicated data sequences DNA speech often practice Most the algorithms select a hypothesis within assuming the observed sequence the direct output In when the output passes a memoryless noisy channel before observation In particula
Paper 6  Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  
Abstract The work discussed motivated of building decision support systems Our goal use these systems supporting Bayes optimal decision making where the action maximizing the expected utility, with respect predicted probabilities should selected For the models need
Paper 7  Title: Constructing Bayesian finite mixture models by the EM algorithm  
Abstract: Email: Firstname.HelsinkiFI Report C-19969, University Department Abstract In finite mixture models building decision support systems capable sound probabilistic inference Finite mixture models have many appealing properties in prediction (reasoning phase the
Paper 8  Title: Training Algorithms for Hidden Markov Models Using Entropy Based Distance Functions  
Abstract We new algorithms parameter estimation HMMs By adapting construct maximize the observations while attempting stay close We use a bound on the relative entropy between the two HMMs as between The result new iterat
Paper 9  Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  
Abstract: We present an algorithm improving algorithms learning binary concepts The improvement achieved combining a large number hypotheses each generated training given learning examples Our algorithm ideas presented Schapire inThe strength weak learnability represents an im
Label: Theory
Paper 10  Title: Support Vector Machines: Training and Applications  
Abstract The Support Vector Machine a new and very promising classification technique developed Vapnik his group [3 24 This new learning algorithm seen an alternative training technique Polynomial, Radial Basis Function and Multi-Layer Perceptron classifiers The main idea the technique separate the classes with a surfa
Paper 11  Title: Learning Markov chains with variable memory length from noisy output  
Abstract The problem modeling complicated data sequences DNA speech often practice Most the algorithms select a hypothesis within assuming the observed sequence the direct output In when the output passes a memoryless noisy channel before observation In particula
Label: Theory
Paper 12  Title: Self bounding learning algorithms  
Abstract Most which attempts give bounds the generalization error the hypothesis generated a learning algorithm methods from uniform convergence These bounds a-priori bounds hold any distribution examples calculated before observed In this paper bounding the generalization e
Label: Theory
Paper 13  Title: Static Data Association with a Terrain-Based Prior Density  
Abstract In there works learning probabilistic belief networks Current state have shown successful two learning scenarios learning both network structure parameters complete data parameters a fixed network from incomplete datathat is, the presence missing values or hidden variables However
Label: Probabilistic Methods
Paper 14  Title: On the Sample Complexity of Learning Bayesian Networks  
Abstract In there learning Bayesian networks data One learning such networks based the minimum description length principle Previous work this learning procedure successful: with probability one, will converge the target distribution given a sufficient numbe
Label: Probabilistic Methods
Paper 15  Title: A Fast Fixed-Point Algorithm for Independent Component Analysis  
Abstract will appear Neural Computation 9:1483 1997 Abstract We introduce a novel fast algorithm Independent Component Analysis can blind source separation feature It shown how a neural network learning rule transformed a txed-point iteration provides an algorithm very simple, does any user-de
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 1528...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper presents a method for using qualitative models to guide inductive learning. Our objectives are to induce rules which are not only accurate but also explainable with respect to the qualitative model, and to reduce learning time by exploiting domain knowledge in the learning process. Such ex-plainability is essential both for practical application of inductive technology, and for integrating the results of learning back into an existing knowledge-base. We apply this method to two process control problems, a water tank network and an ore grinding process used in the mining industry. Surprisingly, in addition to achieving explainability the classificational accuracy of the induced rules is also increased. We show how the value of the qualitative models can be quantified in terms of their equivalence to additional training examples, and finally discuss possible extensions.
Title: Title: Using Qualitative Models to Guide Inductive Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Rule Generation and Compaction in the wwtp  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 3  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 4  Title: Constructing Intermediate Concepts by Decomposition of Real Functions  
Abstract In learning from examples it expand an attribute-vector representation intermediate concepts The usual advantage such structuring of the learning problem easier improves the comprehensibility induced descriptions In develop discovering useful intermediate concepts when both class at
Paper 5  Title: Lookahead and Discretization in ILP  
Abstract We and two methods improving ILP systems One them discretization numerical attributes based Fayyad and Irani text [9 adapted and extended cope some aspects only occur relational learning problemswhen indeterminate literals occur The second technique lookahead It
Paper 6  Title: Theory Revision in Fault Hierarchies  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Label: Theory
Paper 7  Title: FONN: Combining First Order Logic with Connectionist Learning  
Abstract a neural network architecture manage structured data refine knowledge bases expressed a first order logic language The presented framework well classification problems concept de scriptions depend numerical features In fact the main goal the neural architecture that refining the numerical part the k
Paper 8  Title: Cost-sensitive feature reduction applied to a hybrid genetic algorithm  
Abstract is concerned whether it detect what information contained the training data and background knowledge solving irrelevant information eliminated preprocessing before starting A case study data preprocessing a hybrid genetic algorithm shows elimination irrel
Paper 9  Title: Hidden Markov Model Analysis of Motifs in Steroid Dehydrogenases and their Homologs  
Abstract Methods to build function approximators example data have gained Especially methodologies build models allow an interpretation have attracted Most existing algorithms, however either complicated high-dimensional problems presents efficient algorithm construct fuz
Label: Neural Networks
Paper 10  Title: Learning Approximate Control Rules Of High Utility  
Abstract One the area explanation based learning the utility problem; learning too many rules of low utility swamping degradation performance This paper introduces improving the utility learned rules The first technique combine EBL inductive learning techniques a better set control rules;
Paper 11  Title: DISTRIBUTED GENETIC ALGORITHMS FOR PARTITIONING UNIFORM GRIDS  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Paper 12  Title: Submitted to the Future Generation Computer Systems special issue on Data Mining. Using Neural Networks
Abstract Neural networks successfully applied supervised and unsupervised learning applications Neural-network methods not commonly data-mining tasks however because often produce incomprehensible models require long training times In describe neural-network learning algorithms produce comprehensible models,
Paper 13  Title: Induction of decision trees using RELIEFF  
Abstract machine from examples this deals estimating attributes with and dependencies Greedy search prevents current inductive machine learning algorithms to significant dependencies the attributes Recently Kira Rendell developed the RELIEF algorithm estimating attribu
Paper 14  Title: Constructing Fuzzy Graphs from Examples  
Abstract Methods to build function approximators example data have gained Especially methodologies build models allow an interpretation have attracted Most existing algorithms, however either complicated high-dimensional problems presents efficient algorithm construct fuz
Paper 15  Title: Protein Secondary Structure Modelling with Probabilistic Networks (Extended Abstract)  
Abstract In study the performance probabilistic networks protein sequence analysis molecular biology Specifically we report our initial experiments applying this framework the problem protein secondary structure prediction One the probabilistic approach we describe our ability perform detailed exper
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Category: Rule Learning
Prediction:  Category: Rule Learning
Is prediction correct?  False

Prediction: 0
Processing index 1434...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper demonstrates the capabilities of Foidl, an inductive logic programming (ILP) system whose distinguishing characteristics are the ability to produce first-order decision lists, the use of an output completeness assumption as a substitute for negative examples, and the use of intensional background knowledge. The development of Foidl was originally motivated by the problem of learning to generate the past tense of English verbs; however, this paper demonstrates its superior performance on two different sets of benchmark ILP problems. Tests on the finite element mesh design problem show that Foidl's decision lists enable it to produce generally more accurate results than a range of methods previously applied to this problem. Tests with a selection of list-processing problems from Bratko's introductory Prolog text demonstrate that the combination of implicit negatives and intensionality allow Foidl to learn correct programs from far fewer examples than Foil.
Title: Title: Advantages of Decision Lists and Implicit Negatives in Inductive Logic Programming  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: on Inductive Logic Programming (ILP-95) Inducing Logic Programs without Explicit Negative Examples  
Abstract learning logic programs without explicit negative examples exploiting output completeness A mode declaration supplied the target predicate each training input assumed accompanied all its legal outputs Any other outputs generated an incomplete program implicitly negative examples; large
Label: Rule Learning
Paper 3  Title: Combining Top-down and Bottom-up Techniques in Inductive Logic Programming  
Abstract inducing logic programs examples which attempts integrate the best aspects existing ILP methods In particular combines similar Golem Foil It also a method predicate invention similar Champ and an elegant solution the "noisy ora
Label: Rule Learning
Paper 4  Title: Knowledge Acquisition with a Knowledge-Intensive Machine Learning System  
Abstract In the integration knowledge acquisition machine learning techniques. We argue existing machine learning techniques made as knowledge acquisition tools allowing the expert have and interaction We describe a number extensions FOCLa multistrategy Horn-clause learning prog
Label: Rule Learning
Paper 5  Title: Natural Language Grammatical Inference with Recurrent Neural Networks  
Abstract the inductive inference a complex grammar neural networks specifically, the task considered is that training as thereby exhibiting discriminatory power provided the Principles and Parameters linguistic framework or Government-and-Binding theory Neural networ
Paper 6  Title: ILP with Noise and Fixed Example Size: A Bayesian Approach  
Abstract Current inductive logic programming systems limited noise employ a greedy covering approach constructing the hypothesis one clause This approach also causes difficulty learning recursive predicates Additionally many current systems an implicit expectation the cardinality reflect the "prop
Paper 7  Title: Inductive Constraint Logic and the Mutagenesis Problem  
Abstract learning first order logic formulae positive and negative examples incorporated a system named ICL In ICL examples viewed interpretations which true for the target theory present inductive logic programming systems true and false ground facts ( clauses Furthermore ICL uses a c
Paper 8  Title: DISTRIBUTED GENETIC ALGORITHMS FOR PARTITIONING UNIFORM GRIDS  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Paper 9  Title: Theory Revision in Fault Hierarchies  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Label: Theory
Paper 10  Title: An Experimental Comparison of Genetic Programming and Inductive Logic Programming on Learning Recursive List Functions  
Abstract experimentally three approaches program induction inductive logic programming genetic programmingGP genetic logic programminga variant GP for inducing Pro-log programs Each these methods was induce four simple, recursive, list-manipulation functions The results indicate ILP is the likely induce a correct program
Label: Rule Learning
Paper 11  Title: Inverting Implication with Small Training Sets  
Abstract We an algorithm inducing recursive clauses inverse implicationrather inverse resolution Our approach applies a class logic programs similar the class primitive recursive functions Induction performed positive examples that need along Our algorithm, i
Paper 12  Title: First Order Regression  
Abstract We, called First Order Regression (FOR handling numerical information Inductive Logic Programming FOR is a combination ILP and numerical regression First-order logic descriptions induced carve those subspaces amenable numerical regression among The program Fors is an implementation this idea
Label: Rule Learning
Paper 13  Title: Combining FOIL and EBG to Speed-up Logic Programs  
Abstract an algorithm combines traditional EBL techniques recent developments inductive logic programming learn effective clause selection rules Prolog programs When these control rules incorporated the original program significant speed-up The algorithm shown an improvement competing EBL approaches several domain
Paper 14  Title: Theory-Guided Induction of Logic Programs by Inference of Regular Languages recursive clauses. merlin on the
Abstract resent allowed sequences resolution steps the initial theory There, many characterizations allowed sequences resolution steps expressed a set resolvents One approach presented, the system mer-lin an earlier technique learning finite-state automata that represent allowed sequences resolution step
Paper 15  Title: Learning Search-Control Heuristics for Logic Programs: Applications to Speedup Learning and Language Acquisition  
Abstract, learning search-control heuristics logic programs improve both the efficiency accuracy knowledge-based systems expressed definite-clause logic programs The approach combines techniques explanation-based learning recent advances inductive logic programming learn clause-selection heuristics guid
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 2641...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We use a simulated evolution search (genetic programming) for the automatic synthesis of small iterative machine-language programs. For an integer register machine with an addition instruction as its sole arithmetic operator, we show that genetic programming can produce exact and general multiplication routines by synthesizing the necessary iterative control structures from primitive machine-language instructions. Our program representation is a virtual register machine that admits arbitrary control flow. Our evolution strategy furthermore does not artificially restrict the synthesis of any control structure; we only place an upper bound on program evaluation time. A program's fitness is the distance between the output produced by a test case and the desired output (multiplication). The test cases exhaustively cover multiplication over a finite subset of the natural numbers (N 10 ); yet the derived solutions constitute general multiplication for the positive integers. For this problem, simulated evolution with a two-point crossover operator examines significantly fewer individuals in finding a solution than random search. Introduction of a small rate of mutation fur ther increases the number of solutions.
Title: Title: Toward Simulated Evolution of Machine-Language Iteration  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning to Play Games From Experience: An Application of Artificial Neural Networks and Temporal Difference Learning  
Abstract use a simulated evolution searchgenetic programming the automatic synthesis small iterative machine-language programs For an integer register machine an addition instruction as show genetic programming exact and general multiplication routines by primitive mac
Label: Neural Networks
Paper 3  Title: Learning Recursive Sequences via Evolution of Machine-Language Programs  
Abstract use directed search techniques the space computer programs learn recursive sequences Specifically the integer sequences squares x 2 ; cubes factorial!; studied Given a small finite prefix show three directed searches|machinelanguage genetic with crossover exhaustive iterative
Paper 4  Title: Evolving Turing-Complete Programs for a Register Machine with Self-modifying Code  
Abstract The majority commercial computers register machines of von Neumann type We developed evolve Turing-complete programs a register machine The described implementation enables most program constructs arithmetic operators large indexed memory automatic decomposition into subfunctions (ADFs conditional constructs
Label: Genetic Algorithms
Paper 5  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 6  Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 7  Title: Balancing Accuracy and Parsimony in Genetic Programming 1  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 8  Title: Inverting Implication with Small Training Sets  
Abstract We an algorithm inducing recursive clauses inverse implicationrather inverse resolution Our approach applies a class logic programs similar the class primitive recursive functions Induction performed positive examples that need along Our algorithm, i
Paper 9  Title: Optimal Mutation Rates in Genetic Search  
Abstract The optimization a single bit string means iterated mutation and selection the best (a (1+1)-Genetic Algorithm discussed with three simple fitness functions The counting ones problem a standard binary encoded integer a Gray coded integer optimization problem A mutation rate schedule that optimal with the success probability mutation
Paper 10  Title: A Genome Compiler for High Performance Genetic Programming  
Abstract Genetic Programming very computationally For most applications time evaluating candidate solutions so desirable make individual evaluation as efficient We describe a genome compiler which s machine code resulting individual evaluations over standard GP systems Based
Paper 11  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Label: Genetic Algorithms
Paper 12  Title: First Order Regression  
Abstract We, called First Order Regression (FOR handling numerical information Inductive Logic Programming FOR is a combination ILP and numerical regression First-order logic descriptions induced carve those subspaces amenable numerical regression among The program Fors is an implementation this idea
Label: Rule Learning
Paper 13  Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  
Abstract Genetic algorithms solve hard optimization problems ranging the Travelling Salesman problem the Quadratic Assignment problem We show the Simple Genetic Algorithm solve derived the 3-Conjunctive Normal Form problem By separating the populations into small sub parallel genetic algorithms exploits
Paper 14  Title: Towards Automatic Discovery of Building Blocks in Genetic Programming  
Abstract an algorithm the discovery building genetic programmingGP called adaptive representation through learningARL The central idea ARL the adaptation the problem representation, extending terminals functions with The set extracts common knowledge emerging during the evolutiona
Paper 15  Title: Value Function Approximations and Job-Shop Scheduling  
Abstract We a successful application TD() value function approximation the task job-shop scheduling Our scheduling problems based scheduling payload processing steps The value function approximated a 2-layer feedforward network A one-step lookahead greedy algorithm using the learned evaluation
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Category: Genetic Algorithms
Prediction:  Category: Genetic Algorithms
Is prediction correct?  False

Prediction: 0
Processing index 2648...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: An hypothesis of functional transfer of task knowledge is presented that requires the development of a measure of task relatedness and a method of sequential learning. The task rehearsal method (TRM) is introduced to address the issues of sequential learning, namely retention and transfer of knowledge. TRM is a knowledge based inductive learning system that uses functional domain knowledge as a source of inductive bias. The representations of successfully learned tasks are stored within domain knowledge. Virtual examples generated by domain knowledge are rehearsed in parallel with the each new task using either the standard multiple task learning (MTL) or the MTL neural network methods. The results of experiments conducted on a synthetic domain of seven tasks demonstrate the method's ability to retain and transfer task knowledge. TRM is shown to be effective in developing hypothesis for tasks that suffer from impoverished training sets. Difficulties encountered during sequential learning over the diverse domain reinforce the need for a more robust measure of task relatedness. 
Title: Title: The Task Rehearsal Method of Sequential Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The Functional Transfer of Knowledge for Coronary Artery Disease Diagnosis  
Abstract A distinction two forms task knowledge transfer representational functional reviewed followed MTL a modified version multiple ( neural network method functional transfer The MTL method employs a separate learning rate k, each task output node k. k varies as a measure relatedness R k between
Paper 3  Title: Theory Revision in Fault Hierarchies  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Label: Theory
Paper 4  Title: Experiments on the Transfer of Knowledge between Neural Networks Reprinted from: Computational Learning Theory and
Abstract This chapter three studies which address neural network learning via the incorporation information extracted other networks This general problem network transfer encompasses relationships source target networks Our focus the utilization weights from source networks which solve a sub
Paper 5  Title: Modeling the Student with Reinforcement Learning  
Abstract We describe a methodology enabling an intelligent teaching system make high level strategy decisions on low level student modeling information This framework less costly construct superior hand coding teaching strategies as responsive In order accomplish reinforcement learning associate sup
Paper 6  Title: DISTRIBUTED GENETIC ALGORITHMS FOR PARTITIONING UNIFORM GRIDS  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Paper 7  Title: Data Exploration with Reflective Adaptive Models  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Paper 8  Title: Knowledge Acquisition with a Knowledge-Intensive Machine Learning System  
Abstract In the integration knowledge acquisition machine learning techniques. We argue existing machine learning techniques made as knowledge acquisition tools allowing the expert have and interaction We describe a number extensions FOCLa multistrategy Horn-clause learning prog
Label: Rule Learning
Paper 9  Title: Competitive Environments Evolve Better Solutions for Complex Tasks  
Abstract University Computer Technical Report 876September 1989 Abstract In explanation-based learning a specific problem's solution generalized into later Most research explanation-based learning involves relaxing constraints the variables a specific example rather gener
Paper 10  Title: The Utility of Knowledge in Inductive Learning  Running Head: Knowledge in Inductive Learning  
Abstract: This paper investigates learning a lifelong context Lifelong learning addresses situations faces a whole stream Such scenarios provide transfer knowledge across multiple learning tasks in generalize more from less training data In several different approaches lifelong learning
Paper 11  Title: Storing and Indexing Plan Derivations through Explanation-based Analysis of Retrieval Failures  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Paper 12  Title: Strategy Learning with Multilayer Connectionist Representations 1  
Abstract Results the learning search strategies connectionist mechanisms Previous studies strategy learning within the symbolic, production-rule formalism Here a two-layer connectionist system presented that develops its search from weak to a task-specific strategy its performa
Paper 13  Title: A Comparative Study of ID3 and Backpropagation for English Text-to-Speech Mapping  
Abstract The performance the error backpropagation (BP and ID3 learning algorithms compared on the task mapping English text stresses Under the distributed output code developed Sejnowski Rosenberg shown BP consistently out ID3 on this task Three hypotheses explaining) ID3 ov
Paper 14  Title: Evolution, Learning, and Instinct: 100 Years of the Baldwin Effect Using Learning to Facilitate the
Abstract a hybrid methodology integrates genetic algorithms decision tree learning evolve useful subsets discriminatory features for recognizing complex visual concepts A genetic algorithm (GA search the space all possible subsets candidate discrimination features Candidate feature subsets evaluated using C4.5
Label: Genetic Algorithms
Paper 15  Title: Feature Generation for Sequence Categorization  
Abstract The problem sequence categorization to from a corpus labeled sequences procedures for accurately labeling future unlabeled sequences The choice representation sequences can this task background knowledge a good representation known straightforward representations far optimal We propo
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 2431...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Handling multi-class problems and real numbers is important in practical applications of machine learning to KDD problems. While attribute-value learners address these problems as a rule, very few ILP systems do so. The few ILP systems that handle real numbers mostly do so by trying out all real values that are applicable, thus running into efficiency or overfitting problems. This paper discusses some recent extensions of ICL that address these problems. ICL, which stands for Inductive Constraint Logic, is an ILP system that learns first order logic formulae from positive and negative examples. The main charateristic of ICL is its view on examples. These are seen as interpretations which are true or false for the clausal target theory (in CNF). We first argue that ICL can be used for learning a theory in a disjunctive normal form (DNF). With this in mind, a possible solution for handling more than two classes is given (based on some ideas from CN2). Finally, we show how to tackle problems with continuous values by adapting discretization techniques from attribute value learners. 
Title: Title: Multi-class problems and discretization in ICL Extended abstract  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Inductive Constraint Logic and the Mutagenesis Problem  
Abstract learning first order logic formulae positive and negative examples incorporated a system named ICL In ICL examples viewed interpretations which true for the target theory present inductive logic programming systems true and false ground facts ( clauses Furthermore ICL uses a c
Paper 3  Title: Structural Regression Trees  
Abstract many real domains the task a theory predicting numerical values particular several standard test domains used Inductive Logic Programming concerned predicting numerical values examples relational and mostly non-determinate background knowledge However so far no ILP algorithm except can number
Label: Rule Learning
Paper 4  Title: Inductive Constraint Logic  
Abstract learning first order logic Whereas present inductive logic programming systems employ examples as true and false ground facts clauses view examples interpretations which for the target theory This viewpoint allows to reconcile the inductive logic programming paradigm classic
Paper 5  Title: ILP with Noise and Fixed Example Size: A Bayesian Approach  
Abstract Current inductive logic programming systems limited noise employ a greedy covering approach constructing the hypothesis one clause This approach also causes difficulty learning recursive predicates Additionally many current systems an implicit expectation the cardinality reflect the "prop
Paper 6  Title: Symposium Title: Tutorial Discourse What Makes Human Explanations Effective?  
Abstract Many state ILP systems require large numbers negative examples avoid This a considerable disadvantage many ILP applications namely indu ctive program synthesis where relativelly small and sparse example sets a more realistic scenario Integrity constraints first order clauses play negative examples
Paper 7  Title: Integrity Constraints in ILP using a Monte Carlo approach  
Abstract Many state ILP systems require large numbers negative examples avoid This a considerable disadvantage many ILP applications namely indu ctive program synthesis where relativelly small and sparse example sets a more realistic scenario Integrity constraints first order clauses play negative examples
Paper 8  Title: The Difficulties of Learning Logic Programs with Cut  
Abstract As real logic programmers normally cut (! an effective learning procedure logic programs should deal it Because the cut predicate only a procedural meaning clauses containing cut learned an extensional evaluation method most learning systems On searching a space possible programs (instead ind
Paper 9  Title: Lookahead and Discretization in ILP  
Abstract We and two methods improving ILP systems One them discretization numerical attributes based Fayyad and Irani text [9 adapted and extended cope some aspects only occur relational learning problemswhen indeterminate literals occur The second technique lookahead It
Paper 10  Title: Theory-Guided Induction of Logic Programs by Inference of Regular Languages recursive clauses. merlin on the
Abstract resent allowed sequences resolution steps the initial theory There, many characterizations allowed sequences resolution steps expressed a set resolvents One approach presented, the system mer-lin an earlier technique learning finite-state automata that represent allowed sequences resolution step
Paper 11  Title: Predicate Invention and Learning from Positive Examples Only  
Abstract: Previous bias shift approaches predicate invention applicable learning positive examples only if a complete hypothesis found the given language as negative examples required determine new predicates should One approach presented, MERLIN a successor a system in predicate invention i
Label: Rule Learning
Paper 12  Title: Constructing Intermediate Concepts by Decomposition of Real Functions  
Abstract In learning from examples it expand an attribute-vector representation intermediate concepts The usual advantage such structuring of the learning problem easier improves the comprehensibility induced descriptions In develop discovering useful intermediate concepts when both class at
Paper 13  Title: First Order Regression  
Abstract We, called First Order Regression (FOR handling numerical information Inductive Logic Programming FOR is a combination ILP and numerical regression First-order logic descriptions induced carve those subspaces amenable numerical regression among The program Fors is an implementation this idea
Label: Rule Learning
Paper 14  Title: Learning rules with local exceptions  
Abstract We a learning algorithm rule-based concept representations called ripple-down rule sets Ripple-down rule sets allow us deal the exceptions each rule separately by introducing exception rules exception etc up a constant depth These local exception rules contrast decision lists must plac
Paper 15  Title: Applications of a logical discovery engine  
Abstract The clausal discovery engine claudien presented claudien discovers regularities data a representative As such represents data regularities by first order clausal theories Because the search space clausal theories larger attribute value representation claudien also accepts a declarati
Label: Rule Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 452...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Technical Report 317 Department of Statistics University of Washington. 1 Derek Stanford is Graduate Research Assistant and Adrian E. Raftery is Professor of Statistics and Sociology, both at the Department of Statistics, University of Washington, Box 354322, Seattle, WA 98195-4322, USA. E-mail: stanford@stat.washington.edu and raftery@stat.washington.edu. Web: http://www.stat.washington.edu/raftery. This research was supported by ONR grants N00014-96-1-0192 and N00014-96-1-0330. The authors are grateful to Simon Byers, Gilles Celeux and Christian Posse for helpful discussions. 
Title: Title: Principal Curve Clustering With Noise  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Detecting Features in Spatial Point Processes with Clutter via Model-Based Clustering  
Abstract: Technical Report No. 295 Department Statistics University Washington October, 1995 1 Abhijit Dasgupta is a graduate student Box 357232 981957232 and his e-mail address Adrian E. Raftery is Professor Statistics Sociology, Department Statistics Wa
Paper 3  Title: Model Selection and Accounting for Model Uncertainty in Linear Regression Models  
Abstract: 1 Adrian E. Raftery is Professor Statistics Sociology David Madigan is Statistics Jennifer Hoeting, the Department GN-22 Washington 98195 The research of Raftery Hoeting was supported ONR Contract N-00014-91-J-1074 Madigan's research was partially supported NSF no
Label: Probabilistic Methods
Paper 4  Title: Covariate Selection in Hierarchical Models of Hospital Admission Counts: A Bayes Factor Approach 1  
Abstract: TECHNICAL REPORT No. 268 Department Statistics GN-22 University Washington Seattle 98195 USA 1 Susan L. Rosenkranz is Pew Health Policy Postdoctoral Fellow Box 0936 University 94143 and Adrian E. Raftery is Professor Statistics Sociology, Department Statistics GN-
Paper 5  Title: A Note on the Dirichlet Process Prior in Bayesian Nonparametric Inference with Partial Exchangeability 1  
Abstract: Technical Report no 297 Department Statistics University Washington 1 Sonia Petrone is Universita di Pavia Dipartimento Economia Politica e Metodi Quantitativi I-27100 Pavia and Adrian E. Raftery is Professor Statistics Sociology Department Washington Box 354322 This research suppor
Label: Probabilistic Methods
Paper 6  Title: Change Point and Change Curve Modeling in Stochastic Processes and Spatial Statistics  
Abstract 1 This article will appear Volume no 4 (1994 of Journal Applied Statistical Science. Adrian E. Raftery Professor Statistics Department GN-22 Washington This research ONR contract no N-00014-91-J-1074, by NIH Grant no 5R01HD26330-02, by the Ministere de la Recherche et de l'Espace
Paper 7  Title: Estimating Dependency Structure as a Hidden Variable  
Abstract introduces a probability model the mixture trees account sparse, dynamically changing dependence relationships We present a family efficient algorithms EM and the Minimum Spanning Tree the ML and MAP mixture trees priors the MDL priors This report research done the De
Paper 8  Title: FLEXIBLE PARAMETRIC MEASUREMENT ERROR MODELS  
Abstract Inferences in measurement error models sensitive modeling assumptions Specifically the model incorrect the estimates inconsistent To reduce sensitivity modeling assumptions yet the efficiency we propose which accommodate departures We use mixtu
Paper 9  Title: The Weighted Majority Algorithm  
Abstract fl This research primarily while this author Calif. at Santa Cruz with support ONR grant N0001486-K-0454 and at Harvard University supported DARPA AFOSR-890506 Current address NEC Research Institute 4 Independence Way Princeton E-mail address nickl@research.nj.nec.com y Supported O
Paper 10  Title: Sequential Importance Sampling for Nonparametric Bayes Models: The Next Generation Running Title: SIS for Nonparametric Bayes  
Abstract There two generations Gibbs sampling involving The first generation suffered a severe drawback; namely the locations the clusters, or groups parameters essentially fixed moving rarely Two strategies create the second generation Gibbs samplers integration
Paper 11  Title: Sample Size Calculations for Smoothing Splines Based on Bayesian Confidence Intervals  
Abstract Bayesian confidence intervals of a smoothing spline distinguish two curves In this paper provide sample size calculations Bayesian confidence intervals Approximations simulations on special functions indicate reasonably Key Words Bayesian confidence intervals; sample size smoothing
Paper 12  Title: Bayesian Forecasting of Multinomial Time Series through Conditionally Gaussian Dynamic Models  
Abstract Claudia Cargnoni with, 50100 Firenze Peter Muller and Mike West Statistics Durham NC 277080251 Research of Cargnoni was while visiting ISDS during 1995 Muller West were partially supported NSF under grant DMS
Paper 13  Title: Learning from incomplete data  
Abstract Real-world learning tasks often high-dimensional data sets complex patterns missing features In this paper review the problem learning incomplete data from two statistical perspectives|the likelihood The goal two place current neural network approaches missing within describe a set
Paper 14  Title: Learning to Act using Real-Time Dynamic Programming  
Abstract fl The authors thank Rich Yee Brian Pinette Jonathan Bachrach helping clarify heuristic search control We thank Rich Sutton Chris Watkins Paul Werbos Ron Williams sharing their fundamental insights through numerous discussions further Rich Sutton first making us Korf's re
Paper 15  Title: Hierarchical Mixtures of Experts and the EM Algorithm  
Abstract We supervised learning The statistical model underlying the architecture a hierarchical mixture model in both the mixture coefficients mixture components are generalized linear modelsGLIM's Learning is treated a maximum likelihood problem; present Expectation algorithm adjusting
Label: Probabilistic Methods
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 1516...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Handling NP complete problems with GAs is a great challenge. In particular the presence of constraints makes finding solutions hard for a GA. In this paper we present a problem independent constraint handling mechanism, Stepwise Adaptation of Weights (SAW), and apply it for solving the 3-SAT problem. Our experiments prove that the SAW mechanism substantially increases GA performance. Furthermore, we compare our SAW-ing GA with the best heuristic technique we could trace, WGSAT, and conclude that the GA is superior to the heuristic method. 
Title: Title: Solving 3-SAT by GAs Adapting Constraint Weights  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Graph Coloring with Adaptive Evolutionary Algorithms  
Abstract solving graph coloringEA After testing different algorithm variants we conclude an asexual EA using order-based representation an adaptation mechanism periodically the fitness function during This adaptive EA is general, usi
Paper 3  Title: An Evolutionary Approach to Time Constrained Routing Problems  
Abstract Routing problems an important class planning problems Usually there many different constraints optimization criteria involved general methods solving routing problems We propose an evolutionary solver such planning problems An instance this solver has tested a specific routing problem time constraints The performance
Label: Genetic Algorithms
Paper 4  Title: A GENETIC ALGORITHM FOR FRAGMENT ALLOCATION IN A DISTRIBUTED DATABASE SYSTEM  
Abstract In explore the distributed database allocation problem intractable. We also discuss genetic algorithms have successfully Our experimental results the GA to far the greedy heuristic obtaining optimal and near optimal fragment placements the allocation problem with various data sets
Label: Genetic Algorithms
Paper 5  Title: High-Performance Job-Shop Scheduling With A Time-Delay TD() Network  
Abstract Job-shop scheduling manufacturing industries We interested the particular task scheduling payload processing This paper summarizes formulating this task solution by the reinforcement algorithm T D(). A shortcoming this previous work hand-engineered input features
Label: Reinforcement Learning
Paper 6  Title: Bibliography "SMART: Support Management Automated Reasoning Technology for COMPAQ Customer Service," "Instance-Based Learning Algorithms," Machine
Abstract Satisfiability (SAT refers the task finding a truth assignment makes an arbitrary boolean expression This paper compares a simulated annealing algorithm GSATSelman 1992 a greedy algorithm solving GSAT can solve problem instances extremely traditional satisfiability algorithms Results suggest t
Label: Theory
Paper 7  Title: How good are genetic algorithms at finding large cliques: an experimental study  
Abstract the power genetic algorithms at solving the MAX-CLIQUE problem We measure a standard genetic algorithm an elementary set problem instances consisting embedded cliques random graphs We indicate the need improvement introduce the multi-phase annealed GA, exhibits
Paper 8  Title: A Genetic Local Search Approach to the Quadratic Assignment Problem  
Abstract Augmenting genetic algorithms local search heuristics the solution In this paper a genetic local search approach the quadratic assignment problemQAP New genetic operators for realizing the approach described, its performance tested various QAP instances containing between 256
Paper 9  Title: A Genetic Algorithm for File and Task Placement in a Distributed System  
Abstract explore the distributed file and task placement problem. We also discuss genetic algorithms have successfully Our experimental results the GA to far the greedy heuristic obtaining optimal and near optimal file and task placements the problem with various data sets
Paper 10  Title: Simulated Annealing for Hard Satisfiability Problems  
Abstract Satisfiability (SAT refers the task finding a truth assignment makes an arbitrary boolean expression This paper compares a simulated annealing algorithm GSATSelman 1992 a greedy algorithm solving GSAT can solve problem instances extremely traditional satisfiability algorithms Results suggest t
Paper 11  Title: Towards Improving Case Adaptability with a Genetic Algorithm  
Abstract Case combination is Case Based Reasoning sub exhibit conflicts when merged In our previous work formalized case combination by representing a constraint satisfaction problem the minimum conflicts algorithm systematically the global solution However we instances the problem th
Label: Case Based
Paper 12  Title: GENE REGULATION AND BIOLOGICAL DEVELOPMENT IN NEURAL NETWORKS: AN EXPLORATORY MODEL  
Abstract In explore the distributed database allocation problem intractable. We also discuss genetic algorithms have successfully Our experimental results the GA to far the greedy heuristic obtaining optimal and near optimal fragment placements the allocation problem with various data sets
Paper 13  Title: Program Search with a Hierarchical Variable Length Representation: Genetic Programming, Simulated Annealing and Hill Climbing  
Abstract Genetic Programming(GP Simulated AnnealingSA Stochastic Iterated Hill Climbing based a suite program discovery problems which tackled only GP All three search algorithms employ the hierarchical variable length representation programs brought recent prominence with the GP paradigm [8 We fee
Label: Genetic Algorithms
Paper 14  Title: An Evolutionary Approach to Vector Quantizer Design  
Abstract Vector quantization a lossy coding technique encoding a set from such image speech The design vector quantizers that yields the lowest distortion one source coding However this problem known difficult [ The conventional solution technique works through iterative r
Paper 15  Title: Fast Probabilistic Modeling for Combinatorial Optimization  
Abstract Probabilistic models utilized the optimization large combinatorial search problems However complex probabilistic models that attempt capture inter-parameter dependencies have The algorithm presented, termed COMIT provides using conjunction fast search techniques W
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2298...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper analyzes the convergence properties of the canonical genetic algorithm (CGA) with mutation, crossover and proportional reproduction applied to static optimization problems. It is proved by means of homogeneous finite Markov chain analysis that a CGA will never converge to the global optimum regardless of the initialization, crossover operator and objective function. But variants of CGAs that always maintain the best solution in the population, either before or after selection, are shown to converge to the global optimum due to the irreducibility property of the underlying original nonconvergent CGA. These results are discussed with respect to the schema theorem.
Title: Title: Convergence Analysis of Canonical Genetic Algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Graph Coloring with Adaptive Evolutionary Algorithms  
Abstract solving graph coloringEA After testing different algorithm variants we conclude an asexual EA using order-based representation an adaptation mechanism periodically the fitness function during This adaptive EA is general, usi
Paper 3  Title: An Analysis of the MAX Problem in Genetic Programming hold only in some cases, in
Abstract We genetic programmingGP populations the problem finding a program returns and function set a depth limitknown the MAX problem We confirm the basic message [ Gathercole and Ross 1996 crossover together program size restrictions c
Label: Genetic Algorithms
Paper 4  Title: The Power of Self-Directed Learning  
Abstract: A lower-bound result on the power Abstract This paper a genetic algorithm in We describe a new genetic algorithm the merged genetic algorithm and prove for the class monotonic functions finds, does an exponential convergence r
Paper 5  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Label: Genetic Algorithms
Paper 6  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 7  Title: Vector Quantizer Design Using Genetic Algorithms  
Abstract A Genetic ( vector quantizer design the conventional Generalized Lloyd Algorithm [6 is presented We refer this hybrid the Genetic Generalized Lloyd Algorithm It works briefly A finite number codebooks called chromosomes selected Each codebook undergoes iterative cycles reproduction We perform experim
Paper 8  Title: Reformulation: Nonsmooth, Piecewise Smooth, Semismooth and Smoothing Methods, A Globally Convergent Inexact Newton Method for
Abstract solving systems which Newton, proximal point projection methodologies An important property the algorithm iterates globally to a solution without any additional regularity assumptions Moreover under standard assumptions local su-perlinear rate conv
Paper 9  Title: Genetic Programming and Redundancy  
Abstract The Genetic Programming optimization method elaborated John Koza [ Koza 1992 The search space the problem domain consists computer programs represented parse trees the crossover operator realized an exchange subtrees Empirical analyses show large parts those trees never used or evaluated which t
Paper 10  Title: An Evolutionary Approach to Combinatorial Optimization Problems  
Abstract The paper reports genetic algorithms, based the model organic evolution NP-complete combinatorial optimization problems In particular the subset sum, maximum cut minimum tardy task problems considered Except the fitness function no problem-specific changes of the genetic algorithm ac
Paper 11  Title: Genetic Programming of Minimal Neural Nets Using Occam's Razor  
Abstract A genetic programming method investigated optimizing both the architecture the connection weights multilayer feedforward neural networks The genotype each network whose depth dynamically adapted the particular application by specifically defined genetic operators The weights trained a next-ascent hillclimb-ing search A
Paper 12  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract In Operation Research and Artificial Intelligence several stochastic search algorithms designed based global random searchZhigljavsky Basically those techniques iteratively sample the search space with respect a probability distribution which updated according previous samples some predefined strategy Genetic
Paper 13  Title: Price's Theorem and the MAX Problem  
Abstract We GP populations the problem finding a program which returns and function set a depth limitknown the MAX problem We confirm the basic message [ Gathercole and Ross 1996 crossover together program size restrictions responsible
Paper 14  Title: Specialization under Social Conditions in Shared Environments  
Abstract Specialist and behaviors populations artificial neural networks studied A genetic algorithm simulate evolution processes thereby neural network control systems exhibit specialist or according the fitness formula With evolvable fitness the evaluation measure let free evolve obtain a co
Paper 15  Title: WEAK CONVERGENCE AND OPTIMAL SCALING OF RANDOM WALK METROPOLIS ALGORITHMS  
Abstract considers the problem scaling the proposal distribution a multidimensional random walk Metropolis algorithm maximize The main result a weak convergence result as the dimension a sequence target densities, n 1 When the proposal variance appropriately scaled according n, sequence
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2459...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Intermediate and higher vision processes require selection of a subset of the available sensory information before further processing. Usually, this selection is implemented in the form of a spatially circumscribed region of the visual field, the so-called "focus of attention" which scans the visual scene dependent on the input and on the attentional state of the subject. We here present a model for the control of the focus of attention in primates, based on a saliency map. This mechanism is not only expected to model the functionality of biological vision but also to be essential for the understanding of complex scenes in machine vision.
Title: Title: Control of Selective Visual Attention: Modeling the "Where" Pathway  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  
Abstract The sensorimotor integration system can viewed an observer attempting estimate its own state integrating multiple sources We describe a computational framework capturing this notion some specific models integration adaptation result Psychophysical results two sensorimotor systems subserving the i
Paper 3  Title: Expectation-Based Selective Attention for Visual Monitoring and Control of a Robot Vehicle  
Abstract: Reliable vision-based control an autonomous vehicle focus an input scene Previous work with an autonomous lane following system ALVINN [Pomerleau 1993 yielded This paper based learning approach handling difficult scenes which will co
Label: Neural Networks
Paper 4  Title: Optimising Local Hebbian Learning: use the ffi-rule  
Abstract Many the lower-level areas the mammalian visual system organized retinotopically that as maps which preserve to A unit that such a retinotopic map normally responds selectively stimulation a well-delimited part referred its receptive fieldRF Receptive fields probably the mo
Label: Neural Networks
Paper 5  Title: Hidden Markov Modeling of simultaneously recorded cells in the Associative cortex of behaving monkeys  
Abstract A widely held idea regarding information processing the cell-assembly hypothesis suggested Hebb in 1949 According this hypothesis the basic unit information processing an assembly cells can act briefly a closed system in This work presents characterizing this supposed activity usin
Label: Neural Networks
Paper 6  Title: CNN: a Neural Architecture that Learns Multiple Transformations of Spatial Representations  
Abstract Many the lower-level areas the mammalian visual system organized retinotopically that as maps which preserve to A unit that such a retinotopic map normally responds selectively stimulation a well-delimited part referred its receptive fieldRF Receptive fields probably the mo
Paper 7  Title: Residual Q-Learning Applied to Visual Attention  
Abstract Foveal vision features imagers graded acuity coupled context sensitive sensor gaze control analogous prevalent throughout Foveal vision operates more uniform resolution treated requires a more refined visual attention mechanism demonstrate reinforcement lear
Paper 8  Title: Cortical Mechanisms of Visual Recognition and Learning: A Hierarchical Kalman Filter Model  
Abstract dynamic recognition based the statistical theory Kalman filtering from optimal control theory The model utilizes a hierarchical network whose successive levels implement Kalman filters operating successively spatial Each hierarchical level predicts the cu
Paper 9  Title: A Neural Network Model of Visual Tilt Aftereffects  
Abstract RF-LISSOM, laterally connected orientation maps in the psychological phenomenon known the tilt aftereffect The same self-organizing processes are the map its lateral connections shown result tilt aftereffects over in the adult. The
Paper 10  Title: Combining Neural Network Forecasts on Wavelet-Transformed Time Series  
Abstract Many the lower-level areas the mammalian visual system organized retinotopically that as maps which preserve to A unit that such a retinotopic map normally responds selectively stimulation a well-delimited part referred its receptive fieldRF Receptive fields probably the mo
Label: Neural Networks
Paper 11  Title: Receptive Fields for Vision: from Hyperacuity to Object Recognition  
Abstract Many the lower-level areas the mammalian visual system organized retinotopically that as maps which preserve to A unit that such a retinotopic map normally responds selectively stimulation a well-delimited part referred its receptive fieldRF Receptive fields probably the mo
Paper 12  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract A novel architecture and set learning rules The model based the idea multiple information channels modulate plasticity Features learned bottom-up information sources can thus influenced those learned contextual pathways vice A maximum likelihood cost function allows this scheme
Label: Neural Networks
Paper 13  Title: An integrated approach to the study of object features in visual recognition  
Abstract We propose assess theories synaptic modification as models feature extraction human vision by masks derived synaptic weight patterns occlude parts the stimulus images psychophysical experiments In the experiment reported a mask derived principal component analysis object images t
Paper 14  Title: VISIT: An Efficient Computational Model of Human Visual Attention  
Abstract: One for models cognitive phenomena the development efficient and exible interfaces low level sensory information For visual processing researchers argued an attentional mechanism perform many high level vision This thesis presents VISIT, a connectionist model covert vi
Label: Neural Networks
Paper 15  Title: A Model of Invariant Object Recognition in the Visual System  
Abstract: Neurons the ventral stream the primate visual system exhibit responses the images objects which invariant with natural transformations such translation size view Anatomical and neurophysiological evidence this is achieved hierarchical processing areas In elucidate the manner such representation
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1243...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We discuss the advantages of using overdetermined mixtures to improve upon blind source separation algorithms that are designed to extract sound sources from acoustic mixtures. A study of the nature of room impulse responses helps us choose an adaptive filter architecture. We use ideal inverses of acquired room impulse responses to compare the effectiveness of different-sized separating filter configurations of various filter lengths. Using a multi-channel blind least-mean-square algorithm (MBLMS), we show that, by adding additional sensors, we can improve upon the separation of signals mixed with real world filters. 
Title: Title: BLIND SEPARATION OF REAL WORLD AUDIO SIGNALS USING OVERDETERMINED MIXTURES  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Blind separation of delayed and convolved sources.  
Abstract address separating multiple speakers multiple microphones We combine Torkkola Amari Cichocki Yang Natural Gradient information maximisation rules recurrent (IIR) networks blindly adjusting delays separating mixed signals While they work well simulated data these rules fail real r
Paper 3  Title: BLIND SEPARATION OF DELAYED SOURCES BASED ON INFORMATION MAXIMIZATION  
Abstract Recently Bell presented blind source separation We extend this approach into the sources may delayed with each We present a network architecture capable coping such sources, derive the adaptation equations the delays the weights i
Paper 4  Title: Analyzing Hyperspectral Data with Independent Component Analysis  
Abstract Hyperspectral image sensors provide images contiguous spectral channels per enable information different materials within The problem spectrally unmixing materials may viewed a specific case the blind source separation problem where data consists mixed signalsin minerals the goal determin
Paper 5  Title: Recognizing Handwritten Digits Using Mixtures of Linear Models  
Abstract We construct a mixture locally linear generative models a collection pixel-based images digits recognition Different models a given digit capture different styles writing new images classified evaluating their log-likelihoods under We use an EM-based algorithm in the M-step computationally straightforward p
Label: Neural Networks
Paper 6  Title: A Context-Sensitive Generalization of ICA  
Abstract Source separation arises signal processing applications EEG analysis In the square linear blind source separation problem without time delays one an unmixing matrix detangle mixing n unknown independent sources through an unknown n fi n mixing matrix The recently introduced ICA blind source separat
Paper 7  Title: Independent Component Analysis of Electroencephalographic Data  
Abstract Because the distance the skull brain their different resistivities collected any point includes activity generated within This spatial smearing EEG data volume conduction does involve significant time delays however suggesting Independent ComponentICA algori
Paper 8  Title: A Blind Identification and Separation Technique via Multi-layer Neural Networks  
Abstract deals blind identification source separation which consists estimation the mixing matrix without on. The method we propose estimates the mixture matrix by recurrent InputIO Identification using as
Paper 9  Title: Simple Neuron Models for Independent Component Analysis  
Abstract Recently several neural algorithms introduced Independent Component Analysis Here approach a single neuron First simple Hebbian-like learning rules introduced estimating one of from sphered data Some the learning rules can used estimate an independent component which a negative kur
Label: Neural Networks
Paper 10  Title: Finding Overlapping Distributions with MML  
Abstract considers an aspect mixture modelling. Significantly overlapping distributions require their parameters accurately than well separated distributions For example two Gaussian distributions considered significantly overlap their means within If insufficient data only singl
Paper 11  Title: Maximum Likelihood and Covariant Algorithms for Independent Component Analysis somewhat more biologically plausible, involving no
Abstract Bell and Sejnowski1995 derived a blind signal processing algorithm an information maximization viewpoint This paper first shows the same algorithm viewed a maximum likelihood the optimization Third this paper gives a partial proof the `folk-theorem any mixture source
Paper 12  Title: Speech Recognition with Dynamic Bayesian Networks  
Abstract Dynamic Bayesian networks representing Recent developments inference learning DBNs allow their use In this paper apply DBNs the problem speech recognition The factored state representation enabled DBNs allows us explicitly represent long-term articulatory acoustic context
Label: Probabilistic Methods
Paper 13  Title: Causal Discovery via MML  
Abstract Automating the learning causal models from sample data incorporating the automation reasoning under uncertainty This paper the discovery causal models a Minimum Message Length (MML) method We developed encoding search methods discovering linear causal models The in
Paper 14  Title: Using Mixtures of Factor Analyzers for Segmentation and Pose Estimation  Category: Visual Processing Preference: Oral  
Abstract To read a hand-written digit string it segment separate digits Bottom-up segmentation heuristics often neighboring digits substantially We describe has each digit class we the only knowledge required segmentation The system uses Gibbs sampling construct a percept
Label: Neural Networks
Paper 15  Title: Coupled hidden Markov models for complex action recognition  
Abstract: c flMIT Media Lab Perceptual Computing / Learning Common Sense Technical Report 407 20nov96 Abstract We algorithms coupling hidden Markov models model interacting processes their superiority a vision task classifying two-handed actions HMMs perhaps perceptual computing fo
Label: Probabilistic Methods
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1152...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Keywords: Case-Based Reasoning, case retrieval, case representation This paper deals with the retrieval of useful cases in case-based reasoning. It focuses on the questions of what "useful" could mean and how the search for useful cases can be organized. We present the new search algorithm Fish and Shrink that is able to search quickly through the case base, even if the aspects that deflne usefulness are spontaneously combined at query time. We compare Fish and Shrink to other algorithms and show that most of them make an implicit closed world assumption. We flnally refer to a realization of the presented idea in the context of the prototype of the FABEL-Project 1 . The scenery is as follows. Previously collected cases are stored in a large scaled case base. An expert describes his problem and gives the aspects in which the requested case should be similar. The similarity measure thus given spontaneously shall now be used to explore the case base within a short time, shall present a required number of cases and make sure that none of the other cases is more similar. The question is now how to prepare the previously collected cases and how to deflne a retrieval algorithm which is able to deal with sponta neously user-deflned similarity measures.
Title: Title: Fish and Shrink. A next step towards e-cient case retrieval in large scaled case bases  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Case Retrieval Nets: Basic Ideas and Extensions  
Abstract An efficient retrieval a relatively small number relevant cases a huge case base a crucial subtask Case-Based Reasoning In present Case Retrieval Nets ( a memory model has recently this task The main idea apply a spreading activation process a net-like case memory in retrieve cases being similar a pose
Label: Case Based
Paper 3  Title: Context-Based Similarity Applied to Retrieval of Relevant Cases  
Abstract Retrieving relevant cases case-based reasoning systems The task is use user-defined query to useful information i.e., exact matches or which close query-defined request according certain measures The difficulty stems it may ( it specify query requests precisely a
Label: Case Based
Paper 4  Title: Growing a Hypercubical Output Space in a Self-Organizing Feature Map  
Abstract Recent studies planning comparing plan reuse plan generation both the above tasks may computational complexity even we deal very similar problems The aim the same kind results apply also diagnosis. We propose a theoretical complexity analysis coupled some experimental tests intended
Paper 5  Title: On the Usefulness of Re-using Diagnostic Solutions  
Abstract Recent studies planning comparing plan reuse plan generation both the above tasks may computational complexity even we deal very similar problems The aim the same kind results apply also diagnosis. We propose a theoretical complexity analysis coupled some experimental tests intended
Label: Case Based
Paper 6  Title: ADAPtER: an Integrated Diagnostic System Combining Case-Based and Abductive Reasoning  
Abstract the ADAPtER system a diagnostic architecture combining case-based reasoning abductive reasoning exploiting the adaptation the solution old episodes focus the reasoning process Domain knowledge represented via a logical model basic mechanisms based abductive reasoning with consistency constraints have defi
Label: Case Based
Paper 7  Title: Lazy Induction Triggered by CBR  
Abstract In case-based reasoning demonstrated problem complex domains Also mixed paradigm approaches emerged combining CBR and induction techniques aiming verifying the knowledge building an efficient case memory However in complex domains induction over the whole problem space often or too time
Paper 8  Title: REPRO: Supporting Flowsheet Design by Case-Base Retrieval  
Abstract very close the designer behavior during, seems a fruitable computer aided-design approach if a library design cases presents: REPRO, that supports chemical process design The crucial problems like the case represen
Paper 9  Title: A Preprocessing Model for Integrating CBR and Prototype-Based Neural Networks  
Abstract Some important factors play the performances a CBR (Case-Based Reasoning) system the complexity the accuracy the retrieval phase Both flat memory inductive approaches suffer serious drawbacks In the first approach search time increases when dealing large scale memory base while modification of
Paper 10  Title: Adaptive Tuning of Numerical Weather Prediction Models: Simultaneous Estimation of Weighting, Smoothing and Physical Parameters 1  
Abstract In case-based reasoning demonstrated problem complex domains Also mixed paradigm approaches emerged combining CBR and induction techniques aiming verifying the knowledge building an efficient case memory However in complex domains induction over the whole problem space often or too time
Paper 11  Title: Structural Similarity as Guidance in Case-Based Design  
Abstract determine structural similarity as guidance adaptationCbr We advance structural similarity assessment which not only a single numeric value the most specific structure two cases have inclusive the modification rules needed obtain Our approach treats ret
Label: Case Based
Paper 12  Title: Automatic Indexing, Retrieval and Reuse of Topologies in Architectual Layouts  
Abstract Former layouts contain much architects A generic and automatic way formalize this know-how order use by a computer would save However seems The only access are the layouts themselves Developing a generic software tool reuse former layouts you consider every part the architec
Paper 13  Title: Structural Similarity and Adaptation  
Abstract Most commonly case-based reasoning domains attribute value representations cases sufficient relevant support classification diagnosis design tasks Distance functions like the Hamming-distance or their transformation similarity functions applied retrieve past cases to an actual pr
Paper 14  Title: A Similarity-Based Retrieval Tool for Software Repositories  
Abstract In a prototype a flexible similarity-based retrieval system Its flexibility supported allowing an imprecisely specified query Moreover our algorithm allows assessing if the retrieved items the initial context specified The presented system can a supporting tool a software repository We also discuss s
Paper 15  Title: FONN: Combining First Order Logic with Connectionist Learning  
Abstract a neural network architecture manage structured data refine knowledge bases expressed a first order logic language The presented framework well classification problems concept de scriptions depend numerical features In fact the main goal the neural architecture that refining the numerical part the k
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Category: Case Based
Prediction:  Category: Case Based
Is prediction correct?  False

Prediction: 0
Processing index 1020...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present a comparison of error-based and entropy-based methods for discretization of continuous features. Our study includes both an extensive empirical comparison as well as an analysis of scenarios where error minimization may be an inappropriate discretization criterion. We present a discretization method based on the C4.5 decision tree algorithm and compare it to an existing entropy-based discretization algorithm, which employs the Minimum Description Length Principle, and a recently proposed error-based technique. We evaluate these discretization methods with respect to C4.5 and Naive-Bayesian classifiers on datasets from the UCI repository and analyze the computational complexity of each method. Our results indicate that the entropy-based MDL heuristic outperforms error minimization on average. We then analyze the shortcomings of error-based approaches in comparison to entropy-based methods. 
Title: Title: Error-Based and Entropy-Based Discretization of Continuous Features  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Supervised and Unsupervised Discretization of Continuous Features  
Abstract Many supervised machine learning algorithms require a discrete feature space In this paper review continuous feature discretization identify defining characteristics the methods conduct several methods We compare binning, entropy-based and purity-based methods supervised algori
Label: Theory
Paper 3  Title: Evolutionary Design of Neural Architectures A Preliminary Taxonomy and Guide to Literature  
Abstract In a computation-ally efficient method inducing selective Bayesian network classifiers Our approach information-theoretic metrics efficiently select a subset attributes which learn the classifier We explore three conditional, information-theoretic met-rics extensions metrics extensively decision tree learning namel
Paper 4  Title: Efficient Learning of Selective Bayesian Network Classifiers  
Abstract In a computation-ally efficient method inducing selective Bayesian network classifiers Our approach information-theoretic metrics efficiently select a subset attributes which learn the classifier We explore three conditional, information-theoretic met-rics extensions metrics extensively decision tree learning namel
Label: Probabilistic Methods
Paper 5  Title: Search-based Class Discretization  
Abstract We a methodology enables classification algorithms on regression tasks We implement system RECLA that transforms a regression problem classification one and an existent classification system solve The transformation consists mapping a continuous variable grouping
Paper 6  Title: Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic Decision Tree Induction Algorithm  
Abstract introduces ICET costsensitive classification ICET uses evolve biases for a decision tree induction algorithm The fitness function the genetic algorithm the average cost classification when using the decision tree including both the costs testsfeatures measurements classification err
Label: Genetic Algorithms
Paper 7  Title: Pruning Decision Trees with Misclassification Costs  
Abstract We describe pruning methods decision tree classifiers when minimizing loss rather error In two common methods error minimization CART's cost-complexity pruning study the extension loss and one pruning variant based We perform an empir
Paper 8  Title: Understanding Musical Sound with Forward Models and Physical Models  
Abstract introduces ICET costsensitive classification ICET uses evolve biases for a decision tree induction algorithm The fitness function the genetic algorithm the average cost classification when using the decision tree including both the costs testsfeatures measurements classification err
Paper 9  Title: Towards a Better Understanding of Memory-Based Reasoning Systems  
Abstract We quantify both experimentally memory-based reasoning To start gaining insight the capabilities MBR algorithms compare using a value difference metric a popular Bayesian classifier These two approaches similar make certain independence assumptions However whereas
Paper 10  Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  
Abstract With computational costs without accuracy describe two algorithms find sets prototypes nearest neighbor classification Here the term prototypes the reference instances a nearest neighbor computation the instances with respect which similarity assessed assign a new data item Both algorithms re
Paper 11  Title: Building Classifiers using Bayesian Networks  
Abstract Recent work supervised learning a surprisingly simple Bayesian classifier strong assumptions of independence among features called naive Bayes competitive state of such C4.5 This fact raises less restrictive assumptions perform even In this paper and approach
Label: Probabilistic Methods
Paper 12  Title: Automatic Parameter Selection by Minimizing Estimated Error  
Abstract address finding the parameter settings will result learning as We describe a "wrapper" method considering determination as a discrete function optimization problem The method uses best-first search cross wrap around the basic induction al
Paper 13  Title: Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology  
Abstract In the wrapper approach feature subset selection a search the induction algorithm as The estimated future performance the algorithm the heuristic guiding Statistical methods feature subset selection including forward selection backward elimination their stepwise variants can viewed as simple hill
Paper 14  Title: An Efficient Extension to Mixture Techniques for Prediction and Decision Trees  
Abstract We maintaining mixtures prunings a prediction or decision tree extends the "node-based" prunings [Bun90, WST95 HS97 to the larger class The method includes an efficient online weight allocation prediction compression classification Although the set edge-based prunings of a given tree m
Paper 15  Title: Chapter 4 Empirical comparison of stochastic algorithms Empirical comparison of stochastic algorithms in a graph
Abstract There several stochastic methods solving approximatively Examples such algorithms (in increasing computational complexity stochastic greedy search methods simulated annealing genetic algorithms We investigate which these methods likely give best performance practice with respect the comput
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Paper 1: Probabilistic Methods
Prediction:  Paper 1: Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 975...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Genetic programming is distinguished from other evolutionary algorithms in that it uses tree representations of variable size instead of linear strings of fixed length. The flexible representation scheme is very important because it allows the underlying structure of the data to be discovered automatically. One primary difficulty, however, is that the solutions may grow too big without any improvement of their generalization ability. In this paper we investigate the fundamental relationship between the performance and complexity of the evolved structures. The essence of the parsimony problem is demonstrated empirically by analyzing error landscapes of programs evolved for neural network synthesis. We consider genetic programming as a statistical inference problem and apply the Bayesian model-comparison framework to introduce a class of fitness functions with error and complexity terms. An adaptive learning method is then presented that automatically balances the model-complexity factor to evolve parsimonious programs without losing the diversity of the population needed for achieving the desired training accuracy. The effectiveness of this approach is empirically shown on the induction of sigma-pi neural networks for solving a real-world medical diagnosis problem as well as benchmark tasks. 
Title: Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Balancing Accuracy and Parsimony in Genetic Programming 1  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 3  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 4  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Label: Genetic Algorithms
Paper 5  Title: Spline Smoothing For Bivariate Data With Applications To Association Between Hormones  
Abstract Standard methods inducing both the structure weight values recurrent neural networks fit an assumed class architectures to every task This simplification necessary the interactions network structure function Evolutionary computation includes genetic algorithms evolutionary programming a population-based search
Paper 6  Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Abstract Genetic algorithms neural networks two main ways optimize train the weights a fixed architecture While most previous work focuses only of these two options investigates an alternative evolutionary approach called Breeder Genetic Programming the architecture and the weights optimized simult
Paper 7  Title: An Evolutionary Algorithm that Constructs Recurrent Neural Networks  
Abstract Standard methods inducing both the structure weight values recurrent neural networks fit an assumed class architectures to every task This simplification necessary the interactions network structure function Evolutionary computation includes genetic algorithms evolutionary programming a population-based search
Paper 8  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract In Operation Research and Artificial Intelligence several stochastic search algorithms designed based global random searchZhigljavsky Basically those techniques iteratively sample the search space with respect a probability distribution which updated according previous samples some predefined strategy Genetic
Paper 9  Title: Genetic Programming of Minimal Neural Nets Using Occam's Razor  
Abstract A genetic programming method investigated optimizing both the architecture the connection weights multilayer feedforward neural networks The genotype each network whose depth dynamically adapted the particular application by specifically defined genetic operators The weights trained a next-ascent hillclimb-ing search A
Paper 10  Title: Hierarchical Self-Organization in Genetic Programming  
Abstract automatic discovery functions Genetic Programming The approach discovery analyzing the evolution trace generalizing blocks define finally adapting the problem representation on- Adaptating the representation determines a hierarchical organization extended function set
Label: Genetic Algorithms
Paper 11  Title: Evolution, Learning, and Instinct: 100 Years of the Baldwin Effect Using Learning to Facilitate the
Abstract a hybrid methodology integrates genetic algorithms decision tree learning evolve useful subsets discriminatory features for recognizing complex visual concepts A genetic algorithm (GA search the space all possible subsets candidate discrimination features Candidate feature subsets evaluated using C4.5
Label: Genetic Algorithms
Paper 12  Title: DISTRIBUTED GENETIC ALGORITHMS FOR PARTITIONING UNIFORM GRIDS  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Paper 13  Title: Distributed Representations and Nested Compositional Structure  
Abstract Adaptation ecological systems their environments commonly viewed through some explicit fitness function defined measured estimations based reproductive rates These methods do capture the role environmental complexity shaping control the adaptive process Ecological
Paper 14  Title: Evolution-based Discovery of Hierarchical Behaviors  
Abstract Procedural representations control policies two advantages when facing learning tasks First implicit potential over situations Second they facilitate modularization compare several randomized algorithms learning modular procedural representations The main algorithm ca
Paper 15  Title: A Cooperative Coevolutionary Approach to Function Optimization  
Abstract: A general model the coevolution cooperating species This model instantiated and tested the domain function optimization compared a traditional GA-based function optimizer The results encouraging in two respects They suggest ways the performance GA and other EA-based optimizers they ev
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  False

Prediction: 0
Processing index 488...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present a new general-purpose algorithm for learning classes of [0; 1]-valued functions in a generalization of the prediction model, and prove a general upper bound on the expected absolute error of this algorithm in terms of a scale-sensitive generalization of the Vapnik dimension proposed by Alon, Ben-David, Cesa-Bianchi and Haussler. We give lower bounds implying that our upper bounds cannot be improved by more than a constant factor in general. We apply this result, together with techniques due to Haussler and to Benedek and Itai, to obtain new upper bounds on packing numbers in terms of this scale-sensitive notion of dimension. Using a different technique, we obtain new bounds on packing numbers in terms of Kearns and Schapire's fat-shattering function. We show how to apply both packing bounds to obtain improved general bounds on the sample complexity of agnostic learning. For each * &gt; 0, we establish weaker sufficient and stronger necessary conditions for a class of [0; 1]-valued functions to be agnostically learnable to within *, and to be an *-uniform Glivenko-Cantelli class. 
Title: Title: Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Simulating Access to Hidden Information while Learning  
Abstract We introduce which without access hidden information nearly We apply our technique solve Maass Turan [18 showing for any concept class F, the least number queries sufficient learning by which access only arbitrary equivalence
Paper 3  Title: Statistical Queries and Faulty PAC Oracles  
Abstract In study learning the PAC model Valiant [18 the example oracle used may faulty one distorting the distribution examples We first consider models examples misclassified Kearns [12 recently showed efficient learning a new model using statistical queries a s
Paper 4  Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  
Abstract: We present an algorithm improving algorithms learning binary concepts The improvement achieved combining a large number hypotheses each generated training given learning examples Our algorithm ideas presented Schapire inThe strength weak learnability represents an im
Label: Theory
Paper 5  Title: General Bounds on Statistical Query Learning and PAC Learning with Noise via Hypothesis Boosting  
Abstract We derive general bounds learning the Statistical Query model in the PAC model classification noise We do so considering boosting weak learning algorithms which fall the Statistical Query model This new model Kearns [12 efficient PAC learning the presence o
Paper 6  Title: Predicting a binary sequence almost as well as the optimal biased coin  
Abstract apply the exponential weight algorithm and Littlestone and Warmuth by Vovk [24 predicting a binary sequence almost the best biased coin We first show for the case the derived algorithm Jeffrey's prior that was studied Xie Barron under probabilistic assump
Paper 7  Title: Noise-Tolerant Parallel Learning of Geometric Concepts  
Abstract several efficient parallel algorithms PAC-learning geometric concepts robust even malicious misclassification noise of any rate less 1=2 In particular we consider geometric concepts defined (d 1)-dimensional hyperplanes against where
Label: Theory
Paper 8  Title: Theory and Applications of Agnostic PAC-Learning with Small Decision Trees  
Abstract We exhibit a theoretically founded algorithm T2 agnostic PAC-learning of decision trees at whose computation time almost linear the size We evaluate this learning algorithm T2 on 15 common real-world datasets for most provides simple decision trees predictive
Paper 9  Title: On the Sample Complexity of Noise-Tolerant Learning  
Abstract In further characterize the complexity noise-tolerant learning the PAC model Specifically show a general lower log(1=ffi examples required PAC learning classification noise Combined a result Simon, effectively show the sample complexity PAC learning classification noise V
Label: Theory
Paper 10  Title: A General Lower Bound on the Number of Examples Needed for Learning  
Abstract We prove a lower ( 1 * ln 1 ffi + VCdim(C ) random examples required distribution-free learning a concept class C the Vapnik-Chervonenkis dimension * and the accuracy and confidence parameters This improves previous best lower ( 1 * ln 1 ffi VCdim(C comes O
Paper 11  Title: A Fast, Bottom-Up Decision Tree Pruning Algorithm with Near-Optimal Generalization  
Abstract In this work a new bottom-up algorithm decision tree pruning very (requiring only a single pass the given tree prove a strong performance guarantee the generalization error We work the typical setting in the given tree T may derived the given training sample S may badly ove
Paper 12  Title: Monte Carlo Comparison of Non-hierarchical Unsupervised Classifiers  
Abstract In further characterize the complexity noise-tolerant learning the PAC model Specifically show a general lower log(1=ffi examples required PAC learning classification noise Combined a result Simon, effectively show the sample complexity PAC learning classification noise V
Paper 13  Title: Learning Switching Concepts  
Abstract We consider learning situations the function used classify examples may switch back during We examine several models such situations oblivious models in switches independent the selection examples more adversarial models a single adversary both the c
Paper 14  Title: Learning Using Group Representations (Extended Abstract)  
Abstract consider learning functions An algorithm by Kushilevitz Mansour [7 learns any boolean function over f0; 1g n time in the L 1 -norm We show the KM-algorithm This achieved extending their ideas represent
Paper 15  Title: Machine Learning, 22(1/2/3):95-121, 1996. On the Worst-case Analysis of Temporal-difference Learning Algorithms  
Abstract We study the behavior a family learning algorithms Sutton's method temporal differences In our on learning framework learning takes a sequence trials the goal estimate a discounted sum all the reinforcements received the future In this setting able prove general upper bounds the pe
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 1139...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The optimization of a single bit string by means of iterated mutation and selection of the best (a (1+1)-Genetic Algorithm) is discussed with respect to three simple fitness functions: The counting ones problem, a standard binary encoded integer, and a Gray coded integer optimization problem. A mutation rate schedule that is optimal with respect to the success probability of mutation is presented for each of the objective functions, and it turns out that the standard binary code can hamper the search process even in case of unimodal objective functions. While normally a mutation rate of 1=l (where l denotes the bit string length) is recommendable, our results indicate that a variation of the mutation rate is useful in cases where the fitness function is a multimodal pseudo-boolean function, where multimodality may be caused by the objective function as well as the encoding mechanism.
Title: Title: Optimal Mutation Rates in Genetic Search  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Evolutionary Approach to Combinatorial Optimization Problems  
Abstract The paper reports genetic algorithms, based the model organic evolution NP-complete combinatorial optimization problems In particular the subset sum, maximum cut minimum tardy task problems considered Except the fitness function no problem-specific changes of the genetic algorithm ac
Paper 3  Title: An Analysis of the MAX Problem in Genetic Programming hold only in some cases, in
Abstract We genetic programmingGP populations the problem finding a program returns and function set a depth limitknown the MAX problem We confirm the basic message [ Gathercole and Ross 1996 crossover together program size restrictions c
Label: Genetic Algorithms
Paper 4  Title: Genetic algorithms with multi-parent recombination  
Abstract In genetic algorithms where more than two parents the recombination operation In particular introduce gene scanning a reproduction mechanism generalizes classical crossovers n-point crossover uniform crossover applicable an arbitrary number (two parents We performed extensive tests optimizing n
Paper 5  Title: Putting the Genetics back into Genetic Algorithms  
Abstract In genetic algorithms where more than two parents the recombination operation In particular introduce gene scanning a reproduction mechanism generalizes classical crossovers n-point crossover uniform crossover applicable an arbitrary number (two parents We performed extensive tests optimizing n
Paper 6  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 7  Title: Balancing Accuracy and Parsimony in Genetic Programming 1  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 8  Title: Graph Coloring with Adaptive Evolutionary Algorithms  
Abstract solving graph coloringEA After testing different algorithm variants we conclude an asexual EA using order-based representation an adaptation mechanism periodically the fitness function during This adaptive EA is general, usi
Paper 9  Title: Price's Theorem and the MAX Problem  
Abstract We GP populations the problem finding a program which returns and function set a depth limitknown the MAX problem We confirm the basic message [ Gathercole and Ross 1996 crossover together program size restrictions responsible
Paper 10  Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 11  Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Abstract Genetic algorithms neural networks two main ways optimize train the weights a fixed architecture While most previous work focuses only of these two options investigates an alternative evolutionary approach called Breeder Genetic Programming the architecture and the weights optimized simult
Paper 12  Title: A Genetic Algorithm for Continuous Design Space Search  
Abstract Genetic algorithms ( extensively performing global optimization a simple yet reliable manner However some realistic engineering design optimization domains the simple, classical implementation a GA based binary encoding bit mutation and crossover often inefficient unable reach the global optimum In a GA
Label: Genetic Algorithms
Paper 13  Title: A Genetic Local Search Approach to the Quadratic Assignment Problem  
Abstract Augmenting genetic algorithms local search heuristics the solution In this paper a genetic local search approach the quadratic assignment problemQAP New genetic operators for realizing the approach described, its performance tested various QAP instances containing between 256
Paper 14  Title: Genetic Programming of Minimal Neural Nets Using Occam's Razor  
Abstract A genetic programming method investigated optimizing both the architecture the connection weights multilayer feedforward neural networks The genotype each network whose depth dynamically adapted the particular application by specifically defined genetic operators The weights trained a next-ascent hillclimb-ing search A
Paper 15  Title: Adaptation of Genetic Algorithms for Engineering Design Optimization  
Abstract Genetic algorithms extensively different domains as doing global optimization However some realistic engineering design optimization domains was observed a simple classical implementation the GA based binary encoding bit mutation and crossover sometimes inefficient unable reach
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 954...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model is closely related to the Harmonium model defined by Smolensky [RM86][Ch.6]. In the first part of the paper we analyze properties of this distribution representation scheme. We show that arbitrary distributions of binary vectors can be approximated by the combination model. We show how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits. We compare the combination model with the mixture model and with principle component analysis. In the second part of the paper we present two algorithms for learning the combination model from examples. The first algorithm is based on gradient ascent. Here we give a closed form for this gradient that is significantly easier to compute than the corresponding gradient for the general Boltzmann machine. The second learning algorithm is a greedy method that creates the hidden units and computes their weights one at a time. This method is a variant of projection pursuit density estimation. In the third part of the paper we give experimental results for these learning methods on synthetic data and on natural data of handwritten digit images. 
Title: Title: Unsupervised learning of distributions on binary vectors using two layer networks  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Separating Formal Bounds from Practical Performance in Learning Systems  
Abstract We a distribution model binary vectors called the influence combination model and show as feature selection The model closely the Harmonium model defined Smolensky [RM86][Ch.6 In the first part the paper analyze properties this distribution representation scheme We sho
Paper 3  Title: On the Learnability and Usage of Acyclic Probabilistic Finite Automata  
Abstract propose and analyze a distribution learning a subclass This subclass characterized a certain distinguishability property the automata's states Though hardness results are known learning distributions generated general APFAs prove our algorithm efficiently the s
Paper 4  Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,
Abstract Although probabilistic inference a general Bayesian belief network inference computation time reduced most practical cases exploiting domain knowledge by making the knowledge representation In this paper the property similarity states a new method approximate knowledge representation whic
Label: Theory
Paper 5  Title: Training Algorithms for Hidden Markov Models Using Entropy Based Distance Functions  
Abstract We new algorithms parameter estimation HMMs By adapting construct maximize the observations while attempting stay close We use a bound on the relative entropy between the two HMMs as between The result new iterat
Paper 6  Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  
Abstract The work discussed motivated of building decision support systems Our goal use these systems supporting Bayes optimal decision making where the action maximizing the expected utility, with respect predicted probabilities should selected For the models need
Paper 7  Title: Static Data Association with a Terrain-Based Prior Density  
Abstract In there works learning probabilistic belief networks Current state have shown successful two learning scenarios learning both network structure parameters complete data parameters a fixed network from incomplete datathat is, the presence missing values or hidden variables However
Label: Probabilistic Methods
Paper 8  Title: Distribution Category:  Users Guide to the PGAPack Parallel Genetic Algorithm Library  
Abstract The problem modeling complicated data sequences DNA speech often practice Most the algorithms select a hypothesis within assuming the observed sequence the direct output In when the output passes a memoryless noisy channel before observation In particula
Paper 9  Title: Support Vector Machines: Training and Applications  
Abstract The Support Vector Machine a new and very promising classification technique developed Vapnik his group [3 24 This new learning algorithm seen an alternative training technique Polynomial, Radial Basis Function and Multi-Layer Perceptron classifiers The main idea the technique separate the classes with a surfa
Paper 10  Title: Learning Markov chains with variable memory length from noisy output  
Abstract The problem modeling complicated data sequences DNA speech often practice Most the algorithms select a hypothesis within assuming the observed sequence the direct output In when the output passes a memoryless noisy channel before observation In particula
Label: Theory
Paper 11  Title: Self bounding learning algorithms  
Abstract Most which attempts give bounds the generalization error the hypothesis generated a learning algorithm methods from uniform convergence These bounds a-priori bounds hold any distribution examples calculated before observed In this paper bounding the generalization e
Label: Theory
Paper 12  Title: A Fast Fixed-Point Algorithm for Independent Component Analysis  
Abstract will appear Neural Computation 9:1483 1997 Abstract We introduce a novel fast algorithm Independent Component Analysis can blind source separation feature It shown how a neural network learning rule transformed a txed-point iteration provides an algorithm very simple, does any user-de
Paper 13  Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  
Abstract: We present an algorithm improving algorithms learning binary concepts The improvement achieved combining a large number hypotheses each generated training given learning examples Our algorithm ideas presented Schapire inThe strength weak learnability represents an im
Label: Theory
Paper 14  Title: Constructing Bayesian finite mixture models by the EM algorithm  
Abstract: Email: Firstname.HelsinkiFI Report C-19969, University Department Abstract In finite mixture models building decision support systems capable sound probabilistic inference Finite mixture models have many appealing properties in prediction (reasoning phase the
Paper 15  Title: On the Sample Complexity of Learning Bayesian Networks  
Abstract In there learning Bayesian networks data One learning such networks based the minimum description length principle Previous work this learning procedure successful: with probability one, will converge the target distribution given a sufficient numbe
Label: Probabilistic Methods
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Paper 2: Theory  
Paper 3: Probabilistic Methods  
Paper 5: Probabilistic Methods  
Paper 7: Probabilistic Methods  
Paper 8: Genetic Algorithms  
Paper 9: Neural Networks  
Paper 10: Theory  
Paper 11: Theory  
Paper 12: Neural Networks  
Paper 13: Theory  
Paper 15: Probabilistic Methods
Prediction:  Paper 2: Theory  
Paper 3: Probabilistic Methods  
Paper 5: Probabilistic Methods  
Paper 7: Probabilistic Methods  
Paper 8: Genetic Algorithms  
Paper 9: Neural Networks  
Paper 10: Theory  
Paper 11: Theory  
Paper 12: Neural Networks  
Paper 13: Theory  
Paper 15: Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 1520...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Source separation consists in recovering a set of independent signals when only mixtures with unknown coefficients are observed. This paper introduces a class of adaptive algorithms for source separation which implements an adaptive version of equivariant estimation and is henceforth called EASI (Equivariant Adaptive Separation via Independence). The EASI algorithms are based on the idea of serial updating: this specific form of matrix updates systematically yields algorithms with a simple, parallelizable structure, for both real and complex mixtures. Most importantly, the performance of an EASI algorithm does not depend on the mixing matrix. In particular, convergence rates, stability conditions and interference rejection levels depend only on the (normalized) distributions of the source signals. Close form expressions of these quantities are given via an asymptotic performance analysis. This is completed by some numerical experiments illustrating the effectiveness of the proposed approach. 
Title: Title: Equivariant adaptive source separation  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Blind Identification and Separation Technique via Multi-layer Neural Networks  
Abstract deals blind identification source separation which consists estimation the mixing matrix without on. The method we propose estimates the mixture matrix by recurrent InputIO Identification using as
Paper 3  Title: A New Learning Algorithm for Blind Signal Separation  
Abstract A on learning which a statistical dependency among outputs derived for blind separation mixed signals The dependency measured the average mutual information the outputs The source signals and the mixing matrix unknown except the sources The Gram-Charlier expansion instead used evalu
Paper 4  Title: The Central Classifier Bound ANew Error Bound for the Classifier Chosen by Early Stopping Key
Abstract A on learning which a statistical dependency among outputs derived for blind separation mixed signals The dependency measured the average mutual information the outputs The source signals and the mixing matrix unknown except the sources The Gram-Charlier expansion instead used evalu
Paper 5  Title: A FAMILY OF FIXED-POINT ALGORITHMS FOR INDEPENDENT COMPONENT ANALYSIS  
Abstract Independent Component AnalysisICA a statistical signal processing technique whose main applications blind source separation blind deconvolution feature Estimation ICA is usually performed optimizing a 'contrast' function based higher-order cumulants In this paper it almost any error function construct a contrast function
Paper 6  Title: On the performance of orthogonal source separation algorithms  
Abstract Source separation consists recovering n independent signals m n observed instantaneous mixtures possibly corrupted additive noise Many source separation algorithms second order information a whitening operation the non trivial part determining a unitary matrix Most further show a kind invariance
Paper 7  Title: SELF-ADAPTIVE NEURAL NETWORKS FOR BLIND SEPARATION OF SOURCES  
Abstract Novel on learning with self adaptive learning ratesparameters blind separation signals are The main motivation development new learning rules convergence speed to crosstalking especially non-stationary signals Furthermore we discovered under proposed neural models with associ
Paper 8  Title: BLIND SEPARATION OF DELAYED SOURCES BASED ON INFORMATION MAXIMIZATION  
Abstract Recently Bell presented blind source separation We extend this approach into the sources may delayed with each We present a network architecture capable coping such sources, derive the adaptation equations the delays the weights i
Paper 9  Title: NEURAL NETWORK APPROACH TO BLIND SEPARATION AND ENHANCEMENT OF IMAGES  
Abstract In this contribution blind separation sourcesfor one dimensional signals images that not only the waveform sources unknown their number For this purpose multi-layer neural networks with associated adaptive learning algorithms The primary source signals can have any non-Gaussian distribution
Paper 10  Title: Simple Neuron Models for Independent Component Analysis  
Abstract Recently several neural algorithms introduced Independent Component Analysis Here approach a single neuron First simple Hebbian-like learning rules introduced estimating one of from sphered data Some the learning rules can used estimate an independent component which a negative kur
Label: Neural Networks
Paper 11  Title: ADAPTIVE REGULARIZATION  
Abstract: Regularization, in weight decay important training optimization In this work provide based asymptotic sampling theory for iterative estimation weight decay parameters The basic idea do a gradient descent in the estimated generalization error with the regularization parameters The scheme
Paper 12  Title: A Fast Fixed-Point Algorithm for Independent Component Analysis  
Abstract will appear Neural Computation 9:1483 1997 Abstract We introduce a novel fast algorithm Independent Component Analysis can blind source separation feature It shown how a neural network learning rule transformed a txed-point iteration provides an algorithm very simple, does any user-de
Paper 13  Title: LOCAL ADAPTIVE LEARNING ALGORITHMS FOR BLIND SEPARATION OF NATURAL IMAGES  
Abstract In a neural approach for reconstruction natural highly correlated images linear (additive) mixture them A multi-layer architecture local online learning rules developed solve blind separation sources The main motivation using a multi-layer network instead improve
Label: Neural Networks
Paper 14  Title: Journal of Convex Analysis (accepted for publication) A HYBRID PROJECTION-PROXIMAL POINT ALGORITHM  
Abstract We propose a modification the classical proximal point algorithm finding a maximal monotone operator In particular an approximate proximal point iteration construct strictly separates the current iterate the solution set This step then a projection the current iterate onto the separ
Label: Neural Networks
Paper 15  Title: A Context-Sensitive Generalization of ICA  
Abstract Source separation arises signal processing applications EEG analysis In the square linear blind source separation problem without time delays one an unmixing matrix detangle mixing n unknown independent sources through an unknown n fi n mixing matrix The recently introduced ICA blind source separat
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 161...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: New methodology for fully Bayesian mixture analysis is developed, making use of reversible jump Markov chain Monte Carlo methods, that are capable of jumping between the parameter subspaces corresponding to different numbers of components in the mixture. A sample from the full joint distribution of all unknown variables is thereby generated, and this can be used as a basis for a thorough presentation of many aspects of the posterior distribution. The methodology is applied here to the analysis of univariate normal mixtures, using a hierarchical prior model that offers an approach to dealing with weak prior information while avoiding the mathematical pitfalls of using improper priors in the mixture context.
Title: Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Hyperparameter estimation in Dirichlet process mixture models  
Abstract Bayesian density estimation prediction standard, exponential family distributions the precision or total mass parameter a critical hyperparame-ter that strongly resulting inferences numbers mixture components This note shows, respect a flexible class prior distributions
Label: Probabilistic Methods
Paper 3  Title: Strategies for the Parallel Training of Simple Recurrent Neural Networks  
Abstract Bayesian density estimation prediction standard, exponential family distributions the precision or total mass parameter a critical hyperparame-ter that strongly resulting inferences numbers mixture components This note shows, respect a flexible class prior distributions
Paper 4  Title: Bayesian Mixture Modeling by Monte Carlo Simulation  
Abstract It shown from modeled a mixture distribution feasibly via This method exhibits the true Bayesian predictive distribution implicitly integrating over An infinite number mixture components without difficulty a prior distribution mixing propor
Paper 5  Title: In Advances in Neural Information Processing Systems 8  Gaussian Processes for Regression  
Abstract difficult simple prior over weights implies functions In Gaussian process priors over functions permit the predictive Bayesian analysis for fixed values to exactly using matrix operations Two methods using optimization an
Paper 6  Title: Probabilistic Principal Component Analysis  
Abstract Principal component analysis a ubiquitous technique data analysis processing one based upon a probability model In this paper demonstrate the principal axes a set observed data vectors may determined through maximum-likelihood estimation parameters closely factor analysis We consider the propert
Paper 7  Title: Bayesian Finite Mixtures for Nonlinear Modeling of Educational data  
Abstract In finding latent classes In our approach use finite mixture models the underlying structure in demonstrate the possibility to use full joint probability models raises interesting new prospects The concepts discussed are illustrated with usi
Paper 8  Title: Parallel Markov chain Monte Carlo sampling.  
Abstract Markov samplers proved remarkably popular as tools Bayesian computation However problems can their application the density interest dimensional strongly In these circumstances the sampler may slow traverse the state space mixing poor In offer a partial solution The
Label: Probabilistic Methods
Paper 9  Title: Bayesian MARS  
Abstract adaptive regression spline ( fitting 1991 This takes a probability distribution over possible MARS models which explored using reversible jump Markov chain Monte Carlo methods (Green 1995 The generated sample MARS models produced is to when averaged and all
Paper 10  Title: Signal Processing and Communications Reversible Jump Sampler for Autoregressive Time Series, Employing Full Conditionals to
Abstract Technical Report CUED/INFENGTR 304 We use reversible jump Markov MonteGreen 1995 address model order uncertainty au-toregressive (AR) time series within Efficient model jumping achieved proposing model space moves the full conditional density for the AR parameters This
Paper 11  Title: On MCMC Sampling in Hierarchical Longitudinal Models  SUMMARY  
Abstract Bayesian practice In their simplest form ( when parameters updated one, however often slow converge when applied high-dimensional statistical models A remedy block the parameters into groups updated simultaneously using either a Gibbs Metropolis-H
Paper 12  Title: Maximum Working Likelihood Inference with Markov Chain Monte Carlo  
Abstract Maximum working likelihood (MWL) inference the presence missing data can quite the intractability the associated marginal likelihood This problem can further the number parameters involved We propose using first obtain both the MWL estimator the working Fisher information matrix an
Label: Probabilistic Methods
Paper 13  Title: Bayesian Training of Backpropagation Networks by the Hybrid Monte Carlo Method  
Abstract It shown Bayesian training feasibly the "Hybrid Monte Carlo" method This approach allows the true predictive distribution for a test case given training cases to approximated arbitrarily closely in contrast approximate In this work th
Paper 14  Title: Computing Nonparametric Hierarchical Models  
Abstract: Bayesian models involving Dirichlet process mixtures at the modern nonparametric Bayesian movement Much the rapid development these models in advances simulation-based computational methods Some the very early work circa 1988- focused such nonparametric ideas and models applicat
Label: Probabilistic Methods
Paper 15  Title: Convergence controls for MCMC algorithms, with applications to hidden Markov chains  
Abstract In complex models like hidden Markov chains the convergence the MCMC algorithms used approximate and the Bayes estimates interest must controlled We propose in on controls, rely classical non-parametric tests independence the start-up distribution stabilit
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 1853...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: 6] Farach, M. and Thorup, M. 1993. Fast Comparison of Evolutionary Trees, Technical Report 93-46, DIMACS, Rutgers University, Piscataway, NJ. 
Title: Title: 99-113. Construction of Phylogenetic Trees, Science, Fitting the Gene Lineage Into Its Species Lineage. A
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: MML mixture modelling of multi-state, Poisson, von Mises circular and Gaussian distributions  
Abstract 11] Overmars. A random approach motion planning Technical Report RUU-CS-92-32, Department October 1992
Paper 3  Title: Mingers, 1989 J. Mingers. An empirical comparison of pruning methods for decision tree induction. Machine
Abstract Ourston Mooney 1990b ] D. Ourston Mooney. Improving shared rules multiple category domain theories Technical AI90150 Artificial Intelligence Labora tory University Texas December 1990
Paper 4  Title: A Neuro-Dynamic Programming Approach to Retailer Inventory Management 1  
Abstract Miller (1956 The magical number seven plus or: Some limits our capacity processing The Psychological Review 63(2):8197 Schmidhuber (1990b compositional learning with dynamic neural networks Technical Report FKI-12990, Technische Universitat Munchen Institut fu Informatik. Servan-Schreiber Cleermans (198
Label: Reinforcement Learning
Paper 5  Title: References elements that can solve difficult learning control problems. on Simulation of Adaptive Behavior, pages
Abstract Miller (1956 The magical number seven plus or: Some limits our capacity processing The Psychological Review 63(2):8197 Schmidhuber (1990b compositional learning with dynamic neural networks Technical Report FKI-12990, Technische Universitat Munchen Institut fu Informatik. Servan-Schreiber Cleermans (198
Paper 6  Title: Chunking in soar: The anatomy of a general learn ing mechanism. Machine Learning, 1(1). Learning
Abstract: gers University. Also appears tech. report ML- TR-7 Minton (1988 Quantitative results concerning explanation-based learning. Proceedings National Conference Artificial Intelli gence pages
Paper 7  Title: Causal inference, path analysis, and recursive struc-tural equations models. In C. Clogg, editor, Sociological Methodology,
Abstract: Lipid Research Clinic Program 84. The Lipid Research Clinics Coronary Primary Prevention Trial results parts I Journal374 1984 [Pearl 93 Judea Pearl. Aspects graphical models connected causality Technical Report R-195-LL Cognitive Systems Laboratory UCLA June 1993 Submitted
Label: Probabilistic Methods
Paper 8  Title: "Linear Dependencies Represented by Chain Graphs," "Graphical Modelling With MIM," Manual. "Identifying Independence in Bayesian
Abstract: 8] Dori, and Tarsi " Construct a Consistent Extension a Partially Oriented Graph Also Technical Report R-185 UCLA Cognitive Systems Laboratory October 1992 [14] Pearl and Wermuth "When Can Association Graphs Admit" UCLA, Cognitive Systems Laboratory Technical Report
Paper 9  Title: CABeN: A Collection of Algorithms for Belief Networks  Correspond with:  
Abstract: Portions this report the Fifteenth Annual Symposium Computer Applications in Medical CareNovember, 1991
Paper 10  Title: Local quartet splits of a binary tree infer all quartet splits via one dyadic inference
Abstract DIMACS Technical Report 96-43 DIMACS a partnership Rutgers University AT&T Research Bellcore Bell Laboratories DIMACS is an NSF Science and Technology Center funded under contract STC-9119999; also receives the New Jersey Commission
Paper 11  Title: References Automatic student modeling and bug library construction using theory refinement. Ph.D. ml/ Symbolic revision
Abstract ASSERT demonstrates theory refinement techniques developed ef fec- student models intelligent tutoring systems This application unique since inverts theory refinement correcting them A comprehensive experiment a lar ge number students interacting w
Paper 12  Title: Issues in Evolutionary Robotics  
Abstract A version appears: Proceedings SAB92 the Second International Conference Simulation Adaptive Behaviour J.-A. Meyer H. Roitblat and S. Wilson editors MIT Press Bradford Books 1993
Paper 13  Title: Decision Graphs An Extension of Decision Trees  
Abstract Technical Report 92/173 (C) Jonathan Oliver 1992 Shortened appeared AI Statistics 1993[14 Abstract In Decision Graphs We present an inference scheme construct decision graphs the Minimum Message Length Principle demonstrate this scheme compares other decision tree infer
Paper 14  Title: Learning an Optimally Accurate Representational System  
Abstract Multigrid Q-Learning Charles W. Anderson Stewart G. CS-94121 October
Paper 15  Title: Fools Gold: Extracting Finite State Machines From Recurrent Network Dynamics  
Abstract: Several recurrent networks representations the task formal language learning After training a recurrent network, the next step understand the information processing carried Some researchers (Giles 1992 Watrous & Kuhn Cleeremans 1989 resorted extracting finite state machines the internal state tr
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 2591...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present and evaluate two methods for improving the performance of ILP systems. One of them is discretization of numerical attributes, based on Fayyad and Irani's text [9], but adapted and extended in such a way that it can cope with some aspects of discretization that only occur in relational learning problems (when indeterminate literals occur). The second technique is lookahead. It is a well-known problem in ILP that a learner cannot always assess the quality of a refinement without knowing which refinements will be enabled afterwards, i.e. without looking ahead in the refinement lattice. We present a simple method for specifying when lookahead is to be used, and what kind of lookahead is interesting. Both the discretization and lookahead techniques are evaluated experimentally. The results show that both techniques improve the quality of the induced theory, while computational costs are acceptable.
Title: Title: Lookahead and Discretization in ILP  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Using Qualitative Models to Guide Inductive Learning  
Abstract using qualitative models guide inductive learning Our objectives induce rules which not only accurate explainable with respect the qualitative model reduce learning time exploiting domain knowledge Such explainability essential both practical application inductive technology fo
Paper 3  Title: Induction of decision trees using RELIEFF  
Abstract machine from examples this deals estimating attributes with and dependencies Greedy search prevents current inductive machine learning algorithms to significant dependencies the attributes Recently Kira Rendell developed the RELIEF algorithm estimating attribu
Paper 4  Title: Structural Regression Trees  
Abstract many real domains the task a theory predicting numerical values particular several standard test domains used Inductive Logic Programming concerned predicting numerical values examples relational and mostly non-determinate background knowledge However so far no ILP algorithm except can number
Label: Rule Learning
Paper 5  Title: Learning by Refining Algorithm Sketches  
Abstract In suggest improves significantly a top-down inductive logic programming (ILP) learning system This improvement achieved at giving to extra information difficult formulate This information appears the form an algorithm sketch: an incomplete and somewhat vague representation the computati
Paper 6  Title: Naive Bayesian classifier within ILP-R  
Abstract When dealing the classification problems current ILP systems often lag state attributional learners Part the blame can a much larger hypothesis space which, therefore as thoroughly However sometimes due ILP systems do take the probabilistic aspects hypotheses when classifying unsee
Paper 7  Title: Multi-class problems and discretization in ICL Extended abstract  
Abstract Handling multi-class problems real numbers KDD problems While attributevalue learners address as a rule very few ILP systems The few ILP systems handle real numbers mostly trying out all real values applicable thus running efficiency or overfitting This paper
Paper 8  Title: Linear Space Induction in First Order Logic with RELIEFF  
Abstract Current ILP algorithms typically variants extensions the greedy search This prevents to detect significant relationships the training objects Instead myopic impurity functions propose based RELIEF guidance ILP algorithms At each step in our ILP-R system this heuristic a beam candidate literals
Paper 9  Title: Constructing Intermediate Concepts by Decomposition of Real Functions  
Abstract In learning from examples it expand an attribute-vector representation intermediate concepts The usual advantage such structuring of the learning problem easier improves the comprehensibility induced descriptions In develop discovering useful intermediate concepts when both class at
Paper 10  Title: Growing a Hypercubical Output Space in a Self-Organizing Feature Map  
Abstract Recent studies planning comparing plan reuse plan generation both the above tasks may computational complexity even we deal very similar problems The aim the same kind results apply also diagnosis. We propose a theoretical complexity analysis coupled some experimental tests intended
Paper 11  Title: Protein Secondary Structure Modelling with Probabilistic Networks (Extended Abstract)  
Abstract In study the performance probabilistic networks protein sequence analysis molecular biology Specifically we report our initial experiments applying this framework the problem protein secondary structure prediction One the probabilistic approach we describe our ability perform detailed exper
Label: Neural Networks
Paper 12  Title: On the Usefulness of Re-using Diagnostic Solutions  
Abstract Recent studies planning comparing plan reuse plan generation both the above tasks may computational complexity even we deal very similar problems The aim the same kind results apply also diagnosis. We propose a theoretical complexity analysis coupled some experimental tests intended
Label: Case Based
Paper 13  Title: Top-Down Pruning in Relational Learning  
Abstract Pruning dealing noise Machine Learning Recently pruning algorithms, in particular Reduced Error Pruning also attracted Inductive Logic Programming However has shown these methods inefficient most is for generating clauses explain noisy examples subsequently p
Paper 14  Title: Forward-Tracking: A Technique for Searching Beyond Failure  
Abstract In many applications such decision support negotiation planning scheduling etc one express requirements only partially. In order express such requirements propose a technique forward-tracking Intuitively forward-tracking dual of chronological back-tracking if a program globally fails exe
Label: Genetic Algorithms
Paper 15  Title: Symposium Title: Tutorial Discourse What Makes Human Explanations Effective?  
Abstract Many state ILP systems require large numbers negative examples avoid This a considerable disadvantage many ILP applications namely indu ctive program synthesis where relativelly small and sparse example sets a more realistic scenario Integrity constraints first order clauses play negative examples
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Category: Rule Learning
Prediction:  Category: Rule Learning
Is prediction correct?  False

Prediction: 0
Processing index 2507...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper introduces the idea of clearning, of simultaneously cleaning data and learning the underlying structure. The cleaning step can be viewed as top-down processing (the model modifies the data), and the learning step can be viewed as bottom-up processing (where the data modifies the model). After discussing the statistical foundation of the proposed method from a maximum likelihood perspective, we apply clearning to a notoriously hard problem where benchmark performances are very well known: the prediction of foreign exchange rates. On the difficult 1993-1994 test period, clearning in conjunction with pruning yields an annualized return between 35 and 40% (out-of-sample), significantly better than an otherwise identical network trained without cleaning. The network was started with 69 inputs and 15 hidden units and ended up with only 39 non-zero weights between inputs and hidden units. The resulting ultra-sparse final architectures obtained with clearning and pruning are immune against overfitting, even on very noisy problems since the cleaned data allow for a simpler model. Apart from the very competitive performance, clearning gives insight into the data: we show how to estimate the overall signal-to-noise ratio of each input variable, and we show that error estimates for each pattern can be used to detect and remove outliers, and to replace missing or corrupted data by cleaned values. Clearning can be used in any nonlinear regression or classification problem.
Title: Title: The Observer-Observation Dilemma in Neuro-Forecasting: Reliable Models From Unreliable Data Through CLEARNING  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: WRAPPERS FOR PERFORMANCE ENHANCEMENT AND OBLIVIOUS DECISION GRAPHS  
Abstract introduces clearning of simultaneously cleaning data learning the underlying structure The cleaning step can viewed top-down processing (the model modifies the learning stepwhere modifies After discussing the statistical foundation the proposed method from a maximum likelihoo
Paper 3  Title: LEARNING MORE FROM LESS DATA: EXPERIMENTS WITH LIFELONG ROBOT LEARNING  
Abstract: Most connectionist modeling assumes noise-free inputs This assumption often violated. This paper introduces clearning, of simultaneously cleaning the data learning The cleaning step can viewed top-down processing (where the model modifies the learning step
Paper 4  Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  
Abstract: Most connectionist modeling assumes noise-free inputs This assumption often violated. This paper introduces clearning, of simultaneously cleaning the data learning The cleaning step can viewed top-down processing (where the model modifies the learning step
Paper 5  Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  
Abstract: Most connectionist modeling assumes noise-free inputs This assumption often violated. This paper introduces clearning, of simultaneously cleaning the data learning The cleaning step can viewed top-down processing (where the model modifies the learning step
Paper 6  Title: Avoiding overfitting by locally matching the noise level of the data gating network discovers the
Abstract When trying forecast two of nonstationarity of the process, regime switching overfittingparticularly serious for noisy processes This articles shows gated experts point solutions The architecture, also society of experts mixture experts consists
Paper 7  Title: TO IMPROVE FORECASTING  
Abstract Working Paper IS-97007 Leonard N. Stern School In: Journal Computational Intelligence in Finance 61998 14 (Special Issue onImproving Generalization Nonlinear Financial Forecasting Models Abstract. Predictive models for financial data
Label: Neural Networks
Paper 8  Title: Packet Routing and Reinforcement Learning: Estimating Shortest Paths in Dynamic Graphs  
Abstract exposes problems the commonly used technique splitting training, that held fixed warns drawing such static splits shows ignoring variability across splits Using or resampling compare the uncertainty the solution stemming th
Paper 9  Title: A Bootstrap Evaluation of the Effect of Data Splitting on Financial Time Series  
Abstract exposes problems the commonly used technique splitting training, that held fixed warns drawing such static splits shows ignoring variability across splits Using or resampling compare the uncertainty the solution stemming th
Paper 10  Title: Evaluating Neural Network Predictors by Bootstrapping  
Abstract We, inspired the bootstrap, whose goal it determine a neural network predictor Our method leads more robust forecasting along statistical information forecast performance exploit We exhibit the method multi-variate time series prediction on financial data the New Yor
Paper 11  Title: Lessons in Neural Network Training: Overfitting Lessons in Neural Network Training: Overfitting May be Harder
Abstract For many reasons neural networks very popular AI machine learning models Two of machine learning models how generalizes unseen data scales problem complexity Using a controlled task known optimal training error investigate the convergence the backpropagation (BP) algorithm. We find
Paper 12  Title: First experiments using a mixture of nonlinear experts for time series prediction  
Abstract the advantages the mixture experts (ME) model (introduced to the connectionist community [JJNH91 applied time series analysisWM95 on where the dynamics is well The first series consisting a mixture between a noise-free processthe quadratic map a noisy pr
Paper 13  Title: Noisy Time Series Prediction using Symbolic Representation and Recurrent Neural Network Grammatical Inference  
Abstract Financial forecasting an example a signal processing problem which challenging due high noise nonstationarity non Neural networks very signal processing applications We discuss fundamental limitations inherent difficulties when using neural networks the processing high noise small sample si
Label: Neural Networks
Paper 14  Title: Working Paper IS-97-22 (Information Systems) A First Application of Independent Component Analysis to Extracting Structure
Abstract a modern signal processing technique independent component analysisICA or blind source separation multivariate financial time series such a portfolio The key idea ICA linearly map the observed multivariate time series into a new space statistically independent componentsICs This can viewed a factor
Label: Neural Networks
Paper 15  Title: LEARNING TO SOLVE MARKOVIAN DECISION PROCESSES  
Abstract In a neural approach for reconstruction natural highly correlated images linear (additive) mixture them A multi-layer architecture local online learning rules developed solve blind separation sources The main motivation using a multi-layer network instead improve
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 38...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: In most applications of neuro-evolution, each individual in the population represents a complete neural network. Recent work on the SANE system, however, has demonstrated that evolving individual neurons often produces a more efficient genetic search. This paper demonstrates that while SANE can solve easy tasks very quickly, it often stalls in larger problems. A hierarchical approach to neuro-evolution is presented that overcomes SANE's difficulties by integrating both a neuron-level exploratory search and a network-level exploitive search. In a robot arm manipulation task, the hierarchical approach outperforms both a neuron-based search and a network-based search. 
Title: Title: HOW TO EVOLVE AUTONOMOUS ROBOTS: DIFFERENT APPROACHES IN EVOLUTIONARY ROBOTICS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Hierarchical Evolution of Neural Networks  
Abstract most applications each individual in represents Recent work the SANE system however evolving individual neurons often produces a more efficient genetic search This paper demonstrates while SANE solve easy tasks very often stalls larger problems A hierarchical approach
Paper 3  Title: Machine Learning,  Efficient Reinforcement Learning through Symbiotic Evolution  
Abstract a new reinforcement learning method called SANESymbiotic, evolves a population through genetic algorithms form capable Symbiotic evolution promotes both cooperation specialization results a fast, efficient genetic search discourages convergence to suboptimal sol
Paper 4  Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  
Abstract Genetic algorithms solve hard optimization problems ranging the Travelling Salesman problem the Quadratic Assignment problem We show the Simple Genetic Algorithm solve derived the 3-Conjunctive Normal Form problem By separating the populations into small sub parallel genetic algorithms exploits
Paper 5  Title: A Cooperative Coevolutionary Approach to Function Optimization  
Abstract: A general model the coevolution cooperating species This model instantiated and tested the domain function optimization compared a traditional GA-based function optimizer The results encouraging in two respects They suggest ways the performance GA and other EA-based optimizers they ev
Label: Genetic Algorithms
Paper 6  Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Abstract Genetic algorithms neural networks two main ways optimize train the weights a fixed architecture While most previous work focuses only of these two options investigates an alternative evolutionary approach called Breeder Genetic Programming the architecture and the weights optimized simult
Paper 7  Title: Toward a unified theory of spatiotemporal processing in the retina  
Abstract Traditional evolutionary optimization algorithms assume a static evaluation function according solutions evolved. Incremental evolution an approach through a dynamic evaluation function scaled over in improve evolutionary optimization In this paper empirical results this approach
Paper 8  Title: A Coevolutionary Approach to Learning Sequential Decision Rules  
Abstract We learning sequential decision rules which appears a number The coevolutionary approach encourages stable niches representing simpler sub The evolutionary direction each subbehavior can controlled independently providing an alternative evolving complex beh
Label: Genetic Algorithms
Paper 9  Title: Hierarchical priors and mixture models, with application in regression and density estimation  
Abstract We integrated the distributed search genetic programmingGP collective memory form a collective adaptation search method Such a system significantly search as problem complexity Since the pure GP approach does scale problem complexity a natural question actually contributing the se
Paper 10  Title: Evolutionary Neural Networks for Value Ordering in Constraint Satisfaction Problems  
Abstract: Technical Report AI94-218 May 1994 Abstract A new method developing good value-ordering strategies constraint satisfaction search presented Using an evolutionary technique SANE in individual neurons evolve cooperate problem-specific knowledge discovered results better value-ordering decisions than based proble
Label: Genetic Algorithms
Paper 11  Title: Evolving Obstacle Avoidance Behavior in a Robot Arm  
Abstract Existing approaches learning a robot arm rely supervised methods where correct behavior explicitly given It learn avoid obstacles using such methods examples obstacle avoidance behavior generate This paper evolves neural network controllers through genetic algorithms No input
Paper 12  Title: A Comparison of Random Search versus Genetic Programming as Engines for Collective Adaptation  
Abstract We integrated the distributed search genetic programmingGP collective memory form a collective adaptation search method Such a system significantly search as problem complexity Since the pure GP approach does scale problem complexity a natural question actually contributing the se
Paper 13  Title: EVOLVING NEURAL NETWORKS WITH COLLABORATIVE SPECIES  
Abstract We a coevolutionary architecture solving decomposable problems and apply the evolution Although this work preliminary it non-coevolutionary approaches The coevolutionary approach utilizes in species representing simpler subtasks evolved separate insta
Paper 14  Title: Dynamic Hill Climbing: Overcoming the limita- tions of optimization techniques  
Abstract a novel search algorithm, called dynamic hill climbing borrows ideas genetic algorithms hill climbing techniques Unlike both genetic and hill climbing algorithms dynamic hill climbing has dynamically its coordinate frame during an optimization Furthermore the algorithm moves
Paper 15  Title: Induction of decision trees using RELIEFF  
Abstract An investigation the dynamics Genetic Programming applied chaotic time series prediction reported An interesting characteristic adaptive search techniques perform well many problem domains while failing Because Genetic Programming's flexible tree structure any particular problem represented myriad forms These representati
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2652...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Systems for automated design optimization of complex real-world objects can, in principle, be constructed by combining domain-independent numerical routines with existing domain-specific analysis and simulation programs. Unfortunately, such legacy analysis codes are frequently unsuitable for use in automated design. They may crash for large classes of input, be numerically unstable or locally non-smooth, or be highly sensitive to control parameters. To be useful, analysis programs must be modified to reduce or eliminate only the undesired behaviors, without altering the desired computation. To do this by direct modification of the programs is labor-intensive, and necessitates costly revalidation. We have implemented a high-level language and run-time environment that allow failure-handling strategies to be incorporated into existing Fortran and C analysis programs while preserving their computational integrity. Our approach relies on globally managing the execution of these programs at the level of discretely callable functions so that the computation is only affected when problems are detected. Problem handling procedures are constructed from a knowledge base of generic problem management strategies. We show that our approach is effective in improving analysis program robustness and design optimization performance in the domain of conceptual design of jet engine nozzles. 
Title: Title: Knowledge-Based Re-engineering of Legacy Programs for Robustness in Automated Design  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Program Synthesis and Transformation Techniques for Simpuation, Optimization and Constraint Satisfaction Deductive Synthesis of Numerical
Abstract Scientists and face recurring problems constructing, modifying numerical simulation programs The process coding revising such simulators extremely because almost conventional programming languages Scientists can therefore benefit software facilitates construction programs simula
Paper 3  Title: A Transformation System for Interactive Reformulation of Design Optimization Strategies  
Abstract Automatic design optimization highly sensitive problem formulation The choice objective function constraints design parameters dramatically optimization best formulation varies A design engineer will usually not know the best formulation in In order t
Paper 4  Title: Intelligent Gradient-Based Search of Incompletely Defined Design Spaces  
Abstract Gradient-based numerical optimization complex engineering designs offers rapidly producing However such methods generally assume the objective function and constraint functions continuous smooth defined everywhere Unfortunately realistic simulators violate present intelligently co
Paper 5  Title: Using Modeling Knowledge to Guide Design Space Search  
Abstract: Automated search a space candidate designs seems an attractive way the traditional engineering design process To make however the automated design system include both knowledge the modeling limitations evaluate candidate designs also an effective way use influence We suggest
Label: Genetic Algorithms
Paper 6  Title: A Transformation System for Interactive Reformulation of Design Optimization Strategies  
Abstract Numerical design optimization algorithms highly sensitive the particular formulation given formulation the search space, the objective function will generally have the duration the optimization process as the resulting design Furthermore the best formulation will vary fr
Label: Genetic Algorithms
Paper 7  Title: Knowledge Compilation and Speedup Learning in Continuous Task Domains  
Abstract Many techniques speedup learning knowledge compilation focus the learning optimization macrooperators or control rules task domains characterized a problem-space search paradigm However such a characterization fit well the class task domains the problem solver required in a continuous manner For example man
Paper 8  Title: Data Exploration with Reflective Adaptive Models  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Paper 9  Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 10  Title: Using Case-Based Reasoning as a Reinforcement Learning Framework for Optimization with Changing Criteria  
Abstract Practical optimization problems such job-shop scheduling often optimization criteria change Repair-based frameworks identified flexible computational paradigms difficult combinatorial optimization problems Since the control problem of repair-based optimization severe ReinforcementRL techniques potentially Howeve
Label: Case Based
Paper 11  Title: Continuous Case-Based Reasoning  
Abstract Case-based reasoning systems traditionally perform problem domains can adequately discrete, symbolic representations However many real-world problem domains autonomous robotic navigation better characterized using continuous representations Such problem domains also require continuous performance, such
Label: Case Based
Paper 12  Title: Learning in the Presence of Prior Knowledge: A Case Study Using Model Calibration  
Abstract Computational models natural systems often contain free parameters must set optimize the predictive accuracy This process|called calibration|can viewed supervised learning the presence In this view the fixed aspects constitute the prior knowledge the goal learn correct values the free paramet
Paper 13  Title: A Methodology for Processing Problem Constraints in Genetic Programming  
Abstract Search mechanisms artificial intelligence combine two elements representation determines a search mechanism actually explores Unfortunately many searches may explore redundant and/or invalid solutions Genetic programming refers evolutionary algorithms but utilizing a parameterized representatio
Paper 14  Title: Systematic Evaluation of Design Decisions in CBR Systems  
Abstract Two important goals the evaluation an AI theory or model the merit the design decisions the performance an implemented computer system analyze in when faces problem domains with different characteristics This particularly difficult case-based reasoning systems such systems typically
Paper 15  Title: Double Censoring: Characterization and Computation of the Nonparametric Maximum Likelihood Estimator  
Abstract In case-based planning previously generated plans stored cases memory solve CBP can save considerable time over planning from scratch (generative planning thus offering a potential (heuristic) mechanism handling One drawback CBP systems has highly structured m
Label: Probabilistic Methods
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

An error occurred at index 54: 'choices'
Retrying in 0.2 seconds...
Processing index 2652...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Systems for automated design optimization of complex real-world objects can, in principle, be constructed by combining domain-independent numerical routines with existing domain-specific analysis and simulation programs. Unfortunately, such legacy analysis codes are frequently unsuitable for use in automated design. They may crash for large classes of input, be numerically unstable or locally non-smooth, or be highly sensitive to control parameters. To be useful, analysis programs must be modified to reduce or eliminate only the undesired behaviors, without altering the desired computation. To do this by direct modification of the programs is labor-intensive, and necessitates costly revalidation. We have implemented a high-level language and run-time environment that allow failure-handling strategies to be incorporated into existing Fortran and C analysis programs while preserving their computational integrity. Our approach relies on globally managing the execution of these programs at the level of discretely callable functions so that the computation is only affected when problems are detected. Problem handling procedures are constructed from a knowledge base of generic problem management strategies. We show that our approach is effective in improving analysis program robustness and design optimization performance in the domain of conceptual design of jet engine nozzles. 
Title: Title: Knowledge-Based Re-engineering of Legacy Programs for Robustness in Automated Design  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Program Synthesis and Transformation Techniques for Simpuation, Optimization and Constraint Satisfaction Deductive Synthesis of Numerical
Abstract Scientists and face recurring problems constructing, modifying numerical simulation programs The process coding revising such simulators extremely because almost conventional programming languages Scientists can therefore benefit software facilitates construction programs simula
Paper 3  Title: A Transformation System for Interactive Reformulation of Design Optimization Strategies  
Abstract Automatic design optimization highly sensitive problem formulation The choice objective function constraints design parameters dramatically optimization best formulation varies A design engineer will usually not know the best formulation in In order t
Paper 4  Title: Intelligent Gradient-Based Search of Incompletely Defined Design Spaces  
Abstract Gradient-based numerical optimization complex engineering designs offers rapidly producing However such methods generally assume the objective function and constraint functions continuous smooth defined everywhere Unfortunately realistic simulators violate present intelligently co
Paper 5  Title: Using Modeling Knowledge to Guide Design Space Search  
Abstract: Automated search a space candidate designs seems an attractive way the traditional engineering design process To make however the automated design system include both knowledge the modeling limitations evaluate candidate designs also an effective way use influence We suggest
Label: Genetic Algorithms
Paper 6  Title: A Transformation System for Interactive Reformulation of Design Optimization Strategies  
Abstract Numerical design optimization algorithms highly sensitive the particular formulation given formulation the search space, the objective function will generally have the duration the optimization process as the resulting design Furthermore the best formulation will vary fr
Label: Genetic Algorithms
Paper 7  Title: Knowledge Compilation and Speedup Learning in Continuous Task Domains  
Abstract Many techniques speedup learning knowledge compilation focus the learning optimization macrooperators or control rules task domains characterized a problem-space search paradigm However such a characterization fit well the class task domains the problem solver required in a continuous manner For example man
Paper 8  Title: Data Exploration with Reflective Adaptive Models  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Paper 9  Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 10  Title: Using Case-Based Reasoning as a Reinforcement Learning Framework for Optimization with Changing Criteria  
Abstract Practical optimization problems such job-shop scheduling often optimization criteria change Repair-based frameworks identified flexible computational paradigms difficult combinatorial optimization problems Since the control problem of repair-based optimization severe ReinforcementRL techniques potentially Howeve
Label: Case Based
Paper 11  Title: Continuous Case-Based Reasoning  
Abstract Case-based reasoning systems traditionally perform problem domains can adequately discrete, symbolic representations However many real-world problem domains autonomous robotic navigation better characterized using continuous representations Such problem domains also require continuous performance, such
Label: Case Based
Paper 12  Title: Learning in the Presence of Prior Knowledge: A Case Study Using Model Calibration  
Abstract Computational models natural systems often contain free parameters must set optimize the predictive accuracy This process|called calibration|can viewed supervised learning the presence In this view the fixed aspects constitute the prior knowledge the goal learn correct values the free paramet
Paper 13  Title: A Methodology for Processing Problem Constraints in Genetic Programming  
Abstract Search mechanisms artificial intelligence combine two elements representation determines a search mechanism actually explores Unfortunately many searches may explore redundant and/or invalid solutions Genetic programming refers evolutionary algorithms but utilizing a parameterized representatio
Paper 14  Title: Systematic Evaluation of Design Decisions in CBR Systems  
Abstract Two important goals the evaluation an AI theory or model the merit the design decisions the performance an implemented computer system analyze in when faces problem domains with different characteristics This particularly difficult case-based reasoning systems such systems typically
Paper 15  Title: Double Censoring: Characterization and Computation of the Nonparametric Maximum Likelihood Estimator  
Abstract In case-based planning previously generated plans stored cases memory solve CBP can save considerable time over planning from scratch (generative planning thus offering a potential (heuristic) mechanism handling One drawback CBP systems has highly structured m
Label: Probabilistic Methods
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  False

Prediction: 0
Processing index 959...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This article describes a numerical method that may be used to efficiently locate and track underwater sonar targets in the near-field, with both bearing and range estimation, for the case of very large passive arrays. The approach used has no requirement for a priori knowledge about the source and uses only limited information about the receiver array shape. The role of sensor position uncertainty and the consequence of targets always being in the near-field are analysed and the problems associated with the manipulation of large matrices inherent in conventional eigenvalue type algorithms noted. A simpler numerical approach is then presented which reduces the problem to that of search optimization. When using this method the location of a target corresponds to finding the position of the maximum weighted sum of the output from all sensors. Since this search procedure can be dealt with using modern stochastic optimization methods, such as the genetic algorithm, the operational requirement that an acceptable accuracy be achieved in real time can usually be met. The array studied here consists of 225 elements positioned along a flexible cable towed behind a ship with 3.4m between sensors, giving an effective aperture of 761.6m. For such a long array, the far field assumption used in most beam-forming algorithms is no longer appropriate. The waves emitted by the targets then have to be considered as curved rather than plane. It is shown that, for simulated data, if no significant noise 
Title: Title: Numerical techniques for efficient sonar bearing and range searching in the near field using genetic algorithms  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Sequential Niche Technique for Multimodal Function Optimization  
Abstract: c fl UWCC COMMA Technical 93001 1993 x No part Abstract A technique is unimodal function optimization methods extended efficiently locate all optima multimodal problems We describe a traditional genetic algorithmGA This involves iterating the GA, b
Paper 3  Title: Space-Frequency Localized Basis Function Networks for Nonlinear System Estimation and Control  
Abstract Stable neural network control estimation may viewed formally a merging concepts tools multivariate approximation theory This paper extends earlier results adaptive control estimation nonlinear systems gaussian radial basis functions on generation irregularly sampled networks tools mul
Label: Neural Networks
Paper 4  Title: A comparison of neural net and conventional techniques for lighting control  
Abstract We compare two techniques lighting control an actual room equipped seven banks photoresistors detect four sensing points Each bank lights can independently set The task the device intensity levels achieve sensor readings One technique we explor
Paper 5  Title: Data Reconciliation and Gross Error Detection for Dynamic Systems  
Abstract Gross error detection plays parameter estimation data reconciliation In particular recent advances process optimization now data reconciliation dynamic systems appropriate problem formulations need them Data errors due either miscalibrated or faulty sensors just random events nonre
Paper 6  Title: Bayesian Training of Backpropagation Networks by the Hybrid Monte Carlo Method  
Abstract It shown Bayesian training feasibly the "Hybrid Monte Carlo" method This approach allows the true predictive distribution for a test case given training cases to approximated arbitrarily closely in contrast approximate In this work th
Paper 7  Title: A GENERAL METHOD FOR INCREMENTAL SELF-IMPROVEMENT AND MULTI-AGENT LEARNING  
Abstract Process simulation emerged process design analysis operation In this work extend iterated linear programmingLP for dealing problems encountered dynamic nonsmooth process simulation A previously developed LP method refined a new descent strategy which combines line search a trust region appro
Paper 8  Title: An Investigation of Marker-Passing Algorithms for Analogue Retrieval  
Abstract If analogy case-based reasoning systems scale very large case bases analyze retrieving analogues to identify the features for appropriate This paper reports one such analysis a comparison retrieval by marker passing or spreading activation a semantic network with Knowledge
Paper 9  Title: A Fast Fixed-Point Algorithm for Independent Component Analysis  
Abstract will appear Neural Computation 9:1483 1997 Abstract We introduce a novel fast algorithm Independent Component Analysis can blind source separation feature It shown how a neural network learning rule transformed a txed-point iteration provides an algorithm very simple, does any user-de
Paper 10  Title: An Overview of Genetic Algorithms Part 1, Fundamentals  
Abstract Mathematical programming approaches will described: feature selection robust representation The feature selection problem considered discriminating while recognizing irrelevant and redundant features suppressing creates a lean model often generalizes better new unseen data
Paper 11  Title: How good are genetic algorithms at finding large cliques: an experimental study  
Abstract the power genetic algorithms at solving the MAX-CLIQUE problem We measure a standard genetic algorithm an elementary set problem instances consisting embedded cliques random graphs We indicate the need improvement introduce the multi-phase annealed GA, exhibits
Paper 12  Title: Nonsmooth Dynamic Simulation With Linear Programming Based Methods  
Abstract Process simulation emerged process design analysis operation In this work extend iterated linear programmingLP for dealing problems encountered dynamic nonsmooth process simulation A previously developed LP method refined a new descent strategy which combines line search a trust region appro
Paper 13  Title: An information-maximisation approach to blind separation and blind deconvolution  
Abstract We derive a new self-organising learning algorithm which transferred non-linear units The algorithm does assume the input distributions defined here the zero-noise limit Under information maximisation has extra properties not the linear caseLinsker 1989 The nonlinearities the t
Paper 14  Title: Inductive Learning by Selection of Minimal Complexity Representations  
Abstract Behavioural observations can often described a sequence symbols drawn a finite alphabet However the inductive inference such strings by any automated technique to produce models This paper considers modelling behavioural data There information-theoretic techniques
Label: Theory
Paper 15  Title: Induction of decision trees using RELIEFF  
Abstract An investigation the dynamics Genetic Programming applied chaotic time series prediction reported An interesting characteristic adaptive search techniques perform well many problem domains while failing Because Genetic Programming's flexible tree structure any particular problem represented myriad forms These representati
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 616...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: MORGAN is an integrated system for finding genes in vertebrate DNA sequences. MORGAN uses a variety of techniques to accomplish this task, the most distinctive of which is a decision tree classifier. The decision tree system is combined with new methods for identifying start codons, donor sites, and acceptor sites, and these are brought together in a frame-sensitive dynamic programming algorithm that finds the optimal segmentation of a DNA sequence into coding and noncoding regions (exons and introns). The optimal segmentation is dependent on a separate scoring function that takes a subsequence and assigns to it a score reflecting the probability that the sequence is an exon. The scoring functions in MORGAN are sets of decision trees that are combined to give a probability estimate. Experimental results on a database of 570 vertebrate DNA sequences show that MORGAN has excellent performance by many different measures. On a separate test set, it achieves an overall accuracy of 95%, with a correlation coefficient of 0.78 and a sensitivity and specificity for coding bases of 83% and 79%. In addition, MORGAN identifies 58% of coding exons exactly; i.e., both the beginning and end of the coding regions are predicted correctly. This paper describes the MORGAN system, including its decision tree routines and the algorithms for site recognition, and its performance on a benchmark database of vertebrate DNA. 
Title: Title: A Decision Tree System for Finding Genes in DNA  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Generalized Hidden Markov Model for the Recognition of Human Genes in DNA  
Abstract We genes DNA. A Generalized Hidden Markov Model provides the framework describing the grammar a legal parseStormo Haussler 1994 Probabilities assigned transitions states the GHMM to the generation each nucleotide base given Machine learning techniques applied optimi
Paper 3  Title: Finding Genes in DNA with a Hidden Markov Model  
Abstract describes a new Hidden Markov Model (HMM) system segmenting uncharacterized genomic DNA sequences exons introns Separate HMM modules were designed trained specific regions DNA: exons introns intergenic regions The models then tied a biologically feasible topology The integrated HMM was tr
Paper 4  Title: Hidden Markov Models in Computational Biology: Applications to Protein Modeling UCSC-CRL-93-32 Keywords: Hidden Markov Models,
Abstract Hidden Markov Models applied the problems statistical modeling database searching multiple sequence alignment protein families protein domains These methods demonstrated on the globin family the protein the EF-hand calcium binding motif In each case the parameters an HMM estimated a training set unaligned seq
Label: Neural Networks
Paper 5  Title: Dirichlet Mixtures: A Method for Improving Detection of Weak but Significant Protein Sequence Homology  
Abstract UCSC Technical Report-CRL-9609 Abstract the mathematical foundations Dirichlet mixtures improve database search results homologous sequences when a variable number from a protein family or domain known We present condensing a protein database a mixture Dirichlet densities
Paper 6  Title: Face Recognition: A Hybrid Neural Network Approach  
Abstract Faces represent complex, multidimensional, meaningful visual stimuli developing difficult (Turk and Pentland 1991 We present a hybrid neural network solution compares favorably The system combines local image sampling a self-organizing map neural network The self-organizin
Paper 7  Title: Learning to Predict Reading Frames in E. coli DNA Sequences  
Abstract Two fundamental problems analyzing DNA sequences ( locating the regions proteins the reading frame for We investigate using find coding regions, determine reading frames detect frameshift errors E. coli DNA sequences. We describe our adaptation the approach Ube
Paper 8  Title: The megaprior heuristic for discovering protein sequence patterns  
Abstract: Several computer algorithms discovering patterns groups protein sequences in that fitting the parameters related sequences These include hidden Markov model (HMM) algorithms multiple sequence alignment the MEME and Gibbs sampler algorithms discovering motifs These algorithms sometimes prone producin
Label: Neural Networks
Paper 9  Title: Searching for dependencies in Bayesian classifiers j A n V n j If the attributes
Abstract Naive Bayesian classifiers which make independence assumptions perform remarkably poorly We explore ways searching dependencies attributes We propose and evaluate two algorithms dependencies attributes show the backward sequential elimination joining
Paper 10  Title: Maximum A Posteriori Classification of DNA Structure from Sequence Information  
Abstract We introduce, lllama simple pattern recognizers into estimating the entropy Each pattern recognizer exploits a partial match subsequences build Since the primary features interest biological sequence domains subsequences small variations exact composition lllama part
Label: Neural Networks
Paper 11  Title: Achieving High-Accuracy Text-to-Speech with Machine Learning  
Abstract: In 1987 Sejnowski Rosenberg developed their famous NETtalk system English text This chapter describes a machine learning approach text that builds and extends the initial NETtalk work Among the many extensions the NETtalk system were a different learning algorithm a wider input "window error-correcting output coding right
Label: Theory
Paper 12  Title: A Method for Identifying Splice Sites and Translational Start Sites in  
Abstract the consensus sequences that signal the start translation and the boundaries exonsdonor and acceptor sites The method takes into the dependencies adjacent bases in contrast the usual technique considering each position When coupled a dynamic program t
Paper 13  Title: Evolution, Learning, and Instinct: 100 Years of the Baldwin Effect Using Learning to Facilitate the
Abstract a hybrid methodology integrates genetic algorithms decision tree learning evolve useful subsets discriminatory features for recognizing complex visual concepts A genetic algorithm (GA search the space all possible subsets candidate discrimination features Candidate feature subsets evaluated using C4.5
Label: Genetic Algorithms
Paper 14  Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  
Abstract With computational costs without accuracy describe two algorithms find sets prototypes nearest neighbor classification Here the term prototypes the reference instances a nearest neighbor computation the instances with respect which similarity assessed assign a new data item Both algorithms re
Paper 15  Title: A Statistical Approach to Solving the EBL Utility Problem  
Abstract Many "learning from systems use information problem solving experiences modify a performance element PE forming PE 0 solve more However transformations that improve one set problems degrade the new PE 0 is better
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 2049...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The paper investigates the possibilities for using simple recurrent networks as transducers which map sequential natural language input into non-sequential feature-based semantics. The networks perform well on sentences containing a single main predicate (encoded by transitive verbs or prepositions) applied to multiple-feature objects (encoded as noun-phrases with adjectival modifiers), and shows robustness against ungrammatical inputs. A second set of experiments deals with sentences containing embedded structures. Here the network is able to process multiple levels of sentence-final embeddings but only one level of center-embedding. This turns out to be a consequence of the network's inability to retain information that is not reflected in the outputs over intermediate phases of processing. Two extensions to Elman's [9] original recurrent network architecture are introduced. 
Title: Title: Learning Feature-based Semantics with Simple Recurrent Networks  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: TABLE DES MATI ERES 1 Apprentissage et approximation les techniques de regularisation 3 1.1 Introduction
Abstract The paper investigates the possibilities using simple recurrent networks transducers which map sequential natural language input The networks perform sentences containing a single main predicateencoded transitive verbs applied multiple-feature objects with adjectival modifiers
Paper 3  Title: Subsymbolic Case-Role Analysis of Sentences with Embedded Clauses  
Abstract called SPEC for processing sentences recursive relative clauses The model separating the tasks segmenting the input word sequence clauses forming the case-role representations keeping into different modules The system needs trained only the basic sentence construc
Paper 4  Title: Simple Synchrony Networks: Learning Generalisations across Syntactic Constituents  
Abstract describes a training algorithm Simple Synchrony Networks and reports experiments in language learning a recursive grammar The SSN a new connectionist architecture combining a technique learning patterns across time Simple Recurrent Networks Temporal Synchrony Variable Binding The use TSVB means the SSN can learn
Paper 5  Title: Natural Language Grammatical Inference with Recurrent Neural Networks  
Abstract the inductive inference a complex grammar neural networks specifically, the task considered is that training as thereby exhibiting discriminatory power provided the Principles and Parameters linguistic framework or Government-and-Binding theory Neural networ
Paper 6  Title: Data-defined Problems and Multiversion Neural-net Systems  
Abstract We inv estigate an adaptive neural network problems time-dependent input by demonstrating a deterministic parser natural language inputs of recurrent connectionist architectures The traditional stacking mechanism to necessary proper treatment context-free languages symbolic
Paper 7  Title: On the Applicability of Neural Network and Machine Learning Methodologies to Natural Language Processing  
Abstract examine the inductive inference a complex grammar specifically, we training classify thereby exhibiting discriminatory power provided the Principles and Parameters linguistic framework or Government-and-Binding theory We investigate the following models feed-forward ne
Paper 8  Title: Simple Synchrony Networks Learning to Parse Natural Language with Temporal Synchrony Variable Binding  
Abstract The Simple Synchrony Network a new connectionist architecture incorporating the insights Temporal Synchrony Variable Binding Simple Recurrent Networks The use TSVB means SSNs output representations structures can learn generalisations over the constituentsas required systematicity This paper the SSN an asso
Paper 9  Title: Scaling-up RAAMs  
Abstract Modifications Recursive Auto-Associative Memory presented, allow it store reported These modifications include extra layers the compressor and reconstructor networks employing integer rather pre the weights presetting the representations compatible
Paper 10  Title: AN ADAPTIVE NEURAL NETWORK PARSER  
Abstract We inv estigate an adaptive neural network problems time-dependent input by demonstrating a deterministic parser natural language inputs of recurrent connectionist architectures The traditional stacking mechanism to necessary proper treatment context-free languages symbolic
Paper 11  Title: Analysis of Dynamical Recognizers  
Abstract Pollack1991 demonstrated second-order recurrent neural networks act dynamical recognizers formal languages when trained observed both phase transitions learning IFS-like fractal state sets Follow-on work focused mainly the extraction minimization a finite state automaton the trained network However, s
Paper 12  Title: Can Recurrent Neural Networks Learn Natural Language Grammars? W&Z recurrent neural networks are able to
Abstract Recurrent neural networks complex parametric dynamic systems exhibit different behavior We consider the task grammatical inference with recurrent neural networks Specifically consider the task natural language sentences can a recurrent neural network made exhibit the same kind discriminatory pow
Label: Neural Networks
Paper 13  Title: Tilt Aftereffects in a Self-Organizing Model of the Primary Visual Cortex  
Abstract Previous neural network learning algorithms for sequence processing perform it long time lags This paper first introduces a simple principle reducing the descriptions event sequences without loss A consequence this principle only unexpected inputs relevant This insight leads the construct
Paper 14  Title: Gene Structure Prediction by Linguistic Methods  
Abstract The higher-order structure genes other features biological sequences described means formal grammars These grammars can then by detect assemble such structures by syntactic pattern recognition We describe a grammar parser by as effective current co
Paper 15  Title: LEARNING COMPLEX, EXTENDED SEQUENCES USING THE PRINCIPLE OF HISTORY COMPRESSION (Neural Computation, 4(2):234-242, 1992)  
Abstract Previous neural network learning algorithms for sequence processing perform it long time lags This paper first introduces a simple principle reducing the descriptions event sequences without loss A consequence this principle only unexpected inputs relevant This insight leads the construct
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1390...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: One of the open problems listed in [ Rivest and Schapire, 1989 ] is whether and how that the copies of L fl in their algorithm can be combined into one for better performance. This paper describes an algorithm called D fl that does that combination. The idea is to represent the states of the learned model using observable symbols as well as hidden symbols that are constructed during learning. These hidden symbols are created to reflect the distinct behaviors of the model states. The distinct behaviors are represented as local distinguishing experiments (LDEs) (not to be confused with global distinguishing sequences), and these LDEs are created when the learner's prediction mismatches the actual observation from the unknown machine. To synchronize the model with the environment, these LDEs can also be concatenated to form a homing sequence. It can be shown that D fl can learn, with probability 1 , a model that is an *-approximation of the unknown machine, in a number of actions polynomial in the size of the environment and 
Title: Title: Learning Finite Automata Using Local Distinguishing Experiments  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Online Learning with Random Representations  
Abstract We consider the requirements online learning|learning which must done incrementally realtime the results learning available soon each new example acquired Despite the abundance methods learning from examples effectively online learning as components reinforcement learning systems Most of these few, incl
Paper 3  Title: Efficient Learning of Typical Finite Automata from Random Walks (Extended Abstract)  
Abstract new and efficient algorithms learning deterministic finite automata Our approach primarily distinguished two features an average-case setting to model the "typical" labeling a finite automaton while retaining a worst-case model the underlying graph along a learning model in not pr
Paper 4  Title: Distribution Category:  Users Guide to the PGAPack Parallel Genetic Algorithm Library  
Abstract The problem modeling complicated data sequences DNA speech often practice Most the algorithms select a hypothesis within assuming the observed sequence the direct output In when the output passes a memoryless noisy channel before observation In particula
Paper 5  Title: Using Errors to Create Piecewise Learnable Partitions  
Abstract In an algorithm which exploits the error distribution generated a learning algorithm break up the domain which being approximated into piecewise learnable partitions the error distribution neglected favor a lump error measure such RMS By doing however lose The error distr
Label: Theory
Paper 6  Title: Learning Markov chains with variable memory length from noisy output  
Abstract The problem modeling complicated data sequences DNA speech often practice Most the algorithms select a hypothesis within assuming the observed sequence the direct output In when the output passes a memoryless noisy channel before observation In particula
Label: Theory
Paper 7  Title: Two Methods for Hierarchy Learning in Reinforcement Environments  
Abstract two methods hierarchically organizing temporal behaviors first is more intuitive grouping common sequences events single units so may treated individual behaviors This system immediately encounters however the units binary the behaviors must execute completely or hinders
Paper 8  Title: Improving Generalization with Active Learning  
Abstract Active learning differs " from examples assumes what part receives information In some situations active learning provably that learning examples alone giving better generalization for a fixed number training examples In this paper consider pro
Paper 9  Title: Using Mixtures of Factor Analyzers for Segmentation and Pose Estimation  Category: Visual Processing Preference: Oral  
Abstract To read a hand-written digit string it segment separate digits Bottom-up segmentation heuristics often neighboring digits substantially We describe has each digit class we the only knowledge required segmentation The system uses Gibbs sampling construct a percept
Label: Neural Networks
Paper 10  Title: Connectionist Modeling of the Fast Mapping Phenomenon  
Abstract The problem making optimal decisions uncertain conditions central Artificial Intelligence If the state the world known all times can modeled a Markov Decision Process MDPs studied many methods known determining optimal courses or policies The more realistic case where state information only par
Paper 11  Title: Parallel Search for Neural Network  Under the guidance of  
Abstract The problem making optimal decisions uncertain conditions central Artificial Intelligence If the state the world known all times can modeled a Markov Decision Process MDPs studied many methods known determining optimal courses or policies The more realistic case where state information only par
Paper 12  Title: CONVIS: Action Oriented Control and Visualization of Neural Networks Introduction and Technical Description  
Abstract two cooperating robots exactly any strongly-connected directed graph n indistinguishable nodes expected time in We introduce homing sequence two robots helps certain previously-seen nodes We then present in the robots learn the graph the homing sequence simultaneously act
Label: Neural Networks
Paper 13  Title: Forecasting Glucose Concentration in Diabetic Patients using Ignorant Belief Networks  
Abstract learning DFA simple examples We show efficient PAC learning of DFA if distributions restricted simple distributions where a teacher might examples This answers posed Pitt's seminal paper DFA PACidentifiable if examples drawn fr
Label: Probabilistic Methods
Paper 14  Title: A Connectionist Symbol Manipulator That Discovers the Structure of Context-Free Languages  
Abstract discover hierarchical and recursive structure symbol strings To detect structure at the architecture has reducing symbols substrings makes an external stack memory In terms formal languages the architecture can learn parse strings an LR(0) context-free grammar Gi
Label: Neural Networks
Paper 15  Title: Combining the Predictions of Multiple Classifiers: Using Competitive Learning to Initialize Neural Networks  
Abstract inductive learning well that is induce a function accurately produces future inputs Hansen Salamon showed, under combining the predictions several separately trained neural networks will improve One their key assumptions the individual networks independ
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Category: Rule Learning
Prediction:  Category: Rule Learning
Is prediction correct?  False

Prediction: 0
Processing index 1519...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper reports on the development of a realistic knowledge-based application using the MOBAL system. Some problems and requirements resulting from industrial-caliber tasks are formulated. A step-by-step account of the construction of a knowledge base for such a task demonstrates how the interleaved use of several learning algorithms in concert with an inference engine and a graphical interface can fulfill those requirements. Design, analysis, revision, refinement and extension of a working model are combined in one incremental process. This illustrates the balanced cooperative modeling approach. The case study is taken from the telecommunications domain and more precisely deals with security management in telecommunications networks. MOBAL would be used as part of a security management tool for acquiring, validating and refining a security policy. The modeling approach is compared with other approaches, such as KADS and stand-alone machine learning. 
Title: Title: What online Machine Learning can do for Knowledge Acquisition A Case Study  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Adaptive Tuning of Numerical Weather Prediction Models: Simultaneous Estimation of Weighting, Smoothing and Physical Parameters 1  
Abstract In case-based reasoning demonstrated problem complex domains Also mixed paradigm approaches emerged combining CBR and induction techniques aiming verifying the knowledge building an efficient case memory However in complex domains induction over the whole problem space often or too time
Paper 3  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 4  Title: Diplomarbeit A Genetic Algorithm for the Topological Optimization of Neural Networks  
Abstract We describe an integrated problem architecture named INBANCA Bayesian networks case-based reasoning ( work multiagent planning tasks This includes two-team dynamic tasks this paper simulated soccer as Bayesian networks characterize action selection whereas determine ho
Label: Genetic Algorithms
Paper 5  Title: Rule Generation and Compaction in the wwtp  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 6  Title: Structural Similarity as Guidance in Case-Based Design  
Abstract determine structural similarity as guidance adaptationCbr We advance structural similarity assessment which not only a single numeric value the most specific structure two cases have inclusive the modification rules needed obtain Our approach treats ret
Label: Case Based
Paper 7  Title: Lazy Induction Triggered by CBR  
Abstract In case-based reasoning demonstrated problem complex domains Also mixed paradigm approaches emerged combining CBR and induction techniques aiming verifying the knowledge building an efficient case memory However in complex domains induction over the whole problem space often or too time
Paper 8  Title: An Interactive Planning Architecture The Forest Fire Fighting case  
Abstract an interactive planning system was inside aimed an operator when the initial attack forest fires The planning architecture rests the integration case-based reasoning techniques exploited, mainly performing temporal reasoning temporal met
Label: Case Based
Paper 9  Title: TECHNIQUES FOR REDUCING THE DISRUPTION OF SUPERIOR BUILDING BLOCKS IN GENETIC ALGORITHMS  
Abstract We describe an integrated problem architecture named INBANCA Bayesian networks case-based reasoning ( work multiagent planning tasks This includes two-team dynamic tasks this paper simulated soccer as Bayesian networks characterize action selection whereas determine ho
Paper 10  Title: A Similarity-Based Retrieval Tool for Software Repositories  
Abstract In a prototype a flexible similarity-based retrieval system Its flexibility supported allowing an imprecisely specified query Moreover our algorithm allows assessing if the retrieved items the initial context specified The presented system can a supporting tool a software repository We also discuss s
Paper 11  Title: REPRO: Supporting Flowsheet Design by Case-Base Retrieval  
Abstract very close the designer behavior during, seems a fruitable computer aided-design approach if a library design cases presents: REPRO, that supports chemical process design The crucial problems like the case represen
Paper 12  Title: Computer-Supported Argumentation for Cooperative Design on the World-Wide Web  
Abstract an argumentation system cooperative design applications on The system provides experts involved such procedures means of expressing weighing their individual arguments preferences argue the selection a certain choice It supports defeasible and qualitative reasoning ill-structured information
Paper 13  Title: Belief Networks Revisited  
Abstract Experiment design execution is a central activity The SeqER system a general architecture the integration automated planning techniques domain knowledge in plan scientific experiments These planning techniques include rule-based methods, derivational analogy Derivational analogy allows pl
Label: Probabilistic Methods
Paper 14  Title: CHARADE: a Platform for Emergencies Management Systems  
Abstract describe the functional architecture CHARADE a software platform devoted intelligent environmental decision support systems The CHARADE platform based the a task-oriented approach system design on the exploitation a new architecture problem that integrates case-based reasoning constraint reasoning
Paper 15  Title: Inductive Learning and Case-Based Reasoning  
Abstract an inductive learning techniques case-based reasoning We introduce two main forms induction define case-based reasoning present The evaluation the proposed system called TA3 carried a classification task namely character recognition We show how inductive knowledge improves knowledge representation
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Case Based
Prediction:  Case Based
Is prediction correct?  False

Prediction: 0
Processing index 1485...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Quantization of the parameters of a Perceptron is a central problem in hardware implementation of neural networks using a numerical technology. An interesting property of neural networks used as classifiers is their ability to provide some robustness on input noise. This paper presents efficient learning algorithms for the maximization of the robustness of a Perceptron and especially designed to tackle the combinatorial problem arising from the discrete weights. 
Title: Title: Maximizing the Robustness of a Linear Threshold Classifier with Discrete Weights  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Provably Convergent Dynamic Training Method for Multilayer Perceptron Networks  
Abstract training multilayer perceptron networks called DMP1 1 The method based upon builds networks in binary trees dynamically allocating layers as The individual nodes trained using a gentetic algorithm The method capable handling
Label: Neural Networks
Paper 3  Title: Interpretable Neural Networks with BP-SOM  
Abstract Interpretation models induced In focus learning bpsom offers possibilities overcome It shown networks trained with bp-som show interesting regularities in that hidden-unit activations become restricted discrete v
Label: Neural Networks
Paper 4  Title: Feature Selection by Means of a Feature Weighting Approach  
Abstract Selecting a set features which optimal We address using the flexible and robust filter technique EUBAFES EUBAFES based a feature weighting approach binary feature weights therefore a solution in the feature selection sense and gives detailed information abo
Paper 5  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 6  Title: Improving RBF Networks by the Feature Selection Approach EUBAFES  
Abstract The curse dimensionality concerning the application RBF networks The number RBF nodes and therefore training examples needed grows the intrinsic dimensionality the input space One way address the application feature selection as a data preprocessing step In this paper
Label: Neural Networks
Paper 7  Title: Analysis of Decision Boundaries Generated by Constructive Neural Network Learning Algorithms  
Abstract Constructive learning algorithms offer incremental construction near-minimal artificial neural networks for pattern classification Examples such algorithms Tower Pyramid Upstart Tiling algorithms which construct threshold logic unitsor, These algorithms differ the networks t
Paper 8  Title: Adaptive Noise Injection for Input Variables Relevance Determination  
Abstract In consider training with noise to input variables relevance determination Noise injection modified penalize irrelevant features The proposed algorithm attractive requires the tuning This parameter controls the penalization the inputs together the complexity A
Paper 9  Title: Sample Complexity for Learning Recurrent Perceptron Mappings  
Abstract Recurrent perceptron classifiers They take into those correlations dependences input coordinates which arise linear digital filtering This paper tight bounds sample complexity associated to the fitting
Paper 10  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Label: Genetic Algorithms
Paper 11  Title: Local Feedforward Networks  
Abstract Although feedforward neural networks function approximation in some applications networks experience a desired function One problem interference which learning in the input space causes unlearning Networks less susceptible interference referred spatially local networks To unders
Paper 12  Title: Using the Grow-And-Prune Network to Solve Problems of Large Dimensionality  
Abstract a technique creating sparsely connected feed-forward neural networks which may capable producing networks have very large input layers The architecture appears particularly tasks sparse training data as able take the sparseness to further Some initial results pr
Paper 13  Title: MDL Learning of Probabilistic Neural Networks for Discrete Problem Domains  
Abstract Given a problem will search its case memory use the stored cases possibly modifying retrieved cases adapt the required input specifications In discrete domains CBR reasoning based a rigorous Bayesian probability propagation algorithm Such a Bayesian CBR system a probabilistic feedforwar
Paper 14  Title: Faster Learning in Multi-Layer Networks by Handling  
Abstract Generalized delta rule, popularly back (BP [9 5 probably training multi-layer feed-forward networks of sigmoid units Despite reports success interesting problems BP can excruciatingly converging weights meet the desired error criterion Several modifications for improving
Label: Neural Networks
Paper 15  Title: Genetic Programming of Minimal Neural Nets Using Occam's Razor  
Abstract A genetic programming method investigated optimizing both the architecture the connection weights multilayer feedforward neural networks The genotype each network whose depth dynamically adapted the particular application by specifically defined genetic operators The weights trained a next-ascent hillclimb-ing search A
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1643...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Researchers in the field of Distributed Artificial Intelligence (DAI) have been developing efficient mechanisms to coordinate the activities of multiple autonomous agents. The need for coordination arises because agents have to share resources and expertise required to achieve their goals. Previous work in the area includes using sophisticated information exchange protocols, investigating heuristics for negotiation, and developing formal models of possibilities of conflict and cooperation among agent interests. In order to handle the changing requirements of continuous and dynamic environments, we propose learning as a means to provide additional possibilities for effective coordination. We use reinforcement learning techniques on a block pushing problem to show that agents can learn complimentary policies to follow a desired path without any knowledge about each other. We theoretically analyze and experimentally verify the effects of learning rate on system convergence, and demonstrate benefits of using learned coordination knowledge on similar problems. Reinforcement learning based coordination can be achieved in both cooperative and non-cooperative domains, and in domains with noisy communication channels and other stochastic characteristics that present a formidable challenge to using other coordination schemes. 
Title: Title: Learning to coordinate without sharing information  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract We reinforcement learning the policies considered the learning process constrained hierarchies partially specified machines This allows for prior knowledge reduce the search space provides a framework in transferred problems in component solutions recombined larger a
Paper 3  Title: Reinforcement Learning with Imitation in Heterogeneous Multi-Agent Systems  
Abstract The application decision making learning algorithms presents many interestingresearch challenges Among these the ability agents learn act by or We describe, the IQ-algorithm integrates imitation Q-learning, a Q-learner uses the observations it
Paper 4  Title: Scaling Reinforcement Learning Algorithms by Learning Variable Temporal Resolution Models  
Abstract The close connection reinforcement dynamic programming algorithms fueled research RL within Yet increased theoretical understanding RL algorithms applicable simple tasks only In the abstract framework afforded the connection to dynamic programming the scaling is
Label: Reinforcement Learning
Paper 5  Title: Modeling the Student with Reinforcement Learning  
Abstract We describe a methodology enabling an intelligent teaching system make high level strategy decisions on low level student modeling information This framework less costly construct superior hand coding teaching strategies as responsive In order accomplish reinforcement learning associate sup
Paper 6  Title: Evolving Cooperation Strategies  
Abstract The identification, design implementation strategies cooperation is Distributed Artificial Intelligence We propose the construction cooperation strategies a group problem solvers based Genetic Programming (GP GPs a class adaptive algorithms used evolve solution structures
Paper 7  Title: Learning in Multi-Robot Systems  
Abstract 1 why traditional reinforcement learning methods algorithms applied those models result dynamic situated multi-agent domains characterized multiple goals noisy perception action inconsistent reinforcement We propose designing the representation and the forcement functions take implicit
Paper 8  Title: Learning Hierarchical Control Structures for Multiple Tasks and Changing Environments  
Abstract While the need hierarchies within control systems apparent to should learned Learning both the structure the component behaviors is The benefit learning the hierarchical structures behaviors the decomposition the control structure smaller transportable chunks allows previously
Paper 9  Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  
Abstract Mixed-initiative systems present the challenge finding an effective level interaction humans computers Machine learning presents in systems automatically adapt accommodate different users In learning user models an adaptive assistant crisis sched
Paper 10  Title: REINFORCEMENT LEARNING FOR COORDINATED REACTIVE CONTROL  
Abstract The demands rapid response many environments decompose, tune coordinate reactive behaviors while ensuring consistency Reinforcement learning networks address the tuning problem do decomposition coordination We hypothesize interacting reactions often decomposed separate control tas
Paper 11  Title: Using Communication to Reduce Locality in Distributed Multi-Agent Learning  
Abstract attempts bridge the fields robotics distributed AI It discusses communication reducing the undesirable effects locality fully distributed multi-agent systems with multiple agents/robots learning while interacting Two key problems, hidden state and credit assignment addressed applying local u
Paper 12  Title: Planning with Closed-Loop Macro Actions  
Abstract: Planning learning at temporal abstraction In summarize an approach based the mathematical framework Markov decision processes reinforcement learning Conventional model-based reinforcement learning uses primitive actions last one time step that modeled independentl
Label: Reinforcement Learning
Paper 13  Title: Coordinating Reactive Behaviors  keywords: reactive systems, planning and learning  
Abstract Combinating reactivity planning potentially slow response times planners while still making progress The demands rapid response the complexity many environments decompose, tune coordinate reactive behaviors while ensuring consistency Neural networks address the tuning
Paper 14  Title: In  Improving Elevator Performance Using Reinforcement Learning  
Abstract the application reinforcement learningRL the difficult real world problem elevator dispatching The elevator domain poses a combination challenges not most RL research to Elevator systems operate continuous state spaces in as discrete event dynamic systems Their states fully observable nonstati
Paper 15  Title: USING A GENETIC ALGORITHM TO LEARN BEHAVIORS FOR AUTONOMOUS VEHICLES  
Abstract Truly autonomous vehicles both projec - tive planning and reactive components in perform robustly Projective components needed replanning where explicit reasoning about future states Reactive components allow always have some action available themselves exhibit robust behavior lack
Label: Reinforcement Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 469...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A traditional interpolation model is characterized by the choice of reg-ularizer applied to the interpolant, and the choice of noise model. Typically, the regularizer has a single regularization constant ff, and the noise model has a single parameter fi. The ratio ff=fi alone is responsible for determining globally all these attributes of the interpolant: its `complexity', `flexibility', `smoothness', `characteristic scale length', and `characteristic amplitude'. We suggest that interpolation models should be able to capture more than just one flavour of simplicity and complexity. We describe Bayesian models in which the interpolant has a smoothness that varies spatially. We emphasize the importance, in practical implementation, of the concept of `conditional convexity' when designing models with many hyperparameters. We apply the new models to the interpolation of neuronal spike data and demonstrate a substantial improvement in generalization error. 
Title: Title: Interpolation Models with Multiple  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Practical Bayesian Framework for Backprop Networks  
Abstract A quantitative and practical Bayesian framework described learning of mappings The framework makes possible: (1) objective comparisons solutions alternative network architectures objective stopping rules pruning growing procedures magnitude weight decay terms or additive regularisersf
Paper 3  Title: Tempering Backpropagation Networks: Not All Weights are Created Equal approach yields hitherto unparalleled performance on
Abstract Backpropagation learning algorithms typically collapse the network's structure weight parameters to optimized We suggest their performance utilizing the structural information instead introduce tempering each weight accordingly In the tempering model activation error signals treated app
Paper 4  Title: Bayesian Non-linear Modelling for the Prediction Competition  
Abstract The 1993 energy prediction competition involved a series building energy loads from environmental input variables Non-linear regression using `neural networks such modeling tasks Since obvious large a time-window of inputs appropriate or preprocessing of best can viewed a regressio
Paper 5  Title: From Isolation to Cooperation: An Alternative View of a System of Experts  
Abstract introduce a constructive, incremental learning system regression problems models data means locally linear experts contrast the experts trained independently compete data during learning Only when a prediction a query required cooperate by blen ding their individual predictions Each expert
Paper 6  Title: Wavelet Thresholding via a Bayesian Approach  
Abstract We discuss a Bayesian formalism gives wavelet threshold estimation A prior distribution imposed the wavelet coefficients the unknown response function designed capture common most applications For prior specified, the posterior median yields a thresholding procedure Our prior m
Label: Probabilistic Methods
Paper 7  Title: Function Approximation with Neural Networks and Local Methods: Bias, Variance and Smoothness  
Abstract We review global and local methods a function mapping R m ) R n samples the function containing noise The relationship the methods is examined an empirical comparison a linear local approximation following
Paper 8  Title: Choice of Thresholds for Wavelet Shrinkage Estimate of the Spectrum fff j g are level-dependent
Abstract estimating the log spectrum thresholding the empirical wavelet coefficients We propose thresholds t j;n depending n wavelet basis resolution level At fine resolution levelsj =; 2 :: propose The purpose this thresholding level the reconstructed log-spectrum as nearly
Label: Probabilistic Methods
Paper 9  Title: Local Feedforward Networks  
Abstract Although feedforward neural networks function approximation in some applications networks experience a desired function One problem interference which learning in the input space causes unlearning Networks less susceptible interference referred spatially local networks To unders
Paper 10  Title: State Reconstruction for Determining Predictability in Driven Nonlinear Acoustical Systems  
Abstract Genetic programming distinguished other evolutionary algorithms uses tree representations variable size instead linear strings fixed length The flexible representation scheme very important because the underlying structure discovered automatically One primary difficulty, the solutions may grow too without
Paper 11  Title: Probabilistic Instance-Based Learning  
Abstract Traditional instance-based learning methods base directly ( stored The predictions weighting the contributions the individual stored instances a distance function implementing a domain-dependent similarity metrics This basic approach suffers three drawbacks com-putationally expensive prediction when
Label: Case Based
Paper 12  Title: FLAT MINIMA Neural Computation 9(1):1-42 (1997)  
Abstract finding low complexity neural networks The algorithm searches a "flat" minimum the error function A flat minimum a large connected region weight-space the error remains approximately An MDL Bayesian argument suggests flat minima correspond "simple" networks low expected ov
Label: Neural Networks
Paper 13  Title: Some Topics in Neural Networks and Control  
Abstract finding low complexity neural networks The algorithm searches a "flat" minimum the error function A flat minimum a large connected region weight-space the error remains approximately An MDL Bayesian argument suggests flat minima correspond "simple" networks low expected ov
Paper 14  Title: Sequential Update of Bayesian Network Structure  
Abstract There an obvious need improving accuracy a Bayesian network as new data is observed Because errors model construction changes the dynamics the domains afford ignore the information new data While sequential update parameters a fixed structure accomplished standard techniques network
Paper 15  Title: Testing the Generalized Linear Model Null Hypothesis versus `Smooth' Alternatives 1  
Abstract previously introduced named GCM-ISW exploits a highly flexible weighting scheme Our simulations it records faster learning several artificial categorization tasks models more limited abilities warp input spaces This paper extends; experimental results sugge
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 2686...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Chaque parametre du modele est penalise individuellement. Le reglage de ces penalisations se fait automatiquement a partir de la definition d'un hyperparametre de regularisation globale. Cet hyperparametre, qui controle la complexite du regresseur, peut ^etre estime par des techniques de reechantillonnage. Nous montrons experimentalement les performances et la stabilite de la penalisation multiple adaptative dans le cadre de la regression lineaire. Nous avons choisi des problemes pour lesquels le probleme du controle de la complexite est particulierement crucial, comme dans le cadre plus general de l'estimation fonctionnelle. Les comparaisons avec les moindres carres regularises et la selection de variables nous permettent de deduire les conditions d'application de chaque algorithme de penalisation. Lors des simulations, nous testons egalement plusieurs techniques de reechantillonnage. Ces techniques sont utilisees pour selectionner la complexite optimale des estimateurs de la fonction de regression. Nous comparons les pertes occasionnees par chacune d'entre elles lors de la selection de modeles sous-optimaux. Nous regardons egalement si elles permettent de determiner l'estimateur de la fonction de regression minimisant l'erreur en generalisation parmi les differentes methodes de penalisation en competition. 
Title: Title: Penalisation multiple adaptative un nouvel algorithme de regression, la penalisation multiple adapta-tive. Cet algorithme represente
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: ALECSYS and the AutonoMouse: Learning to Control a Real Robot by Distributed Classifier Systems  
Abstract: Chaque parametre du modele est penalise individuellement Le reglage de ces penalisations se a definition d'un hyperparametre de regularisation globale Cet hyperparametre qui controle la complexite du regresseur ^etre estime par des techniques de reechantillonnage Nous montrons experimentalement les performances stabilite penalisatio
Paper 3  Title: Model Selection for Generalized Linear Models via GLIB, with Application to Epidemiology 1  
Abstract 1 This the first draft for Bayesian Biostatistics edited Donald A. Berry and Darlene K. Strangl. Adrian E. Raftery is Professor Statistics Department GN-22 Washington Sylvia Richardson Directeur de Recherche, INSERM Unite 170 16 avenue Paul Vaillant Couturier 94807 Villejuif CEDEX France R
Label: Probabilistic Methods
Paper 4  Title: A DISCUSSION ON SOME DESIGN PRINCIPLES FOR EFFICIENT CROSSOVER OPERATORS FOR GRAPH COLORING PROBLEMS  
Abstract A year a new metaheuristic graph coloring problems Costa Hertz Dubuis They shown, computer experiments some clear indication the benefits Graph coloring has many applications specially the areas scheduling assignments timetabling The metaheuristic can classified a memetic algorithm since a p
Paper 5  Title: GAL: Networks that grow when they learn and shrink when they forget  
Abstract Learning when limited modification some parameters a limited scope the capability the system structure also needed get the learnable In artificial neural networks learning by iterative adjustment only succeed the network designer predefines hidden layers
Paper 6  Title: GREQE a Diplome des Etudes Approfondies en Economie Mathematique et Econometrie A Genetic Algorithm for
Abstract propose a refinement innateness If we merely identify innateness bias obtain a poor characterisation this notion any learning device relies makes choose a given hypothesis instead another We show our intuition innateness better captured a characteristic bias related isotro
Paper 7  Title: Adaptive Boosting of Neural Networks for Character Recognition  
Abstract: Technical Report #1072 D epartement erationnelle Universit e de Montr eal Abstract Boosting is any learning algorithm consistently classifiers need only random guessing recently proposed and promising boosting algorithm AdaBoost [ be
Label: Neural Networks
Paper 8  Title: Stochastic Hillclimbing as a Baseline Method for Evaluating Genetic Algorithms  
Abstract We investigate as a baseline evaluating genetic algorithms (GAs as combinatorial function optimizers In particular address four problems to GAs applied the maximum cut problem, Koza's 11-multiplexer problem MDAP ( the jobshop pr
Paper 9  Title: Wavelet Shrinkage: Asymptopia?  
Abstract Considerable effort directed recently minimax methods in problems recovering infinite-dimensional objectscurves densities spectral densities images noisy data A rich and complex body evolved, nearly- or minimax estimators being obtained interesting problems Unfortunately the results often
Paper 10  Title: TABLE DES MATI ERES 1 Apprentissage et approximation les techniques de regularisation 3 1.1 Introduction
Abstract The paper investigates the possibilities using simple recurrent networks transducers which map sequential natural language input The networks perform sentences containing a single main predicateencoded transitive verbs applied multiple-feature objects with adjectival modifiers
Paper 11  Title: Decomposable graphical Gaussian model determination  
Abstract Bayesian model determination decomposable graphical Gaussian models To achieve consider a hyper inverse Wishart prior distribution on the concentration matrix To compatibility models such prior distributions obtained marginalisation the prior conditional the complete graph We explore alterna
Paper 12  Title: A Modular Q-Learning Architecture for Manipulator Task Decomposition `Data storage in the cerebellar model ar
Abstract Compositional Q-Learning (Singh 1992 composite tasks made several elemental tasks by Skills acquired while performing elemental tasks applied solve composite tasks Individual skills compete act only winning skills included the decomposition the composite task We
Paper 13  Title: An information-maximisation approach to blind separation and blind deconvolution  
Abstract We derive a new self-organising learning algorithm which transferred non-linear units The algorithm does assume the input distributions defined here the zero-noise limit Under information maximisation has extra properties not the linear caseLinsker 1989 The nonlinearities the t
Paper 14  Title: Inductive Bias in Case-Based Reasoning Systems  
Abstract learn case-based reasoners as learning form-alise as a PAC learning algorithm the case-based representation hCB; We first consider a `naive' case-based learning algorithm CB1( H collecting all available cases into which calculates similarity
Paper 15  Title: Scatter-partitioning RBF network for function regression and image  
Abstract: segmentation: Preliminary Abstract. Scatter-partitioning Radial Basis Function (RBF) networks increase their number degrees to be estimated on supervised training Due its superior expressive power a scatter-partitioning Gaussian RBF termed Supervised Growing Neural Gas i
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 417...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: In learning from examples it is often useful to expand an attribute-vector representation by intermediate concepts. The usual advantage of such structuring of the learning problem is that it makes the learning easier and improves the comprehensibility of induced descriptions. In this paper, we develop a technique for discovering useful intermediate concepts when both the class and the attributes are real-valued. The technique is based on a decomposition method originally developed for the design of switching circuits and recently extended to handle incompletely specified multi-valued functions. It was also applied to machine learning tasks. In this paper, we introduce modifications, needed to decompose real functions and to present them in symbolic form. The method is evaluated on a number of test functions. The results show that the method correctly decomposes fairly complex functions. The decomposition hierarchy does not depend on a given repertoir of basic functions (background knowledge). 
Title: Title: Constructing Intermediate Concepts by Decomposition of Real Functions  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: FONN: Combining First Order Logic with Connectionist Learning  
Abstract a neural network architecture manage structured data refine knowledge bases expressed a first order logic language The presented framework well classification problems concept de scriptions depend numerical features In fact the main goal the neural architecture that refining the numerical part the k
Paper 3  Title: Machine Learning by Function Decomposition  
Abstract We, given training examples induces a definition the target concept a hierarchy intermediate concepts their definitions This effectively decomposes the problem The method inspired the Boolean function decomposition approach to the design digital circuits To cope
Paper 4  Title: Evolving Compact Solutions in Genetic Programming: A Case Study  
Abstract Genetic programmingGP genetic algorithms where handled trees This makes GP especially evolving functional relationships or computer programs both represented trees Symbolic regression the determination a function dependence y = g(x thatx i ; In this paper the feasibilit
Label: Genetic Algorithms
Paper 5  Title: Hidden Markov Model Analysis of Motifs in Steroid Dehydrogenases and their Homologs  
Abstract Methods to build function approximators example data have gained Especially methodologies build models allow an interpretation have attracted Most existing algorithms, however either complicated high-dimensional problems presents efficient algorithm construct fuz
Label: Neural Networks
Paper 6  Title: Using Qualitative Models to Guide Inductive Learning  
Abstract using qualitative models guide inductive learning Our objectives induce rules which not only accurate explainable with respect the qualitative model reduce learning time exploiting domain knowledge Such explainability essential both practical application inductive technology fo
Paper 7  Title: First Order Regression: Applications in Real-World Domains  
Abstract first order regression algorithm capable handling introduced and some Regressional learning assumes real-valued class The algorithm combines regressional learning standard ILP concepts first order concept description background knowledge A clause gene
Paper 8  Title: Growing a Hypercubical Output Space in a Self-Organizing Feature Map  
Abstract Recent studies planning comparing plan reuse plan generation both the above tasks may computational complexity even we deal very similar problems The aim the same kind results apply also diagnosis. We propose a theoretical complexity analysis coupled some experimental tests intended
Paper 9  Title: Structural Regression Trees  
Abstract many real domains the task a theory predicting numerical values particular several standard test domains used Inductive Logic Programming concerned predicting numerical values examples relational and mostly non-determinate background knowledge However so far no ILP algorithm except can number
Label: Rule Learning
Paper 10  Title: Constructing Fuzzy Graphs from Examples  
Abstract Methods to build function approximators example data have gained Especially methodologies build models allow an interpretation have attracted Most existing algorithms, however either complicated high-dimensional problems presents efficient algorithm construct fuz
Paper 11  Title: Evolving Self-Supporting Structures Page 18 References Evolution of Visual Control Systems for Robots. To appear
Abstract In are acquiring by integration Our aim construct from several separate sources The need merge knowledge bases can arise, knowledge bases acquired independently interactions several domain experts As opinions different domain experts may knowledge
Paper 12  Title: Learning Controllers from Examples  a motivation for searching alternative, empirical techniques for generating controllers.  
Abstract Today there discovering methods allow a faster design Control theory helps when linear controllers developed but support the generation In it Machine Learning has the Function, Locally Receptive Field Function Approximators Three integrated l
Label: Neural Networks
Paper 13  Title: Architecture for Iterative Learning of Recursive Definitions  
Abstract In are inducing recursive Horn clauses from small sets training examples The method iterative bootstrap induction presented. In the system generates simple clauses regarded properties the required definition Properties represent generalizations the positive examples simulating hav
Paper 14  Title: A Hypothesis-driven Constructive Induction Approach to Expanding Neural Networks  
Abstract With most machine learning methods if the given knowledge representation space inadequate then This also true methods using neural networks the form the representation space To overcome an automatic construction method This paper the BP-HCI method a hypothesis-driven constr
Paper 15  Title: An Evolutionary Method to Find Good Building-Blocks for Architectures of Artificial Neural Networks  
Abstract deals the combination A new method presented find good building-blocks architectures Artificial Neural Networks The method Cellular Encoding a representation scheme by F. Gruau and on Genetic Programming by Koza. First it will shown a modified Cellular Encoding techniq
Label: Genetic Algorithms
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Category: Rule Learning
Prediction:  Category: Rule Learning
Is prediction correct?  False

Prediction: 0
Processing index 2489...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Experience plays an important role in the development of human expertise. One computational model of how experience affects expertise is provided by research on case-based reasoning, which examines how stored cases encapsulating traces of specific prior problem-solving episodes can be retrieved and re-applied to facilitate new problem-solving. Much progress has been made in methods for accessing relevant cases, and case-based reasoning is receiving wide acceptance both as a technology for developing intelligent systems and as a cognitive model of a human reasoning process. However, one important aspect of case-based reasoning remains poorly understood: the process by which retrieved cases are adapted to fit new situations. The difficulty of encoding effective adaptation rules by hand is widely recognized as a serious impediment to the development of fully autonomous case-based reasoning systems. Consequently, an important question is how case-based reasoning systems might learn to improve their expertise at case adaptation. We present a framework for acquiring this expertise by using a combination of general adaptation rules, introspective reasoning, and case-based reasoning about the case adaptation task itself. 
Title: Title: BECOMING AN EXPERT CASE-BASED REASONER: LEARNING TO ADAPT PRIOR CASES  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Computer Evolution of Buildable Objects for Evolutionary Design by Computers  
Abstract: Experience plays human expertise One computational model how experience affects expertise provided research case-based reasoning examines how stored cases encapsulating traces specific prior problem-solving episodes retrieved re facilitate new problem Much progress methods a
Label: Genetic Algorithms
Paper 3  Title: Combining Rules and Cases to Learn Case Adaptation  
Abstract Computer models case-based reasoning generally guide case adaptation adaptation rules A difficult practical problem identify the knowledge guide adaptation particular tasks Likewise an open issue CBR as a cognitive model case adaptation knowledge We describe acquiring case adaptation knowl
Label: Case Based
Paper 4  Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  
Abstract In current CBR systems case adaptation usually performed rule-based methods hand the system developer The ability define those rules depends knowledge the task domain may not a presenting endowing CBR systems the needed adaptation knowledge This paper ongoing resea
Paper 5  Title: Acquiring Case Adaptation Knowledge: A Hybrid Approach  
Abstract The ability case-based reasoning (CBR) systems apply cases novel situations depends their case adaptation knowledge However endowing CBR systems adequate adaptation knowledge has This paper a hybrid method performing case adaptation, It shows this approach
Paper 6  Title: Learning Adaptation Strategies by Introspective Reasoning about Memory Search  
Abstract case-based reasoning systems the case adaptation process traditionally controlled static libraries hand-coded adaptation rules This paper learning adaptation knowledge adaptation strategies of developed and hand Kass [90 Adaptation strategies differ standard adaptation rules encode general memory se
Paper 7  Title: NESTED NETWORKS FOR ROBOT CONTROL  
Abstract Case-based reasoning depends multiple knowledge sources beyond the case library knowledge case adaptation criteria similarity assessment Because hand coding this knowledge accounts the knowledge acquisition burden developing CBR systems appealing acquire, CBR apply This ob
Label: Neural Networks
Paper 8  Title: A Case Study of Case-Based CBR  
Abstract Case-based reasoning depends multiple knowledge sources beyond the case library knowledge case adaptation criteria similarity assessment Because hand coding this knowledge accounts the knowledge acquisition burden developing CBR systems appealing acquire, CBR apply This ob
Label: Case Based
Paper 9  Title: Case-Based Similarity Assessment: Estimating Adaptability from Experience  
Abstract Case-based problem-solving systems rely similarity assessment select stored cases whose solutions easily fit current problems However widely-used similarity assessment strategies, evaluation semantic similarity can poor predictors adaptability As systems may select cases difficult adapt even ea
Label: Case Based
Paper 10  Title: Meta-Cases: Explaining Case-Based Reasoning  
Abstract: AI research case-based reasoning led many laboratory case-based systems As introducing these systems work environments explaining the processes case-based reasoning In this paper the notion a meta-case illustrating, explaining justifying case-based reasoning A meta-
Label: Case Based
Paper 11  Title: Adapting Abstract Knowledge  
Abstract For a case-based reasoner use its knowledge flexibly equipped powerful case adapter A case-based reasoner can only cope variation the problems given the extent its cases in memory efficiently adapted new situations In address the task adapting abstract knowledge planning fit
Paper 12  Title: Generic Teleological Mechanisms and their Use in Case Adaptation  
Abstract In experience-based (or case-based) reasoning new problems retrieving adapting the solutions similar problems encountered An important issue experience-based reasoning identify different types knowledge reasoning useful different classes case-adaptation tasks In this paper a class non-routine case-adaptation tasks
Paper 13  Title: A Goal-Based Approach to Intelligent Information Retrieval  
Abstract: Intelligent information retrievalIIR requires inference The number inferences by even a simple reasoner very large the inferential resources any practical computer system This problem one long faced AI researchers In this paper used two recent machine learning programs for control inference that
Paper 14  Title: Storing and Indexing Plan Derivations through Explanation-based Analysis of Retrieval Failures  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Paper 15  Title: Data Exploration with Reflective Adaptive Models  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 2331...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We extend Hoeffding bounds to develop superior probabilistic performance guarantees for accurate classifiers. The original Hoeffding bounds on classifier accuracy depend on the accuracy itself as a parameter. Since the accuracy is not known a priori, the parameter value that gives the weakest bounds is used. We present a method that loosely bounds the accuracy using the old method and uses the loose bound as an improved parameter value for tighter bounds. We show how to use the bounds in practice, and we generalize the bounds for individual classifiers to form uniform bounds over multiple classifiers. 
Title: Title: Improved Hoeffding-Style Performance Guarantees for Accurate Classifiers  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Improved Uniform Test Error Bounds  
Abstract derive distribution-free uniform test error bounds improve on VC-type bounds validation We show knowledge test inputs the bounds. The bounds sharp require intense computation We introduce trade sharpness speed computation Also compute the bounds several test cases
Label: Theory
Paper 3  Title: Validation of Voting Committees  
Abstract contains a method bound the test errors voting committees with members chosen trained classifiers There so many prospective committees validating them directly does achieve useful error bounds Because fewer classifiers prospective committees better validate individually linear programming
Label: Theory
Paper 4  Title: Self bounding learning algorithms  
Abstract Most which attempts give bounds the generalization error the hypothesis generated a learning algorithm methods from uniform convergence These bounds a-priori bounds hold any distribution examples calculated before observed In this paper bounding the generalization e
Label: Theory
Paper 5  Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  
Abstract: We present an algorithm improving algorithms learning binary concepts The improvement achieved combining a large number hypotheses each generated training given learning examples Our algorithm ideas presented Schapire inThe strength weak learnability represents an im
Label: Theory
Paper 6  Title: Using Qualitative Relationships for Bounding Probability Distributions  
Abstract We exploit qualitative probabilistic relationships variables for computing bounds interest Using the signs qualitative relationships implement abstraction operations guaranteed bound the distributions interest By evaluating incrementally improved approximate network
Label: Probabilistic Methods
Paper 7  Title: Anytime Influence Diagrams  
Abstract the posterior distribution for feedforward neural networks consistent. This paper extends earlier results universal approximation properties The proof consistency embeds a density estimation problem then uses bounds the bracketing entropy show posterior is consist
Label: Probabilistic Methods
Paper 8  Title: An Efficient Extension to Mixture Techniques for Prediction and Decision Trees  
Abstract We maintaining mixtures prunings a prediction or decision tree extends the "node-based" prunings [Bun90, WST95 HS97 to the larger class The method includes an efficient online weight allocation prediction compression classification Although the set edge-based prunings of a given tree m
Paper 9  Title: UNIVERSAL FORMULAS FOR TREATMENT EFFECTS FROM NONCOMPLIANCE DATA  
Abstract establishes formulas bound the actual treatment effect any experimental study treatment assignment random but subject compliance imperfect These formulas provide the tightest bounds the average treatment effect that inferred given assignments treatments responses Our results reveal even high
Label: Probabilistic Methods
Paper 10  Title: A Fast, Bottom-Up Decision Tree Pruning Algorithm with Near-Optimal Generalization  
Abstract In this work a new bottom-up algorithm decision tree pruning very (requiring only a single pass the given tree prove a strong performance guarantee the generalization error We work the typical setting in the given tree T may derived the given training sample S may badly ove
Paper 11  Title: Evolutionary Design of Neural Architectures A Preliminary Taxonomy and Guide to Literature  
Abstract In a computation-ally efficient method inducing selective Bayesian network classifiers Our approach information-theoretic metrics efficiently select a subset attributes which learn the classifier We explore three conditional, information-theoretic met-rics extensions metrics extensively decision tree learning namel
Paper 12  Title: Efficient Learning of Selective Bayesian Network Classifiers  
Abstract In a computation-ally efficient method inducing selective Bayesian network classifiers Our approach information-theoretic metrics efficiently select a subset attributes which learn the classifier We explore three conditional, information-theoretic met-rics extensions metrics extensively decision tree learning namel
Label: Probabilistic Methods
Paper 13  Title: Challenges in Evolving Controllers for Physical Robots  
Abstract General convergence results linear discriminant updates Abstract The problem learning can various mistake-driven update procedures the Winnow family and In this paper define the general class quasi-additive algorithms includes Perceptron Winnow as special cases
Paper 14  Title: Consistency of Posterior Distributions for Neural Networks  
Abstract the posterior distribution for feedforward neural networks consistent. This paper extends earlier results universal approximation properties The proof consistency embeds a density estimation problem then uses bounds the bracketing entropy show posterior is consist
Paper 15  Title: Rigorous Learning Curve Bounds from Statistical Mechanics  
Abstract introduce and investigate a mathematically rigorous theory learning curves ideas statistical mechanics The advantage our theory over the well-established Vapnik-Chervonenkis theory our bounds considerably tighter are also reflective the true behavior (functional form learning curves This behavior
Label: Theory
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 1827...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Evolution is a stochastic process which operates on the DNA of species. The evolutionary process leaves tell-tale signs in the DNA which can be used to construct phylogenies, or evolutionary trees, for a set of species. Maximum Likelihood Estimations (MLE) methods seek the evolutionary tree which is most likely to have produced the DNA under consideration. While these methods are widely accepted and intellectually satisfying, they have been computationally intractable. In this paper, we address the intractability of MLE methods as follows. We introduce a metric on stochastic process models of evolution. We show that this metric is meaningful by proving that in order for any algorithm to distinguish between two stochatic models that are close according to this metric, it needs to be given a lot of observations. We complement this result with a simple and efficient algorithm for inverting the stochastic process of evolution, that is, for building the tree from observations on the DNA of the species. Our result can be viewed as a result on the PAC-learnability of the class of distributions produced by tree-like processes. Though there have been many heuristics suggested for this problem, our algorithm is the first one with a guaranteed convergence rate, and further, this rate is within a polynomial of the lower-bound rate we establish. Ours is also the the first polynomial-time algorithm which is guaranteed to converge at all to the correct tree. 
Title: Title: Efficient Algorithms for Inverting Evolution  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Fast Algorithm for the Computation and Enumeration of Perfect Phylogenies  
Abstract: The Perfect Phylogeny Problem a classical problem computational evolutionary biology in species/taxa described qualitative characters In the problem shown NP-Complete in general while the different fixed parameter versions can each solved In particular Agarwala and Fernandez-Baca developed
Paper 3  Title: On the Sample Complexity of Learning Bayesian Networks  
Abstract In there learning Bayesian networks data One learning such networks based the minimum description length principle Previous work this learning procedure successful: with probability one, will converge the target distribution given a sufficient numbe
Label: Probabilistic Methods
Paper 4  Title: Theory and Applications of Agnostic PAC-Learning with Small Decision Trees  
Abstract We exhibit a theoretically founded algorithm T2 agnostic PAC-learning of decision trees at whose computation time almost linear the size We evaluate this learning algorithm T2 on 15 common real-world datasets for most provides simple decision trees predictive
Paper 5  Title: Learning Bayesian Prototype Trees by Simulated Annealing  
Abstract Given a set samples an unknown probability distribution study the problem constructing a good approximative Bayesian network model in question This task can viewed a search problem the goal a maximal probability network model given In this work do make learn arbitrarily multico
Label: Probabilistic Methods
Paper 6  Title: On the Learnability and Usage of Acyclic Probabilistic Finite Automata  
Abstract propose and analyze a distribution learning a subclass This subclass characterized a certain distinguishability property the automata's states Though hardness results are known learning distributions generated general APFAs prove our algorithm efficiently the s
Paper 7  Title: Constructing Computationally Efficient Bayesian Models via Unsupervised Clustering  Probabilistic Reasoning and Bayesian Belief Networks,  
Abstract Given a set samples an unknown probability distribution study the problem constructing a good approximative Bayesian network model in question This task can viewed a search problem the goal a maximal probability network model given In this work do make learn arbitrarily multico
Paper 8  Title: A Fast, Bottom-Up Decision Tree Pruning Algorithm with Near-Optimal Generalization  
Abstract In this work a new bottom-up algorithm decision tree pruning very (requiring only a single pass the given tree prove a strong performance guarantee the generalization error We work the typical setting in the given tree T may derived the given training sample S may badly ove
Paper 9  Title: Self bounding learning algorithms  
Abstract Most which attempts give bounds the generalization error the hypothesis generated a learning algorithm methods from uniform convergence These bounds a-priori bounds hold any distribution examples calculated before observed In this paper bounding the generalization e
Label: Theory
Paper 10  Title: Learning a set of primitive actions with an Induction of decision trees. Machine Learning, 1(1):81-106,
Abstract Although probabilistic inference a general Bayesian belief network inference computation time reduced most practical cases exploiting domain knowledge by making the knowledge representation In this paper the property similarity states a new method approximate knowledge representation whic
Label: Theory
Paper 11  Title: Predicting a binary sequence almost as well as the optimal biased coin  
Abstract apply the exponential weight algorithm and Littlestone and Warmuth by Vovk [24 predicting a binary sequence almost the best biased coin We first show for the case the derived algorithm Jeffrey's prior that was studied Xie Barron under probabilistic assump
Paper 12  Title: Robust Trainability of Single Neurons  
Abstract We propose efficient on reinforcement the expected mistake bound framework introduced Haussler Littlestone Warmuth1987 The measure of performance we the expected difference the total reward received the learning agent behaving from We call this expected difference the cumula
Paper 13  Title: DYNAMIC CONDITIONAL INDEPENDENCE MODELS AND MARKOV CHAIN MONTE CARLO METHODS  
Abstract There many applications it order rather classify instances Here consider learning order, given feedback in preference judgments to one instance ranked ahead We outline one first learns by conventional means a preference function of
Paper 14  Title: Constructing Bayesian finite mixture models by the EM algorithm  
Abstract: Email: Firstname.HelsinkiFI Report C-19969, University Department Abstract In finite mixture models building decision support systems capable sound probabilistic inference Finite mixture models have many appealing properties in prediction (reasoning phase the
Paper 15  Title: 3 Representation Issues in Neighborhood Search and Evolutionary Algorithms  
Abstract Evolutionary Algorithms presented general purpose search methods Yet we also no search method another over all possible problems and in often problem specific information involved the choice problem representation search operators In explore some very general properties representations a
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Category: Probabilistic Methods
Prediction:  Category: Probabilistic Methods
Is prediction correct?  False

Prediction: 0
Processing index 1534...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Combinatorial explosion of inferences has always been a central problem in artificial intelligence. Although the inferences that can be drawn from a reasoner's knowledge and from available inputs is very large (potentially infinite), the inferential resources available to any reasoning system are limited. With limited inferential capacity and very many potential inferences, reasoners must somehow control the process of inference. Not all inferences are equally useful to a given reasoning system. Any reasoning system that has goals (or any form of a utility function) and acts based on its beliefs indirectly assigns utility to its beliefs. Given limits on the process of inference, and variation in the utility of inferences, it is clear that a reasoner ought to draw the inferences that will be most valuable to it. This paper presents an approach to this problem that makes the utility of a (potential) belief an explicit part of the inference process. The method is to generate explicit desires for knowledge. The question of focus of attention is thereby transformed into two related problems: How can explicit desires for knowledge be used to control inference and facilitate resource-constrained goal pursuit in general? and, Where do these desires for knowledge come from? We present a theory of knowledge goals, or desires for knowledge, and their use in the processes of understanding and learning. The theory is illustrated using two case studies, a natural language understanding program that learns by reading novel or unusual newspaper stories, and a differential diagnosis program that improves its accuracy with experience. 
Title: Title: The Use of Explicit Goals for Knowledge to Guide Inference and Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Goal-Based Approach to Intelligent Information Retrieval  
Abstract: Intelligent information retrievalIIR requires inference The number inferences by even a simple reasoner very large the inferential resources any practical computer system This problem one long faced AI researchers In this paper used two recent machine learning programs for control inference that
Paper 3  Title: Correcting Imperfect Domain Theories: A Knowledge-Level Analysis  
Abstract Explanation-Based Learning [Mitchell 1986 DeJong Mooney promise a powerful analytical learning technique However EBL is severely the requirement a complete and correct domain theory successful learning to occur Clearly in non-trivial domains developing such a domain theory Therefore much research b
Paper 4  Title: Introduction to the Special Section on Knowledge-Based Construction of Probabilistic and Decision Models (IEEE Transactions
Abstract Modeling techniques developed recently the AI uncertain reasoning communities permit significantly more flexible specifications Specifically, graphical decision-modeling formalisms|belief networks influence diagrams their variants|provide compact representation support inference algorithms automatically exp
Label: Probabilistic Methods
Paper 5  Title: Blocking Gibbs Sampling for Linkage Analysis in Large Pedigrees with Many Loops  
Abstract: Learning intelligence a key consideration designing cognitive architectures such Soar [ Laird 1986 This chapter considers what an appropriate general-purpose learning mechanism We interested mechanisms and reproduce the rich variety learning capabilities humans ranging
Label: Probabilistic Methods
Paper 6  Title: Representing Self-knowledge for Introspection about Memory Search  
Abstract This position paper sketches modeling introspective reasoning discusses modeling about memory search It argues effective and flexible memory processing rich memories should built five types explicitly represented self-knowledge information needs relationships differ
Label: Case Based
Paper 7  Title: Learning Analytically and Inductively  
Abstract: Learning intelligence a key consideration designing cognitive architectures such Soar [ Laird 1986 This chapter considers what an appropriate general-purpose learning mechanism We interested mechanisms and reproduce the rich variety learning capabilities humans ranging
Label: Reinforcement Learning
Paper 8  Title: On Decision-Theoretic Foundations for Defaults  
Abstract: In considerable effort gone understanding default reasoning Most this effort concentrated the question entailment what conclusions warranted a knowledge-base of defaults Surprisingly few works formally examine the general role defaults We argue an examination this role defaults suggest
Label: Probabilistic Methods
Paper 9  Title: Between MDPs and Semi-MDPs: Learning, Planning, and Representing Knowledge at Multiple Temporal Scales  
Abstract Learning, planning representing knowledge at temporal abstraction key challenges AI In this paper develop these problems based the mathematical framework reinforcement learning Markov decision processes We extend the usual notion action options|whole courses behavior temporally extended sto
Label: Reinforcement Learning
Paper 10  Title: Adaptive probabilistic networks  
Abstract: Belief networks (or and two forms network representations have the development intelligent systems in Belief networks provide a concise representation general probability distributions over random variables facilitate exact calculation the impact evidence pr
Paper 11  Title: NESTED NETWORKS FOR ROBOT CONTROL  
Abstract Case-based reasoning depends multiple knowledge sources beyond the case library knowledge case adaptation criteria similarity assessment Because hand coding this knowledge accounts the knowledge acquisition burden developing CBR systems appealing acquire, CBR apply This ob
Label: Neural Networks
Paper 12  Title: A Functional Theory of Creative Reading  
Abstract Reading an area human cognition which education researchers artificial intelligence researchers Yet there still does a theory which accurately the complete process. We believe these past attempts fell due the overall task reading; namely complete set men
Paper 13  Title: Computer Evolution of Buildable Objects for Evolutionary Design by Computers  
Abstract: Experience plays human expertise One computational model how experience affects expertise provided research case-based reasoning examines how stored cases encapsulating traces specific prior problem-solving episodes retrieved re facilitate new problem Much progress methods a
Label: Genetic Algorithms
Paper 14  Title: Investigating the Value of a Good Input Representation  
Abstract is reprinted Computational Learning Theory Natural Learning Systems 3, T. Petsche, Judd, and S. Hanson (eds forthcoming 1995 Copyrighted 1995 MIT Press Abstract The ability find a good solution dependent used the features A number factors
Paper 15  Title: Learning an Optimally Accurate Representational System  
Abstract The multiple extension problem a default theory can use its defaults propose, mutually answers some queries This paper observations learn a credulous version this default theory that ( "optimally accurate In more detail can associate a given default theor
Label: Theory
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Theory
Prediction:  Theory
Is prediction correct?  False

Prediction: 0
Processing index 1782...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Submitted to NIPS-98 TD() is a popular family of algorithms for approximate policy evaluation in large MDPs. TD() works by incrementally updating the value function after each observed transition. It has two major drawbacks: it makes inefficient use of data, and it requires the user to manually tune a stepsize schedule for good performance. For the case of linear value function approximations and = 0, the Least-Squares TD (LSTD) algorithm of Bradtke and Barto [5] eliminates all stepsize parameters and improves data efficiency. This paper extends Bradtke and Barto's work in three significant ways. First, it presents a simpler derivation of the LSTD algorithm. Second, it generalizes from = 0 to arbitrary values of ; at the extreme of = 1, the resulting algorithm is shown to be a practical formulation of supervised linear regression. Third, it presents a novel, intuitive interpretation of LSTD as a model-based reinforcement learning technique.
Title: Title: Least-Squares Temporal Difference Learning  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Truncating Temporal Differences: On the Efficient Implementation of TD() for Reinforcement Learning  
Abstract Temporal difference (TD) methods constitute learning predictions multi-step prediction problems parameterized a recency factor. Currently the most important application these methods temporal credit assignment reinforcement learning Well known reinforcement learning algorithms AHC Q-learning may viewed instances TD learnin
Paper 3  Title: Toward Learning Systems That Integrate Different Strategies and Representations TR93-22  
Abstract Temporal difference (TD) methods constitute learning predictions multi-step prediction problems parameterized a recency factor. Currently the most important application these methods temporal credit assignment reinforcement learning Well known reinforcement learning algorithms AHC Q-learning may viewed instances TD learnin
Paper 4  Title: INCREMENTAL POLYNOMIAL CONTROLLER NETWORKS: two self-organising non-linear controllers  
Abstract Temporal difference (TD) methods constitute learning predictions multi-step prediction problems parameterized a recency factor. Currently the most important application these methods temporal credit assignment reinforcement learning Well known reinforcement learning algorithms AHC Q-learning may viewed instances TD learnin
Label: Neural Networks
Paper 5  Title: Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta  
Abstract Appropriate bias widely viewed efficient learning I present a new algorithm the Incremental Delta-Bar-DeltaIDBD the learning appropriate biases based previous learning experience The IDBD algorithm developed the case simple linear learning system|the LMS or delta rule with a separate learning-rate parameter e
Label: Neural Networks
Paper 6  Title: Update rules for parameter estimation in Bayesian networks  
Abstract re parameter estimation missing values hidden variables from the perspective recent work on learning [12 We provide a unified framework parameter estimation that encompasses on learning where continuously adapted new data cases as arrive the more traditional batch learni
Paper 7  Title: Gas Identification System using Graded Temperature Sensor and Neural Net Interpretation  
Abstract We three new algorithms setting ff, temporal-difference learning methods such TD(). The overall task that learning predict an unknown Markov chain based repeated observations its state trajectories The new algorithms select step-size parameters online normall
Label: Neural Networks
Paper 8  Title: On Step-Size and Bias in Temporal-Difference Learning  
Abstract We three new algorithms setting ff, temporal-difference learning methods such TD(). The overall task that learning predict an unknown Markov chain based repeated observations its state trajectories The new algorithms select step-size parameters online normall
Label: Reinforcement Learning
Paper 9  Title: PUSH-PULL SHUNTING MODEL OF GANGLION CELLS Simulations of X and Y retinal ganglion cell behavior
Abstract We three new algorithms setting ff, temporal-difference learning methods such TD(). The overall task that learning predict an unknown Markov chain based repeated observations its state trajectories The new algorithms select step-size parameters online normall
Label: Neural Networks
Paper 10  Title: An Upper Bound on the Loss from Approximate Optimal-Value Functions  
Abstract Many reinforcement can formulated from Markov decision processes the associated method dynamic programming The value this theoretical understanding, tempered many practical concerns One important question DP-based approaches that use function approximation rather lookup tables can avoid catastrophi
Label: Reinforcement Learning
Paper 11  Title: Value Function Approximations and Job-Shop Scheduling  
Abstract We a successful application TD() value function approximation the task job-shop scheduling Our scheduling problems based scheduling payload processing steps The value function approximated a 2-layer feedforward network A one-step lookahead greedy algorithm using the learned evaluation
Paper 12  Title: Machine Learning,  Reinforcement Learning with Replacing Eligibility Traces  
Abstract The eligibility trace one used reinforcement learning handle delayed reward In this paper introduce eligibility trace the replacing trace analyze it theoretically results faster, more reliable learning Both kinds trace assign credit prior events according how recently occu
Label: Reinforcement Learning
Paper 13  Title: Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems  
Abstract Increasing attention reinforcement learning algorithms partly successes the theoretical analysis their behavior Markov environments If the Markov assumption removed however neither generally the algorithms the analyses continue usable We propose and analyze a new learning algorithm solve a certain class non-Markov d
Paper 14  Title: Reinforcement Learning with Soft State Aggregation  
Abstract It more compact representations than lookup tables crucial scaling reinforcement Unfortunately almost all the theory reinforcement learning assumes lookup table representations In address the pressing issue combining function approximation RL, present 1 function ap
Paper 15  Title: Bayesian Methods for Adaptive Models  
Abstract Almost all the work Average-reward Re- inforcement Learning so table-based methods which do scale domains large state spaces In this paper two extensions a model-based ARL method called H-learning address We extend H-learning learn action models reward functions Bayesian networks a
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 487...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Designers across a variety of domains engage in many of the same creative activities. Since much creativity stems from using old solutions in novel ways, we believe that case-based reasoning can be used to explain many creative design processes. 
Title: Title: Language as a dynamical system  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: CASE-BASED CREATIVE DESIGN  
Abstract Designers across domains engage many of Since much creativity stems using old solutions in believe case-based reasoning explain many creative design processes
Paper 3  Title: Explaining Serendipitous Recognition in Design  
Abstract Creative designers see solutions pending design problems the everyday objects surrounding This can often innovation insight sometimes revealing new functions purposes common design pieces We interested modeling solutions pending problems creative mechanical design This paper c
Paper 4  Title: Belief Networks Revisited  
Abstract Experiment design execution is a central activity The SeqER system a general architecture the integration automated planning techniques domain knowledge in plan scientific experiments These planning techniques include rule-based methods, derivational analogy Derivational analogy allows pl
Label: Probabilistic Methods
Paper 5  Title: Towards More Creative Case-Based Design Systems  
Abstract: Case-based reasoning supporting creative design particularly processes rely previous design experience framing the problem evaluating design alternatives However most existing CBR systems living They tend adapt and reuse old solutions in routine ways producing robust but uninspired resul
Paper 6  Title: Creative Design: Reasoning and Understanding  
Abstract memory issues influence long- term creative problem design activity taking a case-based reasoning perspective Our exploration is: the invention by We abstract Bell's reasoning and understanding mechanisms appear time long-term creative design We identif
Paper 7  Title: Understanding Creativity: A Case-Based Approach  
Abstract: Dissatisfaction existing standard case-based reasoning (CBR) systems prompted us we make creative, broadly what would it them creative This paper discusses three research goals understanding creative processes better investigating cases CBR creative problem understanding th
Paper 8  Title: Protein Sequencing Experiment Planning Using Analogy protein sequencing experiments. Planning is interleaved with experiment execution,
Abstract Experiment design execution is a central activity The SeqER system a general architecture the integration automated planning techniques domain knowledge in plan scientific experiments These planning techniques include rule-based methods, derivational analogy Derivational analogy allows pl
Paper 9  Title: Generic Teleological Mechanisms and their Use in Case Adaptation  
Abstract In experience-based (or case-based) reasoning new problems retrieving adapting the solutions similar problems encountered An important issue experience-based reasoning identify different types knowledge reasoning useful different classes case-adaptation tasks In this paper a class non-routine case-adaptation tasks
Paper 10  Title: Grounding Robotic Control with Genetic Neural Networks  
Abstract Technical Report AI94-223 May 1994 Abstract An but often problem grounding systems their environment such the representations manipulate have inherent meaning for Since humans rely semantics the grounding is crucial truly intelligent be
Label: Genetic Algorithms
Paper 11  Title: Integrating Creativity and Reading: A Functional Approach  
Abstract Reading has studied cognitive disciplines yet no theories which sufficiently and accomplish the complete task real-world texts In particular a type knowledge intensive reading known creative reading largely the past research We argue creative reading an aspect practicall
Paper 12  Title: Using Knowledge of Cognitive Behavior to Learn from Failure  
Abstract When learning from reasoning failures knowledge how a system a powerful lever deciding went with in deciding A number benefits arise systems possess knowledge their own operation of Abstract knowledge cognition can select diagnosis and repair strategies from
Paper 13  Title: Functional Representation as Design Rationale  
Abstract Design rationale is a record design activity: of alternatives available choices the reasons explanations how a proposed design intended We describe a representation called the Functional Representation has how a device's functions arise causally the functions We prop
Paper 14  Title: Abduction, Experience, and Goals: A Model of Everyday Abductive Explanation*  
Abstract When a reasoner explains surprising events for its internal use a key motivation explaining perform learning facilitate the achievement Human explainers use build explanations both internal reasoning and external information search, and goal-based considerations have their choices when
Paper 15  Title: Analysis and Empirical Studies of Derivational Analogy  
Abstract Derivational analogy reusing problem experience problem This research addresses common that derivational analogy overcoming the mismatches past experiences new problems impede reuse First this research describes the variety mismatches and proposes a new app
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Case Based
Prediction:  Case Based
Is prediction correct?  False

Prediction: 0
Processing index 928...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Initial Results Abstract. Conversational case-based reasoning (CBR) systems, which incrementally extract a query description through a user-directed conversation, are advertised for their ease of use. However, designing large case libraries that have good performance (i.e., precision and querying efficiency) is difficult. CBR vendors provide guidelines for designing these libraries manually, but the guidelines are difficult to apply. We describe an automated inductive approach that revises conversational case libraries to increase their conformance with design guidelines. Revision increased performance on three conversational case libraries.
Title: Title: Learning to Refine Case Libraries:  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Refining Conversational Case Libraries  
Abstract Conversational case-based reasoning (CBR) shells (, Inference's CBR Express commercially successful tools supporting help desk In contrast rule-based expert systems they capture knowledge as cases rather more problematic rules incrementally However rather eliminate the knowledge engineerin
Paper 3  Title: Towards More Creative Case-Based Design Systems  
Abstract: Case-based reasoning supporting creative design particularly processes rely previous design experience framing the problem evaluating design alternatives However most existing CBR systems living They tend adapt and reuse old solutions in routine ways producing robust but uninspired resul
Paper 4  Title: Belief Networks Revisited  
Abstract Experiment design execution is a central activity The SeqER system a general architecture the integration automated planning techniques domain knowledge in plan scientific experiments These planning techniques include rule-based methods, derivational analogy Derivational analogy allows pl
Label: Probabilistic Methods
Paper 5  Title: Learning to Improve Case Adaptation by Introspective Reasoning and CBR  
Abstract In current CBR systems case adaptation usually performed rule-based methods hand the system developer The ability define those rules depends knowledge the task domain may not a presenting endowing CBR systems the needed adaptation knowledge This paper ongoing resea
Paper 6  Title: Protein Sequencing Experiment Planning Using Analogy protein sequencing experiments. Planning is interleaved with experiment execution,
Abstract Experiment design execution is a central activity The SeqER system a general architecture the integration automated planning techniques domain knowledge in plan scientific experiments These planning techniques include rule-based methods, derivational analogy Derivational analogy allows pl
Paper 7  Title: Data Exploration with Reflective Adaptive Models  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Paper 8  Title: NESTED NETWORKS FOR ROBOT CONTROL  
Abstract Case-based reasoning depends multiple knowledge sources beyond the case library knowledge case adaptation criteria similarity assessment Because hand coding this knowledge accounts the knowledge acquisition burden developing CBR systems appealing acquire, CBR apply This ob
Label: Neural Networks
Paper 9  Title: Modeling Case-based Planning for Repairing Reasoning Failures  
Abstract One application models reasoning behavior allow a reasoner introspectively detect repair failures We address the transferability such models versus the specificity the knowledge in them the kinds needed self-modeling structured the evaluation introspective reasoning sy
Paper 10  Title: Supporting Conversational Case-Based Reasoning in an Integrated Reasoning Framework  Conversational Case-Based Reasoning  
Abstract Conversational case-based reasoningCCBR successfully assist case retrieval tasks However behavioral limitations CCBR motivate integrations other reasoning approaches This paper briefly towards enhancing the inferencing behaviors a conversational case-based reasoning development tool named NaCoDAE
Paper 11  Title: Case-Based Similarity Assessment: Estimating Adaptability from Experience  
Abstract Case-based problem-solving systems rely similarity assessment select stored cases whose solutions easily fit current problems However widely-used similarity assessment strategies, evaluation semantic similarity can poor predictors adaptability As systems may select cases difficult adapt even ea
Label: Case Based
Paper 12  Title: Theory Revision in Fault Hierarchies  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Label: Theory
Paper 13  Title: A Case Study of Case-Based CBR  
Abstract Case-based reasoning depends multiple knowledge sources beyond the case library knowledge case adaptation criteria similarity assessment Because hand coding this knowledge accounts the knowledge acquisition burden developing CBR systems appealing acquire, CBR apply This ob
Label: Case Based
Paper 14  Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  
Abstract Mixed-initiative systems present the challenge finding an effective level interaction humans computers Machine learning presents in systems automatically adapt accommodate different users In learning user models an adaptive assistant crisis sched
Paper 15  Title: Storing and Indexing Plan Derivations through Explanation-based Analysis of Retrieval Failures  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 1238...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Pruning a decision tree is considered by some researchers to be the most important part of tree building in noisy domains. While, there are many approaches to pruning, an alternative approach of averaging over decision trees has not received as much attention. We perform an empirical comparison of pruning with the approach of averaging over decision trees. For this comparison we use a computa-tionally efficient method of averaging, namely averaging over the extended fanned set of a tree. Since there are a wide range of approaches to pruning, we compare tree averaging with a traditional pruning approach, along with an optimal pruning approach.
Title: Title: On Pruning and Averaging Decision Trees  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Pruning Decision Trees with Misclassification Costs  
Abstract We describe pruning methods decision tree classifiers when minimizing loss rather error In two common methods error minimization CART's cost-complexity pruning study the extension loss and one pruning variant based We perform an empir
Paper 3  Title: Building Classifiers using Bayesian Networks  
Abstract Recent work supervised learning a surprisingly simple Bayesian classifier strong assumptions of independence among features called naive Bayes competitive state of such C4.5 This fact raises less restrictive assumptions perform even In this paper and approach
Label: Probabilistic Methods
Paper 4  Title: More Efficient Windowing  
Abstract Windowing has proposed a procedure efficient memory use the ID3 decision tree learning However previous work windowing may often a decrease performance In this work try argue separate-and-conquer rule learning algorithms more appropriate windowing learn rules indepen
Paper 5  Title: Decision Tree Induction: How Effective is the Greedy Heuristic?  
Abstract Most existing decision tree systems induce trees | locally optimal splits are induced Although the greedy approach believed produce reasonably good trees In the current work attempt verify this belief We quantify the goodness greedy tree induction empirically the popular decision tree
Paper 6  Title: An Empirical Evaluation of Bagging and Boosting  
Abstract An ensemble consists independently trained classifierssuch decision trees whose predictions combined when classifying novel instances Previous research an ensemble as often accurate any of the single classifiers Bagging (Breiman 1996a Boosting & Schapire relatively ne
Paper 7  Title: Improving Bagging Performance by Increasing Decision Tree Diversity  
Abstract Ensembles decision trees often exhibit greater predictive accuracy alone Bagging boosting two standard ways generating and combining multiple trees Boosting has empirically determined more of recently proposed this produces more diverse trees bagging This paper reports empiric
Label: Theory
Paper 8  Title: Multivariate Decision Trees  
Abstract COINS Technical Report 92-82 December Abstract Multivariate decision trees overcome a representational limitation restricted splits the instance space the feature's axis This paper discusses the following issues for constructing multivariate decision trees representing inc
Paper 9  Title: Top-Down Pruning in Relational Learning  
Abstract Pruning dealing noise Machine Learning Recently pruning algorithms, in particular Reduced Error Pruning also attracted Inductive Logic Programming However has shown these methods inefficient most is for generating clauses explain noisy examples subsequently p
Paper 10  Title: Simplifying Decision Trees: A Survey  
Abstract Induced decision trees an extensively-researched solution classification tasks For many practical tasks the trees produced tree-generation algorithms not comprehensible users due Although many tree induction algorithms shown produce simpler, more comprehensible treesor data structures derived good classifica
Label: Theory
Paper 11  Title: Prototype and Feature Selection by Sampling and Random Mutation Hill Climbing Algorithms  
Abstract With computational costs without accuracy describe two algorithms find sets prototypes nearest neighbor classification Here the term prototypes the reference instances a nearest neighbor computation the instances with respect which similarity assessed assign a new data item Both algorithms re
Paper 12  Title: Evolutionary Design of Neural Architectures A Preliminary Taxonomy and Guide to Literature  
Abstract In a computation-ally efficient method inducing selective Bayesian network classifiers Our approach information-theoretic metrics efficiently select a subset attributes which learn the classifier We explore three conditional, information-theoretic met-rics extensions metrics extensively decision tree learning namel
Paper 13  Title: Simultaneous Evolution of Programs and their Control Structures Simultaneous Evolution of Programs and their Control
Abstract Previous research a technique error output coding dramatically the classification accuracy that learn data points into one k 2 classes This paper an investigation why the ECOC technique works particularly employed decision-tree learning algorithms It shows th
Paper 14  Title: Using Partitioning to Speed Up Specific-to-General Rule Induction  
Abstract RISEDomingos 1995 in a rule induction proceeds gradually generalizing rules, starting per example This has several advantages compared gradually specializing initially null rules has lead significant accuracy gains algorithms C4.5RULES CN2 in application doma
Paper 15  Title: The Utility of Feature Weighting in Nearest-Neighbor Algorithms  
Abstract Nearest-neighbor algorithms known depend their distance metric In a weighted Euclidean metric which for comes options We describe Diet, an algorithm directs search through a space discrete weights using as its evaluation function Although a large set
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 1081...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: When specializing a recursive predicate in order to exclude a set of negative examples without excluding a set of positive examples, it may not be possible to specialize or remove any of the clauses in a refutation of a negative example without excluding any positive exam ples. A previously proposed solution to this problem is to apply program transformation in order to obtain non-recursive target predicates from recursive ones. However, the application of this method prevents recursive specializations from being found. In this work, we present the algorithm spectre ii which is not limited to specializing non-recursive predicates. The key idea upon which the algorithm is based is that it is not enough to specialize or remove clauses in refutations of negative examples in order to obtain correct specializations, but it is sometimes necessary to specialize clauses that appear only in refutations of positive examples. In contrast to its predecessor spectre, the new algorithm is not limited to specializing clauses defining one predicate only, but may specialize clauses defining multiple predicates. Furthermore, the positive and negative examples are no longer required to be instances of the same predicate. It is proven that the algorithm produces a correct specialization when all positive examples are logical consequences of the original program, there is a finite number of derivations of positive and negative examples and when no positive and negative examples have the same sequence of input clauses in their refutations.
Title: Title: Specialization of Recursive Predicates  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Specialization of Logic Programs by Pruning SLD-Trees  
Abstract: program w.r.t positive and negative examples can viewed the problem pruning an SLD-tree such all refutations and excluded It shown the actual pruning can applying unfolding and clause removal The algorithm spectre presented, this idea The input to,
Paper 3  Title: Predicate Invention and Learning from Positive Examples Only  
Abstract: Previous bias shift approaches predicate invention applicable learning positive examples only if a complete hypothesis found the given language as negative examples required determine new predicates should One approach presented, MERLIN a successor a system in predicate invention i
Label: Rule Learning
Paper 4  Title: Theory-Guided Induction of Logic Programs by Inference of Regular Languages recursive clauses. merlin on the
Abstract resent allowed sequences resolution steps the initial theory There, many characterizations allowed sequences resolution steps expressed a set resolvents One approach presented, the system mer-lin an earlier technique learning finite-state automata that represent allowed sequences resolution step
Paper 5  Title: PAC-Learning PROLOG clauses with or without errors  
Abstract In we can describe a generic ILP problem following given a set E (positive and examples a target predicate some background B the worldusually a logic program including facts auxiliary predicates a logic program Hour hypothesis such can B H while no e
Paper 6  Title: Some studies in machine learning using the game of checkers. IBM Journal, 3(3):211-229, 1959. Some
Abstract covering has In well and compared the covering technique a logic programming framework Covering works repeatedly specializing an overly general hypothesis on each iteration focusing finding a clause a high coverage positive examples Divide- works special
Label: Genetic Algorithms
Paper 7  Title: THE DISCOVERY OF ALGORITHMIC PROBABILITY  
Abstract covering has In well and compared the covering technique a logic programming framework Covering works repeatedly specializing an overly general hypothesis on each iteration focusing finding a clause a high coverage positive examples Divide- works special
Paper 8  Title: The Challenge of Revising an Impure Theory  
Abstract A pure rule-based program will return answers; and set even its rules re However, an impure program the Prolog cut "!" not() operators return different answers re There also many reasoning systems return found for first ans
Label: Theory
Paper 9  Title: Integrity Constraints in ILP using a Monte Carlo approach  
Abstract Many state ILP systems require large numbers negative examples avoid This a considerable disadvantage many ILP applications namely indu ctive program synthesis where relativelly small and sparse example sets a more realistic scenario Integrity constraints first order clauses play negative examples
Paper 10  Title: Bottom-up induction of logic programs with more than one recursive clause  
Abstract In a bottom-up algorithm called MRI induce logic programs from their examples This method induce programs with a base clause from examples MRI based saturations examples It first generates a path structure a stream processed predicates
Label: Rule Learning
Paper 11  Title: Least Generalizations and Greatest Specializations of Sets of Clauses  
Abstract The main operations Inductive Logic Programming generalization specialization only a generality order In ILP the three most important generality orders subsumption implication implication relative background knowledge The two languages used most languages clauses languages only Horn clauses This gives a total si
Label: Rule Learning
Paper 12  Title: Symposium Title: Tutorial Discourse What Makes Human Explanations Effective?  
Abstract Many state ILP systems require large numbers negative examples avoid This a considerable disadvantage many ILP applications namely indu ctive program synthesis where relativelly small and sparse example sets a more realistic scenario Integrity constraints first order clauses play negative examples
Paper 13  Title: Acquiring Recursive and Iterative Concepts with Explanation-Based Learning explanation-based generalization, generalizing explanation structures, generalizing to
Abstract University Computer Technical Report 876September 1989 Abstract In explanation-based learning a specific problem's solution generalized into later Most research explanation-based learning involves relaxing constraints the variables a specific example rather gener
Paper 14  Title: Discovering Representation Space Transformations for Learning Concept Descriptions Combining DNF and M-of-N Rules  
Abstract addresses a class learning require a construction descriptions combine Mof rules traditional Disjunctive Normal form (DNF) rules The presented method learns such descriptions conditional Mof rules the hypothesis-driven constructive induction approach In this approach the representation space modified according
Paper 15  Title: Competitive Environments Evolve Better Solutions for Complex Tasks  
Abstract University Computer Technical Report 876September 1989 Abstract In explanation-based learning a specific problem's solution generalized into later Most research explanation-based learning involves relaxing constraints the variables a specific example rather gener
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 403...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The evolution of a population can be guided by phenotypic traits acquired by members of that population during their lifetime. This phenomenon, known as the Baldwin Effect, can speed the evolutionary process as traits that are initially acquired become genetically specified in later generations. This paper presents conditions under which this genetic assimilation can take place. As well as the benefits that lifetime adaptation can give a population, there may be a cost to be paid for that adaptive ability. It is the evolutionary trade-off between these costs and benefits that provides the selection pressure for acquired traits to become genetically specified. It is also noted that genotypic space, in which evolution operates, and phenotypic space, on which adaptive processes (such as learning) operate, are, in general, of a different nature. To guarantee an acquired characteristic can become genetically specified, then these spaces must have the property of neighbourhood correlation which means that a small distance between two individuals in phenotypic space implies that there is a small distance between the same two individuals in genotypic space.
Title: Title: Landscapes, Learning Costs and Genetic Assimilation.  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The Evolutionary Cost of Learning  
Abstract Traits that acquired members an evolving population during through adaptive processes learning can become genetically specified Thus there a change the level learning the population over evolutionary time This paper explores as well benefits to be learning costs
Paper 3  Title: Genes, Phenes and the Baldwin Effect: Learning and Evolution in a Simulated Population  
Abstract The Baldwin Effect, first proposed suggests the course evolutionary change influenced individually learned behavior The existence this effect still In this paper clear evidence learning-based plasticity at and produce directed changes at Thi
Paper 4  Title: Guiding or Hiding: Explorations into the Effects of Learning on the Rate of Evolution.  
Abstract Individual lifetime learning can `guide an evolving population areas high fitness genotype space through the Baldwin effect 1896 Hin-ton Nowlan It the accepted wisdom this guiding speeds By highlighting another interaction learning evolution that will termed the Hiding eff
Paper 5  Title: Modeling the Evolution of Motivation  
Abstract In order learning improve the adaptiveness thus direct evolution Baldwin suggested incorporate an innate evaluation how influence its reproductive fitness For example many circumstances that damage otherwise reduce painful tend We refer
Paper 6  Title: Mutation Rates as Adaptations  
Abstract In order better life helpful the envelop of A simple model coevolution was implemented with the mutation rate the individual This allowed the mutation rate itself evolve a lineage The model shows when the individuals interact a sort the lineages maintain relatively h
Label: Genetic Algorithms
Paper 7  Title: The Coevolution of Mutation Rates  
Abstract In order better life helpful the envelop of A simple model coevolution was implemented with genes longevity and mutation rate the individuals This made a lineage evolve immortal It also allowed the evolution no mutation or extremely high mutation rates The model shows whe
Paper 8  Title: Generalist and Specialist Behavior Due to Individual Energy Extracting Abilities.  
Abstract The emergence generalist and specialist behavior populations neural networks studied Energy extracting ability included an organism In artificial life simulations with organisms living, the fitness score can interpreted the combination an organisms behavior extract potential food s
Paper 9  Title: Investigating the role of diploidy in simulated populations of evolving individuals  
Abstract In most work applying genetic algorithms populations neural networks there no real distinction genotype In nature both the information the genotype the mapping into usually much The genotypes many organisms exhibit they include two copies: if two
Label: Genetic Algorithms
Paper 10  Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Abstract Holland's analysis the sources power of genetic algorithms served guidance the applications The technique applying a recombination operatorcrossover a population individuals a key that power Neverless there contradictory results concerning crossover operators with respect overall p
Label: Genetic Algorithms
Paper 11  Title: Facing The Facts: Necessary Requirements For The Artificial Evolution of Complex Behaviour  
Abstract sets the open-ended artificial evolution complex behaviour autonomous agents If recurrent dynamical neural networksor similar phenotypes a Genetic that employs variable length genotypes, Inman Harvey's SAGA capable evolving arbitrary levels be-havioural complexity Furthermore with simple r
Paper 12  Title: Specialization under Social Conditions in Shared Environments  
Abstract Specialist and behaviors populations artificial neural networks studied A genetic algorithm simulate evolution processes thereby neural network control systems exhibit specialist or according the fitness formula With evolvable fitness the evaluation measure let free evolve obtain a co
Paper 13  Title: Adapting Crossover in Evolutionary Algorithms  
Abstract One the issues evolutionary algorithms (EAs two search operators mutation crossover Genetic algorithms (GAs and genetic programmingGP) stress the role crossover while evolutionary programming evolution strategiesESs mutation The existence many different forms crossover further D
Label: Genetic Algorithms
Paper 14  Title: The Exploitation of Cooperation in Iterated Prisoner's Dilemma  
Abstract We follow Axelrod [ using the genetic algorithm play Iterated Prisoner's Dilemma Each member the population ( each strategy evaluated how it This creates the algorithm optimising a moving target instead the usual evaluation against some fixed set strategies ca
Paper 15  Title: Every Niching Method has its Niche: Fitness Sharing and Implicit Sharing Compared  
Abstract Various extensions Genetic attempt find all or most optima a search space containing Many these emulate natural speciation For co-evolutionary learning succeed a range management and control problems such learning game strategies such methods find all or most optima However suitable comparison studies We compa
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1680...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The Structure-Mapping Engine (SME) has successfully modeled several aspects of human consistent interpretations of an analogy. While useful for theoretical explorations, this aspect of the algorithm is both psychologically implausible and computationally inefficient. (2) SME contains no mechanism for focusing on interpretations relevant to an analogizer's goals. This paper describes modifications to SME which overcome these flaws. We describe a greedy merge algorithm which efficiently computes an approximate "best" interpretation, and can generate alternate interpretations when necessary. We describe pragmatic marking, a technique which focuses the mapping to produce relevant, yet novel, inferences. We illustrate these techniques via example and evaluate their performance using empirical data and theoretical analysis. analogical processing. However, it has two significant drawbacks: (1) SME constructs all structurally
Title: Title: Making SME greedy and pragmatic  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The Structure-Mapping Engine: Algorithm and Examples  
Abstract the Structure-Mapping Engine studying analogical processing. SME has built explore Gentner's Structure-mapping theory analogy provides a "tool kit constructing matching algorithms consistent Its flexibility enhances cognitive simulation studies experimentation Furthermore SME very efficie
Paper 3  Title: MAC/FAC: A Model of Similarity-based Retrieval  
Abstract We similarity-based retrieval which capture three psychological phenomena people extremely judging analogy when given items to (2) Superficial remindings much (3 People sometimes experience and use purely structural analogical remindings Our model called MAC/FACfor
Paper 4  Title: Double Censoring: Characterization and Computation of the Nonparametric Maximum Likelihood Estimator  
Abstract In case-based planning previously generated plans stored cases memory solve CBP can save considerable time over planning from scratch (generative planning thus offering a potential (heuristic) mechanism handling One drawback CBP systems has highly structured m
Label: Probabilistic Methods
Paper 5  Title: Modeling Case-based Planning for Repairing Reasoning Failures  
Abstract One application models reasoning behavior allow a reasoner introspectively detect repair failures We address the transferability such models versus the specificity the knowledge in them the kinds needed self-modeling structured the evaluation introspective reasoning sy
Paper 6  Title: A Methodology for Processing Problem Constraints in Genetic Programming  
Abstract Search mechanisms artificial intelligence combine two elements representation determines a search mechanism actually explores Unfortunately many searches may explore redundant and/or invalid solutions Genetic programming refers evolutionary algorithms but utilizing a parameterized representatio
Paper 7  Title: Data Exploration with Reflective Adaptive Models  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Paper 8  Title: Proceedings of CogSci89 Structural Evaluation of Analogies: What Counts?  
Abstract Judgments similarity soundness human analogical processing This paper these judgments modeled SME Gentner's structure-mapping theory We focus structural evaluation explicating several principles which psychologically plausible algorithms follow We introduce the Specificity Conjecture claims th
Paper 9  Title: How good are genetic algorithms at finding large cliques: an experimental study  
Abstract the power genetic algorithms at solving the MAX-CLIQUE problem We measure a standard genetic algorithm an elementary set problem instances consisting embedded cliques random graphs We indicate the need improvement introduce the multi-phase annealed GA, exhibits
Paper 10  Title: Selection of Distance Metrics and Feature Subsets for k-Nearest Neighbor Classifiers  
Abstract Prioritized sweeping attempts focus achieve a good estimate environment states To choose effectively where a costly planning step classic prioritized sweeping uses a simple heuristic focus computation the states the largest errors
Paper 11  Title: An Investigation of Marker-Passing Algorithms for Analogue Retrieval  
Abstract If analogy case-based reasoning systems scale very large case bases analyze retrieving analogues to identify the features for appropriate This paper reports one such analysis a comparison retrieval by marker passing or spreading activation a semantic network with Knowledge
Paper 12  Title: Multiassociative Memory  
Abstract how implement connectionist models Traditional symbolic approaches wield explicit representation all alternatives via stored links or implicitly enumerative algorithms Classical pattern association models ignore the issue generating multiple outputs
Paper 13  Title: Advantages of Decision Lists and Implicit Negatives in Inductive Logic Programming  
Abstract demonstrates the capabilities Foidl an inductive logic programming (ILP) system whose distinguishing characteristics produce first-order decision lists an output completeness assumption as a substitute negative examples intensional background knowledge The development Foidl was originally motivated the problem le
Paper 14  Title: A Formalization of Explanation-Based Macro-operator Learning  
Abstract In spite Explanation-Based Learning its theoretical basis Using a generalization Probably Approximately CorrectPAC learning problem domains formalizes two forms Explanation-Based Learning of macrooperators proves the sufficient conditions their success These two forms EBL, called "Macro Cachi
Label: Theory
Paper 15  Title: Storing and Indexing Plan Derivations through Explanation-based Analysis of Retrieval Failures  
Abstract Case-Based Planning scaling domain-independent planning solve It replaces the detailed and lengthy search a solution the retrieval adaptation previous planning experiences In general CBP demonstrated improve performance over generative (from- planning However, the performance improveme
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Theory
Prediction:  Theory
Is prediction correct?  False

Prediction: 0
Processing index 395...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We present an alternative to the cellular encoding technique [Gruau 1992] for evolving graph and network structures via genetic programming. The new technique, called edge encoding, uses edge operators rather than the node operators of cellular encoding. While both cellular encoding and edge encoding can produce all possible graphs, the two encodings bias the genetic search process in different ways; each may therefore be most useful for a different set of problems. The problems for which these techniques may be used, and for which we think edge encoding may be particularly useful, include the evolution of recurrent neural networks, finite automata, and graph-based queries to symbolic knowledge bases. In this preliminary report we present a technical description of edge encoding and an initial comparison to cellular encoding. Experimental investigation of the relative merits of these encoding schemes is currently in progress.
Title: Title: Evolving Graphs and Networks with Edge Encoding: Preliminary Report  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A Study in Program Response and the Negative Effects of Introns in Genetic Programming  
Abstract The standard method obtaining a response tree-based genetic programming take the value returned In non-tree representations alternate methods have explored One alternative treat a specific location indexed memory the response value when the program The purpose explore this technique t
Paper 3  Title: Induction of decision trees using RELIEFF  
Abstract An investigation the dynamics Genetic Programming applied chaotic time series prediction reported An interesting characteristic adaptive search techniques perform well many problem domains while failing Because Genetic Programming's flexible tree structure any particular problem represented myriad forms These representati
Paper 4  Title: Genetic Algorithms for Combinatorial Optimization: The Assembly Line Balancing Problem  
Abstract Genetic algorithms one example a random element within We consider the application the genetic algorithm a particular problem the Assembly Line Balancing A general description genetic algorithms, their specialized use on our test-bed problems We carry extensive computational t
Paper 5  Title: The Royal Road for Genetic Algorithms: Fitness Landscapes and GA Performance  
Abstract Genetic algorithms ( play many artificial-life systems often little detailed understanding why the GA performs as it little theoretical basis on characterize the types fitness landscapes lead successful GA performance In this paper addressing these issues Our strategy consists defining
Paper 6  Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Abstract Holland's analysis the sources power of genetic algorithms served guidance the applications The technique applying a recombination operatorcrossover a population individuals a key that power Neverless there contradictory results concerning crossover operators with respect overall p
Label: Genetic Algorithms
Paper 7  Title: A Comparison of Crossover and Mutation in Genetic Programming  
Abstract a large and systematic body data mutation, crossover combinations mutation genetic programming (GP The literature of traditional genetic algorithms contains related studies mutation and crossover in GP differ their traditional counterparts In this paper
Label: Genetic Algorithms
Paper 8  Title: Cultural Transmission of Information in Genetic Programming  
Abstract shows the performance a genetic programming system through the addition mechanisms non-genetic transmission information (culture Teller has previously shown genetic programming systems enhanced through the addition memory mechanisms for individual programs [Teller 1994 in mem
Paper 9  Title: The Role of Development in Genetic Algorithms  
Abstract Technical Report Number CS94394 Computer Science Abstract The developmental mechanisms transforming to typically omitted formulationsGAs these two representational spaces identical We argue developmental mechanisms useful understanding the success seve
Paper 10  Title: Evolution of Mapmaking: Learning, planning, and memory using Genetic Programming  
Abstract: An essential component an intelligent agent observe encode use Traditional approaches Genetic Programming have evolving functional or reactive programs with only a minimal use state This paper investigating the evolution learning, planning memory Genetic Programming The
Paper 11  Title: Facing The Facts: Necessary Requirements For The Artificial Evolution of Complex Behaviour  
Abstract sets the open-ended artificial evolution complex behaviour autonomous agents If recurrent dynamical neural networksor similar phenotypes a Genetic that employs variable length genotypes, Inman Harvey's SAGA capable evolving arbitrary levels be-havioural complexity Furthermore with simple r
Paper 12  Title: Island Model Genetic Algorithms and Linearly Separable Problems  
Abstract Parallel Genetic Algorithms have often reported yield which a single large panmictic population In the Island Model Genetic Algorithm informally argued having helps preserve each island potentially follow a different search trajectory through the s
Label: Genetic Algorithms
Paper 13  Title: A Cooperative Coevolutionary Approach to Function Optimization  
Abstract: A general model the coevolution cooperating species This model instantiated and tested the domain function optimization compared a traditional GA-based function optimizer The results encouraging in two respects They suggest ways the performance GA and other EA-based optimizers they ev
Label: Genetic Algorithms
Paper 14  Title: How good are genetic algorithms at finding large cliques: an experimental study  
Abstract the power genetic algorithms at solving the MAX-CLIQUE problem We measure a standard genetic algorithm an elementary set problem instances consisting embedded cliques random graphs We indicate the need improvement introduce the multi-phase annealed GA, exhibits
Paper 15  Title: LIBGA: A USER-FRIENDLY WORKBENCH FOR ORDER-BASED GENETIC ALGORITHM RESEARCH  
Abstract Over there several packages developed a workbench genetic algorithm (GA) research Most these packages the generational model inspired A have adopted used Genitor Unfortunately they some deficiencies when working order-based problems packing routing scheduling This paper descri
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1130...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper describes a novel search algorithm, called dynamic hill climbing, that borrows ideas from genetic algorithms and hill climbing techniques. Unlike both genetic and hill climbing algorithms, dynamic hill climbing has the ability to dynamically change its coordinate frame during the course of an optimization. Furthermore, the algorithm moves from a coarse-grained search to a fine-grained search of the function space by changing its mutation rate and uses a diversity-based distance metric to ensure that it searches new regions of the space. Dynamic hill climbing is empirically compared to a traditional genetic algorithm using De Jong's well-known five function test suite [4] and is shown to vastly surpass the performance of the genetic algorithm, often finding better solutions using only 1% as many function evaluations. 
Title: Title: Dynamic Hill Climbing: Overcoming the limita- tions of optimization techniques  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Hybridized Crossover-Based Search Techniques for Program Discovery  
Abstract In address program discovery as Genetic Programming [10 We two major results by combining a hierarchical crossover operator two traditional single point search algorithms: Simulated Annealing Stochastic Iterated Hill Climbing solved some problems fewer fitness evaluations a greater probability a success
Label: Genetic Algorithms
Paper 3  Title: Toward a unified theory of spatiotemporal processing in the retina  
Abstract Traditional evolutionary optimization algorithms assume a static evaluation function according solutions evolved. Incremental evolution an approach through a dynamic evaluation function scaled over in improve evolutionary optimization In this paper empirical results this approach
Paper 4  Title: Improving the Performance of Evolutionary Optimization by Dynamically Scaling the Evaluation Function  
Abstract Traditional evolutionary optimization algorithms assume a static evaluation function according solutions evolved. Incremental evolution an approach through a dynamic evaluation function scaled over in improve evolutionary optimization In this paper empirical results this approach
Label: Genetic Algorithms
Paper 5  Title: Hierarchical Evolution of Neural Networks  
Abstract most applications each individual in represents Recent work the SANE system however evolving individual neurons often produces a more efficient genetic search This paper demonstrates while SANE solve easy tasks very often stalls larger problems A hierarchical approach
Paper 6  Title: TD Learning of Game Evaluation Functions with Hierarchical Neural Architectures  
Abstract Genetic algorithms solve hard optimization problems ranging the Travelling Salesman problem the Quadratic Assignment problem We show the Simple Genetic Algorithm solve derived the 3-Conjunctive Normal Form problem By separating the populations into small sub parallel genetic algorithms exploits
Paper 7  Title: A Study of Genetic Algorithms to Find Approximate Solutions to Hard 3CNF Problems  
Abstract Genetic algorithms solve hard optimization problems ranging the Travelling Salesman problem the Quadratic Assignment problem We show the Simple Genetic Algorithm solve derived the 3-Conjunctive Normal Form problem By separating the populations into small sub parallel genetic algorithms exploits
Paper 8  Title: HOW TO EVOLVE AUTONOMOUS ROBOTS: DIFFERENT APPROACHES IN EVOLUTIONARY ROBOTICS  
Abstract most applications each individual in represents Recent work the SANE system however evolving individual neurons often produces a more efficient genetic search This paper demonstrates while SANE solve easy tasks very often stalls larger problems A hierarchical approach
Paper 9  Title: How good are genetic algorithms at finding large cliques: an experimental study  
Abstract the power genetic algorithms at solving the MAX-CLIQUE problem We measure a standard genetic algorithm an elementary set problem instances consisting embedded cliques random graphs We indicate the need improvement introduce the multi-phase annealed GA, exhibits
Paper 10  Title: Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor  
Abstract Genetic algorithms neural networks two main ways optimize train the weights a fixed architecture While most previous work focuses only of these two options investigates an alternative evolutionary approach called Breeder Genetic Programming the architecture and the weights optimized simult
Paper 11  Title: Fast Probabilistic Modeling for Combinatorial Optimization  
Abstract Probabilistic models utilized the optimization large combinatorial search problems However complex probabilistic models that attempt capture inter-parameter dependencies have The algorithm presented, termed COMIT provides using conjunction fast search techniques W
Label: Genetic Algorithms
Paper 12  Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Abstract Holland's analysis the sources power of genetic algorithms served guidance the applications The technique applying a recombination operatorcrossover a population individuals a key that power Neverless there contradictory results concerning crossover operators with respect overall p
Label: Genetic Algorithms
Paper 13  Title: Guided Crossover: A New Operator for Genetic Algorithm Based Optimization  
Abstract Genetic algorithms ( extensively different domains as doing global optimization a simple yet reliable manner They global optima gradient based methods which usually converge local sub optima However GAs of getting only moderately close the optima iterations To g
Paper 14  Title: Evolution, Learning, and Instinct: 100 Years of the Baldwin Effect Using Learning to Facilitate the
Abstract a hybrid methodology integrates genetic algorithms decision tree learning evolve useful subsets discriminatory features for recognizing complex visual concepts A genetic algorithm (GA search the space all possible subsets candidate discrimination features Candidate feature subsets evaluated using C4.5
Label: Genetic Algorithms
Paper 15  Title: Graph Coloring with Adaptive Evolutionary Algorithms  
Abstract solving graph coloringEA After testing different algorithm variants we conclude an asexual EA using order-based representation an adaptation mechanism periodically the fitness function during This adaptive EA is general, usi
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1981...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: There is strong evidence that face processing is localized in the brain. The double dissociation between prosopagnosia, a face recognition deficit occurring after brain damage, and visual object agnosia, difficulty recognizing other kinds of complex objects, indicates that face and non-face object recognition may be served by partially independent mechanisms in the brain. Is neural specialization innate or learned? We suggest that this specialization could be the result of a competitive learning mechanism that, during development, devotes neural resources to the tasks they are best at performing. Further, we suggest that the specialization arises as an interaction between task requirements and developmental constraints. In this paper, we present a feed-forward computational model of visual processing, in which two modules compete to classify input stimuli. When one module receives low spatial frequency information and the other receives high spatial frequency information, and the task is to identify the faces while simply classifying the objects, the low frequency network shows a strong specialization for faces. No other combination of tasks and inputs shows this strong specialization. We take these results as support for the idea that an innately-specified face processing module is unnecessary.
Title: Title: Task and Spatial Frequency Effects on Face Specialization  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning a Specialization for Face Recognition: The Effect of Spatial Frequency  
Abstract double dissociation a face recognition deficit occurring after brain damage visual object agnosia difficulty other kinds complex objects indicates face and non-face object recognition served partially independent mechanisms in Such a dissociation could a competitive learning mechanism, during
Label: Neural Networks
Paper 3  Title: Robust Parameter Learning in Bayesian Networks with Missing Data  
Abstract There face processing localized. The double dissociation a face recognition deficit occurring brain damage visual object agnosia difficulty recognizing other kinds complex objects indicates face and non-face object recognition served partially independent neural mechanisms In this chapter u
Label: Probabilistic Methods
Paper 4  Title: Prosopagnosia in Modular Neural Network Models  
Abstract There face processing localized. The double dissociation a face recognition deficit occurring brain damage visual object agnosia difficulty recognizing other kinds complex objects indicates face and non-face object recognition served partially independent neural mechanisms In this chapter u
Paper 5  Title: A Mixture of Experts Model Exhibiting Prosopagnosia  
Abstract A considerable body from a deficit face recognition dissociable nonface object recognition indicates devotes a specialized functional area mechanisms appropriate We present a modular neural network composed two expert networks one mediating gate network the task learning the fac
Paper 6  Title: Efficient Visual Search: A Connectionist Solution  
Abstract Searching objects scenes a natural task people and has extensively In this paper examine this task a connectionist perspective Computational complexity arguments suggest parallel feed-forward networks perform efficiently One difficulty, distinguish the target distractors combination o
Paper 7  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract A novel architecture and set learning rules The model based the idea multiple information channels modulate plasticity Features learned bottom-up information sources can thus influenced those learned contextual pathways vice A maximum likelihood cost function allows this scheme
Label: Neural Networks
Paper 8  Title: Topography And Ocular Dominance: A Model Exploring Positive Correlations  
Abstract The map from eye brain in topographic i.e. neighbouring points to In addition when two eyes innervate the same target structure the two sets fibres segregate ocular dominance stripes Experimental evidence the frog goldfish suggests these two phenomena subserved W
Paper 9  Title: Learning Algorithms with Applications to Robot Navigation and Protein Folding  
Abstract Using scene analysis as the task this research focuses three fundamental problems neural network systems representing schemas learning schemas The first problem arises because no practical neural network process simultaneously efficiently The solution process the input in paralle
Paper 10  Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  
Abstract The sensorimotor integration system can viewed an observer attempting estimate its own state integrating multiple sources We describe a computational framework capturing this notion some specific models integration adaptation result Psychophysical results two sensorimotor systems subserving the i
Paper 11  Title: Representing and Learning Visual Schemas in Neural Networks for Scene Analysis  
Abstract Using scene analysis as the task this research focuses three fundamental problems neural network systems representing schemas learning schemas The first problem arises because no practical neural network process simultaneously efficiently The solution process the input in paralle
Paper 12  Title: A Model of Visually Guided Plasticity of the Auditory Spatial Map in the Barn Owl  
Abstract In the barn owl the auditory map of space in the external nucleusICx strongly vision the nature this interaction In this paper a biologically plausible and mini-malistic model ICx self-organization where receives a learn signal based the owl's visual attention When the
Label: Neural Networks
Paper 13  Title: A Neural Network Model of Visual Tilt Aftereffects  
Abstract RF-LISSOM, laterally connected orientation maps in the psychological phenomenon known the tilt aftereffect The same self-organizing processes are the map its lateral connections shown result tilt aftereffects over in the adult. The
Paper 14  Title: Self-Organization and Functional Role of Lateral Connections and Multisize Receptive Fields in the Primary Visual Cortex  
Abstract Cells selective not ocular dominance and orientation the input its size spatial frequency The simulations reported how size selectivity could develop through Hebbian self-organization receptive fields different sizes organize columns like for orientation ocular dominance lateral
Paper 15  Title: Separating hippocampal maps  Spatial Functions of the Hippocampal Formation and the  
Abstract The place fields hippocampal cells old animals sometimes change when removed and then [ Barnes 1997 The ensemble correlation two sequential visits the same environment shows for old animalsnear 0 indicative remapping greater, a similar representation between exp
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 499...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Mean field methods provide computationally efficient approximations to posterior probability distributions for graphical models. Simple mean field methods make a completely factorized approximation to the posterior, which is unlikely to be accurate when the posterior is multimodal. Indeed, if the posterior is multi-modal, only one of the modes can be captured. To improve the mean field approximation in such cases, we employ mixture models as posterior approximations, where each mixture component is a factorized distribution. We describe efficient methods for optimizing the parameters in these models. 
Title: Title: IMPROVING THE MEAN FIELD APPROXIMATION VIA THE USE OF MIXTURE DISTRIBUTIONS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: A note on convergence rates of Gibbs sampling for nonparametric mixtures  
Abstract We consider a mixture model the mixing distribution random given prior We describe two Gibbs sampling algorithms this problem When the kernel f(x j of the mixture bounded show the Markov chains resulting Gibbs sampling uniformly ergodic w
Paper 3  Title: Factorial Hidden Markov Models  
Abstract One the basic probabilistic tools time series modeling the hidden Markov model In an HMM, information of the time series conveyed a single discrete variable|the hidden state We present HMMs which this state factored multiple state variables therefore represented a distributed manner Both inference
Paper 4  Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  
Abstract New methodology fully Bayesian mixture analysis developed making reversible jump Markov chain Monte Carlo methods that capable jumping between the parameter subspaces corresponding different numbers components A sample from the full joint distribution all unknown variables thereby generated this can a thorough
Paper 5  Title: Gaussian Processes for Bayesian Classification via Hybrid Monte Carlo  
Abstract The full Bayesian method applying neural networks a prediction problem to set the prior/hyperprior structure the net and perform the necessary integrals However these integrals tractable Markov Chain methods slow especially the parameter space high- Using Gaussian processes we approximate
Label: Neural Networks
Paper 6  Title: A variational approach to Bayesian logistic regression models and their extensions  
Abstract consider We show accurate variational techniques obtain a closed form posterior distribution given the data thereby yielding The results readily extended (binary) belief networks For belief networks we also derive closed form
Paper 7  Title: Monte Carlo Implementation of Gaussian Process Models for Bayesian Regression and Classification  
Abstract Technical Report No. 9702, Department Statistics Toronto Abstract. Gaussian processes a natural way defining prior distributions over functions In a simple nonparametric regression problem where such a function gives an observed response easily us
Paper 8  Title: Inference in Dynamic Error-in-Variable-Measurement Problems  
Abstract Efficient algorithms estimating model parameters from measured data even gross errors In addition point estimates parameters however assessments uncertainty needed Linear approximations provide standard errors these misleading models substantially nonlinear To overcome "pro
Paper 9  Title: Using Dirichlet Mixture Priors to Derive Hidden Markov Models for Protein Families  
Abstract the amino acid distributions the states a hidden Markov model a protein family or the columns a multiple alignment that family introduced This method Dirichlet mixture densities priors over amino acid distributions These mixture densities determined examination previously constructed HMMs or multiple alignmen
Label: Neural Networks
Paper 10  Title: A VIEW OF THE EM ALGORITHM THAT JUSTIFIES INCREMENTAL, SPARSE, AND OTHER VARIANTS  
Abstract The EM algorithm performs maximum likelihood estimation data which some variables We present a function resembles negative free energy and show the M step maximizes this function with the model parameters the E step over From this perspective justify an i
Paper 11  Title: Finding Overlapping Distributions with MML  
Abstract considers an aspect mixture modelling. Significantly overlapping distributions require their parameters accurately than well separated distributions For example two Gaussian distributions considered significantly overlap their means within If insufficient data only singl
Paper 12  Title: Using Mixtures of Factor Analyzers for Segmentation and Pose Estimation  Category: Visual Processing Preference: Oral  
Abstract To read a hand-written digit string it segment separate digits Bottom-up segmentation heuristics often neighboring digits substantially We describe has each digit class we the only knowledge required segmentation The system uses Gibbs sampling construct a percept
Label: Neural Networks
Paper 13  Title: Comparing Predictive Inference Methods for Discrete Domains  
Abstract Predictive inference seen here determining the predictive distribution given training examples the values the other problem domain variables We consider three approaches computing this predictive distribution assume the joint probability distribution the variables belongs distributions deter
Label: Probabilistic Methods
Paper 14  Title: Bayesian Mixture Modeling by Monte Carlo Simulation  
Abstract It shown from modeled a mixture distribution feasibly via This method exhibits the true Bayesian predictive distribution implicitly integrating over An infinite number mixture components without difficulty a prior distribution mixing propor
Paper 15  Title: Hyperparameter estimation in Dirichlet process mixture models  
Abstract Bayesian density estimation prediction standard, exponential family distributions the precision or total mass parameter a critical hyperparame-ter that strongly resulting inferences numbers mixture components This note shows, respect a flexible class prior distributions
Label: Probabilistic Methods
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Processing index 1183...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper describes the MAXQ method for hierarchical reinforcement learning based on a hierarchical decomposition of the value function and derives conditions under which the MAXQ decomposition can represent the optimal value function. We show that for certain execution models, the MAXQ decomposition will produce better policies than Feudal Q learning.
Title: Title: Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Approximating Value Trees in Structured Dynamic Programming  
Abstract and examine approximate dynamic programming Markov decision processes structured problem representations We assume an MDP represented using a dynamic Bayesian network construct value functions decision trees our function representation The size the representation kept pruning these value trees tha
Paper 3  Title: Constructive Neural Network Learning Algorithms for Multi-Category Real-Valued Pattern Classification  
Abstract Prioritized sweeping attempts focus achieve a good estimate environment states To choose effectively where a costly planning step classic prioritized sweeping uses a simple heuristic focus computation the states the largest errors
Paper 4  Title: Hierarchical Explanation-Based Reinforcement Learning  
Abstract Explanation-Based Reinforcement Learning (EBRL was introduced Dietterich Flann as combining the abilityRL optimal plans the generalization ability (Di-etterich 1995 We extend this work domains the agent must order achieve a sequence subgoals an optimal fashion Hi
Paper 5  Title: Bayesian Methods for Adaptive Models  
Abstract Almost all the work Average-reward Re- inforcement Learning so table-based methods which do scale domains large state spaces In this paper two extensions a model-based ARL method called H-learning address We extend H-learning learn action models reward functions Bayesian networks a
Paper 6  Title: Value Function Approximations and Job-Shop Scheduling  
Abstract We a successful application TD() value function approximation the task job-shop scheduling Our scheduling problems based scheduling payload processing steps The value function approximated a 2-layer feedforward network A one-step lookahead greedy algorithm using the learned evaluation
Paper 7  Title: Using Path Diagrams as a Structural Equation Modelling Tool  
Abstract the problem given of interacting it Many algorithms for work computing improved estimates the optimal value function We extend prior analyses reinforcement-learning algorithms present a powerful new theorem c
Label: Probabilistic Methods
Paper 8  Title: Learning to Achieve Goals  
Abstract Temporal difference methods solve the temporal credit assignment problem reinforcement learning An important subproblem general reinforcement learning learning achieve dynamic goals Although existing temporal difference methods, Q learning applied this problem take advantage its special structure This paper the DG-learning algor
Label: Reinforcement Learning
Paper 9  Title: An Upper Bound on the Loss from Approximate Optimal-Value Functions  
Abstract Many reinforcement can formulated from Markov decision processes the associated method dynamic programming The value this theoretical understanding, tempered many practical concerns One important question DP-based approaches that use function approximation rather lookup tables can avoid catastrophi
Label: Reinforcement Learning
Paper 10  Title: Selection of Distance Metrics and Feature Subsets for k-Nearest Neighbor Classifiers  
Abstract Prioritized sweeping attempts focus achieve a good estimate environment states To choose effectively where a costly planning step classic prioritized sweeping uses a simple heuristic focus computation the states the largest errors
Paper 11  Title: Reinforcement Learning with Modular Neural Networks for Control  
Abstract Reinforcement learning methods control problems the objective optimizing over They used train single neural networks that solutions whole tasks Jacobs Jordan [5 shown a set expert networks combined via a gating network more learn tasks decomposed Even the decompositio
Paper 12  Title: Scaling Up Average Reward Reinforcement Learning by Approximating the Domain Models and the Value Function  
Abstract Almost all the work Average-reward Re- inforcement Learning so table-based methods which do scale domains large state spaces In this paper two extensions a model-based ARL method called H-learning address We extend H-learning learn action models reward functions Bayesian networks a
Paper 13  Title: Reinforcement Learning with Hierarchies of Machines  
Abstract We reinforcement learning the policies considered the learning process constrained hierarchies partially specified machines This allows for prior knowledge reduce the search space provides a framework in transferred problems in component solutions recombined larger a
Paper 14  Title: Solving Combinatorial Optimization Tasks by Reinforcement Learning: A General Methodology Applied to Resource-Constrained Scheduling  
Abstract introduces a methodology solving through reinforcement learning methods The approach can cases several similar instances a combinatorial optimization problem must The key idea analyze a set "training problem instances learn a search control policy solving new problem
Paper 15  Title: Memory Based Stochastic Optimization for Validation and Tuning of Function Approximators  
Abstract focuses the optimization hyper function approximators We describe a kind racing algorithm continuous optimization problems spends evaluating poor parameter settings honing its estimates the most promising regions The algorithm able automatically optimize the parameters a function appr
Label: Reinforcement Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 186...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper describes a self-learning control system for a mobile robot. Based on local sensor data, a robot is taught to avoid collisions with obstacles. The only feedback to the control system is a binary-valued external reinforcement signal, which indicates whether or not a collision has occured. A reinforcement learning scheme is used to find a correct mapping from input (sensor) space to output (steering signal) space. An adaptive quantisation scheme is introduced, through which the discrete division of input space is built up from scratch by the system itself. 
Title: Title: Adaptive state space quantisation: adding and removing neurons  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: LEARNING TO AVOID COLLISIONS: A REINFORCEMENT LEARNING PARADIGM FOR MOBILE ROBOT NAVIGATION  
Abstract The paper a self-learning control system a mobile robot Based sensor information the control system provide a steering signal collisions Since in our case no `examples the system learns on an external reinforcement signal negative case a collision zero otherwise We describe the adapt
Paper 3  Title: Adaptive state space quantisation for reinforcement learning of collision-free navigation  
Abstract The paper a self-learning control system a mobile robot Based sensor information the control system provide a steering signal collisions Since in our case no `examples the system learns on an external reinforcement signal negative case a collision zero otherwise Rules from Temporal D
Paper 4  Title: Evolving Obstacle Avoidance Behavior in a Robot Arm  
Abstract Existing approaches learning a robot arm rely supervised methods where correct behavior explicitly given It learn avoid obstacles using such methods examples obstacle avoidance behavior generate This paper evolves neural network controllers through genetic algorithms No input
Paper 5  Title: Evolution of Homing Navigation in a Real Mobile Robot  
Abstract In to control a real mobile robot In all our experiments the evolutionary procedure carried entirely the physical robot without We show the autonomous development a set behaviors for locating a battery charger periodically returning lifti
Paper 6  Title: Automatic Generation of Adaptive Programs Automatic Generation of Adaptive Programs. In From Animals to Animats
Abstract Fuzzy rules control can effectively tuned Reinforcement learning only information the control application The tuning process allows people generate fuzzy rules unable accurately perform control have them tuned rules provide smooth control This paper
Paper 7  Title: Biological metaphors and the design of modular artificial neural networks Master's thesis of  
Abstract packet routing which embedded Only local information used at each node to accurate statistics which routing policies lead minimal routing times In simple experiments involving a 36-node irregularly-connected network this learning approach proves supe
Paper 8  Title: NEUROCONTROL BY REINFORCEMENT LEARNING  
Abstract: Reinforcement learningRL a model-free tuning adaptation method control dynamic systems Contrary supervised learning based usually gradient descent techniques RL does any model or sensitivity function of Hence RL can applied systems poorly uncertain nonlinear for untractable with
Paper 9  Title: USING MARKER-BASED GENETIC ENCODING OF NEURAL NETWORKS TO EVOLVE FINITE-STATE BEHAVIOUR  
Abstract: A new mechanism genetic encoding neural networks loosely the marker structure biological DNA The mechanism allows all aspects the network structure, the number their connectivity evolved through genetic algorithms The effectiveness the encoding scheme demonstrated an object recognition task that requires
Paper 10  Title: AVERAGED REWARD REINFORCEMENT LEARNING APPLIED TO FUZZY RULE TUNING  
Abstract Fuzzy rules control can effectively tuned Reinforcement learning only information the control application The tuning process allows people generate fuzzy rules unable accurately perform control have them tuned rules provide smooth control This paper
Paper 11  Title: Model Selection based on Minimum Description Length  
Abstract Recently that involves a form simulated evolution the building autonomous robots However still this approach may adequate face real life problems In this paper control systems perform a nontrivial sequence behaviors obtained this methodology by carefully designing the conditions whi
Paper 12  Title: LEARNING TO GENERATE ARTIFICIAL FOVEA TRAJECTORIES FOR TARGET DETECTION  
Abstract It shown how `static' neural approaches adaptive target detection replaced a more efficient and more sequential alternative latter inspired the observation biological systems employ sequential eye-movements A system described which builds an adaptive model controlled an adapti
Label: Reinforcement Learning
Paper 13  Title: Learning Concepts from Sensor Data of a Mobile Robot  
Abstract Machine learning the flexibility robot applications Many approaches applying robotics known Some approaches enhance the planning capabilities. Other approaches enhance the control basic actions. In contrast the approach presented thi
Paper 14  Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  
Abstract Deterministic Context-free (DCF) Grammars a Connectionist paradigm a Recurrent Neural Network Pushdown AutomatonNNPDA The NNPDA consists a recurrent neural network connected an external stack memory through a common error function We show the NNPDA able learn the dynamics an underlying pushdown automaton
Paper 15  Title: [12] J. Whittaker. Graphical Models in Applied Mathematical Multivariate Statis-  
Abstract Self-organizing feature maps usually the low-level neural and parallel distributed processes An external supervisor finds whose weight vector closest in Euclidian distance the neighborhood weight adaptation The weights changed proportional biologically more plausible im
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Reinforcement Learning
Prediction:  Reinforcement Learning
Is prediction correct?  True

Prediction: 1
Processing index 504...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: The use of artificial neural networks in the domain of autonomous vehicle navigation has produced promising results. ALVINN [Pomerleau, 1991] has shown that a neural system can drive a vehicle reliably and safely on many different types of roads, ranging from paved paths to interstate highways. Even with these impressive results, several areas within the neural paradigm for autonomous road following still need to be addressed. These include transparent navigation between roads of different type, simultaneous use of different sensors, and generalization to road types which the neural system has never seen. The system presented here addresses these issue with a modular neural architecture which uses pre-trained ALVINN networks and a connectionist superstructure to robustly drive on many dif ferent types of roads.
Title: Title: MANIAC: A Next Generation Neurally Based Autonomous Road Follower  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The BATmobile: Towards a Bayesian Automated Taxi  
Abstract The problem driving highway traffic engages many areas AI research substantial economic significance We describe work this problem based a decision-theoretic architecture using dynamic probabilistic networks The architecture provides a sound solution sensor noise sensor failure uncertain
Label: Probabilistic Methods
Paper 3  Title: VECTOR ASSOCIATIVE MAPS: UNSUPERVISED REAL-TIME ERROR-BASED LEARNING AND CONTROL OF MOVEMENT TRAJECTORIES  
Abstract: ALVINN (Autonomous Land Vehicle in a Neural Net a Backpropagation trained neural network which steering road and highway environments Although ALVINN fairly robust one has the time train As the vehicle is capable online learning has drive for the ne
Paper 4  Title: Automated Highway System  
Abstract: ALVINN (Autonomous Land Vehicle in a Neural Net a Backpropagation trained neural network which steering road and highway environments Although ALVINN fairly robust one has the time train As the vehicle is capable online learning has drive for the ne
Paper 5  Title: Evolving Obstacle Avoidance Behavior in a Robot Arm  
Abstract Existing approaches learning a robot arm rely supervised methods where correct behavior explicitly given It learn avoid obstacles using such methods examples obstacle avoidance behavior generate This paper evolves neural network controllers through genetic algorithms No input
Paper 6  Title: Using a Genetic Algorithm to Learn Strategies for Collision Avoidance and Local Navigation  
Abstract: Navigation through obstacles such mine fields an important capability autonomous underwater vehicles One way produce robust behavior perform projective planning However real-time performance a critical requirement navigation What needed a truly autonomous vehicle are robust reactive rules perform also
Paper 7  Title: A comparison of neural net and conventional techniques for lighting control  
Abstract We compare two techniques lighting control an actual room equipped seven banks photoresistors detect four sensing points Each bank lights can independently set The task the device intensity levels achieve sensor readings One technique we explor
Paper 8  Title: An Evolutionary Approach to Learning in Robots  
Abstract Evolutionary learning methods found several areas in intelligent robots In the approach described evolutionary algorithms explore alternative robot behaviors within a simulation model as reducing the overall knowledge engineering effort This paper some initial results applying the SAMUEL genetic learnin
Paper 9  Title: ADAPTIVE TESTING OF CONTROLLERS FOR AUTONOMOUS VEHICLES  
Abstract Autonomous vehicles likely require sophisticated software controllers maintain vehicle performance vehicle faults The test and complex software controllers expected a challenging task The goal this e ffort apply machine learning techniques from arti ficial intelligence the general problem evaluating an inte
Paper 10  Title: Appears in Working Notes, Integrating Multiple Learned Models for Improving and Scaling Machine Learning Algorithms
Abstract the Plannett system to achieve expert- level accuracy on the difficult scientific task recognizing volcanos radar images Plannett uses ANNs that vary along the set input features used train hidden units The ANNs combined simply averaging
Label: Neural Networks
Paper 11  Title: Grounding Robotic Control with Genetic Neural Networks  
Abstract Technical Report AI94-223 May 1994 Abstract An but often problem grounding systems their environment such the representations manipulate have inherent meaning for Since humans rely semantics the grounding is crucial truly intelligent be
Label: Genetic Algorithms
Paper 12  Title: Model Selection based on Minimum Description Length  
Abstract Recently that involves a form simulated evolution the building autonomous robots However still this approach may adequate face real life problems In this paper control systems perform a nontrivial sequence behaviors obtained this methodology by carefully designing the conditions whi
Paper 13  Title: Evolving nonTrivial Behaviors on Real Robots: an Autonomous Robot that Picks up Objects  
Abstract Recently that involves a form simulated evolution the building autonomous robots However still this approach may adequate face real life problems In this paper control systems perform a nontrivial sequence behaviors obtained this methodology by carefully designing the conditions whi
Paper 14  Title: A Multi-Chip Module Implementation of a Neural Network  
Abstract The requirement dense interconnect in artificial neural network systems led seek This paper an implementation using multi-chip modules the interconnect medium The specific system described self parallel dynamic learning model which requires a dense interconnect technology effective
Label: Neural Networks
Paper 15  Title: HOW TO EVOLVE AUTONOMOUS ROBOTS: DIFFERENT APPROACHES IN EVOLUTIONARY ROBOTICS  
Abstract most applications each individual in represents Recent work the SANE system however evolving individual neurons often produces a more efficient genetic search This paper demonstrates while SANE solve easy tasks very often stalls larger problems A hierarchical approach
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1903...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A new class of highspeed, self-adaptive, massively parallel computing models called ASOCS (Adaptive Self-Organizing Concurrent Systems) has been proposed. Current analysis suggests that there may be problems implementing ASOCS models in VLSI using the hierarchical network structures originally proposed. The problems are not inherent in the models, but rather in the technology used to implement them. This has led to the development of a new ASOCS model called DNA (Discriminant-Node ASOCS) that does not depend on a hierarchical node structure for success. Three areas of the DNA model are briefly discussed in this paper: DNA's flexible nodes, how DNA overcomes problems other models have allocating unused nodes, and how DNA operates during processing and learning. 
Title: Title: DNA: A New ASOCS Model With Improved Implementation Potential  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Word Perfect Corp. LIA: A Location-Independent Transformation for ASOCS Adaptive Algorithm 2  
Abstract Most Artificial Neural Networks during learning often suffer shortcomings as ANNs that use dynamic topologies have shown ability overcome many Adaptive Self Organizing Concurrent Systems learning models with inherently dynamic topologies This paper introduces Location-Independent Tr
Label: Neural Networks
Paper 3  Title: A VLSI Implementation of a Parallel, Self-Organizing Learning Model  
Abstract a VLSI implementation the Priority Adaptive Self-Organizing Concurrent System learning model built a multi-chip module (MCM) substrate Many current hardware implementations neural network learning models direct implementations structures|a large number simple computing nodes connected a dense number o
Label: Neural Networks
Paper 4  Title: Word Perfect Corp. A TRANSFORMATION FOR IMPLEMENTING EFFICIENT DYNAMIC BACKPROPAGATION NEURAL NETWORKS  
Abstract Most Artificial Neural Networks during learning often suffer shortcomings as Variations ANNs that use dynamic topologies have shown ability overcome many This paper introduces Location-Independent Transformations implementing distributed feedforward networks that dyn
Paper 5  Title: Word Perfect Corp. A TRANSFORMATION FOR IMPLEMENTING NEURAL NETWORKS WITH LOCALIST PROPERTIES  
Abstract Most Artificial Neural Networks during learning typically suffer shortcomings as Variations ANNs that use dynamic topologies have shown ability overcome many This paper introduces Location-Independent Transformations implementing feedforward networks that dynamic top
Paper 6  Title: Digital Neural Networks  
Abstract: Demands applications requiring massive parallelism symbolic environments given rebirth research models labeled neura l networks These models many simple nodes highly interconnected such that computation data amongst To present, most models proposed nodes based simple analog functions wh
Paper 7  Title: ASOCS: A Multilayered Connectionist Network with Guaranteed Learning of Arbitrary Mappings  
Abstract features a new class multilayer connectionist architectures known ASOCS ASOCS is similar most decision-making neural network models attempts learn an adaptive set arbitrary vector mappings However differs dramatically its mechanisms ASOCS is based networks adaptive digital elemen
Label: Neural Networks
Paper 8  Title: Connectionist Layered Object-Oriented Network Simulator (CLONES): User's Manual minimize the learning curve for using CLONES,
Abstract CLONES constructing, training utilizing layered connectionist networks The CLONES library all the object classes needed a simulator with a small amount added source code ( The size experimental ANN programs greatly an object-oriented library; at these programs easier
Paper 9  Title: LEARNING TO CONTROL FAST-WEIGHT MEMORIES: AN ALTERNATIVE TO DYNAMIC RECURRENT NETWORKS (Neural Computation, 4(1):131-139, 1992)  
Abstract Previous algorithms supervised sequence learning dynamic recurrent networks This paper an alternative class gradient-based systems consisting two feedforward nets learn deal temporal sequences using fast weights produce context dependent weight changes whose weights may very The metho
Paper 10  Title: Neural Network Applicability: Classifying the Problem Space  
Abstract The tremendous current effort propose neurally inspired methods computation forces closer scrutiny real world application potential This paper applications into classes particularly discusses features efficiently amenable neural network methods Computational machines deterministic mappings outpu
Paper 11  Title: A Self-Organizing Binary Decision Tree For Incrementally Defined Rule Based  
Abstract: an ASOCS (adaptive self-organizing concurrent system massively parallel processing incrementally defined rule systems such areas adaptive logic robotics logical inference dynamic control An ASOCS is an adaptive network composed many simple computing elements operating This paper focuses adaptive algorit
Paper 12  Title: LIBGA: A USER-FRIENDLY WORKBENCH FOR ORDER-BASED GENETIC ALGORITHM RESEARCH  
Abstract Over there several packages developed a workbench genetic algorithm (GA) research Most these packages the generational model inspired A have adopted used Genitor Unfortunately they some deficiencies when working order-based problems packing routing scheduling This paper descri
Paper 13  Title: Multiassociative Memory  
Abstract how implement connectionist models Traditional symbolic approaches wield explicit representation all alternatives via stored links or implicitly enumerative algorithms Classical pattern association models ignore the issue generating multiple outputs
Paper 14  Title: Spline Smoothing For Bivariate Data With Applications To Association Between Hormones  
Abstract Standard methods inducing both the structure weight values recurrent neural networks fit an assumed class architectures to every task This simplification necessary the interactions network structure function Evolutionary computation includes genetic algorithms evolutionary programming a population-based search
Paper 15  Title: An Evolutionary Algorithm that Constructs Recurrent Neural Networks  
Abstract Standard methods inducing both the structure weight values recurrent neural networks fit an assumed class architectures to every task This simplification necessary the interactions network structure function Evolutionary computation includes genetic algorithms evolutionary programming a population-based search
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 1...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: This paper describes preliminary work that aims to apply some learning strategies to a medical follow-up study. An investigation of the application of three machine learning algorithms-1R, FOIL and InductH to identify risk factors that govern the colposuspension cure rate has been made. The goal of this study is to induce a generalised description or explanation of the classification attribute, colposuspension cure rate (completely cured, improved, unchanged and worse) from the 767 examples in the questionnaires. We looked for a set of rules that described which risk factors result in differences of cure rate. The results were encouraging, and indicate that machine learning can play a useful role in large scale medical problem solving. 
Title: Title: Applications of machine learning: a medical follow up study  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Machine Learning Methods for International Conflict Databases: A Case Study in Predicting Mediation Outcome  
Abstract tries identify rules factors predictive international conflict management attempts We use C4.5, an advanced Machine Learning algorithm generating decision trees prediction rules cases the CONFMAN database The results show simple patterns rules often only understandable reliable comp
Paper 3  Title: Application of Neural Networks for the Classification of Diffuse Liver Disease by Quantitative Echography  
Abstract Three different methods investigated their ability classify various categories diffuse liver disease A statistical method a supervised neural network called and a nonsupervised, self-organizing feature map were examined The investigation performed a previously selected set acoustic a
Paper 4  Title: Induction of decision trees and Bayesian classification applied to diagnosis of sport injuries  
Abstract: Machine learning techniques extract knowledge stored medical databases In our application various machine learning algorithms extract diagnostic knowledge to support sport injuries The applied methods include variants the Assistant algorithm top-down induction decision trees variants T
Paper 5  Title: Rule Generation and Compaction in the wwtp  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 6  Title: Drug design by machine learning: Modelling drug activity  
Abstract modelling drug activity machine learning tools Some experiments modelling using a standard, Hansch, method and Golem were already The paper describes applying two other machine learning systems Magnus Assistant Ret
Paper 7  Title: Simple Genetic Programming for Supervised Learning Problems  
Abstract finding learning rules to several supervised tasks In this approach potential solutions represented variable length mathematical LISP S-expressions Thus similar Genetic ProgrammingGP but employs non-problem-specific functions In this paper three Monk's and parity proble
Paper 8  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 9  Title: Knowledge Discovery in International Conflict Databases  
Abstract Artificial Intelligence heavily supported military institutions while practically no effort goes the investigation possible contributions the avoidance termination crises wars This paper makes into this direction discovering knowledge international conflict conflict managem
Label: Case Based
Paper 10  Title: REPRESENTING PHYSICAL AND DESIGN KNOWLEDGE IN INNOVATIVE DESIGN  
Abstract An important part determining constituent groups or classes which best describes some data We apply the Minimum Message Length (MML) criterion modifying an earlier such MML application We give an empirical comparison criteri
Label: Case Based
Paper 11  Title: In:  A Mixture Model System for Medical and Machine Diagnosis  
Abstract Diagnosis human disease machine fault a missing data problem since many variables initially Additional information needs The joint probability distribution can solve We model with mixture models whose parameters estimated the EM algorithm This gives that missing data itself
Label: Probabilistic Methods
Paper 12  Title: CBR for Document Retrieval: The FAllQ Project  
Abstract reports about a project on document retrieval an industrial setting The objective helps finding documents a given query answers in Frequently Asked Questions databases A CBR approach has develop a running prototypical system which currently practical evaluation
Label: Case Based
Paper 13  Title: An Overview of Genetic Algorithms Part 1, Fundamentals  
Abstract Mathematical programming approaches will described: feature selection robust representation The feature selection problem considered discriminating while recognizing irrelevant and redundant features suppressing creates a lean model often generalizes better new unseen data
Paper 14  Title: Theory Revision in Fault Hierarchies  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Label: Theory
Paper 15  Title: Mathematical Programming in Data Mining  
Abstract Mathematical programming approaches will described: feature selection robust representation The feature selection problem considered discriminating while recognizing irrelevant and redundant features suppressing creates a lean model often generalizes better new unseen data
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 50...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Metacognition addresses the issues of knowledge about cognition and regulating cognition. We argue that the regulation process should be improved with growing experience. Therefore mental models are needed which facilitate the re-use of previous regulation processes. We will satisfy this requirement by describing a case-based approach to Introspection Planning which utilises previous experience obtained during reasoning at the meta-level and at the object level. The introspection plans used in this approach support various metacognitive tasks which are identified by the generation of self-questions. As an example of introspection planning, the metacognitive behaviour of our system, IULIAN, is described. 
Title: Title: Abstract  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Multi-Strategy Learning and Theory Revision  
Abstract the system WHY, learns updates a diagnostic knowledge base using domain knowledge a set examples The a-priori knowledge consists a causal model the domain stating basic phenomena a body describing the links abstract concepts their possible manifestations The phe
Paper 3  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 4  Title: Learning Concepts from Sensor Data of a Mobile Robot  
Abstract Machine learning the flexibility robot applications Many approaches applying robotics known Some approaches enhance the planning capabilities. Other approaches enhance the control basic actions. In contrast the approach presented thi
Paper 5  Title: Adaptive Tuning of Numerical Weather Prediction Models: Simultaneous Estimation of Weighting, Smoothing and Physical Parameters 1  
Abstract In case-based reasoning demonstrated problem complex domains Also mixed paradigm approaches emerged combining CBR and induction techniques aiming verifying the knowledge building an efficient case memory However in complex domains induction over the whole problem space often or too time
Paper 6  Title: Rule Generation and Compaction in the wwtp  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 7  Title: Computer-Supported Argumentation for Cooperative Design on the World-Wide Web  
Abstract an argumentation system cooperative design applications on The system provides experts involved such procedures means of expressing weighing their individual arguments preferences argue the selection a certain choice It supports defeasible and qualitative reasoning ill-structured information
Paper 8  Title: What online Machine Learning can do for Knowledge Acquisition A Case Study  
Abstract This reports a realistic knowledge-based application using the MOBAL system Some problems and requirements resulting industrial-caliber tasks formulated A step account a knowledge base such a task demonstrates how the interleaved use several learning algorithms concert an inference engine graphical
Paper 9  Title: Lazy Induction Triggered by CBR  
Abstract In case-based reasoning demonstrated problem complex domains Also mixed paradigm approaches emerged combining CBR and induction techniques aiming verifying the knowledge building an efficient case memory However in complex domains induction over the whole problem space often or too time
Paper 10  Title: Generic Teleological Mechanisms and their Use in Case Adaptation  
Abstract In experience-based (or case-based) reasoning new problems retrieving adapting the solutions similar problems encountered An important issue experience-based reasoning identify different types knowledge reasoning useful different classes case-adaptation tasks In this paper a class non-routine case-adaptation tasks
Paper 11  Title: ADAPtER: an Integrated Diagnostic System Combining Case-Based and Abductive Reasoning  
Abstract the ADAPtER system a diagnostic architecture combining case-based reasoning abductive reasoning exploiting the adaptation the solution old episodes focus the reasoning process Domain knowledge represented via a logical model basic mechanisms based abductive reasoning with consistency constraints have defi
Label: Case Based
Paper 12  Title: LEARNING FOR DECISION MAKING: The FRD Approach and a Comparative Study  Machine Learning and Inference Laboratory  
Abstract concerns what the best form learning, representing using knowledge for The proposed answer such knowledge learned represented When needed for decision making it should efficiently transferred a procedural form tailored Such an approach
Label: Rule Learning
Paper 13  Title: Inductive Learning and Case-Based Reasoning  
Abstract an inductive learning techniques case-based reasoning We introduce two main forms induction define case-based reasoning present The evaluation the proposed system called TA3 carried a classification task namely character recognition We show how inductive knowledge improves knowledge representation
Paper 14  Title: Using Knowledge of Cognitive Behavior to Learn from Failure  
Abstract When learning from reasoning failures knowledge how a system a powerful lever deciding went with in deciding A number benefits arise systems possess knowledge their own operation of Abstract knowledge cognition can select diagnosis and repair strategies from
Paper 15  Title: Analogical Problem Solving by Adaptation of Schemes  
Abstract We the acquisition problem schemes learning by doing to their application analogical problem Our work its background automatic program construction relies recursive program schemes In contrast cognitive modelling where designed fit specific data we
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Case Based
Prediction:  Case Based
Is prediction correct?  True

Prediction: 1
Processing index 2534...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: A quantitative model is provided for psychophysical data on the tracking of multiple visual elements (multielement tracking). The model employs an object-based attentional mechanism for constructing and updating object representations. The model selectively enhances neural activations to serially construct and update the internal representations of objects through correlation-based changes in synaptic weights. The correspondence problem between items in memory and elements in the visual input is resolved through a combination of top-down prediction signals and bottom-up grouping processes. Simulations of the model on image sequences used in multielement tracking experiments show that reported results are consistent with a serial tracking mechanism that is based on psychophysical and neurobiological findings. In addition, simulations show that observed effects of perceptual grouping on tracking accuracy may result from the interactions between attention-guided predictions of object location and motion and grouping processes involved in solving the motion correspondence problem. 
Title: Title: Data Value Prediction Methods and Performance  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Object-Based Neural Model of Serial Processing in Visual Multielement Tracking  
Abstract A quantitative model provided psychophysical data the tracking multiple visual elementsmultielement tracking The model employs constructing The model selectively enhances serially construct update objects through correlation-based chang
Paper 3  Title: Solving the Temporal Binding Problem: A Neural Theory for Constructing and Updating Object Files  
Abstract Visual objects perceived only their parts correctly integrated A neural network theory is proposed seeks binds visual properties dispersed space of multiple objects a problem known the temporal binding problem [49 30 The proposed theory upon neural mechanisms construct
Paper 4  Title: Computational Models of Sensorimotor Integration  Computational Maps and Motor Control.  
Abstract The sensorimotor integration system can viewed an observer attempting estimate its own state integrating multiple sources We describe a computational framework capturing this notion some specific models integration adaptation result Psychophysical results two sensorimotor systems subserving the i
Paper 5  Title: Cortical Mechanisms of Visual Recognition and Learning: A Hierarchical Kalman Filter Model  
Abstract dynamic recognition based the statistical theory Kalman filtering from optimal control theory The model utilizes a hierarchical network whose successive levels implement Kalman filters operating successively spatial Each hierarchical level predicts the cu
Paper 6  Title: A Theory of Visual Relative Motion Perception: Grouping, Binding, and Gestalt Organization  
Abstract The human visual system more the relative motion their absolute motion An understanding motion perception requires neural circuits can group moving visual elements relative based hierarchical reference frames We modeled visual relative motion perception a neural network architecture that group
Paper 7  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract A novel architecture and set learning rules The model based the idea multiple information channels modulate plasticity Features learned bottom-up information sources can thus influenced those learned contextual pathways vice A maximum likelihood cost function allows this scheme
Label: Neural Networks
Paper 8  Title: Priming, Perceptual Reversal, and Circular Reaction in a Neural Network Model of Schema-Based Vision  
Abstract VISOR scene analysis learns visual schemas examples Processing in VISOR based cooperation, competition parallel bottom-up and schema representations Similar principles appear underlie much human visual processing VISOR therefore model various perceptual phenomena
Label: Neural Networks
Paper 9  Title: A Model of Invariant Object Recognition in the Visual System  
Abstract: Neurons the ventral stream the primate visual system exhibit responses the images objects which invariant with natural transformations such translation size view Anatomical and neurophysiological evidence this is achieved hierarchical processing areas In elucidate the manner such representation
Paper 10  Title: A Neural Network Model of Visual Tilt Aftereffects  
Abstract RF-LISSOM, laterally connected orientation maps in the psychological phenomenon known the tilt aftereffect The same self-organizing processes are the map its lateral connections shown result tilt aftereffects over in the adult. The
Paper 11  Title: Strategy Learning with Multilayer Connectionist Representations 1  
Abstract Results the learning search strategies connectionist mechanisms Previous studies strategy learning within the symbolic, production-rule formalism Here a two-layer connectionist system presented that develops its search from weak to a task-specific strategy its performa
Paper 12  Title: Learning Viewpoint Invariant Face Representations from Visual Experience by Temporal Association  
Abstract natural visual experience different views face tend appear close temporal proximity A set simulations presented demonstrate how viewpoint invariant representations faces developed visual experience by capturing the input patterns The simulations explored temporal smoothing activi
Paper 13  Title: Models of perceptual learning in vernier hyperacuity  
Abstract Performance human subjects early visual processing tasks improves practice HyperBF networks (Poggio Girosi 1990 constitute understanding such improvement or perceptual learning the class tasks known visual hyperacuity The present article two issues raised the rece
Paper 14  Title: VISIT: An Efficient Computational Model of Human Visual Attention  
Abstract: One for models cognitive phenomena the development efficient and exible interfaces low level sensory information For visual processing researchers argued an attentional mechanism perform many high level vision This thesis presents VISIT, a connectionist model covert vi
Label: Neural Networks
Paper 15  Title: In  Unsmearing Visual Motion: Development of Long-Range Horizontal Intrinsic Connections  
Abstract Human vision systems integrate nonlocally across long spatial ranges For example a moving stimulus appears smeared when viewed briefly (30 yet sharp (Burr 1980 This suggests visual systems combine along a trajectory matches Our self-organizing neural network model
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 122...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Previous neural network learning algorithms for sequence processing are computationally expensive and perform poorly when it comes to long time lags. This paper first introduces a simple principle for reducing the descriptions of event sequences without loss of information. A consequence of this principle is that only unexpected inputs can be relevant. This insight leads to the construction of neural architectures that learn to `divide and conquer' by recursively decomposing sequences. I describe two architectures. The first functions as a self-organizing multi-level hierarchy of recurrent networks. The second, involving only two recurrent networks, tries to collapse a multi-level predictor hierarchy into a single recurrent net. Experiments show that the system can require less computation per time step and many fewer training sequences than conventional training algorithms for recurrent nets.
Title: Title: Tilt Aftereffects in a Self-Organizing Model of the Primary Visual Cortex  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: LEARNING COMPLEX, EXTENDED SEQUENCES USING THE PRINCIPLE OF HISTORY COMPRESSION (Neural Computation, 4(2):234-242, 1992)  
Abstract Previous neural network learning algorithms for sequence processing perform it long time lags This paper first introduces a simple principle reducing the descriptions event sequences without loss A consequence this principle only unexpected inputs relevant This insight leads the construct
Paper 3  Title: Object Selection Based on Oscillatory Correlation  
Abstract: 1 Technical Report: OSU-CISRC-12/96 - TR67, 1996 Abstract One the classical topics neural networks winner ( widely unsupervised (competitive) learning, cortical processing Because global connectivity WTA networks, however do encode spatial relations the input, support sensory and perceptua
Label: Neural Networks
Paper 4  Title: LEARNING TO CONTROL FAST-WEIGHT MEMORIES: AN ALTERNATIVE TO DYNAMIC RECURRENT NETWORKS (Neural Computation, 4(1):131-139, 1992)  
Abstract Previous algorithms supervised sequence learning dynamic recurrent networks This paper an alternative class gradient-based systems consisting two feedforward nets learn deal temporal sequences using fast weights produce context dependent weight changes whose weights may very The metho
Paper 5  Title: Implicit learning in 3D object recognition: The importance of temporal context  
Abstract A novel architecture and set learning rules The model based the idea multiple information channels modulate plasticity Features learned bottom-up information sources can thus influenced those learned contextual pathways vice A maximum likelihood cost function allows this scheme
Label: Neural Networks
Paper 6  Title: Using Many-Particle Decomposition to get a Parallel Self-Organising Map  
Abstract We propose decreasing self-organising maps The method uses of the neurons Teaching of the neurons occurs on a cluster-basis instead For teaching an N-neuron network with N 0 samples decreases N 0 log Furthermore introduce a me
Paper 7  Title: Distributed Patterns as Hierarchical Structures  
Abstract Recursive Auto-Associative Memory (RAAM) structures show promise a general representation vehicle that uses distributed patterns. However training which explains, only relatively small networks We show a technique transforming any collection hierarchical structures training patterns a sequential RAAM
Label: Neural Networks
Paper 8  Title: Generative Models for Discovering Sparse Distributed Representations  
Abstract We describe a hierarchical, generative model can viewed factor analysis can The model uses bottom-up perform Bayesian perceptual inference correctly Once perceptual inference the connection strengths can updated a very simple learning rule th
Paper 9  Title: Constructive Learning of Recurrent Neural Networks: Limitations of Recurrent Casade Correlation and a Simple Solution  
Abstract It often predict the optimal neural network size a particular application Constructive or destructive methods that add neurons layers connections might offer We prove one method, Recurrent Cascade Correlation due its topology has fundamental limitations representation thus its learning capabilities
Label: Neural Networks
Paper 10  Title: Pruning Recurrent Neural Networks for Improved Generalization Performance  
Abstract Determining the architecture any learning task For recurrent neural networks no general methods permit the estimation layers hidden neurons the size layers weights We present a simple pruning heuristic which significantly the generalization performance trained recurrent network
Paper 11  Title: Learning Context-free Grammars: Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory  
Abstract Deterministic Context-free (DCF) Grammars a Connectionist paradigm a Recurrent Neural Network Pushdown AutomatonNNPDA The NNPDA consists a recurrent neural network connected an external stack memory through a common error function We show the NNPDA able learn the dynamics an underlying pushdown automaton
Paper 12  Title: Learning Sequential Tasks by Incrementally Adding Higher Orders  
Abstract combines found sequential tasks incremental introduction The network adds higher orders when needed adding dynamically modify connection weights Since the new units modify at with information the pr
Paper 13  Title: Sequence Learning with Incremental Higher-Order Neural Networks  
Abstract combines two properties found useful sequence the incremental introduction The incremental, higher-order neural-network adds higher orders when needed adding dynamically connection weights The new units modify the weights a
Paper 14  Title: Strategy Learning with Multilayer Connectionist Representations 1  
Abstract Results the learning search strategies connectionist mechanisms Previous studies strategy learning within the symbolic, production-rule formalism Here a two-layer connectionist system presented that develops its search from weak to a task-specific strategy its performa
Paper 15  Title: ASOCS: A Multilayered Connectionist Network with Guaranteed Learning of Arbitrary Mappings  
Abstract features a new class multilayer connectionist architectures known ASOCS ASOCS is similar most decision-making neural network models attempts learn an adaptive set arbitrary vector mappings However differs dramatically its mechanisms ASOCS is based networks adaptive digital elemen
Label: Neural Networks
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 2335...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We review the use of global and local methods for estimating a function mapping R m ) R n from samples of the function containing noise. The relationship between the methods is examined and an empirical comparison is performed using the multi-layer perceptron (MLP) global neural network model, the single nearest-neighbour model, a linear local approximation (LA) model, and the following commonly used datasets: the Mackey-Glass chaotic time series, the Sunspot time series, British English Vowel data, TIMIT speech phonemes, building energy prediction data, and the sonar dataset. We find that the simple local approximation models often outperform the MLP. No criterion such as classification/prediction, size of the training set, dimensionality of the training set, etc. can be used to distinguish whether the MLP or the local approximation method will be superior. However, we find that if we consider histograms of the k-NN density estimates for the training datasets then we can choose the best performing method a priori by selecting local approximation when the spread of the density histogram is large and choosing the MLP otherwise. This result correlates with the hypothesis that the global MLP model is less appropriate when the characteristics of the function to be approximated varies throughout the input space. We discuss the results, the smoothness assumption often made in function approximation, and the bias/variance dilemma. 
Title: Title: Function Approximation with Neural Networks and Local Methods: Bias, Variance and Smoothness  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Comparing Predictive Inference Methods for Discrete Domains  
Abstract Predictive inference seen here determining the predictive distribution given training examples the values the other problem domain variables We consider three approaches computing this predictive distribution assume the joint probability distribution the variables belongs distributions deter
Label: Probabilistic Methods
Paper 3  Title: A Bootstrap Evaluation of the Effect of Data Splitting on Financial Time Series  
Abstract exposes problems the commonly used technique splitting training, that held fixed warns drawing such static splits shows ignoring variability across splits Using or resampling compare the uncertainty the solution stemming th
Paper 4  Title: Packet Routing and Reinforcement Learning: Estimating Shortest Paths in Dynamic Graphs  
Abstract exposes problems the commonly used technique splitting training, that held fixed warns drawing such static splits shows ignoring variability across splits Using or resampling compare the uncertainty the solution stemming th
Paper 5  Title: Comparison of Kernel Estimators, Perceptrons, and Radial-Basis Functions for OCR and Speech Classification  
Abstract compare kernel estimators single radial-basis functions the problems handwritten digits By taking two different applications employing many techniques report here whereby a domain-independent assessment these learning methods possible We consider a feed-forward n
Paper 6  Title: What Size Neural Network Gives Optimal Generalization? Convergence Properties of Backpropagation  
Abstract: Technical Report UMIACS-TR-96-22 and CS-TR-3617 Institute Advanced Computer Studies University Maryland 20742 Abstract One any machine learning paradigm scales according problem size Using a task with known optimal training error and prespecified maximum number training updates investigate th
Paper 7  Title: Cross-Validation and the Bootstrap: Estimating the Error Rate of a Prediction Rule  
Abstract: A training set data has construct a rule predicting future responses. What the error rate this rule The traditional answer given cross The cross-validation estimate prediction error nearly unbiased can highly variable This article discusses bootstrap estimates prediction error thought smoo
Paper 8  Title: First experiments using a mixture of nonlinear experts for time series prediction  
Abstract the advantages the mixture experts (ME) model (introduced to the connectionist community [JJNH91 applied time series analysisWM95 on where the dynamics is well The first series consisting a mixture between a noise-free processthe quadratic map a noisy pr
Paper 9  Title: A Comparative Study of ID3 and Backpropagation for English Text-to-Speech Mapping  
Abstract The performance the error backpropagation (BP and ID3 learning algorithms compared on the task mapping English text stresses Under the distributed output code developed Sejnowski Rosenberg shown BP consistently out ID3 on this task Three hypotheses explaining) ID3 ov
Paper 10  Title: Avoiding overfitting by locally matching the noise level of the data gating network discovers the
Abstract When trying forecast two of nonstationarity of the process, regime switching overfittingparticularly serious for noisy processes This articles shows gated experts point solutions The architecture, also society of experts mixture experts consists
Paper 11  Title: Robust Interpretation of Neural-Network Models  
Abstract Artificial Neural Network seem very regression classification large covariate spaces These methods represent as a composition low dimensional ridge functions therefore appear less the covariate space However due non uniqueness a global minimum and (possibly m
Paper 12  Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  
Abstract: Most connectionist modeling assumes noise-free inputs This assumption often violated. This paper introduces clearning, of simultaneously cleaning the data learning The cleaning step can viewed top-down processing (where the model modifies the learning step
Paper 13  Title: On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning  
Abstract: Most connectionist modeling assumes noise-free inputs This assumption often violated. This paper introduces clearning, of simultaneously cleaning the data learning The cleaning step can viewed top-down processing (where the model modifies the learning step
Paper 14  Title: Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation  
Abstract Selecting a good model a set input points by cross validation possible models or training points high Techniques such gradient descent helpful searching the space models problems local minima and more importantly, lack a distance metric between various models
Label: Theory
Paper 15  Title: The Free Speech  Phoneme Probability Estimation with Dynamic Sparsely Connected Artificial Neural Networks  
Abstract new methods training phoneme probability estimation An architecture combining timedelay windows recurrent connections capture the important dynamic information the speech signal Because the number connections a fully connected recurrent network grows superlinear hidden units schemes spars
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 540...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We analyze the blame-assignment task in the context of experience-based design and redesign of physical devices. We identify three types of blame-assignment tasks that differ in the types of information they take as input: the design does not achieve a desired behavior of the device, the design results in an undesirable behavior, a specific structural element in the design misbehaves. We then describe a model-based approach for solving the blame-assignment task. This approach uses structure-behavior-function models that capture a designer's comprehension of the way a device works in terms of causal explanations of how its structure results in its behaviors. We also address the issue of indexing the models in memory. We discuss how the three types of blame-assignment tasks require different types of indices for accessing the models. Finally we describe the KRITIK2 system that implements and evaluates this model-based approach to blame assignment.
Title: Title: A Model-Based Approach to Blame-Assignment in Design  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning Problem-Solving Concepts by Reflecting on Problem Solving  
Abstract Learning problem intimately: problem determines the knowledge requirements the reasoner which learning must fulfill enables improved Different models problem recognize different knowledge needs, set different learning tasks Some recent models analyze problem solving
Paper 3  Title: Functional Representation as Design Rationale  
Abstract Design rationale is a record design activity: of alternatives available choices the reasons explanations how a proposed design intended We describe a representation called the Functional Representation has how a device's functions arise causally the functions We prop
Paper 4  Title: Use of Mental Models for Constraining Index Learning in Experience-Based Design  
Abstract The power comes retrieve when specified This implies learning the "right" indices a case before storing for potential reuse crucial A hierarchical organization the case memory raises index learning learning the indexing vocabu
Label: Case Based
Paper 5  Title: Generic Teleological Mechanisms and their Use in Case Adaptation  
Abstract In experience-based (or case-based) reasoning new problems retrieving adapting the solutions similar problems encountered An important issue experience-based reasoning identify different types knowledge reasoning useful different classes case-adaptation tasks In this paper a class non-routine case-adaptation tasks
Paper 6  Title: GIT-CC-92/60 A Model-Based Approach to Analogical Reasoning and Learning in Design  
Abstract case-basedsystems retrieving the appropriate cases memory solve This implies a case indexed appropriately stored A case-based system, being dynamic stores cases reuse needs learn indices the new knowledge as the system designers envision that knowledge Irrespective in
Paper 7  Title: CABINS A Framework of Knowledge Acquisition and Iterative Revision for Schedule Improvement and Reactive Repair  
Abstract Mixed-initiative systems present the challenge finding an effective level interaction humans computers Machine learning presents in systems automatically adapt accommodate different users In learning user models an adaptive assistant crisis sched
Paper 8  Title: Learning to Predict User Operations for Adaptive Scheduling  
Abstract Mixed-initiative systems present the challenge finding an effective level interaction humans computers Machine learning presents in systems automatically adapt accommodate different users In learning user models an adaptive assistant crisis sched
Paper 9  Title: Problem Solving for Redesign  
Abstract A knowledge-level analysis complex tasks like diagnosis design can give these tasks the goals the different ways to In this paper a knowledge-level analysis redesign. Redesign is viewed a family methods based some common principles a number dimensions along re
Paper 10  Title: EXPLANATORY INTERFACE IN INTERACTIVE DESIGN ENVIRONMENTS  
Abstract Explanation building computer-based interactive design environments in a knowledge system may cooperatively solve We consider the two related problems explaining the system's reasoning generated In particular analyze explanations design reasoning design solutio
Paper 11  Title: Search-based Class Discretization  
Abstract We a methodology enables classification algorithms on regression tasks We implement system RECLA that transforms a regression problem classification one and an existent classification system solve The transformation consists mapping a continuous variable grouping
Paper 12  Title: Modeling Building-Block Interdependency  Dynamical and Evolutionary Machine Organization Group  
Abstract The Building-Block Hypothesis appeals problem decomposition the assembly from sub Accordingly there many varieties GA test problems a structure based building-blocks Many use deceptive fitness functions model interdependency the bits within However very have any model interde
Paper 13  Title: Theory Revision in Fault Hierarchies  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Label: Theory
Paper 14  Title: Model-Based Learning of Structural Indices to Design Cases  
Abstract case-basedsystems retrieving the appropriate cases memory solve This implies a case indexed appropriately stored A case-based system, being dynamic stores cases reuse needs learn indices the new knowledge as the system designers envision that knowledge Irrespective in
Label: Case Based
Paper 15  Title: Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email  
Abstract by a dialogue agent learn choose an optimal dialogue strategy While it widely agreed dialogue strategies should formulated terms communicative intentions little work automatically optimizing an agent's choices when there multiple ways realize Our method a co
Label: Reinforcement Learning
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Case Based

Paper 1: Case Based
Prediction:  Paper 1: Case Based
Is prediction correct?  False

Prediction: 0
Processing index 537...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: DIMACS Technical Report 96-56 December 1996 
Title: Title: Adaptive Global Optimization with Local Search  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Learning and evolution in neural networks  
Abstract 9656 December
Paper 3  Title: Design of Optimization Criteria for Multiple Sequence Alignment  
Abstract DIMACS Technical Report 96
Paper 4  Title: Constructive Training Methods for Feedforward Neural Networks with Binary Weights  
Abstract DIMACS Technical Report 95 August
Label: Neural Networks
Paper 5  Title: DNA Sequence Classification Using Compression-Based Induction  
Abstract DIMACS Technical Report 95 April
Paper 6  Title: Dimension of Recurrent Neural Networks  
Abstract 9656 December
Label: Neural Networks
Paper 7  Title: of nucleotide sites needed to accurately reconstruct large evolutionary trees 1  
Abstract DIMACS Technical Report 96 July
Paper 8  Title: Average-Case Analysis of a Nearest Neighbor Algorithm  
Abstract Eugenic Evolution Combinatorial Optimization John William Prior Report AI98268
Paper 9  Title: Recursive Automatic Algorithm Selection for Inductive Learning  
Abstract COINS Technical Report 94 August
Paper 10  Title: Extended Selection Mechanisms in Genetic Algorithms  
Abstract A Genetic Algorithm Tutorial Darrell Whitley Technical Report CS-93103 1993
Paper 11  Title: A Tutorial on Learning With Bayesian Networks  
Abstract Technical Report MSRTR-95
Label: Probabilistic Methods
Paper 12  Title: A BENCHMARK FOR CLASSIFIER LEARNING  
Abstract: Technical Report November
Label: Rule Learning
Paper 13  Title: Complexity Compression and Evolution  
Abstract CBR Assisted Explanation GA Results Computer Science Technical Report 63
Label: Genetic Algorithms
Paper 14  Title: Experiments with the Cascade-Correlation Algorithm  
Abstract: Technical Report # 9116 July
Paper 15  Title: The Role of Development in Genetic Algorithms  
Abstract A Genetic Algorithm Tutorial Darrell Whitley Technical Report CS-93103 1993
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 2265...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Air Traffic Control is involved in the real-time planning of aircraft trajectories. This is a heavily constrained optimization problem. We concentrate on free-route planning, in which aircraft are not required to fly over way points. The choice of a proper representation for this real-world problem is non-trivial. We propose a two level representation: one level on which the evolutionary operators work, and a derived level on which we do calculations. Furthermore we show that a specific choice of the fitness function is important for finding good solutions to large problem instances. We use a hybrid approach in the sense that we use knowledge about air traffic control by using a number of heuristics. We have built a prototype of a planning tool, and this resulted in a flexible tool for generating a free-route planning of low cost, for a number of aircraft. 
Title: Title: AN APPROACH TO A PROBLEM IN NETWORK DESIGN USING GENETIC ALGORITHMS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Evolutionary Computation in Air Traffic Control Planning  
Abstract Air Traffic Control involved the real-time planning aircraft trajectories This a heavily constrained optimization problem We concentrate free-route planning in aircraft not way points The choice a proper representation this real-world problem non We propose a two level representation: one level on evolutionary
Paper 3  Title: Evolution of Pseudo-colouring Algorithms for Image Enhancement with Interactive Genetic Programming  
Abstract: Technical Report CSRP-97-5 School The University Birmingham Abstract In the interactive development programs image enhancement Genetic Programming pseudo-colour transformations In our approach the user drives GP by deciding should the winner tournament selection The presence
Label: Genetic Algorithms
Paper 4  Title: Genetic Algorithm based Scheduling in a Dynamic Manufacturing Environment  
Abstract The application adaptive optimization strategies scheduling in manufacturing systems recently Population based approaches scheduling predominantly treat static data models whereas tends a dynamic problem This paper briefly the dynamic job shop a
Paper 5  Title: Adaptation of Genetic Algorithms for Engineering Design Optimization  
Abstract Genetic algorithms extensively different domains as doing global optimization However some realistic engineering design optimization domains was observed a simple classical implementation the GA based binary encoding bit mutation and crossover sometimes inefficient unable reach
Paper 6  Title: The Application of a Parallel Genetic Algorithm to the n=m=P=C max Flowshop Problem  
Abstract Hard combinatorial problems sequencing scheduling led recently into Canonical coding the symmetric TSP can modified into the n-job m-machine flowshop problem configurates We show well known genetic operators act this coding scheme They implecitely prefer
Label: Genetic Algorithms
Paper 7  Title: PRONOUNCING NAMES BY A COMBINATION OF RULE-BASED AND CASE-BASED REASONING  
Abstract We describe tuning a controller enforcing compliance a prescribed velocity profile This requires following a trajectory rather fixed set-points automobiles We synthesize a fuzzy controller tracking the velocity profile while staying We use
Paper 8  Title: Genetic Algorithms for Automated Tuning of Fuzzy Controllers: A Transportation Application  
Abstract We describe tuning a controller enforcing compliance a prescribed velocity profile This requires following a trajectory rather fixed set-points automobiles We synthesize a fuzzy controller tracking the velocity profile while staying We use
Paper 9  Title: Feature Selection by Means of a Feature Weighting Approach  
Abstract Selecting a set features which optimal We address using the flexible and robust filter technique EUBAFES EUBAFES based a feature weighting approach binary feature weights therefore a solution in the feature selection sense and gives detailed information abo
Paper 10  Title: An Analysis of the MAX Problem in Genetic Programming hold only in some cases, in
Abstract We genetic programmingGP populations the problem finding a program returns and function set a depth limitknown the MAX problem We confirm the basic message [ Gathercole and Ross 1996 crossover together program size restrictions c
Label: Genetic Algorithms
Paper 11  Title: Robust Sound Localization: An Application of an Auditory Perception System for a Humanoid Robot  
Abstract The paper a learning controller increasing insertion speed during consecutive peginto without the contact force level Our aim find measured forces the controlled velocity, without a complicated (human generated) model We followed a connectionist approach Two learning phases disti
Paper 12  Title: "What is the best thing to do right now?": getting beyond greedy exploration  
Abstract: Genetic programming a methodology program development consisting a special form genetic algorithm capable handling parse trees representing programs that has successfully In this paper a new approach the construction genetic programming A linear chromosome combined a graph represen
Paper 13  Title: An Evolutionary Approach to Time Constrained Routing Problems  
Abstract Routing problems an important class planning problems Usually there many different constraints optimization criteria involved general methods solving routing problems We propose an evolutionary solver such planning problems An instance this solver has tested a specific routing problem time constraints The performance
Label: Genetic Algorithms
Paper 14  Title: Evolutionary Training of CLP-Constrained Neural Networks  
Abstract The paper concerned the integration constraint logic programming systemsCLP systems based genetic algorithmsGA The resulting framework tailored applications a first phase in which a number constraints need generated an optimal solution satisfying produced The first phase is carried b
Label: Genetic Algorithms
Paper 15  Title: Knowledge-Based Genetic Learning  
Abstract Genetic algorithms proven within the area However there some classes problems where they seem scarcely applicable the solution consists several parts influence In that case the classic genetic operators cross mutation do work very thus preventing a good p
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2205...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Augmenting genetic algorithms with local search heuristics is a promising approach to the solution of combinatorial optimization problems. In this paper, a genetic local search approach to the quadratic assignment problem (QAP) is presented. New genetic operators for realizing the approach are described, and its performance is tested on various QAP instances containing between 30 and 256 facilities/locations. The results indicate that the proposed algorithm is able to arrive at high quality solutions in a relatively short time limit: for the largest publicly known prob lem instance, a new best solution could be found.
Title: Title: A Genetic Local Search Approach to the Quadratic Assignment Problem  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: An Evolutionary Approach to Combinatorial Optimization Problems  
Abstract The paper reports genetic algorithms, based the model organic evolution NP-complete combinatorial optimization problems In particular the subset sum, maximum cut minimum tardy task problems considered Except the fitness function no problem-specific changes of the genetic algorithm ac
Paper 3  Title: A Genetic Algorithm for Continuous Design Space Search  
Abstract Genetic algorithms ( extensively performing global optimization a simple yet reliable manner However some realistic engineering design optimization domains the simple, classical implementation a GA based binary encoding bit mutation and crossover often inefficient unable reach the global optimum In a GA
Label: Genetic Algorithms
Paper 4  Title: A GENETIC ALGORITHM FOR FRAGMENT ALLOCATION IN A DISTRIBUTED DATABASE SYSTEM  
Abstract In explore the distributed database allocation problem intractable. We also discuss genetic algorithms have successfully Our experimental results the GA to far the greedy heuristic obtaining optimal and near optimal fragment placements the allocation problem with various data sets
Label: Genetic Algorithms
Paper 5  Title: An evolutionary tabu search algorithm and the NHL scheduling problem  
Abstract We in a new evolutionary procedure solving combines efficiently the mechanisms genetic algorithms tabu search In explore the solution space properly interaction phases periods optimization An adaptation this search principle to National Hockey problem
Paper 6  Title: Adaptation of Genetic Algorithms for Engineering Design Optimization  
Abstract Genetic algorithms extensively different domains as doing global optimization However some realistic engineering design optimization domains was observed a simple classical implementation the GA based binary encoding bit mutation and crossover sometimes inefficient unable reach
Paper 7  Title: An Evolutionary Approach to Time Constrained Routing Problems  
Abstract Routing problems an important class planning problems Usually there many different constraints optimization criteria involved general methods solving routing problems We propose an evolutionary solver such planning problems An instance this solver has tested a specific routing problem time constraints The performance
Label: Genetic Algorithms
Paper 8  Title: Graph Coloring with Adaptive Evolutionary Algorithms  
Abstract solving graph coloringEA After testing different algorithm variants we conclude an asexual EA using order-based representation an adaptation mechanism periodically the fitness function during This adaptive EA is general, usi
Paper 9  Title: A Genetic Algorithm for File and Task Placement in a Distributed System  
Abstract explore the distributed file and task placement problem. We also discuss genetic algorithms have successfully Our experimental results the GA to far the greedy heuristic obtaining optimal and near optimal file and task placements the problem with various data sets
Paper 10  Title: GENE REGULATION AND BIOLOGICAL DEVELOPMENT IN NEURAL NETWORKS: AN EXPLORATORY MODEL  
Abstract In explore the distributed database allocation problem intractable. We also discuss genetic algorithms have successfully Our experimental results the GA to far the greedy heuristic obtaining optimal and near optimal fragment placements the allocation problem with various data sets
Paper 11  Title: Optimal Mutation Rates in Genetic Search  
Abstract The optimization a single bit string means iterated mutation and selection the best (a (1+1)-Genetic Algorithm discussed with three simple fitness functions The counting ones problem a standard binary encoded integer a Gray coded integer optimization problem A mutation rate schedule that optimal with the success probability mutation
Paper 12  Title: Genetic Algorithm based Scheduling in a Dynamic Manufacturing Environment  
Abstract The application adaptive optimization strategies scheduling in manufacturing systems recently Population based approaches scheduling predominantly treat static data models whereas tends a dynamic problem This paper briefly the dynamic job shop a
Paper 13  Title: A Study of Genetic Algorithms to Find Approximate Solutions to Hard 3CNF Problems  
Abstract Genetic algorithms solve hard optimization problems ranging the Travelling Salesman problem the Quadratic Assignment problem We show the Simple Genetic Algorithm solve derived the 3-Conjunctive Normal Form problem By separating the populations into small sub parallel genetic algorithms exploits
Paper 14  Title: An Evolutionary Approach to Vector Quantizer Design  
Abstract Vector quantization a lossy coding technique encoding a set from such image speech The design vector quantizers that yields the lowest distortion one source coding However this problem known difficult [ The conventional solution technique works through iterative r
Paper 15  Title: Solving Combinatorial Optimization Tasks by Reinforcement Learning: A General Methodology Applied to Resource-Constrained Scheduling  
Abstract introduces a methodology solving through reinforcement learning methods The approach can cases several similar instances a combinatorial optimization problem must The key idea analyze a set "training problem instances learn a search control policy solving new problem
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 2143...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Posner and Raichle's Images of Mind is an excellent educational book and very well written. Some aws as a scientific publication are: (a) the accuracy of the linear subtraction method used in PET is subject to scrutiny by further research at finer spatial-temporal resolutions; (b) lack of accuracy of the experimental paradigm used for EEG complementary studies. Images (Posner & Raichle, 1994) is an excellent introduction to interdisciplinary research in cognitive and imaging science. Well written and illustrated, it presents concepts in a manner well suited both to the layman/undergraduate and to the technical nonexpert/graduate student and postdoctoral researcher. Many, not all, people involved in interdisciplinary neuroscience research agree with the P & R's statements on page 33, on the importance of recognizing emergent properties of brain function from assemblies of neurons. It is clear from the sparse references that this book was not intended as a standalone review of a broad field. There are some aws in the scientific development, but this must be expected in such a pioneering venture. P & R hav e proposed many cognitive mechanisms deserving further study with imaging tools yet to be developed which can yield better spatial-temporal resolutions. 
Title: Title: MULTIPLE SCALES OF BRAIN-MIND INTERACTIONS  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Book Review  Introduction to the Theory of Neural Computation Reviewed by: 2  
Abstract Neural computation, also connectionism parallel distributed processing neural network modeling or brain-style computation grown Despite this explosion and ultimately impressive applications a dire need a concise introduction from a theoretical perspective analyzing the strengths connectionist app
Paper 3  Title: Application of statistical mechanics methodol- ogy to term-structure bond-pricing models, Mathl. Comput. Modelling Application of
Abstract The work in progress reported Wright & Liley shows great promise primarily However their tentative conclusion macroscopic neocortex may considered (approximately a linear near-equilibrium system premature does correspond tentative conclusions At exis
Label: Neural Networks
Paper 4  Title: Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems  
Abstract The work in progress reported Wright & Liley shows great promise primarily However their tentative conclusion macroscopic neocortex may considered (approximately a linear near-equilibrium system premature does correspond tentative conclusions At exis
Paper 5  Title: NONLINEAR NONEQUILIBRIUM NONQUANTUM NONCHAOTIC STATISTICAL MECHANICS OF NEOCORTICAL INTERACTIONS  
Abstract The work in progress reported Wright & Liley shows great promise primarily However their tentative conclusion macroscopic neocortex may considered (approximately a linear near-equilibrium system premature does correspond tentative conclusions At exis
Paper 6  Title: New Roles for Machine Learning in Design for Design of Educational Computing New roles for
Abstract Research machine learning design concentrated and techniques solve Invariably this effort, while important at the field scale up address real design problems since all existing techniques based simplifying assumptions do hold In pa
Paper 7  Title: Book Review New Kids on the Block way in the field of connectionist modeling. The
Abstract Connectionist Models is forty papers representing connectionism The book distinguished a single feature the papers almost exclusively contributions graduate students active The students selected participated a two week long summer school devoted connectionism 2.
Label: Neural Networks
Paper 8  Title: A Brief History of Connectionism  
Abstract: Connectionist research firmly within especially cognitive science This diversity, however created which makes connectionist researchers remain aware recent advances let understand the field developed This paper attempts address this p
Paper 9  Title: The New Challenge: From a Century of Statistics to an Age of Causation  
Abstract Some the main users statistical methods - economists are discovering rest not but causal foundations The blurring these foundations over follows mathematical notation capable causal from equational relationships By providing formal and natural explication
Paper 10  Title: Replicability of Neural Computing Experiments  
Abstract If an experiment requires statistical analysis establish a result one do a better experiment Ernest Rutherford 1930 Most proponents cold fusion reporting excess heat their electrolysis experiments claiming one its irreproducibility | 1993 78 Abstract Amid ever
Label: Neural Networks
Paper 11  Title: A Functional Theory of Creative Reading  
Abstract Reading an area human cognition which education researchers artificial intelligence researchers Yet there still does a theory which accurately the complete process. We believe these past attempts fell due the overall task reading; namely complete set men
Paper 12  Title: Inductive Logic Programming  
Abstract A new research area, Inductive Logic Programming presently While inheriting various positive characteristics the parent subjects Logic Programming it hoped the new area overcome its forebears The background present developments within discussed and various goals aspirations the incr
Label: Theory
Paper 13  Title: Submitted to Circuits, Systems and Signal Processing Neural Network Constructive Algorithms: Trading Generalization for Learning Efficiency?  
Abstract There constructive, or growth algorithms available training This paper and the main ones using a fundamental approach the multi-layer perceptron problem-solving mechanisms The claimed convergence properties the algorithms verified just two mapping theorems consequently enables
Paper 14  Title: Studies of Neurological Transmission Analysis using Hierarchical Bayesian Mixture Models  
Abstract Hierarchically structured mixture studied inference on neural synaptic transmission characteristics mammalian, Mixture structures arise due uncertainties governing electro-chemical stimulation individual neuro-transmitter release sites at nerve junc
Paper 15  Title: A THEORY OF LEARNING CLASSIFICATION RULES  
Abstract This chapter takes a different standpoint address learning We here reason only in probability make extensive use the chain rule known A fast definition the basics in probability is provided for Most this chapter a review Bayesian learning applied our modelling purposes
Label: Theory
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 763...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: PREENS a Parallel Research Execution Environment for Neural Systems is a distributed neurosimulator, targeted on networks of workstations and transputer systems. As current applications of neural networks often contain large amounts of data and as the neural networks involved in tasks such as vision are very large, high requirements on memory and computational resources are imposed on the target execution platforms. PREENS can be executed in a distributed environment, i.e. tools and neural network simulation programs can be running on any machine connectable via TCP/IP. Using this approach, larger tasks and more data can be examined using an efficient coarse grained parallelism. Furthermore, the design of PREENS allows for neural networks to be running on any high performance MIMD machine such as a trans-puter system. In this paper, the different features and design concepts of PREENS are discussed. These can also be used for other applications, like image processing.
Title: Title: PREENS, a Parallel Research Execution Environment for Neural Systems  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: CuPit-2: Portable and Efficient High-Level Parallel Programming of Neural Networks for the Systems Analysis Modelling
Abstract CuPit-2 a special-purpose programming language expressing dynamic neural network learning algorithms It provides most general-purpose languages ++ expressive It allows writing much clearer and more elegant programs in algorithms change the network topology dynamically (constructive algorithms pruni
Paper 3  Title: University of Nevada Reno Design Strategies for Evolutionary Robotics  
Abstract CuPit-2 a special-purpose programming language expressing dynamic neural network learning algorithms It provides most general-purpose languages ++ expressive It allows writing much clearer and more elegant programs in algorithms change the network topology dynamically (constructive algorithms pruni
Label: Genetic Algorithms
Paper 4  Title: Quicknet on MultiSpert: Fast Parallel Neural Network Training  
Abstract The MultiSpert parallel system the Spert workstation accelerator predominantly speech recognition research at ICSI In order deliver for Artificial Neural Network training without changes the user interfaces the exisiting Quicknet ANN library modified run MultiSpert In this report presen
Paper 5  Title: Connectionist Layered Object-Oriented Network Simulator (CLONES): User's Manual minimize the learning curve for using CLONES,
Abstract CLONES constructing, training utilizing layered connectionist networks The CLONES library all the object classes needed a simulator with a small amount added source code ( The size experimental ANN programs greatly an object-oriented library; at these programs easier
Paper 6  Title: A Supercomputer for Neural Computation  
Abstract The requirement train large neural networks quickly prompted the design using custom VLSI This design 128 processing nodes communicating connected directly the processor chip Studies peak performance the range 160 billion arithmetic operations This paper custom
Label: Neural Networks
Paper 7  Title: Programming Environment for a High Performance Parallel Supercomputer with Intelligent Communication  
Abstract At the Electronics Lab Techology the high performance Parallel Supercomputer MUSICMUlti processor System with Intelligent Communication beed developed As applications in neural network simulation molecular dynamics show the Electronics Lab Supercomputer absolutely on a par those el
Paper 8  Title: 17 Massively Parallel Genetic Programming  
Abstract As the field its breadth parallel implementations becomes absolutely The transputer-based system presented the chapter by Koza Andre ([11 one the rare such parallel implementations Until today no implementation proposed parallel GP using except
Paper 9  Title: Evolving Turing-Complete Programs for a Register Machine with Self-modifying Code  
Abstract The majority commercial computers register machines of von Neumann type We developed evolve Turing-complete programs a register machine The described implementation enables most program constructs arithmetic operators large indexed memory automatic decomposition into subfunctions (ADFs conditional constructs
Label: Genetic Algorithms
Paper 10  Title: Simulation of Reduced Precision Arithmetic for Digital Neural Networks Using the RAP Machine  
Abstract some our recent work computer architectures efficient execution artificial neural network algorithms Our earlier system, the Ring Array Processor based commercial DSPs with a low-latency ring interconnection scheme We used the RAP to simulate variable precision arithmetic guide us
Paper 11  Title: The Evolution of Communication Schemes Over Continuous Channels  
Abstract As the field Genetic Programming (GP) matures its breadth parallel implementations becomes absolutely The transputer-based system presented [Koza Andre 1995 one the rare such parallel implementations Until today no implementation proposed parallel GP using a SIMD architecture except
Paper 12  Title: A study of the effects of group formation on evolutionary search  
Abstract As the field Genetic Programming (GP) matures its breadth parallel implementations becomes absolutely The transputer-based system presented [Koza Andre 1995 one the rare such parallel implementations Until today no implementation proposed parallel GP using a SIMD architecture except
Paper 13  Title: A Multi-Chip Module Implementation of a Neural Network  
Abstract The requirement dense interconnect in artificial neural network systems led seek This paper an implementation using multi-chip modules the interconnect medium The specific system described self parallel dynamic learning model which requires a dense interconnect technology effective
Label: Neural Networks
Paper 14  Title: A Performance Analysis of the CNS-1 on Large, Dense Backpropagation Networks Connectionist Network Supercomputer  
Abstract determine in the sustained performance the CNS-1 during training evaluation Using a sophisticated coding, the 128-node machine achieve up to 111 Giga connections 22 connection updates During recall the machine archieve 87% multiply-accumulate perf
Paper 15  Title: Performance of the GCel-512 and PowerXPlorer for parallel neural network simulations  
Abstract work IC 3 A programme. Using the GCel-512 PowerXPlorer made the UvA a performance prediction model several neural network simulations could validated quantitatively both a larger processor grid a different target parallel processor configuration The performance prediction mo
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Neural Networks

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  True

Prediction: 1
Processing index 732...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: In this paper we study learning in the PAC model of Valiant [18] in which the example oracle used for learning may be faulty in one of two ways: either by misclassifying the example or by distorting the distribution of examples. We first consider models in which examples are misclassified. Kearns [12] recently showed that efficient learning in a new model using statistical queries is a sufficient condition for PAC learning with classification noise. We show that efficient learning with statistical queries is sufficient for learning in the PAC model with malicious error rate proportional to the required statistical query accuracy. One application of this result is a new lower bound for tolerable malicious error in learning monomials of k literals. This is the first such bound which is independent of the number of irrelevant attributes n. We also use the statistical query model to give sufficient conditions for using distribution specific algorithms on distributions outside their prescribed domains. A corollary of this result expands the class of distributions on which we can weakly learn monotone Boolean formulae. We also consider new models of learning in which examples are not chosen according to the distribution on which the learner will be tested. We examine three variations of distribution noise and give necessary and sufficient conditions for polynomial time learning with such noise. We show containments and separations between the various models of faulty oracles. Finally, we examine hypothesis boosting algorithms in the context of learning with distribution noise, and show that Schapire's result regarding the strength of weak learnabil-ity [17] is in some sense tight in requiring the weak learner to be nearly distribution free. 
Title: Title: Statistical Queries and Faulty PAC Oracles  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: On Learning from Noisy and Incomplete Examples  
Abstract investigate learnability the PAC model when used learning, attributes labels, either corrupted prove our main results define a new complexity measure on statistical query The view an SQ algorithm the maximum over all queries of input bits on We
Label: Theory
Paper 3  Title: Improved Noise-Tolerant Learning and Generalized Statistical Queries  
Abstract The statistical query learning model can viewed creating ( demonstrating the existence the PAC model The complexity a statistical query algorithm conjunction simulating SQ algorithms the PAC model with noise determine the noise-tolerant PAC algorithms produced Although rough
Paper 4  Title: General Bounds on Statistical Query Learning and PAC Learning with Noise via Hypothesis Boosting  
Abstract We derive general bounds learning the Statistical Query model in the PAC model classification noise We do so considering boosting weak learning algorithms which fall the Statistical Query model This new model Kearns [12 efficient PAC learning the presence o
Paper 5  Title: Learning Switching Concepts  
Abstract We consider learning situations the function used classify examples may switch back during We examine several models such situations oblivious models in switches independent the selection examples more adversarial models a single adversary both the c
Paper 6  Title: Simulating Access to Hidden Information while Learning  
Abstract We introduce which without access hidden information nearly We apply our technique solve Maass Turan [18 showing for any concept class F, the least number queries sufficient learning by which access only arbitrary equivalence
Paper 7  Title: 25 Learning in Hybrid Noise Environments Using Statistical Queries  
Abstract consider formal models learning noisy data Specifically focus learning in the probability approximately correct model as defined Valiant Two noise this setting classification noise malicious errors However a more realistic model combining noise We define a learning env
Paper 8  Title: Boosting a weak learning algorithm by majority To be published in Information and Computation  
Abstract: We present an algorithm improving algorithms learning binary concepts The improvement achieved combining a large number hypotheses each generated training given learning examples Our algorithm ideas presented Schapire inThe strength weak learnability represents an im
Label: Theory
Paper 9  Title: Randomly Fallible Teachers: Learning Monotone DNF with an Incomplete Membership Oracle  
Abstract We introduce algorithmic learning an equivalence oracle and an incomplete membership oracle answers a random subset the learner's membership queries may missing We demonstrate, high probability it still learn monotone DNF formulas provided the fraction missing answers boun
Label: Theory
Paper 10  Title: On the Sample Complexity of Weakly Learning  
Abstract In study the sample complexity weak learning. That we ask how much data must an unknown distribution extract a small but significant advantage prediction We show it important distinguish those learning algorithms that output deterministic hypotheses output randomized We prove in
Paper 11  Title: Weakly Learning DNF and Characterizing Statistical Query Learning Using Fourier Analysis  
Abstract We new results, both positive learning disjunctive normal form We first prove an algorithm due Kushilevitz Mansour [16 weakly learn DNF using membership queries respect the uniform distribution on This the first positive result learning unrest
Paper 12  Title: On the Complexity of Function Learning  
Abstract results computational learning theory concerned concept learning function for classes range f0; 1g. Much less learning functions with such IN or IR particular relatively few results about common models function learnin
Label: Theory
Paper 13  Title: Warning: missing six few referencesfixed in proceedings. Learning with Queries but Incomplete Information (Extended Abstract)  
Abstract investigate learning with membership queries assuming incomplete By incomplete we some the membership queries may answered I do This model the incomplete membership query model of Angluin Slonim It attempts model practical learning situations an ex
Label: Theory
Paper 14  Title: Learning in the Presence of Malicious Errors  
Abstract In study an extension the distribution-free model learning introduced Valiant [23also the probably approximately correct or PAC model allows the presence malicious errors the examples given Such errors generated an adversary access the entire history the learning al
Paper 15  Title: PAC-Learning PROLOG clauses with or without errors  
Abstract In we can describe a generic ILP problem following given a set E (positive and examples a target predicate some background B the worldusually a logic program including facts auxiliary predicates a logic program Hour hypothesis such can B H while no e
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Theory

Theory
Prediction:  Theory
Is prediction correct?  True

Prediction: 1
Processing index 837...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: When designing a (deductive) database, the designer has to decide for each predicate (or relation) whether it should be defined extensionally or intensionally, and what the definition should look like. An intelligent system is presented to assist the designer in this task. It starts from an example database in which all predicates are defined extensionally. It then tries to compact the database by transforming extensionally defined predicates into intensionally defined ones. The intelligent system employs techniques from the area of inductive logic programming. 
Title: Title: Inductive Database Design  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Applications of a logical discovery engine  
Abstract The clausal discovery engine claudien presented claudien discovers regularities data a representative As such represents data regularities by first order clausal theories Because the search space clausal theories larger attribute value representation claudien also accepts a declarati
Label: Rule Learning
Paper 3  Title: Constructing Intermediate Concepts by Decomposition of Real Functions  
Abstract In learning from examples it expand an attribute-vector representation intermediate concepts The usual advantage such structuring of the learning problem easier improves the comprehensibility induced descriptions In develop discovering useful intermediate concepts when both class at
Paper 4  Title: FONN: Combining First Order Logic with Connectionist Learning  
Abstract a neural network architecture manage structured data refine knowledge bases expressed a first order logic language The presented framework well classification problems concept de scriptions depend numerical features In fact the main goal the neural architecture that refining the numerical part the k
Paper 5  Title: Inductive Constraint Logic and the Mutagenesis Problem  
Abstract learning first order logic formulae positive and negative examples incorporated a system named ICL In ICL examples viewed interpretations which true for the target theory present inductive logic programming systems true and false ground facts ( clauses Furthermore ICL uses a c
Paper 6  Title: Computation and Psychophysics of Sensorimotor Integration  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 7  Title: Rule Generation and Compaction in the wwtp  
Abstract learning classification rules We sketch two modules namely LINNEO + and GAR LINNEO +, which a knowledge acquisition tool ill-structured domains automatically generating classes examples incrementally works LINNEO + 's output a representation the conceptual st
Paper 8  Title: Multi-Strategy Learning and Theory Revision  
Abstract the system WHY, learns updates a diagnostic knowledge base using domain knowledge a set examples The a-priori knowledge consists a causal model the domain stating basic phenomena a body describing the links abstract concepts their possible manifestations The phe
Paper 9  Title: Rule Based Database Integration in HIPED Heterogeneous Intelligent Processing in Engineering Design  
Abstract 1 we one aspect our research the project called HIPED addressed performing design engineering devices accessing heterogeneous databases The front end the HIPED system consisted interactive KRI-TIK a multimodal reasoning system combined case based model This paper focuses o
Paper 10  Title: Learning by Refining Algorithm Sketches  
Abstract In suggest improves significantly a top-down inductive logic programming (ILP) learning system This improvement achieved at giving to extra information difficult formulate This information appears the form an algorithm sketch: an incomplete and somewhat vague representation the computati
Paper 11  Title: Bottom-up induction of logic programs with more than one recursive clause  
Abstract In a bottom-up algorithm called MRI induce logic programs from their examples This method induce programs with a base clause from examples MRI based saturations examples It first generates a path structure a stream processed predicates
Label: Rule Learning
Paper 12  Title: Learning Concepts from Sensor Data of a Mobile Robot  
Abstract Machine learning the flexibility robot applications Many approaches applying robotics known Some approaches enhance the planning capabilities. Other approaches enhance the control basic actions. In contrast the approach presented thi
Paper 13  Title: Inductive Constraint Logic  
Abstract learning first order logic Whereas present inductive logic programming systems employ examples as true and false ground facts clauses view examples interpretations which for the target theory This viewpoint allows to reconcile the inductive logic programming paradigm classic
Paper 14  Title: Learning Singly-Recursive Relations from Small Datasets  
Abstract The inductive logic programming system LOPSTER the advantage basing induction logical implication -subsumption LOPSTER's sub-unification procedures allow induce recursive relations using examples whereas inductive logic programming algorithms based -subsumption require solve induction tasks
Paper 15  Title: A New Approach for Induction: From a Non-Axiomatic Logical Point of View  
Abstract: Non-Axiomatic Reasoning System designed adaptive works under insufficient knowledge resources This paper focuses the components NARS that contribute the system's induction capacity shows the traditional problems in addressed the system The NARS approach of induction uses
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Rule Learning

Rule Learning
Prediction:  Rule Learning
Is prediction correct?  True

Prediction: 1
Processing index 103...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Reinforcement learning (RL) is a model-free tuning and adaptation method for control of dynamic systems. Contrary to supervised learning, based usually on gradient descent techniques, RL does not require any model or sensitivity function of the process. Hence, RL can be applied to systems that are poorly understood, uncertain, nonlinear or for other reasons untractable with conventional methods. In reinforcement learning, the overall controller performance is evaluated by a scalar measure, called reinforcement. Depending on the type of the control task, reinforcement may represent an evaluation of the most recent control action or, more often, of an entire sequence of past control moves. In the latter case, the RL system learns how to predict the outcome of each individual control action. This prediction is then used to adjust the parameters of the controller. The mathematical background of RL is closely related to optimal control and dynamic programming. This paper gives a comprehensive overview of the RL methods and presents an application to the attitude control of a satellite. Some well known applications from the literature are reviewed as well. 
Title: Title: NEUROCONTROL BY REINFORCEMENT LEARNING  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: Modeling the Student with Reinforcement Learning  
Abstract We describe a methodology enabling an intelligent teaching system make high level strategy decisions on low level student modeling information This framework less costly construct superior hand coding teaching strategies as responsive In order accomplish reinforcement learning associate sup
Paper 3  Title: AVERAGED REWARD REINFORCEMENT LEARNING APPLIED TO FUZZY RULE TUNING  
Abstract Fuzzy rules control can effectively tuned Reinforcement learning only information the control application The tuning process allows people generate fuzzy rules unable accurately perform control have them tuned rules provide smooth control This paper
Paper 4  Title: INCREMENTAL POLYNOMIAL CONTROLLER NETWORKS: two self-organising non-linear controllers  
Abstract Temporal difference (TD) methods constitute learning predictions multi-step prediction problems parameterized a recency factor. Currently the most important application these methods temporal credit assignment reinforcement learning Well known reinforcement learning algorithms AHC Q-learning may viewed instances TD learnin
Label: Neural Networks
Paper 5  Title: Automatic Generation of Adaptive Programs Automatic Generation of Adaptive Programs. In From Animals to Animats
Abstract Fuzzy rules control can effectively tuned Reinforcement learning only information the control application The tuning process allows people generate fuzzy rules unable accurately perform control have them tuned rules provide smooth control This paper
Paper 6  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract In Operation Research and Artificial Intelligence several stochastic search algorithms designed based global random searchZhigljavsky Basically those techniques iteratively sample the search space with respect a probability distribution which updated according previous samples some predefined strategy Genetic
Paper 7  Title: Toward Learning Systems That Integrate Different Strategies and Representations TR93-22  
Abstract Temporal difference (TD) methods constitute learning predictions multi-step prediction problems parameterized a recency factor. Currently the most important application these methods temporal credit assignment reinforcement learning Well known reinforcement learning algorithms AHC Q-learning may viewed instances TD learnin
Paper 8  Title: Category: Control, Navigation and Planning Preference: Oral presentation Exploiting Model Uncertainty Estimates for Safe Dynamic
Abstract Model learning combined dynamic programming control continuous state dynamic systems The simplest method assumes the learned model applies dynamic programming many approximators provide uncertainty estimates on the fit How they exploited This paper addresses where the system must prevented
Paper 9  Title: Learning Controllers for Industrial Robots  
Abstract One the most significant cost factors robotics applications the design real-time robot control software Control theory helps when linear controllers have developed, sufficiently support the generation although in ( compliance control nonlinear control essential achieving high perfor
Label: Neural Networks
Paper 10  Title: On the Computational Economics of Reinforcement Learning  
Abstract: Following terminology adaptive control distinguish indirect learning methods learn explicit models the dynamic structure to be controlled do We compare an existing indirect method, a conventional dynamic programming algorithm a closely related direct reinforcement learning method by appl
Paper 11  Title: Pointer Adaptation and Pruning of Min-Max Fuzzy Inference and Estimation  
Abstract a partial-memory incremental learning method based the AQ15c inductive learning system The method maintains a representative set past training examples used together new examples appropriately modify the currently held hypotheses Incremental learning evoked feedback or Such a method useful appli
Paper 12  Title: EXPERIMENTING WITH THE CHEESEMAN-STUTZ EVIDENCE APPROXIMATION FOR PREDICTIVE MODELING AND DATA MINING  
Abstract The work discussed motivated of building decision support systems Our goal use these systems supporting Bayes optimal decision making where the action maximizing the expected utility, with respect predicted probabilities should selected For the models need
Paper 13  Title: Evolving Networks: Using the Genetic Algorithm with Connectionist Learning  
Abstract is described on The limit cycle the attitude control of a satellite selected One the sources the limit cycle a position dependent error the observed attitude A Reinforcement Learning method selected, able adapt a controller such a cost function optimised An
Label: Genetic Algorithms
Paper 14  Title: A Method for Partial-Memory Incremental Learning and its Application to Computer Intrusion Detection Machine Learning
Abstract a partial-memory incremental learning method based the AQ15c inductive learning system The method maintains a representative set past training examples used together new examples appropriately modify the currently held hypotheses Incremental learning evoked feedback or Such a method useful appli
Paper 15  Title: Optimal Attitude Control of Satellites by Artificial Neural Networks: a Pilot Study  
Abstract is described on The limit cycle the attitude control of a satellite selected One the sources the limit cycle a position dependent error the observed attitude A Reinforcement Learning method selected, able adapt a controller such a cost function optimised An
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Reinforcement Learning

Neural Networks
Prediction:  Neural Networks
Is prediction correct?  False

Prediction: 0
Processing index 1257...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: Holland's Schema Theorem is widely taken to be the foundation for explanations of the power of genetic algorithms (GAs). Yet some dissent has been expressed as to its implications. Here, dissenting arguments are reviewed and elaborated upon, explaining why the Schema Theorem has no implications for how well a GA is performing. Interpretations of the Schema Theorem have implicitly assumed that a correlation exists between parent and offspring fitnesses, and this assumption is made explicit in results based on Price's Covariance and Selection Theorem. Schemata do not play a part in the performance theorems derived for representations and operators in general. However, schemata re-emerge when recombination operators are used. Using Geiringer's recombination distribution representation of recombination operators, a "missing" schema theorem is derived which makes explicit the intuition for when a GA should perform well. Finally, the method of "adaptive landscape" analysis is examined and counterexamples offered to the commonly used correlation statistic. Instead, an alternative statistic | the transmission function in the fitness domain | is proposed as the optimal statistic for estimating GA performance from limited samples.
Title: Title: The Schema Theorem and Price's Theorem  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: The Troubling Aspects of a Building Block Hypothesis for Genetic Programming  
Abstract In carefully formulate a Schema Theorem Genetic ProgrammingGP a schema definition accounts the variable length and GP's representation In a manner early GA research use interpretations our GP Schema Theorem obtain a GP Building Block definition and state
Paper 3  Title: The Role of Development in Genetic Algorithms  
Abstract Technical Report Number CS94394 Computer Science Abstract The developmental mechanisms transforming to typically omitted formulationsGAs these two representational spaces identical We argue developmental mechanisms useful understanding the success seve
Paper 4  Title: Submitted to Circuits, Systems and Signal Processing Neural Network Constructive Algorithms: Trading Generalization for Learning Efficiency?  
Abstract There constructive, or growth algorithms available training This paper and the main ones using a fundamental approach the multi-layer perceptron problem-solving mechanisms The claimed convergence properties the algorithms verified just two mapping theorems consequently enables
Paper 5  Title: Effects of Occam's Razor in Evolving Sigma-Pi Neural Nets  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Label: Genetic Algorithms
Paper 6  Title: MLC Tutorial A Machine Learning library of C classes.  
Abstract Several evolutionary algorithms make hierarchical representations variable size rather linear strings Variable complexity the structures provides an additional representational power widen evolutionary algorithms The price, however that the search space open- solutions grow arbitrarily
Paper 7  Title: A Sampling-Based Heuristic for Tree Search Applied to Grammar Induction  
Abstract In Operation Research and Artificial Intelligence several stochastic search algorithms designed based global random searchZhigljavsky Basically those techniques iteratively sample the search space with respect a probability distribution which updated according previous samples some predefined strategy Genetic
Paper 8  Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Abstract Holland's analysis the sources power of genetic algorithms served guidance the applications The technique applying a recombination operatorcrossover a population individuals a key that power Neverless there contradictory results concerning crossover operators with respect overall p
Label: Genetic Algorithms
Paper 9  Title: DISTRIBUTED GENETIC ALGORITHMS FOR PARTITIONING UNIFORM GRIDS  
Abstract The fault hierarchy representation widely expert systems complex mechanical devices On the assumption an appropriate bias a knowledge representation language also learning in a theory revision method operates directly a fault hierarchy This task presents several challenges: A typi
Paper 10  Title: Facing The Facts: Necessary Requirements For The Artificial Evolution of Complex Behaviour  
Abstract sets the open-ended artificial evolution complex behaviour autonomous agents If recurrent dynamical neural networksor similar phenotypes a Genetic that employs variable length genotypes, Inman Harvey's SAGA capable evolving arbitrary levels be-havioural complexity Furthermore with simple r
Paper 11  Title: Soft Vector Quantization and the EM Algorithm Running Title: Soft Vector Quantization and EM Section:
Abstract demonstrates graphs expressing independenices, as a formal language communicating and processing causal information statistical analysis We show how complex information external interventions organized represented graphically, the graphical representation facilitate quantitati
Paper 12  Title: A New Look at Tree Models for Multiple Sequence Alignment  
Abstract Evolutionary trees frequently the underlying model in the design algorithms optimization criteria software packages multiple sequence alignment In this paper reexamine the suitability trees a universal model MSA in light biological questions's are used A tree model consists a tree topology a mo
Paper 13  Title: The Royal Road for Genetic Algorithms: Fitness Landscapes and GA Performance  
Abstract Genetic algorithms ( play many artificial-life systems often little detailed understanding why the GA performs as it little theoretical basis on characterize the types fitness landscapes lead successful GA performance In this paper addressing these issues Our strategy consists defining
Paper 14  Title: ASPECTS OF GRAPHICAL MODELS CONNECTED WITH CAUSALITY  
Abstract demonstrates graphs expressing independenices, as a formal language communicating and processing causal information statistical analysis We show how complex information external interventions organized represented graphically, the graphical representation facilitate quantitati
Label: Probabilistic Methods
Paper 15  Title: Induction of decision trees using RELIEFF  
Abstract An investigation the dynamics Genetic Programming applied chaotic time series prediction reported An interesting characteristic adaptive search techniques perform well many problem domains while failing Because Genetic Programming's flexible tree structure any particular problem represented myriad forms These representati
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Genetic Algorithms

Genetic Algorithms
Prediction:  Genetic Algorithms
Is prediction correct?  True

Prediction: 1
Processing index 1147...
Please predict the most appropriate category for the paper. Choose from the following categories:

Rule Learning
Neural Networks
Case Based
Genetic Algorithms
Theory
Reinforcement Learning
Probabilistic Methods

Abstract: Abstract: We propose a methodology for Bayesian model determination in decomposable graphical Gaussian models. To achieve this aim we consider a hyper inverse Wishart prior distribution on the concentration matrix for each given graph. To ensure compatibility across models, such prior distributions are obtained by marginalisation from the prior conditional on the complete graph. We explore alternative structures for the hyperparameters of the latter, and their consequences for the model. Model determination is carried out by implementing a reversible jump MCMC sampler. In particular, the dimension-changing move we propose involves adding or dropping an edge from the graph. We characterise the set of moves which preserve the decomposability of the graph, giving a fast algorithm for maintaining the junction tree representation of the graph at each sweep. As state variable, we propose to use the incomplete variance-covariance matrix, containing only the elements for which the corresponding element of the inverse is nonzero. This allows all computations to be performed locally, at the clique level, which is a clear advantage for the analysis of large and complex data-sets. Finally, the statistical and computational performance of the procedure is illustrated by means of both artificial and real multidimensional data-sets. 
Title: Title: Decomposable graphical Gaussian model determination  
The following are related papers to this paper, please consider the content of these papers and making a judgment.
Paper 2  Title: On MCMC Sampling in Hierarchical Longitudinal Models  SUMMARY  
Abstract Bayesian practice In their simplest form ( when parameters updated one, however often slow converge when applied high-dimensional statistical models A remedy block the parameters into groups updated simultaneously using either a Gibbs Metropolis-H
Paper 3  Title: Reparameterisation Issues in Mixture Modelling and their bearing on MCMC algorithms  
Abstract There need efficient estimation mixture distributions following these as modelling tools many applied fields We propose in a Bayesian noninformative approach normal mixtures which relies a reparameterisation the secondary components in divergence from the main c
Paper 4  Title: On Bayesian analysis of mixtures with an unknown number of components  Summary  
Abstract New methodology fully Bayesian mixture analysis developed making reversible jump Markov chain Monte Carlo methods that capable jumping between the parameter subspaces corresponding different numbers components A sample from the full joint distribution all unknown variables thereby generated this can a thorough
Paper 5  Title: Empirical Entropy Manipulation for Real-World Problems  
Abstract No finite sample, and a signal directly Some assumption either the functional form the density about necessary Both amount a prior over the space possible density functions By far assume the density has By contrast we derive a diff
Paper 6  Title: FROM METROPOLIS TO DIFFUSIONS: GIBBS STATES AND OPTIMAL SCALING  
Abstract the behaviour the random walk Metropolis algorithm high dimensional problems Here concentrate the components the target density is a spatially homogeneous Gibbs distribution finite range The performance the algorithm strongly linked phase transition for the Gibbs distribution; the convergence
Paper 7  Title: Wavelet Thresholding via a Bayesian Approach  
Abstract We discuss a Bayesian formalism gives wavelet threshold estimation A prior distribution imposed the wavelet coefficients the unknown response function designed capture common most applications For prior specified, the posterior median yields a thresholding procedure Our prior m
Label: Probabilistic Methods
Paper 8  Title: Bayesian Regression Filters and the Issue of Priors  
Abstract regression problems covers areas which dealt function approximation An online learning algorithm derived which solves regression problems a Kalman filter Its solution always improves increasing model complexity without the infinite dimension limit it approaches the true Bayesian po
Paper 9  Title: Convergence controls for MCMC algorithms, with applications to hidden Markov chains  
Abstract In complex models like hidden Markov chains the convergence the MCMC algorithms used approximate and the Bayes estimates interest must controlled We propose in on controls, rely classical non-parametric tests independence the start-up distribution stabilit
Paper 10  Title: Mixtures of Probabilistic Principal Component Analysers  
Abstract Principal component analysis one processing, compressing visualising, although its effectiveness its global linearity While nonlinear variants PCA proposed an alternative paradigm capture data complexity a combination local linear PCA projections. However conventional PCA does correspond
Paper 11  Title: Parallel Markov chain Monte Carlo sampling.  
Abstract Markov samplers proved remarkably popular as tools Bayesian computation However problems can their application the density interest dimensional strongly In these circumstances the sampler may slow traverse the state space mixing poor In offer a partial solution The
Label: Probabilistic Methods
Paper 12  Title: FILTERING VIA SIMULATION: AUXILIARY PARTICLE FILTERS  
Abstract analyses the recently suggested particle approach filtering time series We suggest the algorithm robust outliers for the design the simulators the discrete support to represent the sequentially updating prior distribution Both problems tackled We believe we largely and redu
Label: Probabilistic Methods
Paper 13  Title: Stochastic Complexity Based Estimation of Missing Elements in Questionnaire Data  
Abstract In study a new informationtheoretically justified approach missing data estimation The approach discussed a model-based imputation procedure relative a model class for the probability distribution the complete data matrix in the set multinomial models some independence assum
Paper 14  Title: Constructing Bayesian finite mixture models by the EM algorithm  
Abstract: Email: Firstname.HelsinkiFI Report C-19969, University Department Abstract In finite mixture models building decision support systems capable sound probabilistic inference Finite mixture models have many appealing properties in prediction (reasoning phase the
Paper 15  Title: A Hierarchical Latent Variable Model for Data Visualization  
Abstract Visualization has proven the analysis multi-variate data Most visualization algorithms aim find a projection from the data space down However for complex data sets living it unlikely a single two-dimensional projection reveal
Do not give any reasoning or logic for your answer.
Answer: 



Ideal_answer: Probabilistic Methods

Probabilistic Methods
Prediction:  Probabilistic Methods
Is prediction correct?  True

Prediction: 1
Accuracy: 0.71
Wrong indexes: [1759, 474, 1217, 2470, 955, 1528, 2641, 1152, 1020, 975, 954, 1853, 2591, 2652, 959, 616, 1390, 1519, 469, 2686, 417, 1827, 1534, 487, 1680, 2534, 540, 537, 103]
Wrong list: [2, 5, 15, 16, 31, 32, 34, 42, 43, 44, 47, 50, 51, 54, 55, 56, 58, 59, 62, 63, 64, 67, 68, 70, 75, 86, 89, 90, 97]
Wrong indexes length: 29
